From 2e2c77fccb12ec840ab08d2c07a3c2f654ae1f77 Mon Sep 17 00:00:00 2001
From: Robert Nelson <robertcnelson@gmail.com>
Date: Tue, 24 Aug 2021 21:18:44 -0500
Subject: [PATCH] backports: cpsw: from: linux.git

Reference: v5.10.60
Signed-off-by: Robert Nelson <robertcnelson@gmail.com>
---
 drivers/net/ethernet/ti/Kconfig               |   50 -
 drivers/net/ethernet/ti/Makefile              |   14 +-
 drivers/net/ethernet/ti/am65-cpsw-ethtool.c   |  121 +-
 drivers/net/ethernet/ti/am65-cpsw-nuss.c      | 1093 +-----
 drivers/net/ethernet/ti/am65-cpsw-nuss.h      |   51 -
 drivers/net/ethernet/ti/am65-cpsw-qos.c       |  863 +----
 drivers/net/ethernet/ti/am65-cpsw-qos.h       |   48 +-
 drivers/net/ethernet/ti/am65-cpsw-switchdev.c |  552 ---
 drivers/net/ethernet/ti/am65-cpsw-switchdev.h |   34 -
 drivers/net/ethernet/ti/am65-cpts.c           |  141 +-
 drivers/net/ethernet/ti/am65-debugfs.c        |  152 -
 drivers/net/ethernet/ti/cpsw.c                |   48 +-
 drivers/net/ethernet/ti/cpsw_ale.c            |  114 +-
 drivers/net/ethernet/ti/cpsw_ale.h            |    3 -
 drivers/net/ethernet/ti/cpsw_new.c            |   20 +-
 drivers/net/ethernet/ti/cpsw_priv.c           |   27 +-
 drivers/net/ethernet/ti/cpsw_priv.h           |   18 +-
 drivers/net/ethernet/ti/cpsw_switch_ioctl.c   |  271 --
 drivers/net/ethernet/ti/cpsw_switchdev.c      |    2 +-
 drivers/net/ethernet/ti/davinci_mdio.c        |   18 +-
 drivers/net/ethernet/ti/icss_iep.c            | 1164 ------
 drivers/net/ethernet/ti/icss_iep.h            |   40 -
 drivers/net/ethernet/ti/icss_lre_firmware.h   |  136 -
 drivers/net/ethernet/ti/icss_mii_rt.h         |  215 --
 drivers/net/ethernet/ti/icss_switch.h         |  336 --
 .../ethernet/ti/icss_vlan_mcast_filter_mmap.h |  100 -
 drivers/net/ethernet/ti/icssg_classifier.c    |  463 ---
 drivers/net/ethernet/ti/icssg_config.c        |  439 ---
 drivers/net/ethernet/ti/icssg_config.h        |  211 --
 drivers/net/ethernet/ti/icssg_ethtool.c       |  356 --
 drivers/net/ethernet/ti/icssg_prueth.c        | 2729 --------------
 drivers/net/ethernet/ti/icssg_prueth.h        |  287 --
 drivers/net/ethernet/ti/icssg_queues.c        |   50 -
 drivers/net/ethernet/ti/icssg_switch_map.h    |  169 -
 drivers/net/ethernet/ti/j721e-cpsw-virt-mac.c | 1499 --------
 drivers/net/ethernet/ti/netcp_core.c          |    4 +-
 drivers/net/ethernet/ti/prueth.h              |  487 ---
 drivers/net/ethernet/ti/prueth_core.c         | 3350 -----------------
 drivers/net/ethernet/ti/prueth_fdb_tbl.h      |   67 -
 drivers/net/ethernet/ti/prueth_lre.c          | 1299 -------
 drivers/net/ethernet/ti/prueth_lre.h          |  200 -
 drivers/net/ethernet/ti/prueth_ptp.h          |   85 -
 drivers/net/ethernet/ti/prueth_qos.c          |  214 --
 drivers/net/ethernet/ti/prueth_switch.c       | 1341 -------
 drivers/net/ethernet/ti/prueth_switch.h       |   58 -
 drivers/net/ethernet/ti/tlan.c                |    3 +-
 46 files changed, 286 insertions(+), 18656 deletions(-)
 delete mode 100644 drivers/net/ethernet/ti/am65-cpsw-switchdev.c
 delete mode 100644 drivers/net/ethernet/ti/am65-cpsw-switchdev.h
 delete mode 100644 drivers/net/ethernet/ti/am65-debugfs.c
 delete mode 100644 drivers/net/ethernet/ti/cpsw_switch_ioctl.c
 delete mode 100644 drivers/net/ethernet/ti/icss_iep.c
 delete mode 100644 drivers/net/ethernet/ti/icss_iep.h
 delete mode 100644 drivers/net/ethernet/ti/icss_lre_firmware.h
 delete mode 100644 drivers/net/ethernet/ti/icss_mii_rt.h
 delete mode 100644 drivers/net/ethernet/ti/icss_switch.h
 delete mode 100644 drivers/net/ethernet/ti/icss_vlan_mcast_filter_mmap.h
 delete mode 100644 drivers/net/ethernet/ti/icssg_classifier.c
 delete mode 100644 drivers/net/ethernet/ti/icssg_config.c
 delete mode 100644 drivers/net/ethernet/ti/icssg_config.h
 delete mode 100644 drivers/net/ethernet/ti/icssg_ethtool.c
 delete mode 100644 drivers/net/ethernet/ti/icssg_prueth.c
 delete mode 100644 drivers/net/ethernet/ti/icssg_prueth.h
 delete mode 100644 drivers/net/ethernet/ti/icssg_queues.c
 delete mode 100644 drivers/net/ethernet/ti/icssg_switch_map.h
 delete mode 100644 drivers/net/ethernet/ti/j721e-cpsw-virt-mac.c
 delete mode 100644 drivers/net/ethernet/ti/prueth.h
 delete mode 100644 drivers/net/ethernet/ti/prueth_core.c
 delete mode 100644 drivers/net/ethernet/ti/prueth_fdb_tbl.h
 delete mode 100644 drivers/net/ethernet/ti/prueth_lre.c
 delete mode 100644 drivers/net/ethernet/ti/prueth_lre.h
 delete mode 100644 drivers/net/ethernet/ti/prueth_ptp.h
 delete mode 100644 drivers/net/ethernet/ti/prueth_qos.c
 delete mode 100644 drivers/net/ethernet/ti/prueth_switch.c
 delete mode 100644 drivers/net/ethernet/ti/prueth_switch.h

diff --git a/drivers/net/ethernet/ti/Kconfig b/drivers/net/ethernet/ti/Kconfig
index 09f449cc82f0..abfc4c435d59 100644
--- a/drivers/net/ethernet/ti/Kconfig
+++ b/drivers/net/ethernet/ti/Kconfig
@@ -92,7 +92,6 @@ config TI_CPTS
 config TI_K3_AM65_CPSW_NUSS
 	tristate "TI K3 AM654x/J721E CPSW Ethernet driver"
 	depends on ARCH_K3 && OF && TI_K3_UDMA_GLUE_LAYER
-	select NET_DEVLINK
 	select TI_DAVINCI_MDIO
 	imply PHY_TI_GMII_SEL
 	depends on TI_K3_AM65_CPTS || !TI_K3_AM65_CPTS
@@ -106,15 +105,6 @@ config TI_K3_AM65_CPSW_NUSS
 	  To compile this driver as a module, choose M here: the module
 	  will be called ti-am65-cpsw-nuss.
 
-config TI_K3_AM65_CPSW_SWITCHDEV
-	bool "TI K3 AM654x/J721E CPSW Switch mode support"
-	depends on TI_K3_AM65_CPSW_NUSS
-	depends on NET_SWITCHDEV
-	help
-	 This enables switchdev support for TI K3 CPSWxG Ethernet
-	 Switch. Enable this driver to support hardware switch support for AM65
-	 CPSW NUSS driver.
-
 config TI_K3_AM65_CPTS
 	tristate "TI K3 AM65x CPTS"
 	depends on ARCH_K3 && OF
@@ -181,44 +171,4 @@ config CPMAC
 	help
 	  TI AR7 CPMAC Ethernet support
 
-config TI_RDEV_ETH_SWITCH_VIRT_EMAC
-	tristate "TI Virtual Eth MAC driver"
-	depends on ARCH_K3 && OF && TI_K3_UDMA_GLUE_LAYER
-	help
-	  Support for 1 Port Virtual Eth MAC driver over remotedev
-	  R5F Eth Switch FW RPMSG protocol.
-	  This is available starting with the J721E platform.
-
-config TI_PRUETH
-	tristate "TI PRU Ethernet EMAC driver"
-	depends on PRU_REMOTEPROC
-	depends on NET_SWITCHDEV
-	select TI_ICSS_IEP
-	imply PTP_1588_CLOCK
-	help
-	  Some TI SoCs has Programmable Realtime Units (PRUs) cores which can
-	  support Single or Dual Ethernet ports with help of firmware code running
-	  on PRU cores. This driver supports remoteproc based communication to
-	  PRU firmware to expose ethernet interface to Linux.
-
-config TI_ICSS_IEP
-	tristate "TI PRU ICSS IEP driver"
-	depends on TI_PRUSS
-	default TI_PRUSS
-	help
-	  This enables support for the PRU-ICSS Industrial Ethernet Peripheral
-	  within a PRU-ICSS subsystem present on various TI SoCs.
-
-config TI_ICSSG_PRUETH
-	tristate "TI Gigabit PRU Ethernet driver"
-	select TI_DAVINCI_MDIO
-	select NET_PTP_CLASSIFY
-	select TI_ICSS_IEP
-	imply PTP_1588_CLOCK
-	depends on PRU_REMOTEPROC
-	depends on ARCH_K3 && OF && TI_K3_UDMA_GLUE_LAYER
-	help
-	  Support dual Gigabit Ethernet ports over the ICSSG PRU Subsystem
-	  This subsystem is available starting with the AM65 platform.
-
 endif # NET_VENDOR_TI
diff --git a/drivers/net/ethernet/ti/Makefile b/drivers/net/ethernet/ti/Makefile
index 1af790ea4dcd..6e779292545d 100644
--- a/drivers/net/ethernet/ti/Makefile
+++ b/drivers/net/ethernet/ti/Makefile
@@ -25,17 +25,5 @@ obj-$(CONFIG_TI_KEYSTONE_NETCP_ETHSS) += keystone_netcp_ethss.o
 keystone_netcp_ethss-y := netcp_ethss.o netcp_sgmii.o netcp_xgbepcsr.o cpsw_ale.o
 
 obj-$(CONFIG_TI_K3_AM65_CPSW_NUSS) += ti-am65-cpsw-nuss.o
-ti-am65-cpsw-nuss-y := am65-cpsw-nuss.o cpsw_sl.o am65-cpsw-ethtool.o cpsw_ale.o k3-cppi-desc-pool.o am65-cpsw-qos.o am65-debugfs.o
-ti-am65-cpsw-nuss-$(CONFIG_TI_K3_AM65_CPSW_SWITCHDEV) += am65-cpsw-switchdev.o
+ti-am65-cpsw-nuss-y := am65-cpsw-nuss.o cpsw_sl.o am65-cpsw-ethtool.o cpsw_ale.o k3-cppi-desc-pool.o am65-cpsw-qos.o
 obj-$(CONFIG_TI_K3_AM65_CPTS) += am65-cpts.o
-
-
-obj-$(CONFIG_TI_RDEV_ETH_SWITCH_VIRT_EMAC) += ti-j721e-cpsw-virt-mac.o
-ti-j721e-cpsw-virt-mac-y := j721e-cpsw-virt-mac.o k3-cppi-desc-pool.o
-
-obj-$(CONFIG_TI_PRUETH) += prueth.o
-prueth-y := prueth_core.o prueth_qos.o prueth_switch.o prueth_lre.o
-obj-$(CONFIG_TI_ICSS_IEP) += icss_iep.o
-
-obj-$(CONFIG_TI_ICSSG_PRUETH) += icssg-prueth.o
-icssg-prueth-y := icssg_prueth.o icssg_classifier.o icssg_ethtool.o icssg_queues.o icssg_config.o k3-cppi-desc-pool.o
diff --git a/drivers/net/ethernet/ti/am65-cpsw-ethtool.c b/drivers/net/ethernet/ti/am65-cpsw-ethtool.c
index 4bb2ed21e3af..6e4d4f9e32e0 100644
--- a/drivers/net/ethernet/ti/am65-cpsw-ethtool.c
+++ b/drivers/net/ethernet/ti/am65-cpsw-ethtool.c
@@ -372,15 +372,7 @@ static const struct am65_cpsw_ethtool_stat am65_slave_stats[] = {
 /* Ethtool priv_flags */
 static const char am65_cpsw_ethtool_priv_flags[][ETH_GSTRING_LEN] = {
 #define	AM65_CPSW_PRIV_P0_RX_PTYPE_RROBIN	BIT(0)
-/* common flags */
 	"p0-rx-ptype-rrobin",
-/* port specific flags */
-#define AM65_CPSW_PRIV_IET_FRAME_PREEMPTION	BIT(1)
-	"iet-frame-preemption",
-#define AM65_CPSW_PRIV_IET_MAC_VERIFY		BIT(2)
-	"iet-mac-verify",
-#define AM65_CPSW_PRIV_CUT_THRU			BIT(3)
-	"cut-thru",
 };
 
 static int am65_cpsw_ethtool_op_begin(struct net_device *ndev)
@@ -729,19 +721,10 @@ static int am65_cpsw_get_ethtool_ts_info(struct net_device *ndev,
 static u32 am65_cpsw_get_ethtool_priv_flags(struct net_device *ndev)
 {
 	struct am65_cpsw_common *common = am65_ndev_to_common(ndev);
-	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
-	struct am65_cpsw_iet *iet = &port->qos.iet;
 	u32 priv_flags = 0;
 
 	if (common->pf_p0_rx_ptype_rrobin)
 		priv_flags |= AM65_CPSW_PRIV_P0_RX_PTYPE_RROBIN;
-	/* Port specific flags */
-	if (iet->fpe_configured)
-		priv_flags |= AM65_CPSW_PRIV_IET_FRAME_PREEMPTION;
-	if (iet->mac_verify_configured)
-		priv_flags |= AM65_CPSW_PRIV_IET_MAC_VERIFY;
-	if (port->qos.cut_thru.enable)
-		priv_flags |= AM65_CPSW_PRIV_CUT_THRU;
 
 	return priv_flags;
 }
@@ -749,115 +732,20 @@ static u32 am65_cpsw_get_ethtool_priv_flags(struct net_device *ndev)
 static int am65_cpsw_set_ethtool_priv_flags(struct net_device *ndev, u32 flags)
 {
 	struct am65_cpsw_common *common = am65_ndev_to_common(ndev);
-	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
-	struct am65_cpsw_iet *iet = &port->qos.iet;
-	int rrobin, iet_fpe, mac_verify, cut_thru;
+	int rrobin;
 
 	rrobin = !!(flags & AM65_CPSW_PRIV_P0_RX_PTYPE_RROBIN);
-	iet_fpe = !!(flags & AM65_CPSW_PRIV_IET_FRAME_PREEMPTION);
-	mac_verify = !!(flags & AM65_CPSW_PRIV_IET_MAC_VERIFY);
-	cut_thru =  !!(flags & AM65_CPSW_PRIV_CUT_THRU);
 
 	if (common->usage_count)
 		return -EBUSY;
 
-	if ((common->est_enabled || common->iet_enabled || iet_fpe) && rrobin) {
+	if (common->est_enabled && rrobin) {
 		netdev_err(ndev,
 			   "p0-rx-ptype-rrobin flag conflicts with QOS\n");
 		return -EINVAL;
 	}
 
-	if (common->tx_ch_num < 2 && iet_fpe) {
-		netdev_err(ndev, "IET fpe needs at least 2 h/w queues\n");
-		return -EINVAL;
-	}
-
-	if (mac_verify && (!iet->fpe_configured && !iet_fpe)) {
-		netdev_err(ndev, "Enable IET FPE for IET MAC verify\n");
-		return -EINVAL;
-	}
-
-	if (cut_thru && !(common->pdata.quirks & AM64_CPSW_QUIRK_CUT_THRU)) {
-		netdev_err(ndev, "Cut-Thru not supported\n");
-		return -EOPNOTSUPP;
-	}
-
-	if (cut_thru && common->is_emac_mode) {
-		netdev_err(ndev, "Enable switch mode for cut-thru\n");
-		return -EINVAL;
-	}
-
 	common->pf_p0_rx_ptype_rrobin = rrobin;
-	iet->fpe_configured = iet_fpe;
-	iet->mac_verify_configured = mac_verify;
-	port->qos.cut_thru.enable = cut_thru;
-
-	return 0;
-}
-
-static int am65_cpsw_get_coalesce(struct net_device *ndev, struct ethtool_coalesce *coal)
-{
-	struct am65_cpsw_common *common = am65_ndev_to_common(ndev);
-	struct am65_cpsw_tx_chn *tx_chn;
-
-	tx_chn = &common->tx_chns[0];
-
-	coal->rx_coalesce_usecs = common->rx_pace_timeout / 1000;
-	coal->tx_coalesce_usecs = tx_chn->tx_pace_timeout / 1000;
-
-	return 0;
-}
-
-static int am65_cpsw_get_per_queue_coalesce(struct net_device *ndev, u32 queue,
-					    struct ethtool_coalesce *coal)
-{
-	struct am65_cpsw_common *common = am65_ndev_to_common(ndev);
-	struct am65_cpsw_tx_chn *tx_chn;
-
-	if (queue >= AM65_CPSW_MAX_TX_QUEUES)
-		return -EINVAL;
-
-	tx_chn = &common->tx_chns[queue];
-
-	coal->tx_coalesce_usecs = tx_chn->tx_pace_timeout / 1000;
-
-	return 0;
-}
-
-static int am65_cpsw_set_coalesce(struct net_device *ndev, struct ethtool_coalesce *coal)
-{
-	struct am65_cpsw_common *common = am65_ndev_to_common(ndev);
-	struct am65_cpsw_tx_chn *tx_chn;
-
-	tx_chn = &common->tx_chns[0];
-
-	if (coal->rx_coalesce_usecs && coal->rx_coalesce_usecs < 20)
-		coal->rx_coalesce_usecs = 20;
-
-	if (coal->tx_coalesce_usecs && coal->tx_coalesce_usecs < 20)
-		coal->tx_coalesce_usecs = 20;
-
-	common->rx_pace_timeout = coal->rx_coalesce_usecs * 1000;
-	tx_chn->tx_pace_timeout = coal->tx_coalesce_usecs * 1000;
-
-	return 0;
-}
-
-static int am65_cpsw_set_per_queue_coalesce(struct net_device *ndev, u32 queue,
-					    struct ethtool_coalesce *coal)
-{
-	struct am65_cpsw_common *common = am65_ndev_to_common(ndev);
-	struct am65_cpsw_tx_chn *tx_chn;
-
-	if (queue >= AM65_CPSW_MAX_TX_QUEUES)
-		return -EINVAL;
-
-	tx_chn = &common->tx_chns[queue];
-
-	if (coal->tx_coalesce_usecs && coal->tx_coalesce_usecs < 20)
-		coal->tx_coalesce_usecs = 20;
-
-	tx_chn->tx_pace_timeout = coal->tx_coalesce_usecs * 1000;
 
 	return 0;
 }
@@ -879,11 +767,6 @@ const struct ethtool_ops am65_cpsw_ethtool_ops_slave = {
 	.get_ts_info		= am65_cpsw_get_ethtool_ts_info,
 	.get_priv_flags		= am65_cpsw_get_ethtool_priv_flags,
 	.set_priv_flags		= am65_cpsw_set_ethtool_priv_flags,
-	.supported_coalesce_params = ETHTOOL_COALESCE_RX_USECS | ETHTOOL_COALESCE_TX_USECS,
-	.get_coalesce           = am65_cpsw_get_coalesce,
-	.set_coalesce           = am65_cpsw_set_coalesce,
-	.get_per_queue_coalesce = am65_cpsw_get_per_queue_coalesce,
-	.set_per_queue_coalesce = am65_cpsw_set_per_queue_coalesce,
 
 	.get_link		= ethtool_op_get_link,
 	.get_link_ksettings	= am65_cpsw_get_link_ksettings,
diff --git a/drivers/net/ethernet/ti/am65-cpsw-nuss.c b/drivers/net/ethernet/ti/am65-cpsw-nuss.c
index 047d0e690fa4..0805edef5625 100644
--- a/drivers/net/ethernet/ti/am65-cpsw-nuss.c
+++ b/drivers/net/ethernet/ti/am65-cpsw-nuss.c
@@ -27,12 +27,10 @@
 #include <linux/sys_soc.h>
 #include <linux/dma/ti-cppi5.h>
 #include <linux/dma/k3-udma-glue.h>
-#include <linux/net_switch_config.h>
 
 #include "cpsw_ale.h"
 #include "cpsw_sl.h"
 #include "am65-cpsw-nuss.h"
-#include "am65-cpsw-switchdev.h"
 #include "k3-cppi-desc-pool.h"
 #include "am65-cpts.h"
 
@@ -80,7 +78,6 @@
 
 /* AM65_CPSW_P0_REG_CTL */
 #define AM65_CPSW_P0_REG_CTL_RX_CHECKSUM_EN	BIT(0)
-#define AM65_CPSW_P0_REG_CTL_RX_REMAP_VLAN	BIT(16)
 
 /* AM65_CPSW_PORT_REG_PRI_CTL */
 #define AM65_CPSW_PORT_REG_PRI_CTL_RX_PTYPE_RROBIN	BIT(8)
@@ -194,11 +191,11 @@ void am65_cpsw_nuss_adjust_link(struct net_device *ndev)
 
 		cpsw_sl_ctl_set(port->slave.mac_sl, mac_control);
 
-		am65_cpsw_qos_link_up(ndev, phy->speed, phy->duplex);
-
 		/* enable forwarding */
 		cpsw_ale_control_set(common->ale, port->port_id,
 				     ALE_PORT_STATE, ALE_PORT_STATE_FORWARD);
+
+		am65_cpsw_qos_link_up(ndev, phy->speed);
 		netif_tx_wake_all_queues(ndev);
 	} else {
 		int tmo;
@@ -231,9 +228,6 @@ static int am65_cpsw_nuss_ndo_slave_add_vid(struct net_device *ndev,
 	u32 port_mask, unreg_mcast = 0;
 	int ret;
 
-	if (!common->is_emac_mode)
-		return 0;
-
 	if (!netif_running(ndev) || !vid)
 		return 0;
 
@@ -247,8 +241,8 @@ static int am65_cpsw_nuss_ndo_slave_add_vid(struct net_device *ndev,
 	if (!vid)
 		unreg_mcast = port_mask;
 	dev_info(common->dev, "Adding vlan %d to vlan filter\n", vid);
-	ret = cpsw_ale_vlan_add_modify(common->ale, vid, port_mask,
-				       unreg_mcast, port_mask, 0);
+	ret = cpsw_ale_add_vlan(common->ale, vid, port_mask,
+				unreg_mcast, port_mask, 0);
 
 	pm_runtime_put(common->dev);
 	return ret;
@@ -258,12 +252,8 @@ static int am65_cpsw_nuss_ndo_slave_kill_vid(struct net_device *ndev,
 					     __be16 proto, u16 vid)
 {
 	struct am65_cpsw_common *common = am65_ndev_to_common(ndev);
-	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
 	int ret;
 
-	if (!common->is_emac_mode)
-		return 0;
-
 	if (!netif_running(ndev) || !vid)
 		return 0;
 
@@ -274,23 +264,17 @@ static int am65_cpsw_nuss_ndo_slave_kill_vid(struct net_device *ndev,
 	}
 
 	dev_info(common->dev, "Removing vlan %d from vlan filter\n", vid);
-	ret = cpsw_ale_del_vlan(common->ale, vid,
-				BIT(port->port_id) | ALE_PORT_HOST);
+	ret = cpsw_ale_del_vlan(common->ale, vid, 0);
 
 	pm_runtime_put(common->dev);
 	return ret;
 }
 
-static void am65_cpsw_slave_set_promisc(struct am65_cpsw_port *port,
-					bool promisc)
+static void am65_cpsw_slave_set_promisc_2g(struct am65_cpsw_port *port,
+					   bool promisc)
 {
 	struct am65_cpsw_common *common = port->common;
 
-	if (promisc && !common->is_emac_mode) {
-		dev_dbg(common->dev, "promisc mode requested in switch mode");
-		return;
-	}
-
 	if (promisc) {
 		/* Enable promiscuous mode */
 		cpsw_ale_control_set(common->ale, port->port_id,
@@ -312,7 +296,7 @@ static void am65_cpsw_nuss_ndo_slave_set_rx_mode(struct net_device *ndev)
 	bool promisc;
 
 	promisc = !!(ndev->flags & IFF_PROMISC);
-	am65_cpsw_slave_set_promisc(port, promisc);
+	am65_cpsw_slave_set_promisc_2g(port, promisc);
 
 	if (promisc)
 		return;
@@ -380,9 +364,8 @@ static int am65_cpsw_nuss_rx_push(struct am65_cpsw_common *common,
 	}
 	desc_dma = k3_cppi_desc_pool_virt2dma(rx_chn->desc_pool, desc_rx);
 
-	buf_dma = dma_map_single(rx_chn->dma_dev, skb->data, pkt_len,
-				 DMA_FROM_DEVICE);
-	if (unlikely(dma_mapping_error(rx_chn->dma_dev, buf_dma))) {
+	buf_dma = dma_map_single(dev, skb->data, pkt_len, DMA_FROM_DEVICE);
+	if (unlikely(dma_mapping_error(dev, buf_dma))) {
 		k3_cppi_desc_pool_free(rx_chn->desc_pool, desc_rx);
 		dev_err(dev, "Failed to map rx skb buffer\n");
 		return -EINVAL;
@@ -390,8 +373,7 @@ static int am65_cpsw_nuss_rx_push(struct am65_cpsw_common *common,
 
 	cppi5_hdesc_init(desc_rx, CPPI5_INFO0_HDESC_EPIB_PRESENT,
 			 AM65_CPSW_NAV_PS_DATA_SIZE);
-	k3_udma_glue_rx_dma_to_cppi5_addr(rx_chn->rx_chn, &buf_dma);
-	cppi5_hdesc_attach_buf(desc_rx, buf_dma, skb_tailroom(skb), buf_dma, skb_tailroom(skb));
+	cppi5_hdesc_attach_buf(desc_rx, 0, 0, buf_dma, skb_tailroom(skb));
 	swdata = cppi5_hdesc_get_swdata(desc_rx);
 	*((void **)swdata) = skb;
 
@@ -422,11 +404,6 @@ void am65_cpsw_nuss_set_p0_ptype(struct am65_cpsw_common *common)
 	writel(val, host_p->port_base + AM65_CPSW_PORT_REG_PRI_CTL);
 }
 
-static void am65_cpsw_init_host_port_switch(struct am65_cpsw_common *common);
-static void am65_cpsw_init_host_port_emac(struct am65_cpsw_common *common);
-static void am65_cpsw_init_port_switch_ale(struct am65_cpsw_port *port);
-static void am65_cpsw_init_port_emac_ale(struct am65_cpsw_port *port);
-
 static int am65_cpsw_nuss_common_open(struct am65_cpsw_common *common,
 				      netdev_features_t features)
 {
@@ -448,9 +425,10 @@ static int am65_cpsw_nuss_common_open(struct am65_cpsw_common *common,
 	/* set base flow_id */
 	writel(common->rx_flow_id_base,
 	       host_p->port_base + AM65_CPSW_PORT0_REG_FLOW_ID_OFFSET);
-	writel(AM65_CPSW_P0_REG_CTL_RX_CHECKSUM_EN |
-	       AM65_CPSW_P0_REG_CTL_RX_REMAP_VLAN,
-	       host_p->port_base + AM65_CPSW_P0_REG_CTL);
+	/* en tx crc offload */
+	if (features & NETIF_F_HW_CSUM)
+		writel(AM65_CPSW_P0_REG_CTL_RX_CHECKSUM_EN,
+		       host_p->port_base + AM65_CPSW_P0_REG_CTL);
 
 	am65_cpsw_nuss_set_p0_ptype(common);
 
@@ -474,6 +452,9 @@ static int am65_cpsw_nuss_common_open(struct am65_cpsw_common *common,
 			     ALE_DEFAULT_THREAD_ID, 0);
 	cpsw_ale_control_set(common->ale, HOST_PORT_NUM,
 			     ALE_DEFAULT_THREAD_ENABLE, 1);
+	if (AM65_CPSW_IS_CPSW2G(common))
+		cpsw_ale_control_set(common->ale, HOST_PORT_NUM,
+				     ALE_PORT_NOLEARN, 1);
 	/* switch to vlan unaware mode */
 	cpsw_ale_control_set(common->ale, HOST_PORT_NUM, ALE_VLAN_AWARE, 1);
 	cpsw_ale_control_set(common->ale, HOST_PORT_NUM,
@@ -487,13 +468,6 @@ static int am65_cpsw_nuss_common_open(struct am65_cpsw_common *common,
 			  port_mask, port_mask,
 			  port_mask & ~ALE_PORT_HOST);
 
-	if (common->is_emac_mode)
-		am65_cpsw_init_host_port_emac(common);
-	else
-		am65_cpsw_init_host_port_switch(common);
-
-	am65_cpsw_qos_tx_p0_rate_init(common);
-
 	for (i = 0; i < common->rx_chns.descs_num; i++) {
 		skb = __netdev_alloc_skb_ip_align(NULL,
 						  AM65_CPSW_MAX_PACKET_SIZE,
@@ -523,10 +497,6 @@ static int am65_cpsw_nuss_common_open(struct am65_cpsw_common *common,
 	}
 
 	napi_enable(&common->napi_rx);
-	if (common->rx_irq_disabled) {
-		common->rx_irq_disabled = false;
-		enable_irq(common->rx_chns.irq);
-	}
 
 	dev_dbg(common->dev, "cpsw_nuss started\n");
 	return 0;
@@ -558,10 +528,8 @@ static int am65_cpsw_nuss_common_stop(struct am65_cpsw_common *common)
 					msecs_to_jiffies(1000));
 	if (!i)
 		dev_err(common->dev, "tx timeout\n");
-	for (i = 0; i < common->tx_ch_num; i++) {
+	for (i = 0; i < common->tx_ch_num; i++)
 		napi_disable(&common->tx_chns[i].napi_tx);
-		hrtimer_cancel(&common->tx_chns[i].tx_hrtimer);
-	}
 
 	for (i = 0; i < common->tx_ch_num; i++) {
 		k3_udma_glue_reset_tx_chn(common->tx_chns[i].tx_chn,
@@ -572,7 +540,6 @@ static int am65_cpsw_nuss_common_stop(struct am65_cpsw_common *common)
 
 	k3_udma_glue_tdown_rx_chn(common->rx_chns.rx_chn, true);
 	napi_disable(&common->napi_rx);
-	hrtimer_cancel(&common->rx_hrtimer);
 
 	for (i = 0; i < AM65_CPSW_MAX_RX_FLOWS; i++)
 		k3_udma_glue_reset_rx_chn(common->rx_chns.rx_chn, i,
@@ -606,10 +573,6 @@ static int am65_cpsw_nuss_ndo_slave_stop(struct net_device *ndev)
 		port->slave.phy = NULL;
 	}
 
-	/* Clean up IET */
-	am65_cpsw_qos_iet_cleanup(ndev);
-	am65_cpsw_qos_cut_thru_cleanup(port);
-
 	ret = am65_cpsw_nuss_common_stop(common);
 	if (ret)
 		return ret;
@@ -633,6 +596,7 @@ static int am65_cpsw_nuss_ndo_slave_open(struct net_device *ndev)
 {
 	struct am65_cpsw_common *common = am65_ndev_to_common(ndev);
 	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
+	u32 port_mask;
 	int ret, i;
 
 	ret = pm_runtime_get_sync(common->dev);
@@ -654,12 +618,8 @@ static int am65_cpsw_nuss_ndo_slave_open(struct net_device *ndev)
 		return ret;
 	}
 
-	for (i = 0; i < common->tx_ch_num; i++) {
-		struct netdev_queue *txq = netdev_get_tx_queue(ndev, i);
-
-		netdev_tx_reset_queue(txq);
-		txq->tx_maxrate =  common->tx_chns[i].rate_mbps;
-	}
+	for (i = 0; i < common->tx_ch_num; i++)
+		netdev_tx_reset_queue(netdev_get_tx_queue(ndev, i));
 
 	ret = am65_cpsw_nuss_common_open(common, ndev->features);
 	if (ret)
@@ -669,10 +629,19 @@ static int am65_cpsw_nuss_ndo_slave_open(struct net_device *ndev)
 
 	am65_cpsw_port_set_sl_mac(port, ndev->dev_addr);
 
-	if (common->is_emac_mode)
-		am65_cpsw_init_port_emac_ale(port);
-	else
-		am65_cpsw_init_port_switch_ale(port);
+	if (port->slave.mac_only)
+		/* enable mac-only mode on port */
+		cpsw_ale_control_set(common->ale, port->port_id,
+				     ALE_PORT_MACONLY, 1);
+	if (AM65_CPSW_IS_CPSW2G(common))
+		cpsw_ale_control_set(common->ale, port->port_id,
+				     ALE_PORT_NOLEARN, 1);
+
+	port_mask = BIT(port->port_id) | ALE_PORT_HOST;
+	cpsw_ale_add_ucast(common->ale, ndev->dev_addr,
+			   HOST_PORT_NUM, ALE_SECURE, 0);
+	cpsw_ale_add_mcast(common->ale, ndev->broadcast,
+			   port_mask, 0, 0, ALE_MCAST_FWD_2);
 
 	/* mac_sl should be configured via phy-link interface */
 	am65_cpsw_sl_ctl_reset(port);
@@ -699,11 +668,6 @@ static int am65_cpsw_nuss_ndo_slave_open(struct net_device *ndev)
 	/* restore vlan configurations */
 	vlan_for_each(ndev, cpsw_restore_vlans, port);
 
-	/* Initialize IET */
-	am65_cpsw_qos_iet_init(ndev);
-	am65_cpsw_qos_cut_thru_init(port);
-	am65_cpsw_qos_mqprio_init(port);
-
 	phy_attached_info(port->slave.phy);
 	phy_start(port->slave.phy);
 
@@ -727,9 +691,8 @@ static void am65_cpsw_nuss_rx_cleanup(void *data, dma_addr_t desc_dma)
 	swdata = cppi5_hdesc_get_swdata(desc_rx);
 	skb = *swdata;
 	cppi5_hdesc_get_obuf(desc_rx, &buf_dma, &buf_dma_len);
-	k3_udma_glue_rx_cppi5_to_dma_addr(rx_chn->rx_chn, &buf_dma);
 
-	dma_unmap_single(rx_chn->dma_dev, buf_dma, buf_dma_len, DMA_FROM_DEVICE);
+	dma_unmap_single(rx_chn->dev, buf_dma, buf_dma_len, DMA_FROM_DEVICE);
 	k3_cppi_desc_pool_free(rx_chn->desc_pool, desc_rx);
 
 	dev_kfree_skb_any(skb);
@@ -804,7 +767,7 @@ static int am65_cpsw_nuss_rx_packets(struct am65_cpsw_common *common,
 		return ret;
 	}
 
-	if (cppi5_desc_is_tdcm(desc_dma)) {
+	if (desc_dma & 0x1) {
 		dev_dbg(dev, "%s RX tdown flow: %u\n", __func__, flow_idx);
 		return 0;
 	}
@@ -816,7 +779,6 @@ static int am65_cpsw_nuss_rx_packets(struct am65_cpsw_common *common,
 	swdata = cppi5_hdesc_get_swdata(desc_rx);
 	skb = *swdata;
 	cppi5_hdesc_get_obuf(desc_rx, &buf_dma, &buf_dma_len);
-	k3_udma_glue_rx_cppi5_to_dma_addr(rx_chn->rx_chn, &buf_dma);
 	pkt_len = cppi5_hdesc_get_pktlen(desc_rx);
 	cppi5_desc_get_tags_ids(&desc_rx->hdr, &port_id, NULL);
 	dev_dbg(dev, "%s rx port_id:%d\n", __func__, port_id);
@@ -831,19 +793,18 @@ static int am65_cpsw_nuss_rx_packets(struct am65_cpsw_common *common,
 	csum_info = psdata[2];
 	dev_dbg(dev, "%s rx csum_info:%#x\n", __func__, csum_info);
 
-	dma_unmap_single(rx_chn->dma_dev, buf_dma, buf_dma_len, DMA_FROM_DEVICE);
+	dma_unmap_single(dev, buf_dma, buf_dma_len, DMA_FROM_DEVICE);
 
 	k3_cppi_desc_pool_free(rx_chn->desc_pool, desc_rx);
 
 	new_skb = netdev_alloc_skb_ip_align(ndev, AM65_CPSW_MAX_PACKET_SIZE);
 	if (new_skb) {
-		ndev_priv = netdev_priv(ndev);
-		am65_cpsw_nuss_set_offload_fwd_mark(skb, ndev_priv->offload_fwd_mark);
 		skb_put(skb, pkt_len);
 		skb->protocol = eth_type_trans(skb, ndev);
 		am65_cpsw_nuss_rx_csum(skb, csum_info);
 		napi_gro_receive(&common->napi_rx, skb);
 
+		ndev_priv = netdev_priv(ndev);
 		stats = this_cpu_ptr(ndev_priv->stats);
 
 		u64_stats_update_begin(&stats->syncp);
@@ -872,15 +833,6 @@ static int am65_cpsw_nuss_rx_packets(struct am65_cpsw_common *common,
 	return ret;
 }
 
-static enum hrtimer_restart am65_cpsw_nuss_rx_timer_callback(struct hrtimer *timer)
-{
-	struct am65_cpsw_common *common =
-			container_of(timer, struct am65_cpsw_common, rx_hrtimer);
-
-	enable_irq(common->rx_chns.irq);
-	return HRTIMER_NORESTART;
-}
-
 static int am65_cpsw_nuss_rx_poll(struct napi_struct *napi_rx, int budget)
 {
 	struct am65_cpsw_common *common = am65_cpsw_napi_to_common(napi_rx);
@@ -905,23 +857,14 @@ static int am65_cpsw_nuss_rx_poll(struct napi_struct *napi_rx, int budget)
 
 	dev_dbg(common->dev, "%s num_rx:%d %d\n", __func__, num_rx, budget);
 
-	if (num_rx < budget && napi_complete_done(napi_rx, num_rx)) {
-		if (common->rx_irq_disabled) {
-			common->rx_irq_disabled = false;
-			if (unlikely(common->rx_pace_timeout)) {
-				hrtimer_start(&common->rx_hrtimer,
-					      ns_to_ktime(common->rx_pace_timeout),
-					      HRTIMER_MODE_REL_PINNED);
-			} else {
-				enable_irq(common->rx_chns.irq);
-			}
-		}
-	}
+	if (num_rx < budget && napi_complete_done(napi_rx, num_rx))
+		enable_irq(common->rx_chns.irq);
 
 	return num_rx;
 }
 
 static void am65_cpsw_nuss_xmit_free(struct am65_cpsw_tx_chn *tx_chn,
+				     struct device *dev,
 				     struct cppi5_host_desc_t *desc)
 {
 	struct cppi5_host_desc_t *first_desc, *next_desc;
@@ -932,23 +875,20 @@ static void am65_cpsw_nuss_xmit_free(struct am65_cpsw_tx_chn *tx_chn,
 	next_desc = first_desc;
 
 	cppi5_hdesc_get_obuf(first_desc, &buf_dma, &buf_dma_len);
-	k3_udma_glue_tx_cppi5_to_dma_addr(tx_chn->tx_chn, &buf_dma);
 
-	dma_unmap_single(tx_chn->dma_dev, buf_dma, buf_dma_len, DMA_TO_DEVICE);
+	dma_unmap_single(dev, buf_dma, buf_dma_len,
+			 DMA_TO_DEVICE);
 
 	next_desc_dma = cppi5_hdesc_get_next_hbdesc(first_desc);
-	k3_udma_glue_tx_cppi5_to_dma_addr(tx_chn->tx_chn, &next_desc_dma);
 	while (next_desc_dma) {
 		next_desc = k3_cppi_desc_pool_dma2virt(tx_chn->desc_pool,
 						       next_desc_dma);
 		cppi5_hdesc_get_obuf(next_desc, &buf_dma, &buf_dma_len);
-		k3_udma_glue_tx_cppi5_to_dma_addr(tx_chn->tx_chn, &buf_dma);
 
-		dma_unmap_page(tx_chn->dma_dev, buf_dma, buf_dma_len,
+		dma_unmap_page(dev, buf_dma, buf_dma_len,
 			       DMA_TO_DEVICE);
 
 		next_desc_dma = cppi5_hdesc_get_next_hbdesc(next_desc);
-		k3_udma_glue_tx_cppi5_to_dma_addr(tx_chn->tx_chn, &next_desc_dma);
 
 		k3_cppi_desc_pool_free(tx_chn->desc_pool, next_desc);
 	}
@@ -966,62 +906,15 @@ static void am65_cpsw_nuss_tx_cleanup(void *data, dma_addr_t desc_dma)
 	desc_tx = k3_cppi_desc_pool_dma2virt(tx_chn->desc_pool, desc_dma);
 	swdata = cppi5_hdesc_get_swdata(desc_tx);
 	skb = *(swdata);
-	am65_cpsw_nuss_xmit_free(tx_chn, desc_tx);
+	am65_cpsw_nuss_xmit_free(tx_chn, tx_chn->common->dev, desc_tx);
 
 	dev_kfree_skb_any(skb);
 }
 
-static struct sk_buff *
-am65_cpsw_nuss_tx_compl_packet(struct am65_cpsw_tx_chn *tx_chn,
-			       dma_addr_t desc_dma)
-{
-	struct am65_cpsw_ndev_priv *ndev_priv;
-	struct am65_cpsw_ndev_stats *stats;
-	struct cppi5_host_desc_t *desc_tx;
-	struct net_device *ndev;
-	struct sk_buff *skb;
-	void **swdata;
-
-	desc_tx = k3_cppi_desc_pool_dma2virt(tx_chn->desc_pool,
-					     desc_dma);
-	swdata = cppi5_hdesc_get_swdata(desc_tx);
-	skb = *(swdata);
-	am65_cpsw_nuss_xmit_free(tx_chn, desc_tx);
-
-	ndev = skb->dev;
-
-	am65_cpts_tx_timestamp(tx_chn->common->cpts, skb);
-
-	ndev_priv = netdev_priv(ndev);
-	stats = this_cpu_ptr(ndev_priv->stats);
-	u64_stats_update_begin(&stats->syncp);
-	stats->tx_packets++;
-	stats->tx_bytes += skb->len;
-	u64_stats_update_end(&stats->syncp);
-
-	return skb;
-}
-
-static void am65_cpsw_nuss_tx_wake(struct am65_cpsw_tx_chn *tx_chn, struct net_device *ndev,
-				   struct netdev_queue *netif_txq)
-{
-	if (netif_tx_queue_stopped(netif_txq)) {
-		/* Check whether the queue is stopped due to stalled
-		 * tx dma, if the queue is stopped then wake the queue
-		 * as we have free desc for tx
-		 */
-		__netif_tx_lock(netif_txq, smp_processor_id());
-		if (netif_running(ndev) &&
-		    (k3_cppi_desc_pool_avail(tx_chn->desc_pool) >= MAX_SKB_FRAGS))
-			netif_tx_wake_queue(netif_txq);
-
-		__netif_tx_unlock(netif_txq);
-	}
-}
-
 static int am65_cpsw_nuss_tx_compl_packets(struct am65_cpsw_common *common,
-					   int chn, unsigned int budget, bool *tdown)
+					   int chn, unsigned int budget)
 {
+	struct cppi5_host_desc_t *desc_tx;
 	struct device *dev = common->dev;
 	struct am65_cpsw_tx_chn *tx_chn;
 	struct netdev_queue *netif_txq;
@@ -1030,70 +923,41 @@ static int am65_cpsw_nuss_tx_compl_packets(struct am65_cpsw_common *common,
 	struct sk_buff *skb;
 	dma_addr_t desc_dma;
 	int res, num_tx = 0;
+	void **swdata;
 
 	tx_chn = &common->tx_chns[chn];
 
 	while (true) {
-		spin_lock(&tx_chn->lock);
+		struct am65_cpsw_ndev_priv *ndev_priv;
+		struct am65_cpsw_ndev_stats *stats;
+
 		res = k3_udma_glue_pop_tx_chn(tx_chn->tx_chn, &desc_dma);
-		spin_unlock(&tx_chn->lock);
 		if (res == -ENODATA)
 			break;
 
-		if (cppi5_desc_is_tdcm(desc_dma)) {
+		if (desc_dma & 0x1) {
 			if (atomic_dec_and_test(&common->tdown_cnt))
 				complete(&common->tdown_complete);
-			*tdown = true;
 			break;
 		}
 
-		skb = am65_cpsw_nuss_tx_compl_packet(tx_chn, desc_dma);
-		total_bytes = skb->len;
-		ndev = skb->dev;
-		napi_consume_skb(skb, budget);
-		num_tx++;
-
-		netif_txq = netdev_get_tx_queue(ndev, chn);
-
-		netdev_tx_completed_queue(netif_txq, num_tx, total_bytes);
-
-		am65_cpsw_nuss_tx_wake(tx_chn, ndev, netif_txq);
-	}
-
-	dev_dbg(dev, "%s:%u pkt:%d\n", __func__, chn, num_tx);
-
-	return num_tx;
-}
-
-static int am65_cpsw_nuss_tx_compl_packets_2g(struct am65_cpsw_common *common,
-					      int chn, unsigned int budget, bool *tdown)
-{
-	struct device *dev = common->dev;
-	struct am65_cpsw_tx_chn *tx_chn;
-	struct netdev_queue *netif_txq;
-	unsigned int total_bytes = 0;
-	struct net_device *ndev;
-	struct sk_buff *skb;
-	dma_addr_t desc_dma;
-	int res, num_tx = 0;
-
-	tx_chn = &common->tx_chns[chn];
+		desc_tx = k3_cppi_desc_pool_dma2virt(tx_chn->desc_pool,
+						     desc_dma);
+		swdata = cppi5_hdesc_get_swdata(desc_tx);
+		skb = *(swdata);
+		am65_cpsw_nuss_xmit_free(tx_chn, dev, desc_tx);
 
-	while (true) {
-		res = k3_udma_glue_pop_tx_chn(tx_chn->tx_chn, &desc_dma);
-		if (res == -ENODATA)
-			break;
+		ndev = skb->dev;
 
-		if (cppi5_desc_is_tdcm(desc_dma)) {
-			if (atomic_dec_and_test(&common->tdown_cnt))
-				complete(&common->tdown_complete);
-			*tdown = true;
-			break;
-		}
+		am65_cpts_tx_timestamp(common->cpts, skb);
 
-		skb = am65_cpsw_nuss_tx_compl_packet(tx_chn, desc_dma);
+		ndev_priv = netdev_priv(ndev);
+		stats = this_cpu_ptr(ndev_priv->stats);
+		u64_stats_update_begin(&stats->syncp);
+		stats->tx_packets++;
+		stats->tx_bytes += skb->len;
+		u64_stats_update_end(&stats->syncp);
 
-		ndev = skb->dev;
 		total_bytes += skb->len;
 		napi_consume_skb(skb, budget);
 		num_tx++;
@@ -1106,56 +970,44 @@ static int am65_cpsw_nuss_tx_compl_packets_2g(struct am65_cpsw_common *common,
 
 	netdev_tx_completed_queue(netif_txq, num_tx, total_bytes);
 
-	am65_cpsw_nuss_tx_wake(tx_chn, ndev, netif_txq);
+	if (netif_tx_queue_stopped(netif_txq)) {
+		/* Check whether the queue is stopped due to stalled tx dma,
+		 * if the queue is stopped then wake the queue as
+		 * we have free desc for tx
+		 */
+		__netif_tx_lock(netif_txq, smp_processor_id());
+		if (netif_running(ndev) &&
+		    (k3_cppi_desc_pool_avail(tx_chn->desc_pool) >=
+		     MAX_SKB_FRAGS))
+			netif_tx_wake_queue(netif_txq);
 
+		__netif_tx_unlock(netif_txq);
+	}
 	dev_dbg(dev, "%s:%u pkt:%d\n", __func__, chn, num_tx);
 
 	return num_tx;
 }
 
-static enum hrtimer_restart am65_cpsw_nuss_tx_timer_callback(struct hrtimer *timer)
-{
-	struct am65_cpsw_tx_chn *tx_chns =
-			container_of(timer, struct am65_cpsw_tx_chn, tx_hrtimer);
-
-	enable_irq(tx_chns->irq);
-	return HRTIMER_NORESTART;
-}
-
 static int am65_cpsw_nuss_tx_poll(struct napi_struct *napi_tx, int budget)
 {
 	struct am65_cpsw_tx_chn *tx_chn = am65_cpsw_napi_to_tx_chn(napi_tx);
-	bool tdown = false;
 	int num_tx;
 
-	if (AM65_CPSW_IS_CPSW2G(tx_chn->common))
-		num_tx = am65_cpsw_nuss_tx_compl_packets_2g(tx_chn->common, tx_chn->id,
-							    budget, &tdown);
-	else
-		num_tx = am65_cpsw_nuss_tx_compl_packets(tx_chn->common,
-							 tx_chn->id, budget, &tdown);
-
-	if (num_tx >= budget)
-		return budget;
-
-	if (napi_complete_done(napi_tx, num_tx)) {
-		if (unlikely(tx_chn->tx_pace_timeout && !tdown)) {
-			hrtimer_start(&tx_chn->tx_hrtimer,
-				      ns_to_ktime(tx_chn->tx_pace_timeout),
-				      HRTIMER_MODE_REL_PINNED);
-		} else {
-			enable_irq(tx_chn->irq);
-		}
+	num_tx = am65_cpsw_nuss_tx_compl_packets(tx_chn->common, tx_chn->id,
+						 budget);
+	num_tx = min(num_tx, budget);
+	if (num_tx < budget) {
+		napi_complete(napi_tx);
+		enable_irq(tx_chn->irq);
 	}
 
-	return 0;
+	return num_tx;
 }
 
 static irqreturn_t am65_cpsw_nuss_rx_irq(int irq, void *dev_id)
 {
 	struct am65_cpsw_common *common = dev_id;
 
-	common->rx_irq_disabled = true;
 	disable_irq_nosync(irq);
 	napi_schedule(&common->napi_rx);
 
@@ -1201,9 +1053,9 @@ static netdev_tx_t am65_cpsw_nuss_ndo_slave_xmit(struct sk_buff *skb,
 	netif_txq = netdev_get_tx_queue(ndev, q_idx);
 
 	/* Map the linear buffer */
-	buf_dma = dma_map_single(tx_chn->dma_dev, skb->data, pkt_len,
+	buf_dma = dma_map_single(dev, skb->data, pkt_len,
 				 DMA_TO_DEVICE);
-	if (unlikely(dma_mapping_error(tx_chn->dma_dev, buf_dma))) {
+	if (unlikely(dma_mapping_error(dev, buf_dma))) {
 		dev_err(dev, "Failed to map tx skb buffer\n");
 		ndev->stats.tx_errors++;
 		goto err_free_skb;
@@ -1212,8 +1064,7 @@ static netdev_tx_t am65_cpsw_nuss_ndo_slave_xmit(struct sk_buff *skb,
 	first_desc = k3_cppi_desc_pool_alloc(tx_chn->desc_pool);
 	if (!first_desc) {
 		dev_dbg(dev, "Failed to allocate descriptor\n");
-		dma_unmap_single(tx_chn->dma_dev, buf_dma, pkt_len,
-				 DMA_TO_DEVICE);
+		dma_unmap_single(dev, buf_dma, pkt_len, DMA_TO_DEVICE);
 		goto busy_stop_q;
 	}
 
@@ -1223,7 +1074,6 @@ static netdev_tx_t am65_cpsw_nuss_ndo_slave_xmit(struct sk_buff *skb,
 	cppi5_hdesc_set_pkttype(first_desc, 0x7);
 	cppi5_desc_set_tags_ids(&first_desc->hdr, 0, port->port_id);
 
-	k3_udma_glue_tx_dma_to_cppi5_addr(tx_chn->tx_chn, &buf_dma);
 	cppi5_hdesc_attach_buf(first_desc, buf_dma, pkt_len, buf_dma, pkt_len);
 	swdata = cppi5_hdesc_get_swdata(first_desc);
 	*(swdata) = skb;
@@ -1259,9 +1109,9 @@ static netdev_tx_t am65_cpsw_nuss_ndo_slave_xmit(struct sk_buff *skb,
 			goto busy_free_descs;
 		}
 
-		buf_dma = skb_frag_dma_map(tx_chn->dma_dev, frag, 0, frag_size,
+		buf_dma = skb_frag_dma_map(dev, frag, 0, frag_size,
 					   DMA_TO_DEVICE);
-		if (unlikely(dma_mapping_error(tx_chn->dma_dev, buf_dma))) {
+		if (unlikely(dma_mapping_error(dev, buf_dma))) {
 			dev_err(dev, "Failed to map tx skb page\n");
 			k3_cppi_desc_pool_free(tx_chn->desc_pool, next_desc);
 			ndev->stats.tx_errors++;
@@ -1269,13 +1119,11 @@ static netdev_tx_t am65_cpsw_nuss_ndo_slave_xmit(struct sk_buff *skb,
 		}
 
 		cppi5_hdesc_reset_hbdesc(next_desc);
-		k3_udma_glue_tx_dma_to_cppi5_addr(tx_chn->tx_chn, &buf_dma);
 		cppi5_hdesc_attach_buf(next_desc,
 				       buf_dma, frag_size, buf_dma, frag_size);
 
 		desc_dma = k3_cppi_desc_pool_virt2dma(tx_chn->desc_pool,
 						      next_desc);
-		k3_udma_glue_tx_dma_to_cppi5_addr(tx_chn->tx_chn, &desc_dma);
 		cppi5_hdesc_link_hbdesc(cur_desc, desc_dma);
 
 		pkt_len += frag_size;
@@ -1291,13 +1139,7 @@ static netdev_tx_t am65_cpsw_nuss_ndo_slave_xmit(struct sk_buff *skb,
 
 	cppi5_hdesc_set_pktlen(first_desc, pkt_len);
 	desc_dma = k3_cppi_desc_pool_virt2dma(tx_chn->desc_pool, first_desc);
-	if (AM65_CPSW_IS_CPSW2G(common)) {
-		ret = k3_udma_glue_push_tx_chn(tx_chn->tx_chn, first_desc, desc_dma);
-	} else {
-		spin_lock_bh(&tx_chn->lock);
-		ret = k3_udma_glue_push_tx_chn(tx_chn->tx_chn, first_desc, desc_dma);
-		spin_unlock_bh(&tx_chn->lock);
-	}
+	ret = k3_udma_glue_push_tx_chn(tx_chn->tx_chn, first_desc, desc_dma);
 	if (ret) {
 		dev_err(dev, "can't push desc %d\n", ret);
 		/* inform bql */
@@ -1323,14 +1165,14 @@ static netdev_tx_t am65_cpsw_nuss_ndo_slave_xmit(struct sk_buff *skb,
 	return NETDEV_TX_OK;
 
 err_free_descs:
-	am65_cpsw_nuss_xmit_free(tx_chn, first_desc);
+	am65_cpsw_nuss_xmit_free(tx_chn, dev, first_desc);
 err_free_skb:
 	ndev->stats.tx_dropped++;
 	dev_kfree_skb_any(skb);
 	return NETDEV_TX_OK;
 
 busy_free_descs:
-	am65_cpsw_nuss_xmit_free(tx_chn, first_desc);
+	am65_cpsw_nuss_xmit_free(tx_chn, dev, first_desc);
 busy_stop_q:
 	netif_tx_stop_queue(netif_txq);
 	return NETDEV_TX_BUSY;
@@ -1472,43 +1314,6 @@ static int am65_cpsw_nuss_hwtstamp_get(struct net_device *ndev,
 	return copy_to_user(ifr->ifr_data, &cfg, sizeof(cfg)) ? -EFAULT : 0;
 }
 
-static int am65_cpsw_switch_config_ioctl(struct net_device *ndev,
-					 struct ifreq *ifrq, int cmd)
-{
-	struct am65_cpsw_common *common = am65_ndev_to_common(ndev);
-	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
-	struct net_switch_config config;
-	int ret = -EINVAL;
-
-	/* Only SIOCSWITCHCONFIG is used as cmd argument and hence, there is no
-	 * switch statement required.
-	 * Function calls are based on switch_config.cmd
-	 */
-
-	if (copy_from_user(&config, ifrq->ifr_data, sizeof(config)))
-		return -EFAULT;
-
-	switch (config.cmd) {
-	case SWITCH_RATELIMIT:
-	{
-		ret = cpsw_ale_rx_ratelimit_mc(common->ale, port->port_id, config.mcast_rate_limit);
-		if (ret)
-			dev_err(common->dev, "CPSW_ALE set MC ratelimit failed");
-
-		ret = cpsw_ale_rx_ratelimit_bc(common->ale, port->port_id, config.bcast_rate_limit);
-		if (ret)
-			dev_err(common->dev, "CPSW_ALE set BC ratelimit failed");
-
-		break;
-	}
-
-	default:
-		ret = -EOPNOTSUPP;
-	}
-
-	return ret;
-}
-
 static int am65_cpsw_nuss_ndo_slave_ioctl(struct net_device *ndev,
 					  struct ifreq *req, int cmd)
 {
@@ -1522,8 +1327,6 @@ static int am65_cpsw_nuss_ndo_slave_ioctl(struct net_device *ndev,
 		return am65_cpsw_nuss_hwtstamp_set(ndev, req);
 	case SIOCGHWTSTAMP:
 		return am65_cpsw_nuss_hwtstamp_get(ndev, req);
-	case SIOCSWITCHCONFIG:
-		return am65_cpsw_switch_config_ioctl(ndev, req, cmd);
 	}
 
 	if (!port->slave.phy)
@@ -1566,14 +1369,32 @@ static void am65_cpsw_nuss_ndo_get_stats(struct net_device *dev,
 	stats->tx_dropped	= dev->stats.tx_dropped;
 }
 
-static struct devlink_port *am65_cpsw_ndo_get_devlink_port(struct net_device *ndev)
+static int am65_cpsw_nuss_ndo_slave_set_features(struct net_device *ndev,
+						 netdev_features_t features)
 {
-	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
+	struct am65_cpsw_common *common = am65_ndev_to_common(ndev);
+	netdev_features_t changes = features ^ ndev->features;
+	struct am65_cpsw_host *host_p;
+
+	host_p = am65_common_get_host(common);
 
-	return &port->devlink_port;
+	if (changes & NETIF_F_HW_CSUM) {
+		bool enable = !!(features & NETIF_F_HW_CSUM);
+
+		dev_info(common->dev, "Turn %s tx-checksum-ip-generic\n",
+			 enable ? "ON" : "OFF");
+		if (enable)
+			writel(AM65_CPSW_P0_REG_CTL_RX_CHECKSUM_EN,
+			       host_p->port_base + AM65_CPSW_P0_REG_CTL);
+		else
+			writel(0,
+			       host_p->port_base + AM65_CPSW_P0_REG_CTL);
+	}
+
+	return 0;
 }
 
-static const struct net_device_ops am65_cpsw_nuss_netdev_ops = {
+static const struct net_device_ops am65_cpsw_nuss_netdev_ops_2g = {
 	.ndo_open		= am65_cpsw_nuss_ndo_slave_open,
 	.ndo_stop		= am65_cpsw_nuss_ndo_slave_stop,
 	.ndo_start_xmit		= am65_cpsw_nuss_ndo_slave_xmit,
@@ -1585,9 +1406,8 @@ static const struct net_device_ops am65_cpsw_nuss_netdev_ops = {
 	.ndo_vlan_rx_add_vid	= am65_cpsw_nuss_ndo_slave_add_vid,
 	.ndo_vlan_rx_kill_vid	= am65_cpsw_nuss_ndo_slave_kill_vid,
 	.ndo_do_ioctl		= am65_cpsw_nuss_ndo_slave_ioctl,
+	.ndo_set_features	= am65_cpsw_nuss_ndo_slave_set_features,
 	.ndo_setup_tc           = am65_cpsw_qos_ndo_setup_tc,
-	.ndo_set_tx_maxrate	= am65_cpsw_qos_ndo_tx_p0_set_maxrate,
-	.ndo_get_devlink_port   = am65_cpsw_ndo_get_devlink_port,
 };
 
 static void am65_cpsw_nuss_slave_disable_unused(struct am65_cpsw_port *port)
@@ -1597,6 +1417,7 @@ static void am65_cpsw_nuss_slave_disable_unused(struct am65_cpsw_port *port)
 	if (!port->disabled)
 		return;
 
+	common->disabled_ports_mask |= BIT(port->port_id);
 	cpsw_ale_control_set(common->ale, port->port_id,
 			     ALE_PORT_STATE, ALE_PORT_STATE_DISABLE);
 
@@ -1629,7 +1450,6 @@ void am65_cpsw_nuss_remove_tx_chns(struct am65_cpsw_common *common)
 
 	devm_remove_action(dev, am65_cpsw_nuss_free_tx_chns, common);
 
-	common->tx_ch_rate_msk = 0;
 	for (i = 0; i < common->tx_ch_num; i++) {
 		struct am65_cpsw_tx_chn *tx_chn = &common->tx_chns[i];
 
@@ -1676,29 +1496,28 @@ static int am65_cpsw_nuss_init_tx_chns(struct am65_cpsw_common *common)
 		snprintf(tx_chn->tx_chn_name,
 			 sizeof(tx_chn->tx_chn_name), "tx%d", i);
 
-		spin_lock_init(&tx_chn->lock);
 		tx_chn->common = common;
 		tx_chn->id = i;
 		tx_chn->descs_num = max_desc_num;
+		tx_chn->desc_pool =
+			k3_cppi_desc_pool_create_name(dev,
+						      tx_chn->descs_num,
+						      hdesc_size,
+						      tx_chn->tx_chn_name);
+		if (IS_ERR(tx_chn->desc_pool)) {
+			ret = PTR_ERR(tx_chn->desc_pool);
+			dev_err(dev, "Failed to create poll %d\n", ret);
+			goto err;
+		}
 
 		tx_chn->tx_chn =
 			k3_udma_glue_request_tx_chn(dev,
 						    tx_chn->tx_chn_name,
 						    &tx_cfg);
 		if (IS_ERR(tx_chn->tx_chn)) {
-			ret = dev_err_probe(dev, PTR_ERR(tx_chn->tx_chn),
-					    "Failed to request tx dma channel\n");
-			goto err;
-		}
-		tx_chn->dma_dev = k3_udma_glue_tx_get_dma_device(tx_chn->tx_chn);
-
-		tx_chn->desc_pool = k3_cppi_desc_pool_create_name(tx_chn->dma_dev,
-								  tx_chn->descs_num,
-								  hdesc_size,
-								  tx_chn->tx_chn_name);
-		if (IS_ERR(tx_chn->desc_pool)) {
-			ret = PTR_ERR(tx_chn->desc_pool);
-			dev_err(dev, "Failed to create poll %d\n", ret);
+			ret = PTR_ERR(tx_chn->tx_chn);
+			dev_err(dev, "Failed to request tx dma channel %d\n",
+				ret);
 			goto err;
 		}
 
@@ -1758,16 +1577,7 @@ static int am65_cpsw_nuss_init_rx_chns(struct am65_cpsw_common *common)
 	/* init all flows */
 	rx_chn->dev = dev;
 	rx_chn->descs_num = max_desc_num;
-
-	rx_chn->rx_chn = k3_udma_glue_request_rx_chn(dev, "rx", &rx_cfg);
-	if (IS_ERR(rx_chn->rx_chn)) {
-		ret = dev_err_probe(dev, PTR_ERR(rx_chn->rx_chn),
-				    "Failed to request rx dma channel\n");
-		goto err;
-	}
-	rx_chn->dma_dev = k3_udma_glue_rx_get_dma_device(rx_chn->rx_chn);
-
-	rx_chn->desc_pool = k3_cppi_desc_pool_create_name(rx_chn->dma_dev,
+	rx_chn->desc_pool = k3_cppi_desc_pool_create_name(dev,
 							  rx_chn->descs_num,
 							  hdesc_size, "rx");
 	if (IS_ERR(rx_chn->desc_pool)) {
@@ -1776,6 +1586,13 @@ static int am65_cpsw_nuss_init_rx_chns(struct am65_cpsw_common *common)
 		goto err;
 	}
 
+	rx_chn->rx_chn = k3_udma_glue_request_rx_chn(dev, "rx", &rx_cfg);
+	if (IS_ERR(rx_chn->rx_chn)) {
+		ret = PTR_ERR(rx_chn->rx_chn);
+		dev_err(dev, "Failed to request rx dma channel %d\n", ret);
+		goto err;
+	}
+
 	common->rx_flow_id_base =
 			k3_udma_glue_rx_get_flow_id_base(rx_chn->rx_chn);
 	dev_info(dev, "set new flow-id-base %u\n", common->rx_flow_id_base);
@@ -1789,6 +1606,7 @@ static int am65_cpsw_nuss_init_rx_chns(struct am65_cpsw_common *common)
 		};
 		struct k3_ring_cfg fdqring_cfg = {
 			.elm_size = K3_RINGACC_RING_ELSIZE_8,
+			.mode = K3_RINGACC_RING_MODE_MESSAGE,
 			.flags = K3_RINGACC_RING_SHARED,
 		};
 		struct k3_udma_glue_rx_flow_cfg rx_flow_cfg = {
@@ -1802,7 +1620,6 @@ static int am65_cpsw_nuss_init_rx_chns(struct am65_cpsw_common *common)
 		rx_flow_cfg.ring_rxfdq0_id = fdqring_id;
 		rx_flow_cfg.rx_cfg.size = max_desc_num;
 		rx_flow_cfg.rxfdq_cfg.size = max_desc_num;
-		rx_flow_cfg.rxfdq_cfg.mode = common->pdata.fdqring_mode;
 
 		ret = k3_udma_glue_rx_flow_init(rx_chn->rx_chn,
 						i, &rx_flow_cfg);
@@ -1908,13 +1725,6 @@ static int am65_cpsw_init_cpts(struct am65_cpsw_common *common)
 		return ret;
 	}
 	common->cpts = cpts;
-	/* Forbid PM runtime if CPTS is running.
-	 * K3 CPSWxG modules may completely lose context during ON->OFF
-	 * transitions depending on integration.
-	 * AM65x/J721E MCU CPSW2G: false
-	 * J721E MAIN_CPSW9G: true
-	 */
-	pm_runtime_forbid(dev);
 
 	return 0;
 }
@@ -1968,10 +1778,8 @@ static int am65_cpsw_nuss_init_slave_ports(struct am65_cpsw_common *common)
 			return PTR_ERR(port->slave.mac_sl);
 
 		port->disabled = !of_device_is_available(port_np);
-		if (port->disabled) {
-			common->disabled_ports_mask |= BIT(port->port_id);
+		if (port->disabled)
 			continue;
-		}
 
 		port->slave.ifphy = devm_of_phy_get(dev, port_np, NULL);
 		if (IS_ERR(port->slave.ifphy)) {
@@ -1987,10 +1795,12 @@ static int am65_cpsw_nuss_init_slave_ports(struct am65_cpsw_common *common)
 		/* get phy/link info */
 		if (of_phy_is_fixed_link(port_np)) {
 			ret = of_phy_register_fixed_link(port_np);
-			if (ret)
-				return dev_err_probe(dev, ret,
-						     "failed to register fixed-link phy %pOF\n",
-						     port_np);
+			if (ret) {
+				if (ret != -EPROBE_DEFER)
+					dev_err(dev, "%pOF failed to register fixed-link phy: %d\n",
+						port_np, ret);
+				return ret;
+			}
 			port->slave.phy_node = of_node_get(port_np);
 		} else {
 			port->slave.phy_node =
@@ -2023,12 +1833,6 @@ static int am65_cpsw_nuss_init_slave_ports(struct am65_cpsw_common *common)
 	}
 	of_node_put(node);
 
-	/* is there at least one ext.port */
-	if (!(~common->disabled_ports_mask & GENMASK(common->port_num, 1))) {
-		dev_err(dev, "No Ext. port are available\n");
-		return -ENODEV;
-	}
-
 	return 0;
 }
 
@@ -2039,18 +1843,14 @@ static void am65_cpsw_pcpu_stats_free(void *data)
 	free_percpu(stats);
 }
 
-static int
-am65_cpsw_nuss_init_port_ndev(struct am65_cpsw_common *common, u32 port_idx)
+static int am65_cpsw_nuss_init_ndev_2g(struct am65_cpsw_common *common)
 {
 	struct am65_cpsw_ndev_priv *ndev_priv;
 	struct device *dev = common->dev;
 	struct am65_cpsw_port *port;
 	int ret;
 
-	port = &common->ports[port_idx];
-
-	if (port->disabled)
-		return 0;
+	port = am65_common_get_port(common, 1);
 
 	/* alloc netdev */
 	port->ndev = devm_alloc_etherdev_mqs(common->dev,
@@ -2079,7 +1879,7 @@ am65_cpsw_nuss_init_port_ndev(struct am65_cpsw_common *common, u32 port_idx)
 	port->ndev->features = port->ndev->hw_features |
 			       NETIF_F_HW_VLAN_CTAG_FILTER;
 	port->ndev->vlan_features |=  NETIF_F_SG;
-	port->ndev->netdev_ops = &am65_cpsw_nuss_netdev_ops;
+	port->ndev->netdev_ops = &am65_cpsw_nuss_netdev_ops_2g;
 	port->ndev->ethtool_ops = &am65_cpsw_ethtool_ops_slave;
 
 	/* Disable TX checksum offload by default due to HW bug */
@@ -2092,46 +1892,30 @@ am65_cpsw_nuss_init_port_ndev(struct am65_cpsw_common *common, u32 port_idx)
 
 	ret = devm_add_action_or_reset(dev, am65_cpsw_pcpu_stats_free,
 				       ndev_priv->stats);
-	if (ret)
-		dev_err(dev, "failed to add percpu stat free action %d\n", ret);
-
-	if (!common->dma_ndev)
-		common->dma_ndev = port->ndev;
-
-	return ret;
-}
-
-static int am65_cpsw_nuss_init_ndevs(struct am65_cpsw_common *common)
-{
-	int ret;
-	int i;
-
-	for (i = 0; i < common->port_num; i++) {
-		ret = am65_cpsw_nuss_init_port_ndev(common, i);
-		if (ret)
-			return ret;
+	if (ret) {
+		dev_err(dev, "Failed to add percpu stat free action %d\n", ret);
+		return ret;
 	}
 
-	netif_napi_add(common->dma_ndev, &common->napi_rx,
+	netif_napi_add(port->ndev, &common->napi_rx,
 		       am65_cpsw_nuss_rx_poll, NAPI_POLL_WEIGHT);
-	hrtimer_init(&common->rx_hrtimer, CLOCK_MONOTONIC, HRTIMER_MODE_REL_PINNED);
-	common->rx_hrtimer.function = &am65_cpsw_nuss_rx_timer_callback;
 
 	return ret;
 }
 
-static int am65_cpsw_nuss_ndev_add_tx_napi(struct am65_cpsw_common *common)
+static int am65_cpsw_nuss_ndev_add_napi_2g(struct am65_cpsw_common *common)
 {
 	struct device *dev = common->dev;
+	struct am65_cpsw_port *port;
 	int i, ret = 0;
 
+	port = am65_common_get_port(common, 1);
+
 	for (i = 0; i < common->tx_ch_num; i++) {
 		struct am65_cpsw_tx_chn *tx_chn = &common->tx_chns[i];
 
-		netif_tx_napi_add(common->dma_ndev, &tx_chn->napi_tx,
+		netif_tx_napi_add(port->ndev, &tx_chn->napi_tx,
 				  am65_cpsw_nuss_tx_poll, NAPI_POLL_WEIGHT);
-		hrtimer_init(&tx_chn->tx_hrtimer, CLOCK_MONOTONIC, HRTIMER_MODE_REL_PINNED);
-		tx_chn->tx_hrtimer.function = &am65_cpsw_nuss_tx_timer_callback;
 
 		ret = devm_request_irq(dev, tx_chn->irq,
 				       am65_cpsw_nuss_tx_irq,
@@ -2148,468 +1932,16 @@ static int am65_cpsw_nuss_ndev_add_tx_napi(struct am65_cpsw_common *common)
 	return ret;
 }
 
-static void am65_cpsw_nuss_cleanup_ndev(struct am65_cpsw_common *common)
-{
-	struct am65_cpsw_port *port;
-	int i;
-
-	for (i = 0; i < common->port_num; i++) {
-		port = &common->ports[i];
-		if (port->ndev)
-			unregister_netdev(port->ndev);
-	}
-}
-
-static void am65_cpsw_port_offload_fwd_mark_update(struct am65_cpsw_common *common)
-{
-	int set_val = 0;
-	int i;
-
-	if (common->br_members == (GENMASK(common->port_num, 1) & ~common->disabled_ports_mask))
-		set_val = 1;
-
-	dev_dbg(common->dev, "set offload_fwd_mark %d\n", set_val);
-
-	for (i = 1; i <= common->port_num; i++) {
-		struct am65_cpsw_port *port = am65_common_get_port(common, i);
-		struct am65_cpsw_ndev_priv *priv;
-
-		if (!port->ndev)
-			continue;
-
-		priv = am65_ndev_to_priv(port->ndev);
-		priv->offload_fwd_mark = set_val;
-	}
-}
-
-bool am65_cpsw_port_dev_check(const struct net_device *ndev)
-{
-	if (ndev->netdev_ops == &am65_cpsw_nuss_netdev_ops) {
-		struct am65_cpsw_common *common = am65_ndev_to_common(ndev);
-
-		return !common->is_emac_mode;
-	}
-
-	return false;
-}
-
-static int am65_cpsw_netdevice_port_link(struct net_device *ndev, struct net_device *br_ndev)
-{
-	struct am65_cpsw_common *common = am65_ndev_to_common(ndev);
-	struct am65_cpsw_ndev_priv *priv = am65_ndev_to_priv(ndev);
-
-	if (!common->br_members) {
-		common->hw_bridge_dev = br_ndev;
-	} else {
-		/* This is adding the port to a second bridge, this is
-		 * unsupported
-		 */
-		if (common->hw_bridge_dev != br_ndev)
-			return -EOPNOTSUPP;
-	}
-
-	common->br_members |= BIT(priv->port->port_id);
-
-	am65_cpsw_port_offload_fwd_mark_update(common);
-
-	return NOTIFY_DONE;
-}
-
-static void am65_cpsw_netdevice_port_unlink(struct net_device *ndev)
-{
-	struct am65_cpsw_common *common = am65_ndev_to_common(ndev);
-	struct am65_cpsw_ndev_priv *priv = am65_ndev_to_priv(ndev);
-
-	common->br_members &= ~BIT(priv->port->port_id);
-
-	am65_cpsw_port_offload_fwd_mark_update(common);
-
-	if (!common->br_members)
-		common->hw_bridge_dev = NULL;
-}
-
-/* netdev notifier */
-static int am65_cpsw_netdevice_event(struct notifier_block *unused,
-				     unsigned long event, void *ptr)
-{
-	struct net_device *ndev = netdev_notifier_info_to_dev(ptr);
-	struct netdev_notifier_changeupper_info *info;
-	int ret = NOTIFY_DONE;
-
-	if (!am65_cpsw_port_dev_check(ndev))
-		return NOTIFY_DONE;
-
-	switch (event) {
-	case NETDEV_CHANGEUPPER:
-		info = ptr;
-
-		if (netif_is_bridge_master(info->upper_dev)) {
-			if (info->linking)
-				ret = am65_cpsw_netdevice_port_link(ndev, info->upper_dev);
-			else
-				am65_cpsw_netdevice_port_unlink(ndev);
-		}
-		break;
-	default:
-		return NOTIFY_DONE;
-	}
-
-	return notifier_from_errno(ret);
-}
-
-static int am65_cpsw_register_notifiers(struct am65_cpsw_common *cpsw)
-{
-	int ret = 0;
-
-	if (AM65_CPSW_IS_CPSW2G(cpsw) ||
-	    !IS_REACHABLE(CONFIG_TI_K3_AM65_CPSW_SWITCHDEV))
-		return 0;
-
-	cpsw->am65_cpsw_netdevice_nb.notifier_call = &am65_cpsw_netdevice_event;
-	ret = register_netdevice_notifier(&cpsw->am65_cpsw_netdevice_nb);
-	if (ret) {
-		dev_err(cpsw->dev, "can't register netdevice notifier\n");
-		return ret;
-	}
-
-	ret = am65_cpsw_switchdev_register_notifiers(cpsw);
-	if (ret)
-		unregister_netdevice_notifier(&cpsw->am65_cpsw_netdevice_nb);
-
-	return ret;
-}
-
-static void am65_cpsw_unregister_notifiers(struct am65_cpsw_common *cpsw)
+static int am65_cpsw_nuss_ndev_reg_2g(struct am65_cpsw_common *common)
 {
-	if (AM65_CPSW_IS_CPSW2G(cpsw) ||
-	    !IS_REACHABLE(CONFIG_TI_K3_AM65_CPSW_SWITCHDEV))
-		return;
-
-	am65_cpsw_switchdev_unregister_notifiers(cpsw);
-	unregister_netdevice_notifier(&cpsw->am65_cpsw_netdevice_nb);
-}
-
-static const struct devlink_ops am65_cpsw_devlink_ops = {};
-
-static void am65_cpsw_init_stp_ale_entry(struct am65_cpsw_common *cpsw)
-{
-	cpsw_ale_add_mcast(cpsw->ale, eth_stp_addr, ALE_PORT_HOST, ALE_SUPER, 0,
-			   ALE_MCAST_BLOCK_LEARN_FWD);
-}
-
-static void am65_cpsw_init_host_port_switch(struct am65_cpsw_common *common)
-{
-	struct am65_cpsw_host *host = am65_common_get_host(common);
-
-	writel(common->default_vlan, host->port_base + AM65_CPSW_PORT_VLAN_REG_OFFSET);
-
-	am65_cpsw_init_stp_ale_entry(common);
-
-	cpsw_ale_control_set(common->ale, HOST_PORT_NUM, ALE_P0_UNI_FLOOD, 1);
-	dev_dbg(common->dev, "Set P0_UNI_FLOOD\n");
-	cpsw_ale_control_set(common->ale, HOST_PORT_NUM, ALE_PORT_NOLEARN, 0);
-}
-
-static void am65_cpsw_init_host_port_emac(struct am65_cpsw_common *common)
-{
-	struct am65_cpsw_host *host = am65_common_get_host(common);
-
-	writel(0, host->port_base + AM65_CPSW_PORT_VLAN_REG_OFFSET);
-
-	cpsw_ale_control_set(common->ale, HOST_PORT_NUM, ALE_P0_UNI_FLOOD, 0);
-	dev_dbg(common->dev, "unset P0_UNI_FLOOD\n");
-
-	/* learning make no sense in multi-mac mode */
-	cpsw_ale_control_set(common->ale, HOST_PORT_NUM, ALE_PORT_NOLEARN, 1);
-}
-
-static int am65_cpsw_dl_switch_mode_get(struct devlink *dl, u32 id,
-					struct devlink_param_gset_ctx *ctx)
-{
-	struct am65_cpsw_devlink *dl_priv = devlink_priv(dl);
-	struct am65_cpsw_common *common = dl_priv->common;
-
-	dev_dbg(common->dev, "%s id:%u\n", __func__, id);
-
-	if (id != AM65_CPSW_DL_PARAM_SWITCH_MODE)
-		return -EOPNOTSUPP;
-
-	ctx->val.vbool = !common->is_emac_mode;
-
-	return 0;
-}
-
-static void am65_cpsw_init_port_emac_ale(struct  am65_cpsw_port *port)
-{
-	struct am65_cpsw_slave_data *slave = &port->slave;
-	struct am65_cpsw_common *common = port->common;
-	u32 port_mask;
-
-	writel(slave->port_vlan, port->port_base + AM65_CPSW_PORT_VLAN_REG_OFFSET);
-
-	if (slave->mac_only)
-		/* enable mac-only mode on port */
-		cpsw_ale_control_set(common->ale, port->port_id,
-				     ALE_PORT_MACONLY, 1);
-
-	cpsw_ale_control_set(common->ale, port->port_id, ALE_PORT_NOLEARN, 1);
-
-	port_mask = BIT(port->port_id) | ALE_PORT_HOST;
-
-	cpsw_ale_add_ucast(common->ale, port->ndev->dev_addr,
-			   HOST_PORT_NUM, ALE_SECURE, slave->port_vlan);
-	cpsw_ale_add_mcast(common->ale, port->ndev->broadcast,
-			   port_mask, ALE_VLAN, slave->port_vlan, ALE_MCAST_FWD_2);
-}
-
-static void am65_cpsw_init_port_switch_ale(struct am65_cpsw_port *port)
-{
-	struct am65_cpsw_slave_data *slave = &port->slave;
-	struct am65_cpsw_common *cpsw = port->common;
-	u32 port_mask;
-
-	cpsw_ale_control_set(cpsw->ale, port->port_id,
-			     ALE_PORT_NOLEARN, 0);
-
-	cpsw_ale_add_ucast(cpsw->ale, port->ndev->dev_addr,
-			   HOST_PORT_NUM, ALE_SECURE | ALE_BLOCKED | ALE_VLAN,
-			   slave->port_vlan);
-
-	port_mask = BIT(port->port_id) | ALE_PORT_HOST;
-
-	cpsw_ale_add_mcast(cpsw->ale, port->ndev->broadcast,
-			   port_mask, ALE_VLAN, slave->port_vlan,
-			   ALE_MCAST_FWD_2);
-
-	writel(slave->port_vlan, port->port_base + AM65_CPSW_PORT_VLAN_REG_OFFSET);
-
-	cpsw_ale_control_set(cpsw->ale, port->port_id,
-			     ALE_PORT_MACONLY, 0);
-}
-
-static int am65_cpsw_dl_switch_mode_set(struct devlink *dl, u32 id,
-					struct devlink_param_gset_ctx *ctx)
-{
-	struct am65_cpsw_devlink *dl_priv = devlink_priv(dl);
-	struct am65_cpsw_common *cpsw = dl_priv->common;
-	bool switch_en = ctx->val.vbool;
-	bool if_running = false;
-	int i;
-
-	dev_dbg(cpsw->dev, "%s id:%u\n", __func__, id);
-
-	if (id != AM65_CPSW_DL_PARAM_SWITCH_MODE)
-		return -EOPNOTSUPP;
-
-	if (switch_en == !cpsw->is_emac_mode)
-		return 0;
-
-	if (!switch_en && cpsw->br_members) {
-		dev_err(cpsw->dev, "Remove ports from bridge before disabling switch mode\n");
-		return -EINVAL;
-	}
-
-	rtnl_lock();
-
-	cpsw->is_emac_mode = !switch_en;
-
-	for (i = 0; i < cpsw->port_num; i++) {
-		struct net_device *sl_ndev = cpsw->ports[i].ndev;
-
-		if (!sl_ndev || !netif_running(sl_ndev))
-			continue;
-
-		if_running = true;
-	}
-
-	if (!if_running) {
-		/* all ndevs are down */
-		for (i = 0; i < cpsw->port_num; i++) {
-			struct net_device *sl_ndev = cpsw->ports[i].ndev;
-			struct am65_cpsw_slave_data *slave;
-
-			if (!sl_ndev)
-				continue;
-
-			slave = am65_ndev_to_slave(sl_ndev);
-			if (switch_en)
-				slave->port_vlan = cpsw->default_vlan;
-			else
-				slave->port_vlan = 0;
-		}
-
-		goto exit;
-	}
-
-	cpsw_ale_control_set(cpsw->ale, 0, ALE_BYPASS, 1);
-	/* clean up ALE table */
-	cpsw_ale_control_set(cpsw->ale, HOST_PORT_NUM, ALE_CLEAR, 1);
-	cpsw_ale_control_get(cpsw->ale, HOST_PORT_NUM, ALE_AGEOUT);
-
-	if (switch_en) {
-		dev_info(cpsw->dev, "Enable switch mode\n");
-
-		am65_cpsw_init_host_port_switch(cpsw);
-
-		for (i = 0; i < cpsw->port_num; i++) {
-			struct net_device *sl_ndev = cpsw->ports[i].ndev;
-			struct am65_cpsw_slave_data *slave;
-			struct am65_cpsw_port *port;
-
-			if (!sl_ndev)
-				continue;
-
-			port = am65_ndev_to_port(sl_ndev);
-			slave = am65_ndev_to_slave(sl_ndev);
-			slave->port_vlan = cpsw->default_vlan;
-
-			if (netif_running(sl_ndev))
-				am65_cpsw_init_port_switch_ale(port);
-		}
-
-	} else {
-		dev_info(cpsw->dev, "Disable switch mode\n");
-
-		am65_cpsw_init_host_port_emac(cpsw);
-
-		for (i = 0; i < cpsw->port_num; i++) {
-			struct net_device *sl_ndev = cpsw->ports[i].ndev;
-			struct am65_cpsw_port *port;
-
-			if (!sl_ndev)
-				continue;
-
-			port = am65_ndev_to_port(sl_ndev);
-			port->slave.port_vlan = 0;
-			if (netif_running(sl_ndev)) {
-				am65_cpsw_init_port_emac_ale(port);
-				am65_cpsw_qos_cut_thru_cleanup(port);
-			}
-		}
-	}
-	cpsw_ale_control_set(cpsw->ale, HOST_PORT_NUM, ALE_BYPASS, 0);
-exit:
-	rtnl_unlock();
-
-	return 0;
-}
-
-static const struct devlink_param am65_cpsw_devlink_params[] = {
-	DEVLINK_PARAM_DRIVER(AM65_CPSW_DL_PARAM_SWITCH_MODE, "switch_mode",
-			     DEVLINK_PARAM_TYPE_BOOL,
-			     BIT(DEVLINK_PARAM_CMODE_RUNTIME),
-			     am65_cpsw_dl_switch_mode_get,
-			     am65_cpsw_dl_switch_mode_set, NULL),
-};
-
-static void am65_cpsw_unregister_devlink_ports(struct am65_cpsw_common *common)
-{
-	struct devlink_port *dl_port;
-	struct am65_cpsw_port *port;
-	int i;
-
-	for (i = 1; i <= common->port_num; i++) {
-		port = am65_common_get_port(common, i);
-		dl_port = &port->devlink_port;
-
-		if (dl_port->registered)
-			devlink_port_unregister(dl_port);
-	}
-}
-
-static int am65_cpsw_nuss_register_devlink(struct am65_cpsw_common *common)
-{
-	struct devlink_port_attrs attrs = {};
-	struct am65_cpsw_devlink *dl_priv;
 	struct device *dev = common->dev;
-	struct devlink_port *dl_port;
 	struct am65_cpsw_port *port;
 	int ret = 0;
-	int i;
-
-	common->devlink =
-		devlink_alloc(&am65_cpsw_devlink_ops, sizeof(*dl_priv));
-	if (!common->devlink)
-		return -ENOMEM;
-
-	dl_priv = devlink_priv(common->devlink);
-	dl_priv->common = common;
-
-	ret = devlink_register(common->devlink, dev);
-	if (ret) {
-		dev_err(dev, "devlink reg fail ret:%d\n", ret);
-		goto dl_free;
-	}
-
-	/* Provide devlink hook to switch mode when multiple external ports
-	 * are present NUSS switchdev driver is enabled.
-	 */
-	if (!AM65_CPSW_IS_CPSW2G(common) &&
-	    IS_ENABLED(CONFIG_TI_K3_AM65_CPSW_SWITCHDEV)) {
-		ret = devlink_params_register(common->devlink,
-					      am65_cpsw_devlink_params,
-					      ARRAY_SIZE(am65_cpsw_devlink_params));
-		if (ret) {
-			dev_err(dev, "devlink params reg fail ret:%d\n", ret);
-			goto dl_unreg;
-		}
-		devlink_params_publish(common->devlink);
-	}
-
-	for (i = 1; i <= common->port_num; i++) {
-		port = am65_common_get_port(common, i);
-		dl_port = &port->devlink_port;
-
-		attrs.flavour = DEVLINK_PORT_FLAVOUR_PHYSICAL;
-		attrs.phys.port_number = port->port_id;
-		attrs.switch_id.id_len = sizeof(resource_size_t);
-		memcpy(attrs.switch_id.id, common->switch_id, attrs.switch_id.id_len);
-		devlink_port_attrs_set(dl_port, &attrs);
-
-		ret = devlink_port_register(common->devlink, dl_port, port->port_id);
-		if (ret) {
-			dev_err(dev, "devlink_port reg fail for port %d, ret:%d\n",
-				port->port_id, ret);
-			goto dl_port_unreg;
-		}
-		devlink_port_type_eth_set(dl_port, port->ndev);
-	}
-
-	return ret;
-
-dl_port_unreg:
-	am65_cpsw_unregister_devlink_ports(common);
-dl_unreg:
-	devlink_unregister(common->devlink);
-dl_free:
-	devlink_free(common->devlink);
-
-	return ret;
-}
-
-static void am65_cpsw_unregister_devlink(struct am65_cpsw_common *common)
-{
-	if (!AM65_CPSW_IS_CPSW2G(common) &&
-	    IS_ENABLED(CONFIG_TI_K3_AM65_CPSW_SWITCHDEV)) {
-		devlink_params_unpublish(common->devlink);
-		devlink_params_unregister(common->devlink, am65_cpsw_devlink_params,
-					  ARRAY_SIZE(am65_cpsw_devlink_params));
-	}
-
-	am65_cpsw_unregister_devlink_ports(common);
-	devlink_unregister(common->devlink);
-	devlink_free(common->devlink);
-}
-
-static int am65_cpsw_nuss_register_ndevs(struct am65_cpsw_common *common)
-{
-	struct device *dev = common->dev;
-	struct am65_cpsw_port *port;
-	int ret = 0, i;
 
-	ret = am65_cpsw_nuss_ndev_add_tx_napi(common);
+	port = am65_common_get_port(common, 1);
+	ret = am65_cpsw_nuss_ndev_add_napi_2g(common);
 	if (ret)
-		return ret;
+		goto err;
 
 	ret = devm_request_irq(dev, common->rx_chns.irq,
 			       am65_cpsw_nuss_rx_irq,
@@ -2617,45 +1949,17 @@ static int am65_cpsw_nuss_register_ndevs(struct am65_cpsw_common *common)
 	if (ret) {
 		dev_err(dev, "failure requesting rx irq %u, %d\n",
 			common->rx_chns.irq, ret);
-		return ret;
-	}
-
-	for (i = 0; i < common->port_num; i++) {
-		port = &common->ports[i];
-
-		ret = am65_cpsw_nuss_register_port_debugfs(port);
-		if (ret)
-			goto err_cleanup_ndev;
-
-		if (!port->ndev)
-			continue;
-
-		ret = register_netdev(port->ndev);
-		if (ret) {
-			dev_err(dev, "error registering slave net device%i %d\n",
-				i, ret);
-			goto err_cleanup_ndev;
-		}
+		goto err;
 	}
 
-	ret = am65_cpsw_register_notifiers(common);
+	ret = register_netdev(port->ndev);
 	if (ret)
-		goto err_cleanup_ndev;
-
-	ret = am65_cpsw_nuss_register_devlink(common);
-	if (ret)
-		goto clean_unregister_notifiers;
+		dev_err(dev, "error registering slave net device %d\n", ret);
 
 	/* can't auto unregister ndev using devm_add_action() due to
 	 * devres release sequence in DD core for DMA
 	 */
-
-	return 0;
-clean_unregister_notifiers:
-	am65_cpsw_unregister_notifiers(common);
-err_cleanup_ndev:
-	am65_cpsw_nuss_cleanup_ndev(common);
-
+err:
 	return ret;
 }
 
@@ -2668,7 +1972,19 @@ int am65_cpsw_nuss_update_tx_chns(struct am65_cpsw_common *common, int num_tx)
 	if (ret)
 		return ret;
 
-	return am65_cpsw_nuss_ndev_add_tx_napi(common);
+	return am65_cpsw_nuss_ndev_add_napi_2g(common);
+}
+
+static void am65_cpsw_nuss_cleanup_ndev(struct am65_cpsw_common *common)
+{
+	struct am65_cpsw_port *port;
+	int i;
+
+	for (i = 0; i < common->port_num; i++) {
+		port = &common->ports[i];
+		if (port->ndev)
+			unregister_netdev(port->ndev);
+	}
 }
 
 struct am65_cpsw_soc_pdata {
@@ -2689,26 +2005,15 @@ static const struct soc_device_attribute am65_cpsw_socinfo[] = {
 
 static const struct am65_cpsw_pdata am65x_sr1_0 = {
 	.quirks = AM65_CPSW_QUIRK_I2027_NO_TX_CSUM,
-	.ale_dev_id = "am65x-cpsw2g",
-	.fdqring_mode = K3_RINGACC_RING_MODE_MESSAGE,
 };
 
 static const struct am65_cpsw_pdata j721e_pdata = {
 	.quirks = 0,
-	.ale_dev_id = "am65x-cpsw2g",
-	.fdqring_mode = K3_RINGACC_RING_MODE_MESSAGE,
-};
-
-static const struct am65_cpsw_pdata am64x_cpswxg_pdata = {
-	.quirks = AM64_CPSW_QUIRK_CUT_THRU,
-	.ale_dev_id = "am64-cpswxg",
-	.fdqring_mode = K3_RINGACC_RING_MODE_RING,
 };
 
 static const struct of_device_id am65_cpsw_nuss_of_mtable[] = {
 	{ .compatible = "ti,am654-cpsw-nuss", .data = &am65x_sr1_0},
 	{ .compatible = "ti,j721e-cpsw-nuss", .data = &j721e_pdata},
-	{ .compatible = "ti,am642-cpsw-nuss", .data = &am64x_cpswxg_pdata},
 	{ /* sentinel */ },
 };
 MODULE_DEVICE_TABLE(of, am65_cpsw_nuss_of_mtable);
@@ -2735,7 +2040,6 @@ static int am65_cpsw_nuss_probe(struct platform_device *pdev)
 	struct device_node *node;
 	struct resource *res;
 	struct clk *clk;
-	u64 id_temp;
 	int ret, i;
 
 	common = devm_kzalloc(dev, sizeof(struct am65_cpsw_common), GFP_KERNEL);
@@ -2755,9 +2059,6 @@ static int am65_cpsw_nuss_probe(struct platform_device *pdev)
 	if (IS_ERR(common->ss_base))
 		return PTR_ERR(common->ss_base);
 	common->cpsw_base = common->ss_base + AM65_CPSW_CPSW_NU_BASE;
-	/* Use device's physical base address as switch id */
-	id_temp = cpu_to_be64(res->start);
-	memcpy(common->switch_id, &id_temp, sizeof(res->start));
 
 	node = of_get_child_by_name(dev->of_node, "ethernet-ports");
 	if (!node)
@@ -2767,11 +2068,19 @@ static int am65_cpsw_nuss_probe(struct platform_device *pdev)
 		return -ENOENT;
 	of_node_put(node);
 
+	if (common->port_num != 1)
+		return -EOPNOTSUPP;
+
 	common->rx_flow_id_base = -1;
 	init_completion(&common->tdown_complete);
 	common->tx_ch_num = 1;
 	common->pf_p0_rx_ptype_rrobin = false;
-	common->default_vlan = 1;
+
+	ret = dma_coerce_mask_and_coherent(dev, DMA_BIT_MASK(48));
+	if (ret) {
+		dev_err(dev, "error setting dma mask: %d\n", ret);
+		return ret;
+	}
 
 	common->ports = devm_kcalloc(dev, common->port_num,
 				     sizeof(*common->ports),
@@ -2780,8 +2089,13 @@ static int am65_cpsw_nuss_probe(struct platform_device *pdev)
 		return -ENOMEM;
 
 	clk = devm_clk_get(dev, "fck");
-	if (IS_ERR(clk))
-		return dev_err_probe(dev, PTR_ERR(clk), "getting fck clock\n");
+	if (IS_ERR(clk)) {
+		ret = PTR_ERR(clk);
+
+		if (ret != -EPROBE_DEFER)
+			dev_err(dev, "error getting fck clock %d\n", ret);
+		return ret;
+	}
 	common->bus_freq = clk_get_rate(clk);
 
 	pm_runtime_enable(dev);
@@ -2831,7 +2145,7 @@ static int am65_cpsw_nuss_probe(struct platform_device *pdev)
 	ale_params.ale_ageout = AM65_CPSW_ALE_AGEOUT_DEFAULT;
 	ale_params.ale_ports = common->port_num + 1;
 	ale_params.ale_regs = common->cpsw_base + AM65_CPSW_NU_ALE_BASE;
-	ale_params.dev_id = common->pdata.ale_dev_id;
+	ale_params.dev_id = "am65x-cpsw2g";
 	ale_params.bus_freq = common->bus_freq;
 
 	common->ale = cpsw_ale_create(&ale_params);
@@ -2851,22 +2165,14 @@ static int am65_cpsw_nuss_probe(struct platform_device *pdev)
 
 	dev_set_drvdata(dev, common);
 
-	common->is_emac_mode = true;
-
-	ret = am65_cpsw_nuss_init_ndevs(common);
+	ret = am65_cpsw_nuss_init_ndev_2g(common);
 	if (ret)
 		goto err_of_clear;
 
-	ret = am65_cpsw_nuss_register_debugfs(common);
+	ret = am65_cpsw_nuss_ndev_reg_2g(common);
 	if (ret)
 		goto err_of_clear;
 
-	ret = am65_cpsw_nuss_register_ndevs(common);
-	if (ret) {
-		am65_cpsw_nuss_unregister_debugfs(common);
-		goto err_of_clear;
-	}
-
 	pm_runtime_put(dev);
 	return 0;
 
@@ -2892,9 +2198,6 @@ static int am65_cpsw_nuss_remove(struct platform_device *pdev)
 		return ret;
 	}
 
-	am65_cpsw_unregister_devlink(common);
-	am65_cpsw_unregister_notifiers(common);
-
 	/* must unregister ndevs here because DD release_driver routine calls
 	 * dma_deconfigure(dev) before devres_release_all(dev)
 	 */
diff --git a/drivers/net/ethernet/ti/am65-cpsw-nuss.h b/drivers/net/ethernet/ti/am65-cpsw-nuss.h
index 3aea4a3d73e1..993e1d4d3222 100644
--- a/drivers/net/ethernet/ti/am65-cpsw-nuss.h
+++ b/drivers/net/ethernet/ti/am65-cpsw-nuss.h
@@ -6,15 +6,11 @@
 #ifndef AM65_CPSW_NUSS_H_
 #define AM65_CPSW_NUSS_H_
 
-#include <linux/debugfs.h>
-#include <linux/if_ether.h>
 #include <linux/kernel.h>
 #include <linux/module.h>
 #include <linux/netdevice.h>
 #include <linux/phy.h>
 #include <linux/platform_device.h>
-#include <linux/soc/ti/k3-ringacc.h>
-#include <net/devlink.h>
 #include "am65-cpsw-qos.h"
 
 struct am65_cpts;
@@ -25,8 +21,6 @@ struct am65_cpts;
 #define AM65_CPSW_MAX_RX_QUEUES	1
 #define AM65_CPSW_MAX_RX_FLOWS	1
 
-#define AM65_CPSW_PORT_VLAN_REG_OFFSET	0x014
-
 struct am65_cpsw_slave_data {
 	bool				mac_only;
 	struct cpsw_sl			*mac_sl;
@@ -37,7 +31,6 @@ struct am65_cpsw_slave_data {
 	bool				rx_pause;
 	bool				tx_pause;
 	u8				mac_addr[ETH_ALEN];
-	int				port_vlan;
 };
 
 struct am65_cpsw_port {
@@ -53,8 +46,6 @@ struct am65_cpsw_port {
 	bool				tx_ts_enabled;
 	bool				rx_ts_enabled;
 	struct am65_cpsw_qos		qos;
-	struct devlink_port		devlink_port;
-	struct dentry			*debugfs_port;
 };
 
 struct am65_cpsw_host {
@@ -64,24 +55,18 @@ struct am65_cpsw_host {
 };
 
 struct am65_cpsw_tx_chn {
-	struct device *dma_dev;
 	struct napi_struct napi_tx;
 	struct am65_cpsw_common	*common;
 	struct k3_cppi_desc_pool *desc_pool;
 	struct k3_udma_glue_tx_channel *tx_chn;
-	spinlock_t lock; /* protect TX rings in multi-port mode */
-	struct hrtimer tx_hrtimer;
-	unsigned long tx_pace_timeout;
 	int irq;
 	u32 id;
 	u32 descs_num;
 	char tx_chn_name[128];
-	u32  rate_mbps;
 };
 
 struct am65_cpsw_rx_chn {
 	struct device *dev;
-	struct device *dma_dev;
 	struct k3_cppi_desc_pool *desc_pool;
 	struct k3_udma_glue_rx_channel *rx_chn;
 	u32 descs_num;
@@ -89,21 +74,9 @@ struct am65_cpsw_rx_chn {
 };
 
 #define AM65_CPSW_QUIRK_I2027_NO_TX_CSUM BIT(0)
-#define AM64_CPSW_QUIRK_CUT_THRU BIT(1)
 
 struct am65_cpsw_pdata {
 	u32	quirks;
-	enum k3_ring_mode fdqring_mode;
-	const char	*ale_dev_id;
-};
-
-enum cpsw_devlink_param_id {
-	AM65_CPSW_DEVLINK_PARAM_ID_BASE = DEVLINK_PARAM_GENERIC_ID_MAX,
-	AM65_CPSW_DL_PARAM_SWITCH_MODE,
-};
-
-struct am65_cpsw_devlink {
-	struct am65_cpsw_common *common;
 };
 
 struct am65_cpsw_common {
@@ -118,12 +91,10 @@ struct am65_cpsw_common {
 	struct am65_cpsw_host   host;
 	struct am65_cpsw_port	*ports;
 	u32			disabled_ports_mask;
-	struct net_device	*dma_ndev;
 
 	int			usage_count; /* number of opened ports */
 	struct cpsw_ale		*ale;
 	int			tx_ch_num;
-	u32			tx_ch_rate_msk;
 	u32			rx_flow_id_base;
 
 	struct am65_cpsw_tx_chn	tx_chns[AM65_CPSW_MAX_TX_QUEUES];
@@ -132,9 +103,6 @@ struct am65_cpsw_common {
 
 	struct am65_cpsw_rx_chn	rx_chns;
 	struct napi_struct	napi_rx;
-	bool			rx_irq_disabled;
-	struct hrtimer rx_hrtimer;
-	unsigned long rx_pace_timeout;
 
 	u32			nuss_ver;
 	u32			cpsw_ver;
@@ -142,18 +110,6 @@ struct am65_cpsw_common {
 	bool			pf_p0_rx_ptype_rrobin;
 	struct am65_cpts	*cpts;
 	int			est_enabled;
-	int			iet_enabled;
-	unsigned int		cut_thru_enabled;
-
-	bool		is_emac_mode;
-	u16			br_members;
-	int			default_vlan;
-	struct devlink *devlink;
-	struct net_device *hw_bridge_dev;
-	struct notifier_block am65_cpsw_netdevice_nb;
-	unsigned char switch_id[MAX_PHYS_ITEM_ID_LEN];
-
-	struct dentry		*debugfs_root;
 };
 
 struct am65_cpsw_ndev_stats {
@@ -168,7 +124,6 @@ struct am65_cpsw_ndev_priv {
 	u32			msg_enable;
 	struct am65_cpsw_port	*port;
 	struct am65_cpsw_ndev_stats __percpu *stats;
-	bool offload_fwd_mark;
 };
 
 #define am65_ndev_to_priv(ndev) \
@@ -196,10 +151,4 @@ void am65_cpsw_nuss_set_p0_ptype(struct am65_cpsw_common *common);
 void am65_cpsw_nuss_remove_tx_chns(struct am65_cpsw_common *common);
 int am65_cpsw_nuss_update_tx_chns(struct am65_cpsw_common *common, int num_tx);
 
-bool am65_cpsw_port_dev_check(const struct net_device *dev);
-
-int am65_cpsw_nuss_register_port_debugfs(struct am65_cpsw_port *port);
-int am65_cpsw_nuss_register_debugfs(struct am65_cpsw_common *common);
-void am65_cpsw_nuss_unregister_debugfs(struct am65_cpsw_common *common);
-
 #endif /* AM65_CPSW_NUSS_H_ */
diff --git a/drivers/net/ethernet/ti/am65-cpsw-qos.c b/drivers/net/ethernet/ti/am65-cpsw-qos.c
index 3c1068175df3..3bdd4dbcd2ff 100644
--- a/drivers/net/ethernet/ti/am65-cpsw-qos.c
+++ b/drivers/net/ethernet/ti/am65-cpsw-qos.c
@@ -4,10 +4,8 @@
  *
  * quality of service module includes:
  * Enhanced Scheduler Traffic (EST - P802.1Qbv/D2.2)
- * Interspersed Express Traffic (IET - P802.3br/D2.0)
  */
 
-#include <linux/bitfield.h>
 #include <linux/pm_runtime.h>
 #include <linux/time.h>
 
@@ -16,29 +14,14 @@
 #include "am65-cpts.h"
 
 #define AM65_CPSW_REG_CTL			0x004
-#define AM65_CPSW_REG_FREQ			0x05c
 #define AM65_CPSW_PN_REG_CTL			0x004
-#define AM65_CPSW_PN_REG_MAX_BLKS		0x008
-#define AM65_CPSW_PN_REG_TX_PRI_MAP		0x018
-#define AM65_CPSW_PN_REG_RX_PRI_MAP		0x020
-#define AM65_CPSW_PN_REG_IET_CTRL		0x040
-#define AM65_CPSW_PN_REG_IET_STATUS		0x044
-#define AM65_CPSW_PN_REG_IET_VERIFY		0x048
 #define AM65_CPSW_PN_REG_FIFO_STATUS		0x050
 #define AM65_CPSW_PN_REG_EST_CTL		0x060
-#define AM65_CPSW_PN_REG_PRI_CIR(pri)		(0x140 + 4 * (pri))
-#define AM65_CPSW_PN_REG_PRI_EIR(pri)		(0x160 + 4 * (pri))
-
-#define AM64_CPSW_PN_CUT_THRU			0x3C0
-#define AM64_CPSW_PN_SPEED			0x3C4
 
 /* AM65_CPSW_REG_CTL register fields */
-#define AM65_CPSW_CTL_IET_EN			BIT(17)
 #define AM65_CPSW_CTL_EST_EN			BIT(18)
-#define AM64_CPSW_CTL_CUT_THRU_EN		BIT(19)
 
 /* AM65_CPSW_PN_REG_CTL register fields */
-#define AM65_CPSW_PN_CTL_IET_PORT_EN		BIT(16)
 #define AM65_CPSW_PN_CTL_EST_PORT_EN		BIT(17)
 
 /* AM65_CPSW_PN_REG_EST_CTL register fields */
@@ -49,25 +32,6 @@
 #define AM65_CPSW_PN_EST_ONEPRI			BIT(4)
 #define AM65_CPSW_PN_EST_TS_PRI_MSK		GENMASK(7, 5)
 
-/* AM65_CPSW_PN_REG_IET_CTRL register fields */
-#define AM65_CPSW_PN_IET_MAC_PENABLE		BIT(0)
-#define AM65_CPSW_PN_IET_MAC_DISABLEVERIFY	BIT(2)
-#define AM65_CPSW_PN_IET_MAC_LINKFAIL		BIT(3)
-#define AM65_CPSW_PN_IET_PREMPT_MASK		GENMASK(23, 16)
-#define AM65_CPSW_PN_IET_PREMPT_OFFSET		16
-
-/* AM65_CPSW_PN_REG_IET_STATUS register fields */
-#define AM65_CPSW_PN_MAC_VERIFIED		BIT(0)
-#define AM65_CPSW_PN_MAC_VERIFY_FAIL		BIT(1)
-#define AM65_CPSW_PN_MAC_RESPOND_ERR		BIT(2)
-#define AM65_CPSW_PN_MAC_VERIFY_ERR		BIT(3)
-
-/* AM65_CPSW_PN_REG_IET_VERIFY register fields */
-/* 10 msec converted to NSEC */
-#define AM65_CPSW_IET_VERIFY_CNT_MS		(10)
-#define AM65_CPSW_IET_VERIFY_CNT_NS		(AM65_CPSW_IET_VERIFY_CNT_MS * \
-						 NSEC_PER_MSEC)
-
 /* AM65_CPSW_PN_REG_FIFO_STATUS register fields */
 #define AM65_CPSW_PN_FST_TX_PRI_ACTIVE_MSK	GENMASK(7, 0)
 #define AM65_CPSW_PN_FST_TX_E_MAC_ALLOW_MSK	GENMASK(15, 8)
@@ -83,255 +47,12 @@
 #define AM65_CPSW_FETCH_ALLOW_MSK		GENMASK(7, 0)
 #define AM65_CPSW_FETCH_ALLOW_MAX		AM65_CPSW_FETCH_ALLOW_MSK
 
-/* Cut-Thru AM64_CPSW_PN_CUT_THRU */
-#define  AM64_PN_CUT_THRU_TX_PRI		GENMASK(7, 0)
-#define  AM64_PN_CUT_THRU_RX_PRI		GENMASK(15, 8)
-
-/* Cut-Thru AM64_CPSW_PN_SPEED */
-#define  AM64_PN_SPEED_VAL			GENMASK(3, 0)
-#define  AM64_PN_SPEED_AUTO_EN			BIT(8)
-#define  AM64_PN_AUTO_SPEED			GENMASK(15, 12)
-
-/* AM65_CPSW_PN_REG_MAX_BLKS fields for IET and No IET cases */
-/* 7 blocks for pn_rx_max_blks, 13 for pn_tx_max_blks*/
-#define AM65_CPSW_PN_TX_RX_MAX_BLKS_IET		0xD07
-#define AM65_CPSW_PN_TX_RX_MAX_BLKS_DEFAULT	0x1004
-
 enum timer_act {
 	TACT_PROG,		/* need program timer */
 	TACT_NEED_STOP,		/* need stop first */
 	TACT_SKIP_PROG,		/* just buffer can be updated */
 };
 
-/* number of traffic classes (fifos) per port */
-#define AM65_CPSW_PN_TC_NUM			8
-#define AM65_CPSW_PN_TX_PRI_MAP_DEF			0x76543210
-
-static int am65_cpsw_mqprio_setup(struct net_device *ndev, void *type_data);
-
-/* Fetch command count it's number of bytes in Gigabit mode or nibbles in
- * 10/100Mb mode. So, having speed and time in ns, recalculate ns to number of
- * bytes/nibbles that can be sent while transmission on given speed.
- */
-static int am65_est_cmd_ns_to_cnt(u64 ns, int link_speed)
-{
-	u64 temp;
-
-	temp = ns * link_speed;
-	if (link_speed < SPEED_1000)
-		temp <<= 1;
-
-	return DIV_ROUND_UP(temp, 8 * 1000);
-}
-
-/* IET */
-
-static void am65_cpsw_iet_enable(struct am65_cpsw_common *common)
-{
-	int common_enable = 0;
-	u32 val;
-	int i;
-
-	for (i = 0; i < common->port_num; i++)
-		common_enable |= !!common->ports[i].qos.iet.mask;
-
-	val = readl(common->cpsw_base + AM65_CPSW_REG_CTL);
-
-	if (common_enable)
-		val |= AM65_CPSW_CTL_IET_EN;
-	else
-		val &= ~AM65_CPSW_CTL_IET_EN;
-
-	writel(val, common->cpsw_base + AM65_CPSW_REG_CTL);
-	common->iet_enabled = common_enable;
-}
-
-static void am65_cpsw_port_iet_enable(struct am65_cpsw_port *port,
-				      u32 mask)
-{
-	u32 val;
-
-	val = readl(port->port_base + AM65_CPSW_PN_REG_CTL);
-	if (mask)
-		val |= AM65_CPSW_PN_CTL_IET_PORT_EN;
-	else
-		val &= ~AM65_CPSW_PN_CTL_IET_PORT_EN;
-
-	writel(val, port->port_base + AM65_CPSW_PN_REG_CTL);
-	port->qos.iet.mask = mask;
-}
-
-static int am65_cpsw_iet_verify(struct am65_cpsw_port *port)
-{
-	int try;
-	u32 val;
-
-	netdev_info(port->ndev, "Starting IET/FPE MAC Verify\n");
-	/* Set verify timeout depending on link speed. It is 10 msec
-	 * in wireside clocks
-	 */
-	val = am65_est_cmd_ns_to_cnt(AM65_CPSW_IET_VERIFY_CNT_NS,
-				     port->qos.link_speed);
-	writel(val, port->port_base + AM65_CPSW_PN_REG_IET_VERIFY);
-
-	/* By experiment, keep this about 20 * 50 msec = 1000 msec.
-	 * Usually succeeds in one try. But at times it takes more
-	 * attempts especially at initial boot. Try for 20 times
-	 * before give up
-	 */
-	try = 20;
-	do {
-		/* Enable IET Preemption for the port and
-		 * reset LINKFAIL bit to start Verify.
-		 */
-		writel(AM65_CPSW_PN_IET_MAC_PENABLE,
-		       port->port_base + AM65_CPSW_PN_REG_IET_CTRL);
-
-		/* Takes 10 msec to complete this in h/w assuming other
-		 * side is already ready. However since both side might
-		 * take variable setup/config time, need to Wait for
-		 * additional time. Chose 50 msec through trials
-		 */
-		msleep(50);
-
-		val = readl(port->port_base + AM65_CPSW_PN_REG_IET_STATUS);
-		if (val & AM65_CPSW_PN_MAC_VERIFIED)
-			break;
-
-		if (val & AM65_CPSW_PN_MAC_VERIFY_FAIL) {
-			netdev_dbg(port->ndev,
-				   "IET MAC verify failed, trying again");
-			/* Reset the verify state machine by writing 1
-			 * to LINKFAIL
-			 */
-			writel(AM65_CPSW_PN_IET_MAC_LINKFAIL,
-			       port->port_base + AM65_CPSW_PN_REG_IET_CTRL);
-		}
-
-		if (val & AM65_CPSW_PN_MAC_RESPOND_ERR) {
-			netdev_err(port->ndev, "IET MAC respond error");
-			return -ENODEV;
-		}
-
-		if (val & AM65_CPSW_PN_MAC_VERIFY_ERR) {
-			netdev_err(port->ndev, "IET MAC verify error");
-			return -ENODEV;
-		}
-
-	} while (try-- > 0);
-
-	if (try <= 0) {
-		netdev_err(port->ndev, "IET MAC Verify/Response timeout");
-		return -ENODEV;
-	}
-
-	netdev_info(port->ndev, "IET/FPE MAC Verify Success\n");
-	return 0;
-}
-
-static void am65_cpsw_iet_config_mac_preempt(struct am65_cpsw_port *port,
-					     bool enable, bool force)
-{
-	struct am65_cpsw_iet *iet = &port->qos.iet;
-	u32 val;
-
-	/* Enable pre-emption queues and force mode if no mac verify */
-	val = 0;
-	if (enable) {
-		if (!force) {
-			/* AM65_CPSW_PN_IET_MAC_PENABLE already
-			 * set as part of MAC Verify. So read
-			 * modify
-			 */
-			val = readl(port->port_base +
-				    AM65_CPSW_PN_REG_IET_CTRL);
-		} else {
-			val |= AM65_CPSW_PN_IET_MAC_PENABLE;
-			val |= AM65_CPSW_PN_IET_MAC_DISABLEVERIFY;
-		}
-		val |= ((iet->fpe_mask_configured <<
-			AM65_CPSW_PN_IET_PREMPT_OFFSET) &
-			AM65_CPSW_PN_IET_PREMPT_MASK);
-	}
-	writel(val, port->port_base + AM65_CPSW_PN_REG_IET_CTRL);
-	iet->fpe_enabled = enable;
-}
-
-static void am65_cpsw_iet_set(struct net_device *ndev)
-{
-	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
-	struct am65_cpsw_common *common = port->common;
-	struct am65_cpsw_iet *iet = &port->qos.iet;
-
-	/* For IET, Change MAX_BLKS */
-	writel(AM65_CPSW_PN_TX_RX_MAX_BLKS_IET,
-	       port->port_base + AM65_CPSW_PN_REG_MAX_BLKS);
-
-	am65_cpsw_port_iet_enable(port, iet->fpe_mask_configured);
-	am65_cpsw_iet_enable(common);
-}
-
-static int am65_cpsw_iet_fpe_enable(struct am65_cpsw_port *port, bool verify)
-{
-	int ret;
-
-	if (verify) {
-		ret = am65_cpsw_iet_verify(port);
-		if (ret)
-			return ret;
-	}
-
-	am65_cpsw_iet_config_mac_preempt(port, true, !verify);
-
-	return 0;
-}
-
-void am65_cpsw_qos_iet_init(struct net_device *ndev)
-{
-	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
-	struct am65_cpsw_common *common = port->common;
-	struct am65_cpsw_iet *iet = &port->qos.iet;
-
-	/* Enable IET FPE only if user has enabled priv flag for iet frame
-	 * preemption.
-	 */
-	if (!iet->fpe_configured) {
-		iet->fpe_mask_configured = 0;
-		return;
-	}
-	/* Use highest priority queue as express queue and others
-	 * as preemptible queues.
-	 */
-	iet->fpe_mask_configured = GENMASK(common->tx_ch_num - 2, 0);
-
-	/* Init work queue for IET MAC verify process */
-	iet->ndev = ndev;
-
-	am65_cpsw_iet_set(ndev);
-}
-
-static void am65_cpsw_iet_fpe_disable(struct am65_cpsw_port *port)
-{
-	struct am65_cpsw_iet *iet = &port->qos.iet;
-
-	am65_cpsw_iet_config_mac_preempt(port, false,
-					 !iet->mac_verify_configured);
-}
-
-void am65_cpsw_qos_iet_cleanup(struct net_device *ndev)
-{
-	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
-	struct am65_cpsw_common *common = am65_ndev_to_common(ndev);
-
-	/* restore MAX_BLKS to default */
-	writel(AM65_CPSW_PN_TX_RX_MAX_BLKS_DEFAULT,
-	       port->port_base + AM65_CPSW_PN_REG_MAX_BLKS);
-
-	am65_cpsw_iet_fpe_disable(port);
-	am65_cpsw_port_iet_enable(port, 0);
-	am65_cpsw_iet_enable(common);
-}
-
 static int am65_cpsw_port_est_enabled(struct am65_cpsw_port *port)
 {
 	return port->qos.est_oper || port->qos.est_admin;
@@ -502,6 +223,21 @@ static void am65_cpsw_est_update_state(struct net_device *ndev)
 	am65_cpsw_admin_to_oper(ndev);
 }
 
+/* Fetch command count it's number of bytes in Gigabit mode or nibbles in
+ * 10/100Mb mode. So, having speed and time in ns, recalculate ns to number of
+ * bytes/nibbles that can be sent while transmission on given speed.
+ */
+static int am65_est_cmd_ns_to_cnt(u64 ns, int link_speed)
+{
+	u64 temp;
+
+	temp = ns * link_speed;
+	if (link_speed < SPEED_1000)
+		temp <<= 1;
+
+	return DIV_ROUND_UP(temp, 8 * 1000);
+}
+
 static void __iomem *am65_cpsw_est_set_sched_cmds(void __iomem *addr,
 						  int fetch_cnt,
 						  int fetch_allow)
@@ -620,7 +356,7 @@ static void am65_cpsw_est_set_sched_list(struct net_device *ndev,
 		writel(~all_fetch_allow & AM65_CPSW_FETCH_ALLOW_MSK, ram_addr);
 }
 
-/*
+/**
  * Enable ESTf periodic output, set cycle start time and interval.
  */
 static int am65_cpsw_timer_set(struct net_device *ndev,
@@ -858,46 +594,18 @@ int am65_cpsw_qos_ndo_setup_tc(struct net_device *ndev, enum tc_setup_type type,
 	switch (type) {
 	case TC_SETUP_QDISC_TAPRIO:
 		return am65_cpsw_setup_taprio(ndev, type_data);
-	case TC_SETUP_QDISC_MQPRIO:
-		return am65_cpsw_mqprio_setup(ndev, type_data);
 	default:
 		return -EOPNOTSUPP;
 	}
 }
 
-static void am65_cpsw_iet_link_up(struct net_device *ndev)
-{
-	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
-	struct am65_cpsw_iet *iet = &port->qos.iet;
-
-	if (!iet->fpe_configured)
-		return;
-
-	/* Schedule MAC Verify and enable IET FPE if configured */
-	if (iet->mac_verify_configured) {
-		am65_cpsw_iet_fpe_enable(port, true);
-	} else {
-		/* Force IET FPE here */
-		netdev_info(ndev, "IET Enable Force mode\n");
-		am65_cpsw_iet_fpe_enable(port, false);
-	}
-}
-
-static void am65_cpsw_cut_thru_link_up(struct am65_cpsw_port *port);
-static void am65_cpsw_tx_pn_shaper_link_up(struct am65_cpsw_port *port);
-
-void am65_cpsw_qos_link_up(struct net_device *ndev, int link_speed, int duplex)
+void am65_cpsw_qos_link_up(struct net_device *ndev, int link_speed)
 {
 	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
 
-	port->qos.link_speed = link_speed;
-	port->qos.duplex = duplex;
-	am65_cpsw_iet_link_up(ndev);
-	am65_cpsw_cut_thru_link_up(port);
-	am65_cpsw_tx_pn_shaper_link_up(port);
-
 	if (!IS_ENABLED(CONFIG_TI_AM65_CPSW_TAS))
 		return;
+
 	am65_cpsw_est_link_up(ndev, link_speed);
 	port->qos.link_down_time = 0;
 }
@@ -906,8 +614,6 @@ void am65_cpsw_qos_link_down(struct net_device *ndev)
 {
 	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
 
-	am65_cpsw_iet_fpe_disable(port);
-
 	if (!IS_ENABLED(CONFIG_TI_AM65_CPSW_TAS))
 		return;
 
@@ -916,536 +622,3 @@ void am65_cpsw_qos_link_down(struct net_device *ndev)
 
 	port->qos.link_speed = SPEED_UNKNOWN;
 }
-
-static void am65_cpsw_cut_thru_dump(struct am65_cpsw_port *port)
-{
-	struct am65_cpsw_common *common = port->common;
-	u32 contro, cut_thru, speed;
-
-	contro = readl(common->cpsw_base + AM65_CPSW_REG_CTL);
-	cut_thru = readl(port->port_base + AM64_CPSW_PN_CUT_THRU);
-	speed = readl(port->port_base + AM64_CPSW_PN_SPEED);
-	dev_dbg(common->dev, "Port%u: cut_thru dump control:%08x cut_thru:%08x hwspeed:%08x\n",
-		port->port_id, contro, cut_thru, speed);
-}
-
-static void am65_cpsw_cut_thru_enable(struct am65_cpsw_common *common)
-{
-	u32 val;
-
-	if (common->cut_thru_enabled) {
-		common->cut_thru_enabled++;
-		return;
-	}
-
-	/* Populate CPSW VBUS freq for auto speed detection */
-	writel(common->bus_freq / 1000000,
-	       common->cpsw_base + AM65_CPSW_REG_FREQ);
-
-	val = readl(common->cpsw_base + AM65_CPSW_REG_CTL);
-	val |= AM64_CPSW_CTL_CUT_THRU_EN;
-	writel(val, common->cpsw_base + AM65_CPSW_REG_CTL);
-	common->cut_thru_enabled++;
-}
-
-void am65_cpsw_qos_cut_thru_init(struct am65_cpsw_port *port)
-{
-	struct am65_cpsw_cut_thru *cut_thru = &port->qos.cut_thru;
-	struct am65_cpsw_common *common = port->common;
-
-	/* Enable cut_thr only if user has enabled priv flag */
-	if (!cut_thru->enable)
-		return;
-
-	if (common->is_emac_mode) {
-		cut_thru->enable = false;
-		dev_info(common->dev, "Disable cut-thru, need Switch mode\n");
-		return;
-	}
-
-	am65_cpsw_cut_thru_enable(common);
-
-	/* en auto speed */
-	writel(AM64_PN_SPEED_AUTO_EN, port->port_base + AM64_CPSW_PN_SPEED);
-	dev_info(common->dev, "Init cut_thru\n");
-	am65_cpsw_cut_thru_dump(port);
-}
-
-static void am65_cpsw_cut_thru_disable(struct am65_cpsw_common *common)
-{
-	u32 val;
-
-	if (--common->cut_thru_enabled)
-		return;
-
-	val = readl(common->cpsw_base + AM65_CPSW_REG_CTL);
-	val &= ~AM64_CPSW_CTL_CUT_THRU_EN;
-	writel(val, common->cpsw_base + AM65_CPSW_REG_CTL);
-}
-
-void am65_cpsw_qos_cut_thru_cleanup(struct am65_cpsw_port *port)
-{
-	struct am65_cpsw_cut_thru *cut_thru = &port->qos.cut_thru;
-	struct am65_cpsw_common *common = port->common;
-
-	if (!cut_thru->enable)
-		return;
-
-	writel(0, port->port_base + AM64_CPSW_PN_CUT_THRU);
-	writel(0, port->port_base + AM64_CPSW_PN_SPEED);
-
-	am65_cpsw_cut_thru_disable(common);
-	dev_info(common->dev, "Cleanup cut_thru\n");
-	am65_cpsw_cut_thru_dump(port);
-}
-
-static u32 am65_cpsw_cut_thru_speed2hw(int link_speed)
-{
-	switch (link_speed) {
-	case SPEED_10:
-		return 1;
-	case SPEED_100:
-		return 2;
-	case SPEED_1000:
-		return 3;
-	default:
-		return 0;
-	}
-}
-
-static void am65_cpsw_cut_thru_link_up(struct am65_cpsw_port *port)
-{
-	struct am65_cpsw_cut_thru *cut_thru = &port->qos.cut_thru;
-	struct am65_cpsw_common *common = port->common;
-	u32 val, speed;
-
-	if (!cut_thru->enable)
-		return;
-
-	writel(AM64_PN_SPEED_AUTO_EN, port->port_base + AM64_CPSW_PN_SPEED);
-	/* barrier */
-	readl(port->port_base + AM64_CPSW_PN_SPEED);
-	/* HW need 15us in 10/100 mode and 3us in 1G mode auto speed detection
-	 * add delay with some margin
-	 */
-	usleep_range(40, 50);
-	val = readl(port->port_base + AM64_CPSW_PN_SPEED);
-	speed = FIELD_GET(AM64_PN_AUTO_SPEED, val);
-	if (!speed) {
-		dev_warn(common->dev,
-			 "Port%u: cut_thru no speed auto detected switch to manual\n",
-			 port->port_id);
-		speed = am65_cpsw_cut_thru_speed2hw(port->qos.link_speed);
-		if (!speed) {
-			dev_err(common->dev,
-				"Port%u: cut_thru speed configuration failed\n",
-				port->port_id);
-			return;
-		}
-		val = FIELD_PREP(AM64_PN_SPEED_VAL, speed);
-		writel(val, port->port_base + AM64_CPSW_PN_SPEED);
-	}
-
-	val = FIELD_PREP(AM64_PN_CUT_THRU_TX_PRI, cut_thru->tx_pri_mask) |
-	      FIELD_PREP(AM64_PN_CUT_THRU_RX_PRI, cut_thru->rx_pri_mask);
-
-	if (port->qos.duplex) {
-		writel(val, port->port_base + AM64_CPSW_PN_CUT_THRU);
-		dev_info(common->dev, "Port%u: Enable cut_thru rx:%08x tx:%08x hwspeed:%u (%08x)\n",
-			 port->port_id,
-			 cut_thru->rx_pri_mask, cut_thru->tx_pri_mask,
-			 speed, val);
-	} else {
-		writel(0, port->port_base + AM64_CPSW_PN_CUT_THRU);
-		dev_info(common->dev, "Port%u: Disable cut_thru duplex=%d\n",
-			 port->port_id, port->qos.duplex);
-	}
-	am65_cpsw_cut_thru_dump(port);
-}
-
-static u32
-am65_cpsw_qos_tx_rate_calc(u32 rate_mbps, unsigned long bus_freq)
-{
-	u32 ir;
-
-	bus_freq /= 1000000;
-	ir = DIV_ROUND_UP(((u64)rate_mbps * 32768),  bus_freq);
-	return ir;
-}
-
-static void
-am65_cpsw_qos_tx_p0_rate_apply(struct am65_cpsw_common *common,
-			       int tx_ch, u32 rate_mbps)
-{
-	struct am65_cpsw_host *host = am65_common_get_host(common);
-	u32 ch_cir;
-	int i;
-
-	ch_cir = am65_cpsw_qos_tx_rate_calc(rate_mbps, common->bus_freq);
-	writel(ch_cir, host->port_base + AM65_CPSW_PN_REG_PRI_CIR(tx_ch));
-
-	/* update rates for every port tx queues */
-	for (i = 0; i < common->port_num; i++) {
-		struct net_device *ndev = common->ports[i].ndev;
-
-		if (!ndev)
-			continue;
-		netdev_get_tx_queue(ndev, tx_ch)->tx_maxrate = rate_mbps;
-	}
-}
-
-int am65_cpsw_qos_ndo_tx_p0_set_maxrate(struct net_device *ndev,
-					int queue, u32 rate_mbps)
-{
-	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
-	struct am65_cpsw_common *common = port->common;
-	struct am65_cpsw_tx_chn *tx_chn;
-	u32 ch_rate, tx_ch_rate_msk_new;
-	u32 ch_msk = 0;
-	int ret;
-
-	dev_dbg(common->dev, "apply TX%d rate limiting %uMbps tx_rate_msk%x\n",
-		queue, rate_mbps, common->tx_ch_rate_msk);
-
-	if (common->pf_p0_rx_ptype_rrobin) {
-		dev_err(common->dev, "TX Rate Limiting failed - rrobin mode\n");
-		return -EINVAL;
-	}
-
-	ch_rate = netdev_get_tx_queue(ndev, queue)->tx_maxrate;
-	if (ch_rate == rate_mbps)
-		return 0;
-
-	ret = pm_runtime_get_sync(common->dev);
-	if (ret < 0) {
-		pm_runtime_put_noidle(common->dev);
-		return ret;
-	}
-	ret = 0;
-
-	tx_ch_rate_msk_new = common->tx_ch_rate_msk;
-	if (rate_mbps && !(tx_ch_rate_msk_new & BIT(queue))) {
-		tx_ch_rate_msk_new |= BIT(queue);
-		ch_msk = GENMASK(common->tx_ch_num - 1, queue);
-		ch_msk = tx_ch_rate_msk_new ^ ch_msk;
-	} else if (!rate_mbps) {
-		tx_ch_rate_msk_new &= ~BIT(queue);
-		ch_msk = queue ? GENMASK(queue - 1, 0) : 0;
-		ch_msk = tx_ch_rate_msk_new & ch_msk;
-	}
-
-	if (ch_msk) {
-		dev_err(common->dev, "TX rate limiting has to be enabled sequentially hi->lo tx_rate_msk:%x tx_rate_msk_new:%x\n",
-			common->tx_ch_rate_msk, tx_ch_rate_msk_new);
-		ret = -EINVAL;
-		goto exit_put;
-	}
-
-	tx_chn = &common->tx_chns[queue];
-	tx_chn->rate_mbps = rate_mbps;
-	common->tx_ch_rate_msk = tx_ch_rate_msk_new;
-
-	if (!common->usage_count)
-		/* will be applied on next netif up */
-		goto exit_put;
-
-	am65_cpsw_qos_tx_p0_rate_apply(common, queue, rate_mbps);
-
-exit_put:
-	pm_runtime_put(common->dev);
-	return ret;
-}
-
-void am65_cpsw_qos_tx_p0_rate_init(struct am65_cpsw_common *common)
-{
-	struct am65_cpsw_host *host = am65_common_get_host(common);
-	int tx_ch;
-
-	for (tx_ch = 0; tx_ch < common->tx_ch_num; tx_ch++) {
-		struct am65_cpsw_tx_chn *tx_chn = &common->tx_chns[tx_ch];
-		u32 ch_cir;
-
-		if (!tx_chn->rate_mbps)
-			continue;
-
-		ch_cir = am65_cpsw_qos_tx_rate_calc(tx_chn->rate_mbps,
-						    common->bus_freq);
-		writel(ch_cir,
-		       host->port_base + AM65_CPSW_PN_REG_PRI_CIR(tx_ch));
-	}
-}
-
-static void am65_cpsw_tx_pn_shaper_apply(struct am65_cpsw_port *port)
-{
-	struct am65_cpsw_mqprio *p_mqprio = &port->qos.mqprio;
-	struct am65_cpsw_common *common = port->common;
-	struct tc_mqprio_qopt_offload *mqprio;
-	bool shaper_en;
-	u32 rate_mbps;
-	int i;
-
-	mqprio = &p_mqprio->mqprio_hw;
-	shaper_en = p_mqprio->shaper_en && !p_mqprio->shaper_susp;
-
-	for (i = 0; i < mqprio->qopt.num_tc; i++) {
-		rate_mbps = 0;
-		if (shaper_en) {
-			rate_mbps = mqprio->min_rate[i] * 8 / 1000000;
-			rate_mbps = am65_cpsw_qos_tx_rate_calc(rate_mbps,
-							       common->bus_freq);
-		}
-
-		writel(rate_mbps,
-		       port->port_base + AM65_CPSW_PN_REG_PRI_CIR(i));
-	}
-
-	for (i = 0; i < mqprio->qopt.num_tc; i++) {
-		rate_mbps = 0;
-		if (shaper_en && mqprio->max_rate[i]) {
-			rate_mbps = mqprio->max_rate[i] - mqprio->min_rate[i];
-			rate_mbps = rate_mbps * 8 / 1000000;
-			rate_mbps = am65_cpsw_qos_tx_rate_calc(rate_mbps,
-							       common->bus_freq);
-		}
-
-		writel(rate_mbps,
-		       port->port_base + AM65_CPSW_PN_REG_PRI_EIR(i));
-	}
-}
-
-static void am65_cpsw_tx_pn_shaper_link_up(struct am65_cpsw_port *port)
-{
-	struct am65_cpsw_mqprio *p_mqprio = &port->qos.mqprio;
-	struct am65_cpsw_common *common = port->common;
-	bool shaper_susp = false;
-
-	if (!p_mqprio->enable || !p_mqprio->shaper_en)
-		return;
-
-	if (p_mqprio->max_rate_total > port->qos.link_speed)
-		shaper_susp = true;
-
-	if (p_mqprio->shaper_susp == shaper_susp)
-		return;
-
-	if (shaper_susp)
-		dev_info(common->dev,
-			 "Port%u: total shaper tx rate > link speed - suspend shaper\n",
-			 port->port_id);
-	else
-		dev_info(common->dev,
-			 "Port%u: link recover - resume shaper\n",
-			 port->port_id);
-
-	p_mqprio->shaper_susp = shaper_susp;
-	am65_cpsw_tx_pn_shaper_apply(port);
-}
-
-void am65_cpsw_qos_mqprio_init(struct am65_cpsw_port *port)
-{
-	struct am65_cpsw_host *host = am65_common_get_host(port->common);
-	struct am65_cpsw_mqprio *p_mqprio = &port->qos.mqprio;
-	struct tc_mqprio_qopt_offload *mqprio = &p_mqprio->mqprio_hw;
-	int i, fifo, rx_prio_map;
-
-	rx_prio_map = readl(host->port_base + AM65_CPSW_PN_REG_RX_PRI_MAP);
-
-	if (p_mqprio->enable) {
-		for (i = 0; i < AM65_CPSW_PN_TC_NUM; i++) {
-			fifo = mqprio->qopt.prio_tc_map[i];
-			p_mqprio->tx_prio_map |= fifo << (4 * i);
-		}
-
-		netdev_set_num_tc(port->ndev, mqprio->qopt.num_tc);
-		for (i = 0; i < mqprio->qopt.num_tc; i++) {
-			netdev_set_tc_queue(port->ndev, i,
-					    mqprio->qopt.count[i],
-					    mqprio->qopt.offset[i]);
-			if (!i) {
-				p_mqprio->tc0_q = mqprio->qopt.offset[i];
-				rx_prio_map &= ~(0x7 << (4 * p_mqprio->tc0_q));
-			}
-		}
-	} else {
-		/* restore default configuration */
-		netdev_reset_tc(port->ndev);
-		p_mqprio->tx_prio_map = AM65_CPSW_PN_TX_PRI_MAP_DEF;
-		rx_prio_map |= p_mqprio->tc0_q << (4 * p_mqprio->tc0_q);
-		p_mqprio->tc0_q = 0;
-	}
-
-	writel(p_mqprio->tx_prio_map,
-	       port->port_base + AM65_CPSW_PN_REG_TX_PRI_MAP);
-	writel(rx_prio_map,
-	       host->port_base + AM65_CPSW_PN_REG_RX_PRI_MAP);
-
-	am65_cpsw_tx_pn_shaper_apply(port);
-}
-
-static int am65_cpsw_mqprio_verify(struct am65_cpsw_port *port,
-				   struct tc_mqprio_qopt_offload *mqprio)
-{
-	int i;
-
-	for (i = 0; i < mqprio->qopt.num_tc; i++) {
-		unsigned int last = mqprio->qopt.offset[i] +
-				    mqprio->qopt.count[i];
-
-		if (mqprio->qopt.offset[i] >= port->ndev->real_num_tx_queues ||
-		    !mqprio->qopt.count[i] ||
-		    last >  port->ndev->real_num_tx_queues)
-			return -EINVAL;
-	}
-
-	return 0;
-}
-
-static int am65_cpsw_mqprio_verify_shaper(struct am65_cpsw_port *port,
-					  struct tc_mqprio_qopt_offload *mqprio,
-					  u64 *max_rate)
-{
-	struct am65_cpsw_common *common = port->common;
-	bool has_min_rate, has_max_rate;
-	u64 min_rate_total = 0, max_rate_total = 0;
-	u32 min_rate_msk = 0, max_rate_msk = 0;
-	int num_tc, i;
-
-	has_min_rate = !!(mqprio->flags & TC_MQPRIO_F_MIN_RATE);
-	has_max_rate = !!(mqprio->flags & TC_MQPRIO_F_MAX_RATE);
-
-	if (!has_min_rate && has_max_rate)
-		return -EOPNOTSUPP;
-
-	if (!has_min_rate)
-		return 0;
-
-	num_tc = mqprio->qopt.num_tc;
-
-	for (i = num_tc - 1; i >= 0; i--) {
-		u32 ch_msk;
-
-		if (mqprio->min_rate[i])
-			min_rate_msk |= BIT(i);
-		min_rate_total +=  mqprio->min_rate[i];
-
-		if (has_max_rate) {
-			if (mqprio->max_rate[i])
-				max_rate_msk |= BIT(i);
-			max_rate_total +=  mqprio->max_rate[i];
-
-			if (!mqprio->min_rate[i] && mqprio->max_rate[i]) {
-				dev_err(common->dev, "TX tc%d rate max>0 but min=0\n",
-					i);
-				return -EINVAL;
-			}
-
-			if (mqprio->max_rate[i] &&
-			    mqprio->max_rate[i] < mqprio->min_rate[i]) {
-				dev_err(common->dev, "TX tc%d rate min(%llu)>max(%llu)\n",
-					i, mqprio->min_rate[i],
-					mqprio->max_rate[i]);
-				return -EINVAL;
-			}
-		}
-
-		ch_msk = GENMASK(num_tc - 1, i);
-		if ((min_rate_msk & BIT(i)) && (min_rate_msk ^ ch_msk)) {
-			dev_err(common->dev, "TX Min rate limiting has to be enabled sequentially hi->lo tx_rate_msk%x\n",
-				min_rate_msk);
-			return -EINVAL;
-		}
-
-		if ((max_rate_msk & BIT(i)) && (max_rate_msk ^ ch_msk)) {
-			dev_err(common->dev, "TX max rate limiting has to be enabled sequentially hi->lo tx_rate_msk%x\n",
-				max_rate_msk);
-			return -EINVAL;
-		}
-	}
-	min_rate_total *= 8;
-	min_rate_total /= 1000 * 1000;
-	max_rate_total *= 8;
-	max_rate_total /= 1000 * 1000;
-
-	if (port->qos.link_speed != SPEED_UNKNOWN) {
-		if (min_rate_total > port->qos.link_speed) {
-			dev_err(common->dev, "TX rate min exceed %llu link speed %d\n",
-				min_rate_total, port->qos.link_speed);
-			return -EINVAL;
-		}
-
-		if (max_rate_total > port->qos.link_speed) {
-			dev_err(common->dev, "TX rate max exceed %llu link speed %d\n",
-				max_rate_total, port->qos.link_speed);
-			return -EINVAL;
-		}
-	}
-
-	*max_rate = max_t(u64, min_rate_total, max_rate_total);
-
-	return 0;
-}
-
-static int am65_cpsw_mqprio_setup(struct net_device *ndev, void *type_data)
-{
-	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
-	struct tc_mqprio_qopt_offload *mqprio = type_data;
-	struct am65_cpsw_common *common = port->common;
-	struct am65_cpsw_mqprio *p_mqprio = &port->qos.mqprio;
-	bool has_min_rate;
-	int num_tc, ret;
-	u64 max_rate;
-
-	if (!mqprio->qopt.hw)
-		goto skip_check;
-
-	if (mqprio->mode != TC_MQPRIO_MODE_CHANNEL)
-		return -EOPNOTSUPP;
-
-	num_tc = mqprio->qopt.num_tc;
-	if (num_tc > AM65_CPSW_PN_TC_NUM)
-		return -ERANGE;
-
-	if ((mqprio->flags & TC_MQPRIO_F_SHAPER) &&
-	    mqprio->shaper != TC_MQPRIO_SHAPER_BW_RATE)
-		return -EOPNOTSUPP;
-
-	ret = am65_cpsw_mqprio_verify(port, mqprio);
-	if (ret)
-		return ret;
-
-	ret = am65_cpsw_mqprio_verify_shaper(port, mqprio, &max_rate);
-	if (ret)
-		return ret;
-
-skip_check:
-	ret = pm_runtime_get_sync(common->dev);
-	if (ret < 0) {
-		pm_runtime_put_noidle(common->dev);
-		return ret;
-	}
-
-	if (mqprio->qopt.hw) {
-		memcpy(&p_mqprio->mqprio_hw, mqprio, sizeof(*mqprio));
-		has_min_rate = !!(mqprio->flags & TC_MQPRIO_F_MIN_RATE);
-		p_mqprio->enable = 1;
-		p_mqprio->shaper_en = has_min_rate;
-		p_mqprio->shaper_susp = !has_min_rate;
-		p_mqprio->max_rate_total = max_rate;
-		p_mqprio->tx_prio_map = 0;
-	} else {
-		unsigned int tc0_q = p_mqprio->tc0_q;
-
-		memset(p_mqprio, 0, sizeof(*p_mqprio));
-		p_mqprio->mqprio_hw.qopt.num_tc = AM65_CPSW_PN_TC_NUM;
-		p_mqprio->tc0_q = tc0_q;
-	}
-
-	if (!netif_running(ndev))
-		goto exit_put;
-
-	am65_cpsw_qos_mqprio_init(port);
-
-exit_put:
-	pm_runtime_put(common->dev);
-	return 0;
-}
diff --git a/drivers/net/ethernet/ti/am65-cpsw-qos.h b/drivers/net/ethernet/ti/am65-cpsw-qos.h
index 0df451772afa..e8f1b6b59e93 100644
--- a/drivers/net/ethernet/ti/am65-cpsw-qos.h
+++ b/drivers/net/ethernet/ti/am65-cpsw-qos.h
@@ -7,10 +7,6 @@
 
 #include <linux/netdevice.h>
 #include <net/pkt_sched.h>
-#include <net/pkt_cls.h>
-
-struct am65_cpsw_port;
-struct am65_cpsw_common;
 
 struct am65_cpsw_est {
 	int buf;
@@ -18,58 +14,16 @@ struct am65_cpsw_est {
 	struct tc_taprio_qopt_offload taprio;
 };
 
-struct am65_cpsw_iet {
-	struct net_device *ndev;
-	/* Set through priv flags */
-	bool fpe_configured;
-	bool mac_verify_configured;
-	/* frame preemption enabled */
-	bool fpe_enabled;
-	/* configured mask */
-	u32 fpe_mask_configured;
-	/* current mask */
-	u32 mask;
-};
-
-struct am65_cpsw_mqprio {
-	struct tc_mqprio_qopt_offload mqprio_hw;
-	u64 max_rate_total;
-	u32 tx_prio_map;
-
-	unsigned enable:1;
-	unsigned shaper_en:1;
-	unsigned shaper_susp:1;
-	unsigned tc0_q:3;
-};
-
-struct am65_cpsw_cut_thru {
-	unsigned int rx_pri_mask;
-	unsigned int tx_pri_mask;
-	bool enable;
-};
-
 struct am65_cpsw_qos {
 	struct am65_cpsw_est *est_admin;
 	struct am65_cpsw_est *est_oper;
 	ktime_t link_down_time;
 	int link_speed;
-	int duplex;
-	struct am65_cpsw_iet iet;
-	struct am65_cpsw_mqprio mqprio;
-	struct am65_cpsw_cut_thru cut_thru;
 };
 
 int am65_cpsw_qos_ndo_setup_tc(struct net_device *ndev, enum tc_setup_type type,
 			       void *type_data);
-void am65_cpsw_qos_link_up(struct net_device *ndev, int link_speed, int duplex);
+void am65_cpsw_qos_link_up(struct net_device *ndev, int link_speed);
 void am65_cpsw_qos_link_down(struct net_device *ndev);
-void am65_cpsw_qos_iet_init(struct net_device *ndev);
-void am65_cpsw_qos_iet_cleanup(struct net_device *ndev);
-void am65_cpsw_qos_cut_thru_init(struct am65_cpsw_port *port);
-void am65_cpsw_qos_cut_thru_cleanup(struct am65_cpsw_port *port);
-int am65_cpsw_qos_ndo_tx_p0_set_maxrate(struct net_device *ndev,
-					int queue, u32 rate_mbps);
-void am65_cpsw_qos_tx_p0_rate_init(struct am65_cpsw_common *common);
-void am65_cpsw_qos_mqprio_init(struct am65_cpsw_port *port);
 
 #endif /* AM65_CPSW_QOS_H_ */
diff --git a/drivers/net/ethernet/ti/am65-cpsw-switchdev.c b/drivers/net/ethernet/ti/am65-cpsw-switchdev.c
deleted file mode 100644
index b9ab087b63ea..000000000000
--- a/drivers/net/ethernet/ti/am65-cpsw-switchdev.c
+++ /dev/null
@@ -1,552 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Texas Instruments K3 AM65 Ethernet Switchdev Driver
- *
- * Copyright (C) 2020 Texas Instruments Incorporated - https://www.ti.com/
- *
- */
-
-#include <linux/etherdevice.h>
-#include <linux/if_bridge.h>
-#include <linux/netdevice.h>
-#include <linux/workqueue.h>
-#include <net/switchdev.h>
-
-#include "am65-cpsw-nuss.h"
-#include "am65-cpsw-switchdev.h"
-#include "cpsw_ale.h"
-
-struct am65_cpsw_switchdev_event_work {
-	struct work_struct work;
-	struct switchdev_notifier_fdb_info fdb_info;
-	struct am65_cpsw_port *port;
-	unsigned long event;
-};
-
-static int am65_cpsw_port_stp_state_set(struct am65_cpsw_port *port,
-					struct switchdev_trans *trans, u8 state)
-{
-	struct am65_cpsw_common *cpsw = port->common;
-	u8 cpsw_state;
-	int ret = 0;
-
-	if (switchdev_trans_ph_prepare(trans))
-		return 0;
-
-	switch (state) {
-	case BR_STATE_FORWARDING:
-		cpsw_state = ALE_PORT_STATE_FORWARD;
-		break;
-	case BR_STATE_LEARNING:
-		cpsw_state = ALE_PORT_STATE_LEARN;
-		break;
-	case BR_STATE_DISABLED:
-		cpsw_state = ALE_PORT_STATE_DISABLE;
-		break;
-	case BR_STATE_LISTENING:
-	case BR_STATE_BLOCKING:
-		cpsw_state = ALE_PORT_STATE_BLOCK;
-		break;
-	default:
-		return -EOPNOTSUPP;
-	}
-
-	ret = cpsw_ale_control_set(cpsw->ale, port->port_id,
-				   ALE_PORT_STATE, cpsw_state);
-	netdev_dbg(port->ndev, "ale state: %u\n", cpsw_state);
-
-	return ret;
-}
-
-static int am65_cpsw_port_attr_br_flags_set(struct am65_cpsw_port *port,
-					    struct switchdev_trans *trans,
-					    struct net_device *orig_dev,
-					    unsigned long brport_flags)
-{
-	struct am65_cpsw_common *cpsw = port->common;
-	bool unreg_mcast_add = false;
-
-	if (switchdev_trans_ph_prepare(trans))
-		return 0;
-
-	if (brport_flags & BR_MCAST_FLOOD)
-		unreg_mcast_add = true;
-	netdev_dbg(port->ndev, "BR_MCAST_FLOOD: %d port %u\n",
-		   unreg_mcast_add, port->port_id);
-
-	cpsw_ale_set_unreg_mcast(cpsw->ale, BIT(port->port_id),
-				 unreg_mcast_add);
-
-	return 0;
-}
-
-static int am65_cpsw_port_attr_br_flags_pre_set(struct net_device *netdev,
-						struct switchdev_trans *trans,
-						unsigned long flags)
-{
-	if (flags & ~(BR_LEARNING | BR_MCAST_FLOOD))
-		return -EINVAL;
-
-	return 0;
-}
-
-static int am65_cpsw_port_attr_set(struct net_device *ndev,
-				   const struct switchdev_attr *attr,
-				   struct switchdev_trans *trans)
-{
-	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
-	int ret;
-
-	netdev_dbg(ndev, "attr: id %u port: %u\n", attr->id, port->port_id);
-
-	switch (attr->id) {
-	case SWITCHDEV_ATTR_ID_PORT_PRE_BRIDGE_FLAGS:
-		ret = am65_cpsw_port_attr_br_flags_pre_set(ndev, trans,
-							   attr->u.brport_flags);
-		break;
-	case SWITCHDEV_ATTR_ID_PORT_STP_STATE:
-		ret = am65_cpsw_port_stp_state_set(port, trans, attr->u.stp_state);
-		netdev_dbg(ndev, "stp state: %u\n", attr->u.stp_state);
-		break;
-	case SWITCHDEV_ATTR_ID_PORT_BRIDGE_FLAGS:
-		ret = am65_cpsw_port_attr_br_flags_set(port, trans, attr->orig_dev,
-						       attr->u.brport_flags);
-		break;
-	default:
-		ret = -EOPNOTSUPP;
-		break;
-	}
-
-	return ret;
-}
-
-static u16 am65_cpsw_get_pvid(struct am65_cpsw_port *port)
-{
-	struct am65_cpsw_common *cpsw = port->common;
-	struct am65_cpsw_host *host_p = am65_common_get_host(cpsw);
-	u32 pvid;
-
-	if (port->port_id)
-		pvid = readl(port->port_base + AM65_CPSW_PORT_VLAN_REG_OFFSET);
-	else
-		pvid = readl(host_p->port_base + AM65_CPSW_PORT_VLAN_REG_OFFSET);
-
-	pvid = pvid & 0xfff;
-
-	return pvid;
-}
-
-static void am65_cpsw_set_pvid(struct am65_cpsw_port *port, u16 vid, bool cfi, u32 cos)
-{
-	struct am65_cpsw_common *cpsw = port->common;
-	struct am65_cpsw_host *host_p = am65_common_get_host(cpsw);
-	u32 pvid;
-
-	pvid = vid;
-	pvid |= cfi ? BIT(12) : 0;
-	pvid |= (cos & 0x7) << 13;
-
-	if (port->port_id)
-		writel(pvid, port->port_base + AM65_CPSW_PORT_VLAN_REG_OFFSET);
-	else
-		writel(pvid, host_p->port_base + AM65_CPSW_PORT_VLAN_REG_OFFSET);
-}
-
-static int am65_cpsw_port_vlan_add(struct am65_cpsw_port *port, bool untag, bool pvid,
-				   u16 vid, struct net_device *orig_dev)
-{
-	bool cpu_port = netif_is_bridge_master(orig_dev);
-	struct am65_cpsw_common *cpsw = port->common;
-	int unreg_mcast_mask = 0;
-	int reg_mcast_mask = 0;
-	int untag_mask = 0;
-	int port_mask;
-	int ret = 0;
-	u32 flags;
-
-	if (cpu_port) {
-		port_mask = BIT(HOST_PORT_NUM);
-		flags = orig_dev->flags;
-		unreg_mcast_mask = port_mask;
-	} else {
-		port_mask = BIT(port->port_id);
-		flags = port->ndev->flags;
-	}
-
-	if (flags & IFF_MULTICAST)
-		reg_mcast_mask = port_mask;
-
-	if (untag)
-		untag_mask = port_mask;
-
-	ret = cpsw_ale_vlan_add_modify(cpsw->ale, vid, port_mask, untag_mask,
-				       reg_mcast_mask, unreg_mcast_mask);
-	if (ret) {
-		netdev_err(port->ndev, "Unable to add vlan\n");
-		return ret;
-	}
-
-	if (cpu_port)
-		cpsw_ale_add_ucast(cpsw->ale, port->slave.mac_addr,
-				   HOST_PORT_NUM, ALE_VLAN | ALE_SECURE, vid);
-	if (!pvid)
-		return ret;
-
-	am65_cpsw_set_pvid(port, vid, 0, 0);
-
-	netdev_dbg(port->ndev, "VID add: %s: vid:%u ports:%X\n",
-		   port->ndev->name, vid, port_mask);
-
-	return ret;
-}
-
-static int am65_cpsw_port_vlan_del(struct am65_cpsw_port *port, u16 vid,
-				   struct net_device *orig_dev)
-{
-	bool cpu_port = netif_is_bridge_master(orig_dev);
-	struct am65_cpsw_common *cpsw = port->common;
-	int port_mask;
-	int ret = 0;
-
-	if (cpu_port)
-		port_mask = BIT(HOST_PORT_NUM);
-	else
-		port_mask = BIT(port->port_id);
-
-	ret = cpsw_ale_del_vlan(cpsw->ale, vid, port_mask);
-	if (ret != 0)
-		return ret;
-
-	/* We don't care for the return value here, error is returned only if
-	 * the unicast entry is not present
-	 */
-	if (cpu_port)
-		cpsw_ale_del_ucast(cpsw->ale, port->slave.mac_addr,
-				   HOST_PORT_NUM, ALE_VLAN, vid);
-
-	if (vid == am65_cpsw_get_pvid(port))
-		am65_cpsw_set_pvid(port, 0, 0, 0);
-
-	/* We don't care for the return value here, error is returned only if
-	 * the multicast entry is not present
-	 */
-	cpsw_ale_del_mcast(cpsw->ale, port->ndev->broadcast, port_mask,
-			   ALE_VLAN, vid);
-	netdev_dbg(port->ndev, "VID del: %s: vid:%u ports:%X\n",
-		   port->ndev->name, vid, port_mask);
-
-	return ret;
-}
-
-static int am65_cpsw_port_vlans_add(struct am65_cpsw_port *port,
-				    const struct switchdev_obj_port_vlan *vlan,
-				    struct switchdev_trans *trans)
-{
-	bool untag = vlan->flags & BRIDGE_VLAN_INFO_UNTAGGED;
-	struct net_device *orig_dev = vlan->obj.orig_dev;
-	bool cpu_port = netif_is_bridge_master(orig_dev);
-	bool pvid = vlan->flags & BRIDGE_VLAN_INFO_PVID;
-
-	netdev_dbg(port->ndev, "VID add: %s: vid:%u flags:%X\n",
-		   port->ndev->name, vlan->vid_begin, vlan->flags);
-
-	if (cpu_port && !(vlan->flags & BRIDGE_VLAN_INFO_BRENTRY))
-		return 0;
-
-	if (switchdev_trans_ph_prepare(trans))
-		return 0;
-
-	return am65_cpsw_port_vlan_add(port, untag, pvid, vlan->vid_begin, orig_dev);
-}
-
-static int am65_cpsw_port_vlans_del(struct am65_cpsw_port *port,
-				    const struct switchdev_obj_port_vlan *vlan)
-
-{
-	return am65_cpsw_port_vlan_del(port, vlan->vid_begin, vlan->obj.orig_dev);
-}
-
-static int am65_cpsw_port_mdb_add(struct am65_cpsw_port *port,
-				  struct switchdev_obj_port_mdb *mdb,
-				  struct switchdev_trans *trans)
-
-{
-	struct net_device *orig_dev = mdb->obj.orig_dev;
-	bool cpu_port = netif_is_bridge_master(orig_dev);
-	struct am65_cpsw_common *cpsw = port->common;
-	int port_mask;
-	int err;
-
-	if (switchdev_trans_ph_prepare(trans))
-		return 0;
-
-	if (cpu_port)
-		port_mask = BIT(HOST_PORT_NUM);
-	else
-		port_mask = BIT(port->port_id);
-
-	err = cpsw_ale_add_mcast(cpsw->ale, mdb->addr, port_mask,
-				 ALE_VLAN, mdb->vid, 0);
-	netdev_dbg(port->ndev, "MDB add: %s: vid %u:%pM  ports: %X\n",
-		   port->ndev->name, mdb->vid, mdb->addr, port_mask);
-
-	return err;
-}
-
-static int am65_cpsw_port_mdb_del(struct am65_cpsw_port *port,
-				  struct switchdev_obj_port_mdb *mdb)
-
-{
-	struct net_device *orig_dev = mdb->obj.orig_dev;
-	bool cpu_port = netif_is_bridge_master(orig_dev);
-	struct am65_cpsw_common *cpsw = port->common;
-	int del_mask;
-
-	if (cpu_port)
-		del_mask = BIT(HOST_PORT_NUM);
-	else
-		del_mask = BIT(port->port_id);
-
-	/* Ignore error as error code is returned only when entry is already removed */
-	cpsw_ale_del_mcast(cpsw->ale, mdb->addr, del_mask,
-			   ALE_VLAN, mdb->vid);
-	netdev_dbg(port->ndev, "MDB del: %s: vid %u:%pM  ports: %X\n",
-		   port->ndev->name, mdb->vid, mdb->addr, del_mask);
-
-	return 0;
-}
-
-static int am65_cpsw_port_obj_add(struct net_device *ndev,
-				  const struct switchdev_obj *obj,
-				  struct switchdev_trans *trans,
-				  struct netlink_ext_ack *extack)
-{
-	struct switchdev_obj_port_vlan *vlan = SWITCHDEV_OBJ_PORT_VLAN(obj);
-	struct switchdev_obj_port_mdb *mdb = SWITCHDEV_OBJ_PORT_MDB(obj);
-	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
-	int err = 0;
-
-	netdev_dbg(ndev, "obj_add: id %u port: %u\n", obj->id, port->port_id);
-
-	switch (obj->id) {
-	case SWITCHDEV_OBJ_ID_PORT_VLAN:
-		err = am65_cpsw_port_vlans_add(port, vlan, trans);
-		break;
-	case SWITCHDEV_OBJ_ID_PORT_MDB:
-	case SWITCHDEV_OBJ_ID_HOST_MDB:
-		err = am65_cpsw_port_mdb_add(port, mdb, trans);
-		break;
-	default:
-		err = -EOPNOTSUPP;
-		break;
-	}
-
-	return err;
-}
-
-static int am65_cpsw_port_obj_del(struct net_device *ndev,
-				  const struct switchdev_obj *obj)
-{
-	struct switchdev_obj_port_vlan *vlan = SWITCHDEV_OBJ_PORT_VLAN(obj);
-	struct switchdev_obj_port_mdb *mdb = SWITCHDEV_OBJ_PORT_MDB(obj);
-	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
-	int err = 0;
-
-	netdev_dbg(ndev, "obj_del: id %u port: %u\n", obj->id, port->port_id);
-
-	switch (obj->id) {
-	case SWITCHDEV_OBJ_ID_PORT_VLAN:
-		err = am65_cpsw_port_vlans_del(port, vlan);
-		break;
-	case SWITCHDEV_OBJ_ID_PORT_MDB:
-	case SWITCHDEV_OBJ_ID_HOST_MDB:
-		err = am65_cpsw_port_mdb_del(port, mdb);
-		break;
-	default:
-		err = -EOPNOTSUPP;
-		break;
-	}
-
-	return err;
-}
-
-static void am65_cpsw_fdb_offload_notify(struct net_device *ndev,
-					 struct switchdev_notifier_fdb_info *rcv)
-{
-	struct switchdev_notifier_fdb_info info;
-
-	info.addr = rcv->addr;
-	info.vid = rcv->vid;
-	info.offloaded = true;
-	call_switchdev_notifiers(SWITCHDEV_FDB_OFFLOADED,
-				 ndev, &info.info, NULL);
-}
-
-static void am65_cpsw_switchdev_event_work(struct work_struct *work)
-{
-	struct am65_cpsw_switchdev_event_work *switchdev_work =
-		container_of(work, struct am65_cpsw_switchdev_event_work, work);
-	struct am65_cpsw_port *port = switchdev_work->port;
-	struct switchdev_notifier_fdb_info *fdb;
-	struct am65_cpsw_common *cpsw = port->common;
-	int port_id = port->port_id;
-
-	rtnl_lock();
-	switch (switchdev_work->event) {
-	case SWITCHDEV_FDB_ADD_TO_DEVICE:
-		fdb = &switchdev_work->fdb_info;
-
-		netdev_dbg(port->ndev, "cpsw_fdb_add: MACID = %pM vid = %u flags = %u %u -- port %d\n",
-			   fdb->addr, fdb->vid, fdb->added_by_user,
-			   fdb->offloaded, port_id);
-
-		if (!fdb->added_by_user)
-			break;
-		if (memcmp(port->slave.mac_addr, (u8 *)fdb->addr, ETH_ALEN) == 0)
-			port_id = HOST_PORT_NUM;
-
-		cpsw_ale_add_ucast(cpsw->ale, (u8 *)fdb->addr, port_id,
-				   fdb->vid ? ALE_VLAN : 0, fdb->vid);
-		am65_cpsw_fdb_offload_notify(port->ndev, fdb);
-		break;
-	case SWITCHDEV_FDB_DEL_TO_DEVICE:
-		fdb = &switchdev_work->fdb_info;
-
-		netdev_dbg(port->ndev, "cpsw_fdb_del: MACID = %pM vid = %u flags = %u %u -- port %d\n",
-			   fdb->addr, fdb->vid, fdb->added_by_user,
-			   fdb->offloaded, port_id);
-
-		if (!fdb->added_by_user)
-			break;
-		if (memcmp(port->slave.mac_addr, (u8 *)fdb->addr, ETH_ALEN) == 0)
-			port_id = HOST_PORT_NUM;
-
-		cpsw_ale_del_ucast(cpsw->ale, (u8 *)fdb->addr, port_id,
-				   fdb->vid ? ALE_VLAN : 0, fdb->vid);
-		break;
-	default:
-		break;
-	}
-	rtnl_unlock();
-
-	kfree(switchdev_work->fdb_info.addr);
-	kfree(switchdev_work);
-	dev_put(port->ndev);
-}
-
-/* called under rcu_read_lock() */
-static int am65_cpsw_switchdev_event(struct notifier_block *unused,
-				     unsigned long event, void *ptr)
-{
-	struct net_device *ndev = switchdev_notifier_info_to_dev(ptr);
-	struct am65_cpsw_switchdev_event_work *switchdev_work;
-	struct am65_cpsw_port *port = am65_ndev_to_port(ndev);
-	struct switchdev_notifier_fdb_info *fdb_info = ptr;
-	int err;
-
-	if (event == SWITCHDEV_PORT_ATTR_SET) {
-		err = switchdev_handle_port_attr_set(ndev, ptr,
-						     am65_cpsw_port_dev_check,
-						     am65_cpsw_port_attr_set);
-		return notifier_from_errno(err);
-	}
-
-	if (!am65_cpsw_port_dev_check(ndev))
-		return NOTIFY_DONE;
-
-	switchdev_work = kzalloc(sizeof(*switchdev_work), GFP_ATOMIC);
-	if (WARN_ON(!switchdev_work))
-		return NOTIFY_BAD;
-
-	INIT_WORK(&switchdev_work->work, am65_cpsw_switchdev_event_work);
-	switchdev_work->port = port;
-	switchdev_work->event = event;
-
-	switch (event) {
-	case SWITCHDEV_FDB_ADD_TO_DEVICE:
-	case SWITCHDEV_FDB_DEL_TO_DEVICE:
-		memcpy(&switchdev_work->fdb_info, ptr,
-		       sizeof(switchdev_work->fdb_info));
-		switchdev_work->fdb_info.addr = kzalloc(ETH_ALEN, GFP_ATOMIC);
-		if (!switchdev_work->fdb_info.addr)
-			goto err_addr_alloc;
-		ether_addr_copy((u8 *)switchdev_work->fdb_info.addr,
-				fdb_info->addr);
-		dev_hold(ndev);
-		break;
-	default:
-		kfree(switchdev_work);
-		return NOTIFY_DONE;
-	}
-
-	queue_work(system_long_wq, &switchdev_work->work);
-
-	return NOTIFY_DONE;
-
-err_addr_alloc:
-	kfree(switchdev_work);
-	return NOTIFY_BAD;
-}
-
-static struct notifier_block cpsw_switchdev_notifier = {
-	.notifier_call = am65_cpsw_switchdev_event,
-};
-
-static int am65_cpsw_switchdev_blocking_event(struct notifier_block *unused,
-					      unsigned long event, void *ptr)
-{
-	struct net_device *dev = switchdev_notifier_info_to_dev(ptr);
-	int err;
-
-	switch (event) {
-	case SWITCHDEV_PORT_OBJ_ADD:
-		err = switchdev_handle_port_obj_add(dev, ptr,
-						    am65_cpsw_port_dev_check,
-						    am65_cpsw_port_obj_add);
-		return notifier_from_errno(err);
-	case SWITCHDEV_PORT_OBJ_DEL:
-		err = switchdev_handle_port_obj_del(dev, ptr,
-						    am65_cpsw_port_dev_check,
-						    am65_cpsw_port_obj_del);
-		return notifier_from_errno(err);
-	case SWITCHDEV_PORT_ATTR_SET:
-		err = switchdev_handle_port_attr_set(dev, ptr,
-						     am65_cpsw_port_dev_check,
-						     am65_cpsw_port_attr_set);
-		return notifier_from_errno(err);
-	default:
-		break;
-	}
-
-	return NOTIFY_DONE;
-}
-
-static struct notifier_block cpsw_switchdev_bl_notifier = {
-	.notifier_call = am65_cpsw_switchdev_blocking_event,
-};
-
-int am65_cpsw_switchdev_register_notifiers(struct am65_cpsw_common *cpsw)
-{
-	int ret = 0;
-
-	ret = register_switchdev_notifier(&cpsw_switchdev_notifier);
-	if (ret) {
-		dev_err(cpsw->dev, "register switchdev notifier fail ret:%d\n",
-			ret);
-		return ret;
-	}
-
-	ret = register_switchdev_blocking_notifier(&cpsw_switchdev_bl_notifier);
-	if (ret) {
-		dev_err(cpsw->dev, "register switchdev blocking notifier ret:%d\n",
-			ret);
-		unregister_switchdev_notifier(&cpsw_switchdev_notifier);
-	}
-
-	return ret;
-}
-
-void am65_cpsw_switchdev_unregister_notifiers(struct am65_cpsw_common *cpsw)
-{
-	unregister_switchdev_blocking_notifier(&cpsw_switchdev_bl_notifier);
-	unregister_switchdev_notifier(&cpsw_switchdev_notifier);
-}
diff --git a/drivers/net/ethernet/ti/am65-cpsw-switchdev.h b/drivers/net/ethernet/ti/am65-cpsw-switchdev.h
deleted file mode 100644
index a67a7606bc80..000000000000
--- a/drivers/net/ethernet/ti/am65-cpsw-switchdev.h
+++ /dev/null
@@ -1,34 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2020 Texas Instruments Incorporated - https://www.ti.com/
- */
-
-#ifndef DRIVERS_NET_ETHERNET_TI_AM65_CPSW_SWITCHDEV_H_
-#define DRIVERS_NET_ETHERNET_TI_AM65_CPSW_SWITCHDEV_H_
-
-#include <linux/skbuff.h>
-
-#if IS_ENABLED(CONFIG_TI_K3_AM65_CPSW_SWITCHDEV)
-static inline void am65_cpsw_nuss_set_offload_fwd_mark(struct sk_buff *skb, bool val)
-{
-	skb->offload_fwd_mark = val;
-}
-
-int am65_cpsw_switchdev_register_notifiers(struct am65_cpsw_common *cpsw);
-void am65_cpsw_switchdev_unregister_notifiers(struct am65_cpsw_common *cpsw);
-#else
-static inline int am65_cpsw_switchdev_register_notifiers(struct am65_cpsw_common *cpsw)
-{
-	return -EOPNOTSUPP;
-}
-
-static inline void am65_cpsw_switchdev_unregister_notifiers(struct am65_cpsw_common *cpsw)
-{
-}
-
-static inline void am65_cpsw_nuss_set_offload_fwd_mark(struct sk_buff *skb, bool val)
-{
-}
-
-#endif
-
-#endif /* DRIVERS_NET_ETHERNET_TI_AM65_CPSW_SWITCHDEV_H_ */
diff --git a/drivers/net/ethernet/ti/am65-cpts.c b/drivers/net/ethernet/ti/am65-cpts.c
index cdcb0184157b..5dc60ecabe56 100644
--- a/drivers/net/ethernet/ti/am65-cpts.c
+++ b/drivers/net/ethernet/ti/am65-cpts.c
@@ -176,10 +176,6 @@ struct am65_cpts {
 	u32 genf_enable;
 	u32 hw_ts_enable;
 	struct sk_buff_head txq;
-	bool pps_enabled;
-	bool pps_present;
-	u32 pps_hw_ts_idx;
-	u32 pps_genf_idx;
 };
 
 struct am65_cpts_skb_cb_data {
@@ -313,17 +309,8 @@ static int am65_cpts_fifo_read(struct am65_cpts *cpts)
 		case AM65_CPTS_EV_HW:
 			pevent.index = am65_cpts_event_get_port(event) - 1;
 			pevent.timestamp = event->timestamp;
-			if (cpts->pps_enabled &&
-			    pevent.index == cpts->pps_hw_ts_idx) {
-				pevent.type = PTP_CLOCK_PPSUSR;
-				pevent.pps_times.ts_real =
-					ns_to_timespec64(pevent.timestamp);
-			} else {
-				pevent.type = PTP_CLOCK_EXTTS;
-			}
-			dev_dbg(cpts->dev, "AM65_CPTS_EV_HW:%s p:%d t:%llu\n",
-				pevent.type == PTP_CLOCK_EXTTS ?
-				"extts" : "pps",
+			pevent.type = PTP_CLOCK_EXTTS;
+			dev_dbg(cpts->dev, "AM65_CPTS_EV_HW p:%d t:%llu\n",
 				pevent.index, event->timestamp);
 
 			ptp_clock_event(cpts->ptp_clock, &pevent);
@@ -397,12 +384,9 @@ static irqreturn_t am65_cpts_interrupt(int irq, void *dev_id)
 static int am65_cpts_ptp_adjfreq(struct ptp_clock_info *ptp, s32 ppb)
 {
 	struct am65_cpts *cpts = container_of(ptp, struct am65_cpts, ptp_info);
-	u32 pps_ctrl_val = 0, pps_ppm_hi = 0, pps_ppm_low = 0;
-	int pps_index = cpts->pps_genf_idx;
-	u64 adj_period, pps_adj_period;
-	u32 ctrl_val, ppm_hi, ppm_low;
-	unsigned long flags;
 	int neg_adj = 0;
+	u64 adj_period;
+	u32 val;
 
 	if (ppb < 0) {
 		neg_adj = 1;
@@ -422,53 +406,17 @@ static int am65_cpts_ptp_adjfreq(struct ptp_clock_info *ptp, s32 ppb)
 
 	mutex_lock(&cpts->ptp_clk_lock);
 
-	ctrl_val = am65_cpts_read32(cpts, control);
+	val = am65_cpts_read32(cpts, control);
 	if (neg_adj)
-		ctrl_val |= AM65_CPTS_CONTROL_TS_PPM_DIR;
+		val |= AM65_CPTS_CONTROL_TS_PPM_DIR;
 	else
-		ctrl_val &= ~AM65_CPTS_CONTROL_TS_PPM_DIR;
-
-	ppm_hi = upper_32_bits(adj_period) & 0x3FF;
-	ppm_low = lower_32_bits(adj_period);
-
-	if (cpts->pps_enabled) {
-		pps_ctrl_val = am65_cpts_read32(cpts, genf[pps_index].control);
-		if (neg_adj)
-			pps_ctrl_val &= ~BIT(1);
-		else
-			pps_ctrl_val |= BIT(1);
-
-		/* GenF PPM will do correction using cpts refclk tick which is
-		 * (cpts->ts_add_val + 1) ns, so GenF length PPM adj period
-		 * need to be corrected.
-		 */
-		pps_adj_period = adj_period * (cpts->ts_add_val + 1);
-		pps_ppm_hi = upper_32_bits(pps_adj_period) & 0x3FF;
-		pps_ppm_low = lower_32_bits(pps_adj_period);
-	}
-
-	spin_lock_irqsave(&cpts->lock, flags);
-
-	/* All below writes must be done extremely fast:
-	 *  - delay between PPM dir and PPM value changes can cause err due old
-	 *    PPM correction applied in wrong direction
-	 *  - delay between CPTS-clock PPM cfg and GenF PPM cfg can cause err
-	 *    due CPTS-clock PPM working with new cfg while GenF PPM cfg still
-	 *    with old for short period of time
-	 */
-
-	am65_cpts_write32(cpts, ctrl_val, control);
-	am65_cpts_write32(cpts, ppm_hi, ts_ppm_hi);
-	am65_cpts_write32(cpts, ppm_low, ts_ppm_low);
-
-	if (cpts->pps_enabled) {
-		am65_cpts_write32(cpts, pps_ctrl_val, genf[pps_index].control);
-		am65_cpts_write32(cpts, pps_ppm_hi, genf[pps_index].ppm_hi);
-		am65_cpts_write32(cpts, pps_ppm_low, genf[pps_index].ppm_low);
-	}
+		val &= ~AM65_CPTS_CONTROL_TS_PPM_DIR;
+	am65_cpts_write32(cpts, val, control);
 
-	/* All GenF/EstF can be updated here the same way */
-	spin_unlock_irqrestore(&cpts->lock, flags);
+	val = upper_32_bits(adj_period) & 0x3FF;
+	am65_cpts_write32(cpts, val, ts_ppm_hi);
+	val = lower_32_bits(adj_period);
+	am65_cpts_write32(cpts, val, ts_ppm_low);
 
 	mutex_unlock(&cpts->ptp_clk_lock);
 
@@ -548,10 +496,6 @@ static void am65_cpts_extts_enable_hw(struct am65_cpts *cpts, u32 index, int on)
 
 static int am65_cpts_extts_enable(struct am65_cpts *cpts, u32 index, int on)
 {
-
-	if (cpts->pps_present && index == cpts->pps_hw_ts_idx)
-		return -EINVAL;
-
 	if (!!(cpts->hw_ts_enable & BIT(index)) == !!on)
 		return 0;
 
@@ -636,9 +580,6 @@ static void am65_cpts_perout_enable_hw(struct am65_cpts *cpts,
 static int am65_cpts_perout_enable(struct am65_cpts *cpts,
 				   struct ptp_perout_request *req, int on)
 {
-	if (cpts->pps_present && req->index == cpts->pps_genf_idx)
-		return -EINVAL;
-
 	if (!!(cpts->genf_enable & BIT(req->index)) == !!on)
 		return 0;
 
@@ -652,48 +593,6 @@ static int am65_cpts_perout_enable(struct am65_cpts *cpts,
 	return 0;
 }
 
-static int am65_cpts_pps_enable(struct am65_cpts *cpts, int on)
-{
-	struct ptp_clock_request rq;
-	struct timespec64 ts;
-	int ret = 0;
-	u64 ns;
-
-	if (!cpts->pps_present)
-		return -EINVAL;
-
-	if (cpts->pps_enabled == !!on)
-		return 0;
-
-	mutex_lock(&cpts->ptp_clk_lock);
-
-	if (on) {
-		am65_cpts_extts_enable_hw(cpts, cpts->pps_hw_ts_idx, on);
-
-		ns = am65_cpts_gettime(cpts, NULL);
-		ts = ns_to_timespec64(ns);
-		rq.perout.period.sec = 1;
-		rq.perout.period.nsec = 0;
-		rq.perout.start.sec = ts.tv_sec + 2;
-		rq.perout.start.nsec = 0;
-		rq.perout.index = cpts->pps_genf_idx;
-
-		am65_cpts_perout_enable_hw(cpts, &rq.perout, on);
-		cpts->pps_enabled = true;
-	} else {
-		rq.perout.index = cpts->pps_genf_idx;
-		am65_cpts_perout_enable_hw(cpts, &rq.perout, on);
-		am65_cpts_extts_enable_hw(cpts, cpts->pps_hw_ts_idx, on);
-		cpts->pps_enabled = false;
-	}
-
-	mutex_unlock(&cpts->ptp_clk_lock);
-
-	dev_dbg(cpts->dev, "%s: pps: %s\n",
-		__func__, on ? "enabled" : "disabled");
-	return ret;
-}
-
 static int am65_cpts_ptp_enable(struct ptp_clock_info *ptp,
 				struct ptp_clock_request *rq, int on)
 {
@@ -704,8 +603,6 @@ static int am65_cpts_ptp_enable(struct ptp_clock_info *ptp,
 		return am65_cpts_extts_enable(cpts, rq->extts.index, on);
 	case PTP_CLK_REQ_PEROUT:
 		return am65_cpts_perout_enable(cpts, &rq->perout, on);
-	case PTP_CLK_REQ_PPS:
-		return am65_cpts_pps_enable(cpts, on);
 	default:
 		break;
 	}
@@ -830,7 +727,7 @@ static long am65_cpts_ts_work(struct ptp_clock_info *ptp)
 /**
  * am65_cpts_rx_enable - enable rx timestamping
  * @cpts: cpts handle
- * @en: enable
+ * @skb: packet
  *
  * This functions enables rx packets timestamping. The CPTS can timestamp all
  * rx packets.
@@ -1018,12 +915,6 @@ static int am65_cpts_of_parse(struct am65_cpts *cpts, struct device_node *node)
 	if (!of_property_read_u32(node, "ti,cpts-periodic-outputs", &prop[0]))
 		cpts->genf_num = prop[0];
 
-	if (!of_property_read_u32_array(node, "ti,pps", prop, 2)) {
-		cpts->pps_present = true;
-		cpts->pps_hw_ts_idx = prop[0];
-		cpts->pps_genf_idx = prop[1];
-	}
-
 	return cpts_of_mux_clk_setup(cpts, node);
 }
 
@@ -1094,8 +985,6 @@ struct am65_cpts *am65_cpts_create(struct device *dev, void __iomem *regs,
 		cpts->ptp_info.n_ext_ts = cpts->ext_ts_inputs;
 	if (cpts->genf_num)
 		cpts->ptp_info.n_per_out = cpts->genf_num;
-	if (cpts->pps_present)
-		cpts->ptp_info.pps = 1;
 
 	am65_cpts_set_add_val(cpts);
 
@@ -1131,9 +1020,9 @@ struct am65_cpts *am65_cpts_create(struct device *dev, void __iomem *regs,
 		return ERR_PTR(ret);
 	}
 
-	dev_info(dev, "CPTS ver 0x%08x, freq:%u, add_val:%u pps:%d\n",
+	dev_info(dev, "CPTS ver 0x%08x, freq:%u, add_val:%u\n",
 		 am65_cpts_read32(cpts, idver),
-		 cpts->refclk_freq, cpts->ts_add_val, cpts->pps_present);
+		 cpts->refclk_freq, cpts->ts_add_val);
 
 	return cpts;
 
diff --git a/drivers/net/ethernet/ti/am65-debugfs.c b/drivers/net/ethernet/ti/am65-debugfs.c
deleted file mode 100644
index f8435c1852ec..000000000000
--- a/drivers/net/ethernet/ti/am65-debugfs.c
+++ /dev/null
@@ -1,152 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/* Texas Instruments K3 AM65 Ethernet debugfs submodule
- * Copyright (C) 2020 Texas Instruments Incorporated - http://www.ti.com/
- */
-
-#include <linux/bitfield.h>
-#include <linux/debugfs.h>
-
-#include "am65-cpsw-nuss.h"
-
-int am65_cpsw_nuss_register_debugfs(struct am65_cpsw_common *common)
-{
-	common->debugfs_root = debugfs_create_dir(dev_name(common->dev), NULL);
-	if (IS_ERR(common->debugfs_root))
-		return PTR_ERR(common->debugfs_root);
-
-	return 0;
-}
-
-void am65_cpsw_nuss_unregister_debugfs(struct am65_cpsw_common *common)
-{
-	debugfs_remove_recursive(common->debugfs_root);
-}
-
-static int
-cut_thru_tx_pri_mask_get(void *data, u64 *val)
-{
-	struct am65_cpsw_port *port = data;
-	struct am65_cpsw_cut_thru *cut_thru;
-	int ret = -EINVAL;
-
-	read_lock(&dev_base_lock);
-	cut_thru = &port->qos.cut_thru;
-	if (port->ndev->reg_state == NETREG_REGISTERED) {
-		*val =  cut_thru->tx_pri_mask;
-		ret = 0;
-	}
-	read_unlock(&dev_base_lock);
-
-	return ret;
-}
-
-static int
-cut_thru_tx_pri_mask_set(void *data, u64 val)
-{
-	struct am65_cpsw_cut_thru *cut_thru;
-	struct am65_cpsw_port *port = data;
-	struct am65_cpsw_common *common;
-	int ret = 0;
-
-	if (val & ~GENMASK(7, 0))
-		return -EINVAL;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-
-	common = port->common;
-	cut_thru = &port->qos.cut_thru;
-
-	if (cut_thru->enable) {
-		dev_err(common->dev, "Port%u: can't set cut-thru tx_pri_mask while cut-thru enabled\n",
-			port->port_id);
-		ret = -EINVAL;
-		goto err;
-	}
-	cut_thru->tx_pri_mask = val;
-
-err:
-	rtnl_unlock();
-	return ret;
-}
-
-DEFINE_DEBUGFS_ATTRIBUTE(fops_cut_thru_tx_pri_mask, cut_thru_tx_pri_mask_get,
-			 cut_thru_tx_pri_mask_set, "%llx\n");
-
-static int
-cut_thru_rx_pri_mask_get(void *data, u64 *val)
-{
-	struct am65_cpsw_port *port = data;
-	struct am65_cpsw_cut_thru *cut_thru;
-	int ret = -EINVAL;
-
-	read_lock(&dev_base_lock);
-	cut_thru = &port->qos.cut_thru;
-	if (port->ndev->reg_state == NETREG_REGISTERED) {
-		*val =  cut_thru->rx_pri_mask;
-		ret = 0;
-	}
-	read_unlock(&dev_base_lock);
-
-	return ret;
-}
-
-static int
-cut_thru_rx_pri_mask_set(void *data, u64 val)
-{
-	struct am65_cpsw_cut_thru *cut_thru;
-	struct am65_cpsw_port *port = data;
-	struct am65_cpsw_common *common;
-	int ret = 0;
-
-	if (val & ~GENMASK(7, 0))
-		return -EINVAL;
-
-	if (!rtnl_trylock())
-		return restart_syscall();
-
-	common = port->common;
-	cut_thru = &port->qos.cut_thru;
-
-	if (cut_thru->enable) {
-		dev_err(common->dev, "Port%u: can't set cut-thru rx_pri_mask while cut-thru enabled\n",
-			port->port_id);
-		ret = -EINVAL;
-		goto err;
-	}
-	cut_thru->rx_pri_mask = val;
-
-err:
-	rtnl_unlock();
-	return ret;
-}
-
-DEFINE_DEBUGFS_ATTRIBUTE(fops_cut_thru_rx_pri_mask, cut_thru_rx_pri_mask_get,
-			 cut_thru_rx_pri_mask_set, "%llx\n");
-
-int am65_cpsw_nuss_register_port_debugfs(struct am65_cpsw_port *port)
-{
-	struct am65_cpsw_common *common = port->common;
-	char dirn[32];
-
-	scnprintf(dirn, sizeof(dirn), "Port%x", port->port_id);
-	port->debugfs_port = debugfs_create_dir(dirn, common->debugfs_root);
-	if (IS_ERR(port->debugfs_port))
-		return PTR_ERR(port->debugfs_port);
-
-	debugfs_create_bool("disabled", 0400,
-			    port->debugfs_port, &port->disabled);
-	if (port->disabled)
-		return 0;
-
-	if (common->pdata.quirks & AM64_CPSW_QUIRK_CUT_THRU) {
-		debugfs_create_file("cut_thru_tx_pri_mask", 0600,
-				    port->debugfs_port,
-				    port, &fops_cut_thru_tx_pri_mask);
-		debugfs_create_file("cut_thru_rx_pri_mask", 0600,
-				    port->debugfs_port,
-				    port, &fops_cut_thru_rx_pri_mask);
-	}
-
-	return 0;
-}
diff --git a/drivers/net/ethernet/ti/cpsw.c b/drivers/net/ethernet/ti/cpsw.c
index 896fddae91f0..b0f00b4edd94 100644
--- a/drivers/net/ethernet/ti/cpsw.c
+++ b/drivers/net/ethernet/ti/cpsw.c
@@ -34,8 +34,6 @@
 #include <net/page_pool.h>
 #include <linux/bpf.h>
 #include <linux/bpf_trace.h>
-//#include <linux/filter.h>
-#include <linux/net_switch_config.h>
 
 #include <linux/pinctrl/consumer.h>
 #include <net/pkt_cls.h>
@@ -61,10 +59,6 @@ static int rx_packet_max = CPSW_MAX_PACKET_SIZE;
 module_param(rx_packet_max, int, 0);
 MODULE_PARM_DESC(rx_packet_max, "maximum receive packet size (bytes)");
 
-static int tx_packet_min = CPSW_MIN_PACKET_SIZE;
-module_param(tx_packet_min, int, 0444);
-MODULE_PARM_DESC(tx_packet_min, "minimum tx packet size (bytes)");
-
 static int descs_pool_size = CPSW_CPDMA_DESCS_POOL_SIZE_DEFAULT;
 module_param(descs_pool_size, int, 0444);
 MODULE_PARM_DESC(descs_pool_size, "Number of CPDMA CPPI descriptors in pool");
@@ -415,10 +409,12 @@ static void cpsw_rx_handler(void *token, int len, int status)
 		xdp.frame_sz = PAGE_SIZE;
 
 		port = priv->emac_port + cpsw->data.dual_emac;
-		ret = cpsw_run_xdp(priv, ch, &xdp, page, port, &len);
+		ret = cpsw_run_xdp(priv, ch, &xdp, page, port);
 		if (ret != CPSW_XDP_PASS)
 			goto requeue;
 
+		/* XDP prog might have changed packet data and boundaries */
+		len = xdp.data_end - xdp.data;
 		headroom = xdp.data - xdp.data_hard_start;
 
 		/* XDP prog can modify vlan tag, so can't use encap header */
@@ -502,8 +498,7 @@ static void _cpsw_adjust_link(struct cpsw_slave *slave,
 
 		/* enable forwarding */
 		cpsw_ale_control_set(cpsw->ale, slave_port,
-				     ALE_PORT_STATE,
-				     priv->port_state[slave_port]);
+				     ALE_PORT_STATE, ALE_PORT_STATE_FORWARD);
 
 		*link = true;
 
@@ -616,7 +611,6 @@ static void cpsw_slave_open(struct cpsw_slave *slave, struct cpsw_priv *priv)
 	slave->mac_control = 0;	/* no link yet */
 
 	slave_port = cpsw_get_slave_port(slave->slave_num);
-	priv->port_state[slave_port] = ALE_PORT_STATE_FORWARD;
 
 	if (cpsw->data.dual_emac)
 		cpsw_add_dual_emac_def_ale_entries(priv, slave, slave_port);
@@ -917,17 +911,14 @@ static netdev_tx_t cpsw_ndo_start_xmit(struct sk_buff *skb,
 	struct cpts *cpts = cpsw->cpts;
 	struct netdev_queue *txq;
 	struct cpdma_chan *txch;
-	unsigned int len;
 	int ret, q_idx;
 
-	if (skb_padto(skb, tx_packet_min)) {
+	if (skb_padto(skb, CPSW_MIN_PACKET_SIZE)) {
 		cpsw_err(priv, tx_err, "packet pad failed\n");
 		ndev->stats.tx_dropped++;
 		return NET_XMIT_DROP;
 	}
 
-	len = skb->len < tx_packet_min ? tx_packet_min : skb->len;
-
 	if (skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP &&
 	    priv->tx_ts_enabled && cpts_can_timestamp(cpts, skb))
 		skb_shinfo(skb)->tx_flags |= SKBTX_IN_PROGRESS;
@@ -1147,7 +1138,7 @@ static int cpsw_ndo_xdp_xmit(struct net_device *ndev, int n,
 
 	for (i = 0; i < n; i++) {
 		xdpf = frames[i];
-		if (xdpf->len < tx_packet_min) {
+		if (xdpf->len < CPSW_MIN_PACKET_SIZE) {
 			xdp_return_frame_rx_napi(xdpf);
 			drops++;
 			continue;
@@ -1173,37 +1164,12 @@ static void cpsw_ndo_poll_controller(struct net_device *ndev)
 }
 #endif
 
-#include "cpsw_switch_ioctl.c"
-
-static int cpsw_ndo_ioctl_legacy(struct net_device *dev, struct ifreq *req, int cmd)
-{
-	struct cpsw_priv *priv = netdev_priv(dev);
-	struct cpsw_common *cpsw = priv->cpsw;
-	int slave_no = cpsw_slave_index(cpsw, priv);
-
-	if (!netif_running(dev))
-		return -EINVAL;
-
-	switch (cmd) {
-	case SIOCSHWTSTAMP:
-		return cpsw_hwtstamp_set(dev, req);
-	case SIOCGHWTSTAMP:
-		return cpsw_hwtstamp_get(dev, req);
-	case SIOCSWITCHCONFIG:
-		return cpsw_switch_config_ioctl(dev, req, cmd);
-	}
-
-	if (!cpsw->slaves[slave_no].phy)
-		return -EOPNOTSUPP;
-	return phy_mii_ioctl(cpsw->slaves[slave_no].phy, req, cmd);
-}
-
 static const struct net_device_ops cpsw_netdev_ops = {
 	.ndo_open		= cpsw_ndo_open,
 	.ndo_stop		= cpsw_ndo_stop,
 	.ndo_start_xmit		= cpsw_ndo_start_xmit,
 	.ndo_set_mac_address	= cpsw_ndo_set_mac_address,
-	.ndo_do_ioctl		= cpsw_ndo_ioctl_legacy,
+	.ndo_do_ioctl		= cpsw_ndo_ioctl,
 	.ndo_validate_addr	= eth_validate_addr,
 	.ndo_tx_timeout		= cpsw_ndo_tx_timeout,
 	.ndo_set_rx_mode	= cpsw_ndo_set_rx_mode,
diff --git a/drivers/net/ethernet/ti/cpsw_ale.c b/drivers/net/ethernet/ti/cpsw_ale.c
index be75bb0099e8..a6a455c32628 100644
--- a/drivers/net/ethernet/ti/cpsw_ale.c
+++ b/drivers/net/ethernet/ti/cpsw_ale.c
@@ -50,8 +50,6 @@
 /* ALE_AGING_TIMER */
 #define ALE_AGING_TIMER_MASK	GENMASK(23, 0)
 
-#define ALE_RATE_LIMIT_MIN_PPS 1000
-
 /**
  * struct ale_entry_fld - The ALE tbl entry field description
  * @start_bit: field start bit
@@ -636,8 +634,8 @@ int cpsw_ale_add_vlan(struct cpsw_ale *ale, u16 vid, int port_mask, int untag,
 	return 0;
 }
 
-static void cpsw_ale_vlan_del_modify_int(struct cpsw_ale *ale,  u32 *ale_entry,
-					 u16 vid, int port_mask)
+static void cpsw_ale_del_vlan_modify(struct cpsw_ale *ale, u32 *ale_entry,
+				     u16 vid, int port_mask)
 {
 	int reg_mcast, unreg_mcast;
 	int members, untag;
@@ -646,7 +644,6 @@ static void cpsw_ale_vlan_del_modify_int(struct cpsw_ale *ale,  u32 *ale_entry,
 					ALE_ENT_VID_MEMBER_LIST);
 	members &= ~port_mask;
 	if (!members) {
-		cpsw_ale_set_vlan_untag(ale, ale_entry, vid, 0);
 		cpsw_ale_set_entry_type(ale_entry, ALE_TYPE_FREE);
 		return;
 	}
@@ -676,27 +673,10 @@ static void cpsw_ale_vlan_del_modify_int(struct cpsw_ale *ale,  u32 *ale_entry,
 			      ALE_ENT_VID_MEMBER_LIST, members);
 }
 
-int cpsw_ale_vlan_del_modify(struct cpsw_ale *ale, u16 vid, int port_mask)
-{
-	u32 ale_entry[ALE_ENTRY_WORDS] = {0, 0, 0};
-	int idx;
-
-	idx = cpsw_ale_match_vlan(ale, vid);
-	if (idx < 0)
-		return -ENOENT;
-
-	cpsw_ale_read(ale, idx, ale_entry);
-
-	cpsw_ale_vlan_del_modify_int(ale, ale_entry, vid, port_mask);
-	cpsw_ale_write(ale, idx, ale_entry);
-
-	return 0;
-}
-
 int cpsw_ale_del_vlan(struct cpsw_ale *ale, u16 vid, int port_mask)
 {
 	u32 ale_entry[ALE_ENTRY_WORDS] = {0, 0, 0};
-	int members, idx;
+	int idx;
 
 	idx = cpsw_ale_match_vlan(ale, vid);
 	if (idx < 0)
@@ -704,22 +684,11 @@ int cpsw_ale_del_vlan(struct cpsw_ale *ale, u16 vid, int port_mask)
 
 	cpsw_ale_read(ale, idx, ale_entry);
 
-	/* if !port_mask - force remove VLAN (legacy).
-	 * Check if there are other VLAN members ports
-	 * if no - remove VLAN.
-	 * if yes it means same VLAN was added to >1 port in multi port mode, so
-	 * remove port_mask ports from VLAN ALE entry excluding Host port.
-	 */
-	members = cpsw_ale_vlan_get_fld(ale, ale_entry, ALE_ENT_VID_MEMBER_LIST);
-	members &= ~port_mask;
-
-	if (!port_mask || !members) {
-		/* last port or force remove - remove VLAN */
+	if (port_mask) {
+		cpsw_ale_del_vlan_modify(ale, ale_entry, vid, port_mask);
+	} else {
 		cpsw_ale_set_vlan_untag(ale, ale_entry, vid, 0);
 		cpsw_ale_set_entry_type(ale_entry, ALE_TYPE_FREE);
-	} else {
-		port_mask &= ~ALE_PORT_HOST;
-		cpsw_ale_vlan_del_modify_int(ale, ale_entry, vid, port_mask);
 	}
 
 	cpsw_ale_write(ale, idx, ale_entry);
@@ -1138,50 +1107,6 @@ int cpsw_ale_control_get(struct cpsw_ale *ale, int port, int control)
 	return tmp & BITMASK(info->bits);
 }
 
-int cpsw_ale_rx_ratelimit_mc(struct cpsw_ale *ale, int port, unsigned int ratelimit_pps)
-
-{
-	int val = ratelimit_pps / ALE_RATE_LIMIT_MIN_PPS;
-	u32 remainder = ratelimit_pps % ALE_RATE_LIMIT_MIN_PPS;
-
-	if (ratelimit_pps && !val) {
-		dev_err(ale->params.dev, "ALE MC port:%d ratelimit min value 1000pps\n", port);
-		return -EINVAL;
-	}
-
-	if (remainder)
-		dev_info(ale->params.dev, "ALE port:%d MC ratelimit set to %dpps (requested %d)\n",
-			 port, ratelimit_pps - remainder, ratelimit_pps);
-
-	cpsw_ale_control_set(ale, port, ALE_PORT_MCAST_LIMIT, val);
-
-	dev_dbg(ale->params.dev, "ALE port:%d MC ratelimit set %d\n",
-		port, val * ALE_RATE_LIMIT_MIN_PPS);
-	return 0;
-}
-
-int cpsw_ale_rx_ratelimit_bc(struct cpsw_ale *ale, int port, unsigned int ratelimit_pps)
-
-{
-	int val = ratelimit_pps / ALE_RATE_LIMIT_MIN_PPS;
-	u32 remainder = ratelimit_pps % ALE_RATE_LIMIT_MIN_PPS;
-
-	if (ratelimit_pps && !val) {
-		dev_err(ale->params.dev, "ALE port:%d BC ratelimit min value 1000pps\n", port);
-		return -EINVAL;
-	}
-
-	if (remainder)
-		dev_info(ale->params.dev, "ALE port:%d BC ratelimit set to %dpps (requested %d)\n",
-			 port, ratelimit_pps - remainder, ratelimit_pps);
-
-	cpsw_ale_control_set(ale, port, ALE_PORT_BCAST_LIMIT, val);
-
-	dev_dbg(ale->params.dev, "ALE port:%d BC ratelimit set %d\n",
-		port, val * ALE_RATE_LIMIT_MIN_PPS);
-	return 0;
-}
-
 static void cpsw_ale_timer(struct timer_list *t)
 {
 	struct cpsw_ale *ale = from_timer(ale, t, timer);
@@ -1245,26 +1170,6 @@ static void cpsw_ale_aging_stop(struct cpsw_ale *ale)
 
 void cpsw_ale_start(struct cpsw_ale *ale)
 {
-	unsigned long ale_prescale;
-
-	/* configure Broadcast and Multicast Rate Limit
-	 * number_of_packets = (Fclk / ALE_PRESCALE) * port.BCAST/MCAST_LIMIT
-	 * ALE_PRESCALE width is 19bit and min value 0x10
-	 * port.BCAST/MCAST_LIMIT is 8bit
-	 *
-	 * For multi port configuration support the ALE_PRESCALE is configured to 1ms interval,
-	 * which allows to configure port.BCAST/MCAST_LIMIT per port and achieve:
-	 * min number_of_packets = 1000 when port.BCAST/MCAST_LIMIT = 1
-	 * max number_of_packets = 1000 * 255 = 255000 when port.BCAST/MCAST_LIMIT = 0xFF
-	 */
-	ale_prescale = ale->params.bus_freq / ALE_RATE_LIMIT_MIN_PPS;
-	writel((u32)ale_prescale, ale->params.ale_regs + ALE_PRESCALE);
-
-	/* Allow MC/BC rate limiting globally.
-	 * The actual Rate Limit cfg enabled per-port by port.BCAST/MCAST_LIMIT
-	 */
-	cpsw_ale_control_set(ale, 0, ALE_RATE_LIMIT, 1);
-
 	cpsw_ale_control_set(ale, 0, ALE_ENABLE, 1);
 	cpsw_ale_control_set(ale, 0, ALE_CLEAR, 1);
 
@@ -1322,13 +1227,6 @@ static const struct cpsw_ale_dev_id cpsw_ale_id_match[] = {
 		.major_ver_mask = 0x7,
 		.vlan_entry_tbl = vlan_entry_k3_cpswxg,
 	},
-	{
-		.dev_id = "am64-cpswxg",
-		.features = CPSW_ALE_F_STATUS_REG | CPSW_ALE_F_HW_AUTOAGING,
-		.major_ver_mask = 0x7,
-		.vlan_entry_tbl = vlan_entry_k3_cpswxg,
-		.tbl_entries = 512,
-	},
 	{ },
 };
 
diff --git a/drivers/net/ethernet/ti/cpsw_ale.h b/drivers/net/ethernet/ti/cpsw_ale.h
index aba4572cfa3b..5e4a69662c5f 100644
--- a/drivers/net/ethernet/ti/cpsw_ale.h
+++ b/drivers/net/ethernet/ti/cpsw_ale.h
@@ -120,8 +120,6 @@ int cpsw_ale_add_vlan(struct cpsw_ale *ale, u16 vid, int port, int untag,
 			int reg_mcast, int unreg_mcast);
 int cpsw_ale_del_vlan(struct cpsw_ale *ale, u16 vid, int port);
 void cpsw_ale_set_allmulti(struct cpsw_ale *ale, int allmulti, int port);
-int cpsw_ale_rx_ratelimit_bc(struct cpsw_ale *ale, int port, unsigned int ratelimit_pps);
-int cpsw_ale_rx_ratelimit_mc(struct cpsw_ale *ale, int port, unsigned int ratelimit_pps);
 
 int cpsw_ale_control_get(struct cpsw_ale *ale, int port, int control);
 int cpsw_ale_control_set(struct cpsw_ale *ale, int port,
@@ -136,7 +134,6 @@ static inline int cpsw_ale_get_vlan_p0_untag(struct cpsw_ale *ale, u16 vid)
 
 int cpsw_ale_vlan_add_modify(struct cpsw_ale *ale, u16 vid, int port_mask,
 			     int untag_mask, int reg_mcast, int unreg_mcast);
-int cpsw_ale_vlan_del_modify(struct cpsw_ale *ale, u16 vid, int port_mask);
 void cpsw_ale_set_unreg_mcast(struct cpsw_ale *ale, int unreg_mcast_mask,
 			      bool add);
 
diff --git a/drivers/net/ethernet/ti/cpsw_new.c b/drivers/net/ethernet/ti/cpsw_new.c
index 1fdffcc387cc..31cefd6ef680 100644
--- a/drivers/net/ethernet/ti/cpsw_new.c
+++ b/drivers/net/ethernet/ti/cpsw_new.c
@@ -46,8 +46,6 @@ static int debug_level;
 static int ale_ageout = CPSW_ALE_AGEOUT_DEFAULT;
 static int rx_packet_max = CPSW_MAX_PACKET_SIZE;
 static int descs_pool_size = CPSW_CPDMA_DESCS_POOL_SIZE_DEFAULT;
-module_param(descs_pool_size, int, 0444);
-MODULE_PARM_DESC(descs_pool_size, "Number of CPDMA CPPI descriptors in pool");
 
 struct cpsw_devlink {
 	struct cpsw_common *cpsw;
@@ -353,10 +351,12 @@ static void cpsw_rx_handler(void *token, int len, int status)
 		xdp.rxq = &priv->xdp_rxq[ch];
 		xdp.frame_sz = PAGE_SIZE;
 
-		ret = cpsw_run_xdp(priv, ch, &xdp, page, priv->emac_port, &len);
+		ret = cpsw_run_xdp(priv, ch, &xdp, page, priv->emac_port);
 		if (ret != CPSW_XDP_PASS)
 			goto requeue;
 
+		/* XDP prog might have changed packet data and boundaries */
+		len = xdp.data_end - xdp.data;
 		headroom = xdp.data - xdp.data_hard_start;
 
 		/* XDP prog can modify vlan tag, so can't use encap header */
@@ -926,17 +926,14 @@ static netdev_tx_t cpsw_ndo_start_xmit(struct sk_buff *skb,
 	struct cpts *cpts = cpsw->cpts;
 	struct netdev_queue *txq;
 	struct cpdma_chan *txch;
-	unsigned int len;
 	int ret, q_idx;
 
-	if (skb_padto(skb, priv->tx_packet_min)) {
+	if (skb_put_padto(skb, READ_ONCE(priv->tx_packet_min))) {
 		cpsw_err(priv, tx_err, "packet pad failed\n");
 		ndev->stats.tx_dropped++;
 		return NET_XMIT_DROP;
 	}
 
-	len = skb->len < priv->tx_packet_min ? priv->tx_packet_min : skb->len;
-
 	if (skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP &&
 	    priv->tx_ts_enabled && cpts_can_timestamp(cpts, skb))
 		skb_shinfo(skb)->tx_flags |= SKBTX_IN_PROGRESS;
@@ -948,7 +945,7 @@ static netdev_tx_t cpsw_ndo_start_xmit(struct sk_buff *skb,
 	txch = cpsw->txv[q_idx].ch;
 	txq = netdev_get_tx_queue(ndev, q_idx);
 	skb_tx_timestamp(skb);
-	ret = cpdma_chan_submit(txch, skb, skb->data, len,
+	ret = cpdma_chan_submit(txch, skb, skb->data, skb->len,
 				priv->emac_port);
 	if (unlikely(ret != 0)) {
 		cpsw_err(priv, tx_err, "desc submit failed\n");
@@ -1111,8 +1108,7 @@ static int cpsw_ndo_xdp_xmit(struct net_device *ndev, int n,
 
 	for (i = 0; i < n; i++) {
 		xdpf = frames[i];
-
-		if (xdpf->len < priv->tx_packet_min) {
+		if (xdpf->len < READ_ONCE(priv->tx_packet_min)) {
 			xdp_return_frame_rx_napi(xdpf);
 			drops++;
 			continue;
@@ -1704,7 +1700,7 @@ static int cpsw_dl_switch_mode_set(struct devlink *dl, u32 id,
 
 			priv = netdev_priv(sl_ndev);
 			slave->port_vlan = vlan;
-			priv->tx_packet_min = CPSW_MIN_PACKET_SIZE_VLAN;
+			WRITE_ONCE(priv->tx_packet_min, CPSW_MIN_PACKET_SIZE_VLAN);
 			if (netif_running(sl_ndev))
 				cpsw_port_add_switch_def_ale_entries(priv,
 								     slave);
@@ -1733,7 +1729,7 @@ static int cpsw_dl_switch_mode_set(struct devlink *dl, u32 id,
 
 			priv = netdev_priv(slave->ndev);
 			slave->port_vlan = slave->data->dual_emac_res_vlan;
-			priv->tx_packet_min = CPSW_MIN_PACKET_SIZE;
+			WRITE_ONCE(priv->tx_packet_min, CPSW_MIN_PACKET_SIZE);
 			cpsw_port_add_dual_emac_def_ale_entries(priv, slave);
 		}
 
diff --git a/drivers/net/ethernet/ti/cpsw_priv.c b/drivers/net/ethernet/ti/cpsw_priv.c
index 91ef049347c3..424e644724e4 100644
--- a/drivers/net/ethernet/ti/cpsw_priv.c
+++ b/drivers/net/ethernet/ti/cpsw_priv.c
@@ -502,7 +502,6 @@ int cpsw_init_common(struct cpsw_common *cpsw, void __iomem *ss_regs,
 	ale_params.ale_ageout		= ale_ageout;
 	ale_params.ale_ports		= CPSW_ALE_PORTS_NUM;
 	ale_params.dev_id		= "cpsw";
-	ale_params.bus_freq		= cpsw->bus_freq_mhz * 1000000;
 
 	cpsw->ale = cpsw_ale_create(&ale_params);
 	if (IS_ERR(cpsw->ale)) {
@@ -613,7 +612,7 @@ static void cpsw_hwtstamp_v2(struct cpsw_priv *priv)
 	writel_relaxed(ETH_P_8021Q, &cpsw->regs->vlan_ltype);
 }
 
-int cpsw_hwtstamp_set(struct net_device *dev, struct ifreq *ifr)
+static int cpsw_hwtstamp_set(struct net_device *dev, struct ifreq *ifr)
 {
 	struct cpsw_priv *priv = netdev_priv(dev);
 	struct cpsw_common *cpsw = priv->cpsw;
@@ -677,7 +676,7 @@ int cpsw_hwtstamp_set(struct net_device *dev, struct ifreq *ifr)
 	return copy_to_user(ifr->ifr_data, &cfg, sizeof(cfg)) ? -EFAULT : 0;
 }
 
-int cpsw_hwtstamp_get(struct net_device *dev, struct ifreq *ifr)
+static int cpsw_hwtstamp_get(struct net_device *dev, struct ifreq *ifr)
 {
 	struct cpsw_common *cpsw = ndev_to_cpsw(dev);
 	struct cpsw_priv *priv = netdev_priv(dev);
@@ -694,6 +693,16 @@ int cpsw_hwtstamp_get(struct net_device *dev, struct ifreq *ifr)
 
 	return copy_to_user(ifr->ifr_data, &cfg, sizeof(cfg)) ? -EFAULT : 0;
 }
+#else
+static int cpsw_hwtstamp_get(struct net_device *dev, struct ifreq *ifr)
+{
+	return -EOPNOTSUPP;
+}
+
+static int cpsw_hwtstamp_set(struct net_device *dev, struct ifreq *ifr)
+{
+	return -EOPNOTSUPP;
+}
 #endif /*CONFIG_TI_CPTS*/
 
 int cpsw_ndo_ioctl(struct net_device *dev, struct ifreq *req, int cmd)
@@ -1314,7 +1323,7 @@ int cpsw_xdp_tx_frame(struct cpsw_priv *priv, struct xdp_frame *xdpf,
 }
 
 int cpsw_run_xdp(struct cpsw_priv *priv, int ch, struct xdp_buff *xdp,
-		 struct page *page, int port, int *len)
+		 struct page *page, int port)
 {
 	struct cpsw_common *cpsw = priv->cpsw;
 	struct net_device *ndev = priv->ndev;
@@ -1332,13 +1341,10 @@ int cpsw_run_xdp(struct cpsw_priv *priv, int ch, struct xdp_buff *xdp,
 	}
 
 	act = bpf_prog_run_xdp(prog, xdp);
-	/* XDP prog might have changed packet data and boundaries */
-	*len = xdp->data_end - xdp->data;
-
 	switch (act) {
 	case XDP_PASS:
 		ret = CPSW_XDP_PASS;
-		goto out;
+		break;
 	case XDP_TX:
 		xdpf = xdp_convert_buff_to_frame(xdp);
 		if (unlikely(!xdpf))
@@ -1364,13 +1370,8 @@ int cpsw_run_xdp(struct cpsw_priv *priv, int ch, struct xdp_buff *xdp,
 		trace_xdp_exception(ndev, prog, act);
 		fallthrough;	/* handle aborts by dropping packet */
 	case XDP_DROP:
-		ndev->stats.rx_bytes += *len;
-		ndev->stats.rx_packets++;
 		goto drop;
 	}
-
-	ndev->stats.rx_bytes += *len;
-	ndev->stats.rx_packets++;
 out:
 	rcu_read_unlock();
 	return ret;
diff --git a/drivers/net/ethernet/ti/cpsw_priv.h b/drivers/net/ethernet/ti/cpsw_priv.h
index 83cd9ae2d3d1..a100c93edee8 100644
--- a/drivers/net/ethernet/ti/cpsw_priv.h
+++ b/drivers/net/ethernet/ti/cpsw_priv.h
@@ -382,7 +382,6 @@ struct cpsw_priv {
 	struct cpsw_common *cpsw;
 	int offload_fwd_mark;
 	u32 tx_packet_min;
-	u8 port_state[3];
 };
 
 #define ndev_to_cpsw(ndev) (((struct cpsw_priv *)netdev_priv(ndev))->cpsw)
@@ -441,7 +440,7 @@ int cpsw_ndo_bpf(struct net_device *ndev, struct netdev_bpf *bpf);
 int cpsw_xdp_tx_frame(struct cpsw_priv *priv, struct xdp_frame *xdpf,
 		      struct page *page, int port);
 int cpsw_run_xdp(struct cpsw_priv *priv, int ch, struct xdp_buff *xdp,
-		 struct page *page, int port, int *len);
+		 struct page *page, int port);
 irqreturn_t cpsw_tx_interrupt(int irq, void *dev_id);
 irqreturn_t cpsw_rx_interrupt(int irq, void *dev_id);
 irqreturn_t cpsw_misc_interrupt(int irq, void *dev_id);
@@ -496,19 +495,4 @@ int cpsw_set_channels_common(struct net_device *ndev,
 			     cpdma_handler_fn rx_handler);
 int cpsw_get_ts_info(struct net_device *ndev, struct ethtool_ts_info *info);
 
-#if IS_ENABLED(CONFIG_TI_CPTS)
-int cpsw_hwtstamp_set(struct net_device *dev, struct ifreq *ifr);
-int cpsw_hwtstamp_get(struct net_device *dev, struct ifreq *ifr);
-#else
-static int cpsw_hwtstamp_get(struct net_device *dev, struct ifreq *ifr)
-{
-	return -EOPNOTSUPP;
-}
-
-static int cpsw_hwtstamp_set(struct net_device *dev, struct ifreq *ifr)
-{
-	return -EOPNOTSUPP;
-}
-#endif /*CONFIG_TI_CPTS*/
-
 #endif /* DRIVERS_NET_ETHERNET_TI_CPSW_PRIV_H_ */
diff --git a/drivers/net/ethernet/ti/cpsw_switch_ioctl.c b/drivers/net/ethernet/ti/cpsw_switch_ioctl.c
deleted file mode 100644
index 05a43fb41508..000000000000
--- a/drivers/net/ethernet/ti/cpsw_switch_ioctl.c
+++ /dev/null
@@ -1,271 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/* CPSW switch-configuration using non-standard private ioctl SIOCSWITCHCONFIG
- * Grygorii Strashko <grygorii.strashko@ti.com>:
- *  moved code in separate file to minimize merge conflicts with LKML
- */
-
-static int cpsw_set_port_state(struct cpsw_priv *priv, int port,
-			       int port_state)
-{
-	switch (port_state) {
-	case PORT_STATE_DISABLED:
-		priv->port_state[port] = ALE_PORT_STATE_DISABLE;
-		break;
-	case PORT_STATE_BLOCKED:
-		priv->port_state[port] = ALE_PORT_STATE_BLOCK;
-		break;
-	case PORT_STATE_LEARN:
-		priv->port_state[port] = ALE_PORT_STATE_LEARN;
-		break;
-	case PORT_STATE_FORWARD:
-		priv->port_state[port] = ALE_PORT_STATE_FORWARD;
-		break;
-	default:
-		dev_err(priv->dev, "Switch config: Invalid port state\n");
-		return -EINVAL;
-	}
-	return cpsw_ale_control_set(priv->cpsw->ale, port, ALE_PORT_STATE,
-			priv->port_state[port]);
-}
-
-static int cpsw_switch_config_ioctl(struct net_device *ndev,
-				    struct ifreq *ifrq, int cmd)
-{
-	struct cpsw_priv *priv = netdev_priv(ndev);
-	struct cpsw_common *cpsw = priv->cpsw;
-	struct net_switch_config config;
-	int ret = -EINVAL;
-
-	if (cpsw->data.dual_emac) {
-		dev_err(priv->dev, "CPSW not in switch mode\n");
-		return -EOPNOTSUPP;
-	}
-
-	/* Only SIOCSWITCHCONFIG is used as cmd argument and hence, there is no
-	 * switch statement required.
-	 * Function calls are based on switch_config.cmd
-	 */
-
-	if (copy_from_user(&config, ifrq->ifr_data, sizeof(config)))
-		return -EFAULT;
-
-	if (config.vid > 4095) {
-		dev_err(priv->dev, "Invalid VLAN id Arguments for cmd %d\n",
-			config.cmd);
-		return ret;
-	}
-
-	switch (config.cmd) {
-	case SWITCH_ADD_MULTICAST:
-		if (config.port > 0 && config.port <= 7 &&
-		    is_multicast_ether_addr(config.addr)) {
-			ret = cpsw_ale_add_mcast(cpsw->ale, config.addr,
-						 config.port, ALE_VLAN,
-						 config.vid, 0);
-		} else {
-			dev_err(priv->dev, "Invalid Arguments for cmd %d\n",
-				config.cmd);
-		}
-		break;
-	case SWITCH_DEL_MULTICAST:
-		if (is_multicast_ether_addr(config.addr)) {
-			ret = cpsw_ale_del_mcast(cpsw->ale, config.addr,
-						 0, ALE_VLAN, config.vid);
-		} else {
-			dev_err(priv->dev, "Invalid Arguments for cmd %d\n",
-				config.cmd);
-		}
-		break;
-	case SWITCH_ADD_VLAN:
-		if (config.port > 0 && config.port <= 7) {
-			ret = cpsw_ale_add_vlan(cpsw->ale, config.vid,
-						config.port,
-						config.untag_port,
-						config.reg_multi,
-						config.unreg_multi);
-		} else {
-			dev_err(priv->dev, "Invalid Arguments for cmd %d\n",
-				config.cmd);
-		}
-		break;
-	case SWITCH_DEL_VLAN:
-		ret = cpsw_ale_del_vlan(cpsw->ale, config.vid, 0);
-		break;
-	case SWITCH_SET_PORT_CONFIG:
-	{
-		struct phy_device *phy = NULL;
-		struct ethtool_link_ksettings cmd;
-
-		if (config.port == 1 || config.port == 2)
-			phy = cpsw->slaves[config.port - 1].phy;
-
-		if (!phy) {
-			dev_err(priv->dev, "Phy not Found\n");
-			break;
-		}
-
-		convert_legacy_settings_to_link_ksettings(&cmd, &config.ecmd);
-		cmd.base.phy_address = phy->mdio.addr;
-		ret = phy_ethtool_ksettings_set(phy, &cmd);
-		break;
-	}
-	case SWITCH_GET_PORT_CONFIG:
-	{
-		struct phy_device *phy = NULL;
-		struct ethtool_link_ksettings cmd;
-
-		if (config.port == 1 || config.port == 2)
-			phy = cpsw->slaves[config.port - 1].phy;
-
-		if (!phy) {
-			dev_err(priv->dev, "Phy not Found\n");
-			break;
-		}
-
-		cmd.base.phy_address = phy->mdio.addr;
-		phy_ethtool_ksettings_get(phy, &cmd);
-		convert_link_ksettings_to_legacy_settings(&config.ecmd, &cmd);
-
-		ret = copy_to_user(ifrq->ifr_data, &config, sizeof(config));
-		break;
-	}
-	case SWITCH_ADD_UNKNOWN_VLAN_INFO:
-		if (config.unknown_vlan_member <= 7 &&
-		    config.unknown_vlan_untag <= 7 &&
-		    config.unknown_vlan_unreg_multi <= 7 &&
-		    config.unknown_vlan_reg_multi <= 7) {
-			cpsw_ale_control_set(cpsw->ale, 0,
-					     ALE_PORT_UNTAGGED_EGRESS,
-					     config.unknown_vlan_untag);
-			cpsw_ale_control_set(cpsw->ale, 0,
-					     ALE_PORT_UNKNOWN_REG_MCAST_FLOOD,
-					     config.unknown_vlan_reg_multi);
-			cpsw_ale_control_set(cpsw->ale, 0,
-					     ALE_PORT_UNKNOWN_MCAST_FLOOD,
-					     config.unknown_vlan_unreg_multi);
-			cpsw_ale_control_set(cpsw->ale, 0,
-					     ALE_PORT_UNKNOWN_VLAN_MEMBER,
-					     config.unknown_vlan_member);
-			ret = 0;
-		} else {
-			dev_err(priv->dev, "Invalid Unknown VLAN Arguments\n");
-		}
-		break;
-	case SWITCH_GET_PORT_STATE:
-		if (config.port == 1 || config.port == 2) {
-			config.port_state = priv->port_state[config.port];
-			ret = copy_to_user(ifrq->ifr_data, &config,
-					   sizeof(config));
-		} else {
-			dev_err(priv->dev, "Invalid Port number\n");
-		}
-		break;
-	case SWITCH_SET_PORT_STATE:
-		if (config.port == 1 || config.port == 2) {
-			ret = cpsw_set_port_state(priv, config.port,
-						  config.port_state);
-		} else {
-			dev_err(priv->dev, "Invalid Port number\n");
-		}
-		break;
-	case SWITCH_GET_PORT_VLAN_CONFIG:
-	{
-		u32 __iomem *port_vlan_reg;
-		u32 port_vlan;
-
-		switch (config.port) {
-		case 0:
-			port_vlan_reg = &cpsw->host_port_regs->port_vlan;
-			port_vlan = readl(port_vlan_reg);
-			ret = 0;
-
-			break;
-		case 1:
-		case 2:
-		{
-			int slave = config.port - 1;
-			int reg = CPSW2_PORT_VLAN;
-
-			if (cpsw->version == CPSW_VERSION_1)
-				reg = CPSW1_PORT_VLAN;
-
-			port_vlan = slave_read(cpsw->slaves + slave, reg);
-			ret = 0;
-
-			break;
-		}
-		default:
-			dev_err(priv->dev, "Invalid Port number\n");
-			break;
-		}
-
-		if (!ret) {
-			config.vid = port_vlan & 0xfff;
-			config.vlan_cfi = port_vlan & BIT(12) ? true : false;
-			config.prio = (port_vlan >> 13) & 0x7;
-			ret = copy_to_user(ifrq->ifr_data, &config,
-					   sizeof(config));
-		}
-		break;
-	}
-	case SWITCH_SET_PORT_VLAN_CONFIG:
-	{
-		void __iomem *port_vlan_reg;
-		u32 port_vlan;
-
-		port_vlan = config.vid;
-		port_vlan |= config.vlan_cfi ? BIT(12) : 0;
-		port_vlan |= (config.prio & 0x7) << 13;
-
-		switch (config.port) {
-		case 0:
-			port_vlan_reg = &cpsw->host_port_regs->port_vlan;
-			writel(port_vlan, port_vlan_reg);
-			ret = 0;
-
-			break;
-		case 1:
-		case 2:
-		{
-			int slave = config.port - 1;
-			int reg = CPSW2_PORT_VLAN;
-
-			if (cpsw->version == CPSW_VERSION_1)
-				reg = CPSW1_PORT_VLAN;
-
-			slave_write(cpsw->slaves + slave, port_vlan, reg);
-			ret = 0;
-
-			break;
-		}
-		default:
-			dev_err(priv->dev, "Invalid Port number\n");
-			break;
-		}
-
-		break;
-	}
-	case SWITCH_RATELIMIT:
-	{
-		if (config.port > 2) {
-			dev_err(priv->dev, "Invalid Port number\n");
-			break;
-		}
-
-		ret = cpsw_ale_rx_ratelimit_mc(cpsw->ale, config.port, config.mcast_rate_limit);
-		if (ret)
-			dev_err(priv->dev, "CPSW_ALE set MC ratelimit failed");
-
-		ret = cpsw_ale_rx_ratelimit_bc(cpsw->ale, config.port, config.bcast_rate_limit);
-		if (ret)
-			dev_err(priv->dev, "CPSW_ALE set BC ratelimit failed");
-
-		break;
-	}
-
-	default:
-		ret = -EOPNOTSUPP;
-	}
-
-	return ret;
-}
diff --git a/drivers/net/ethernet/ti/cpsw_switchdev.c b/drivers/net/ethernet/ti/cpsw_switchdev.c
index 29747da5c514..985a929bb957 100644
--- a/drivers/net/ethernet/ti/cpsw_switchdev.c
+++ b/drivers/net/ethernet/ti/cpsw_switchdev.c
@@ -227,7 +227,7 @@ static int cpsw_port_vlan_del(struct cpsw_priv *priv, u16 vid,
 	else
 		port_mask = BIT(priv->emac_port);
 
-	ret = cpsw_ale_vlan_del_modify(cpsw->ale, vid, port_mask);
+	ret = cpsw_ale_del_vlan(cpsw->ale, vid, port_mask);
 	if (ret != 0)
 		return ret;
 
diff --git a/drivers/net/ethernet/ti/davinci_mdio.c b/drivers/net/ethernet/ti/davinci_mdio.c
index a4efd5e35158..702fdc393da0 100644
--- a/drivers/net/ethernet/ti/davinci_mdio.c
+++ b/drivers/net/ethernet/ti/davinci_mdio.c
@@ -358,16 +358,20 @@ static int davinci_mdio_probe(struct platform_device *pdev)
 	}
 
 	if (IS_ENABLED(CONFIG_OF) && dev->of_node) {
-		const struct davinci_mdio_of_param *of_mdio_data;
+		const struct of_device_id	*of_id;
 
 		ret = davinci_mdio_probe_dt(&data->pdata, pdev);
 		if (ret)
 			return ret;
 		snprintf(data->bus->id, MII_BUS_ID_SIZE, "%s", pdev->name);
 
-		of_mdio_data = of_device_get_match_data(&pdev->dev);
-		if (of_mdio_data) {
-			autosuspend_delay_ms =
+		of_id = of_match_device(davinci_mdio_of_mtable, &pdev->dev);
+		if (of_id) {
+			const struct davinci_mdio_of_param *of_mdio_data;
+
+			of_mdio_data = of_id->data;
+			if (of_mdio_data)
+				autosuspend_delay_ms =
 					of_mdio_data->autosuspend_delay_ms;
 		}
 	} else {
@@ -377,9 +381,9 @@ static int davinci_mdio_probe(struct platform_device *pdev)
 	}
 
 	data->bus->name		= dev_name(dev);
-	data->bus->read		= davinci_mdio_read;
-	data->bus->write	= davinci_mdio_write;
-	data->bus->reset	= davinci_mdio_reset;
+	data->bus->read		= davinci_mdio_read,
+	data->bus->write	= davinci_mdio_write,
+	data->bus->reset	= davinci_mdio_reset,
 	data->bus->parent	= dev;
 	data->bus->priv		= data;
 
diff --git a/drivers/net/ethernet/ti/icss_iep.c b/drivers/net/ethernet/ti/icss_iep.c
deleted file mode 100644
index d3aa3dca729c..000000000000
--- a/drivers/net/ethernet/ti/icss_iep.c
+++ /dev/null
@@ -1,1164 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/* Texas Instruments ICSSG Industrial Ethernet Peripheral (IEP) Driver
- *
- * Copyright (C) 2018 Texas Instruments Incorporated - http://www.ti.com
- *
- */
-
-#include <linux/bitops.h>
-#include <linux/clk.h>
-#include <linux/err.h>
-#include <linux/io.h>
-#include <linux/module.h>
-#include <linux/of.h>
-#include <linux/of_platform.h>
-#include <linux/platform_device.h>
-#include <linux/timekeeping.h>
-#include <linux/interrupt.h>
-#include <linux/of_irq.h>
-
-#include "icss_iep.h"
-
-#define IEP_MAX_DEF_INC		0xf
-#define IEP_MAX_COMPEN_INC		0xfff
-#define IEP_MAX_COMPEN_COUNT	0xffffff
-
-#define IEP_GLOBAL_CFG_CNT_ENABLE	BIT(0)
-#define IEP_GLOBAL_CFG_DEFAULT_INC_MASK		GENMASK(7, 4)
-#define IEP_GLOBAL_CFG_DEFAULT_INC_SHIFT	4
-#define IEP_GLOBAL_CFG_COMPEN_INC_MASK		GENMASK(19, 8)
-#define IEP_GLOBAL_CFG_COMPEN_INC_SHIFT		8
-
-#define IEP_GLOBAL_STATUS_CNT_OVF	BIT(0)
-
-#define CMP_INDEX(sync)			((sync) + 1)
-#define IEP_CMP_CFG_SHADOW_EN		BIT(17)
-#define IEP_CMP_CFG_CMP0_RST_CNT_EN	BIT(0)
-#define IEP_CMP_CFG_CMP_EN(cmp)		(GENMASK(16, 1) & (1 << ((cmp) + 1)))
-
-#define IEP_CMP_STATUS(cmp)		(1 << (cmp))
-
-#define IEP_SYNC_CTRL_SYNC_EN		BIT(0)
-#define IEP_SYNC_CTRL_SYNC_N_EN(n)	(GENMASK(2, 1) & (BIT(1) << (n)))
-
-#define IEP_MIN_CMP	0
-#define IEP_MAX_CMP	15
-
-#define ICSS_IEP_64BIT_COUNTER_SUPPORT		BIT(0)
-#define ICSS_IEP_SLOW_COMPEN_REG_SUPPORT	BIT(1)
-#define ICSS_IEP_SHADOW_MODE_SUPPORT		BIT(2)
-
-#define LATCH_INDEX(ts_index)			((ts_index) + 6)
-#define IEP_CAP_CFG_CAPNR_1ST_EVENT_EN(n)	BIT(LATCH_INDEX(n))
-#define IEP_CAP_CFG_CAPNF_1ST_EVENT_EN(n)	BIT(LATCH_INDEX(n) + 1)
-#define IEP_CAP_CFG_CAP_ASYNC_EN(n)		BIT(LATCH_INDEX(n) + 10)
-
-enum {
-	ICSS_IEP_GLOBAL_CFG_REG,
-	ICSS_IEP_GLOBAL_STATUS_REG,
-	ICSS_IEP_COMPEN_REG,
-	ICSS_IEP_SLOW_COMPEN_REG,
-	ICSS_IEP_COUNT_REG0,
-	ICSS_IEP_COUNT_REG1,
-	ICSS_IEP_CAPTURE_CFG_REG,
-	ICSS_IEP_CAPTURE_STAT_REG,
-
-	ICSS_IEP_CAP6_RISE_REG0,
-	ICSS_IEP_CAP6_RISE_REG1,
-
-	ICSS_IEP_CAP7_RISE_REG0,
-	ICSS_IEP_CAP7_RISE_REG1,
-
-	ICSS_IEP_CMP_CFG_REG,
-	ICSS_IEP_CMP_STAT_REG,
-	ICSS_IEP_CMP0_REG0,
-	ICSS_IEP_CMP0_REG1,
-	ICSS_IEP_CMP1_REG0,
-	ICSS_IEP_CMP1_REG1,
-
-	ICSS_IEP_CMP8_REG0,
-	ICSS_IEP_CMP8_REG1,
-	ICSS_IEP_SYNC_CTRL_REG,
-	ICSS_IEP_SYNC0_STAT_REG,
-	ICSS_IEP_SYNC1_STAT_REG,
-	ICSS_IEP_SYNC_PWIDTH_REG,
-	ICSS_IEP_SYNC0_PERIOD_REG,
-	ICSS_IEP_SYNC1_DELAY_REG,
-	ICSS_IEP_SYNC_START_REG,
-	ICSS_IEP_MAX_REGS,
-};
-
-/**
- * struct icss_iep_plat_data - Plat data to handle SoC variants
- * @config: Regmap configuration data
- * @reg_offs: register offsets to capture offset differences across SoCs
- * @flags: Flags to represent IEP properties
- */
-struct icss_iep_plat_data {
-	struct regmap_config *config;
-	u32 reg_offs[ICSS_IEP_MAX_REGS];
-	u32 flags;
-};
-
-struct icss_iep {
-	struct device *dev;
-	void __iomem *base;
-	const struct icss_iep_plat_data *plat_data;
-	struct regmap *map;
-	struct device_node *client_np;
-	unsigned long refclk_freq;
-	int clk_tick_time;	/* one refclk tick time in ns */
-	struct ptp_clock_info ptp_info;
-	struct ptp_clock *ptp_clock;
-	struct mutex ptp_clk_mutex;	/* PHC access serializer */
-	spinlock_t irq_lock; /* CMP IRQ vs icss_iep_ptp_enable access */
-	u32 def_inc;
-	s16 slow_cmp_inc;
-	u32 slow_cmp_count;
-	const struct icss_iep_clockops *ops;
-	void *clockops_data;
-	u32 cycle_time_ns;
-	u32 perout_enabled;
-	bool pps_enabled;
-	int cap_cmp_irq;
-	u64 period;
-	u32 latch_enable;
-	struct hrtimer sync_timer;
-};
-
-static u32 icss_iep_readl(struct icss_iep *iep, int reg)
-{
-	return readl(iep->base + iep->plat_data->reg_offs[reg]);
-}
-
-static void icss_iep_writel(struct icss_iep *iep, int reg, u32 val)
-{
-	return writel(val, iep->base + iep->plat_data->reg_offs[reg]);
-}
-
-/**
- * icss_iep_get_count_hi() - Get the upper 32 bit IEP counter
- * @iep: Pointer to structure representing IEP.
- *
- * Return: upper 32 bit IEP counter
- */
-int icss_iep_get_count_hi(struct icss_iep *iep)
-{
-	u32 val = 0;
-
-	if (iep && (iep->plat_data->flags & ICSS_IEP_64BIT_COUNTER_SUPPORT))
-		val = icss_iep_readl(iep, ICSS_IEP_COUNT_REG1);
-
-	return val;
-}
-EXPORT_SYMBOL_GPL(icss_iep_get_count_hi);
-
-/**
- * icss_iep_get_count_low() - Get the lower 32 bit IEP counter
- * @iep: Pointer to structure representing IEP.
- *
- * Return: lower 32 bit IEP counter
- */
-int icss_iep_get_count_low(struct icss_iep *iep)
-{
-	u32 val = 0;
-
-	if (iep)
-		val = icss_iep_readl(iep, ICSS_IEP_COUNT_REG0);
-
-	return val;
-}
-EXPORT_SYMBOL_GPL(icss_iep_get_count_low);
-
-/**
- * icss_iep_get_ptp_clock_idx() - Get PTP clock index using IEP driver
- * @iep: Pointer to structure representing IEP.
- *
- * Return: PTP clock index, -1 if not registered
- */
-int icss_iep_get_ptp_clock_idx(struct icss_iep *iep)
-{
-	if (!iep || !iep->ptp_clock)
-		return -1;
-	return ptp_clock_index(iep->ptp_clock);
-}
-EXPORT_SYMBOL_GPL(icss_iep_get_ptp_clock_idx);
-
-static void icss_iep_set_counter(struct icss_iep *iep, u64 ns)
-{
-	if (iep->plat_data->flags & ICSS_IEP_64BIT_COUNTER_SUPPORT)
-		icss_iep_writel(iep, ICSS_IEP_COUNT_REG1, upper_32_bits(ns));
-	icss_iep_writel(iep, ICSS_IEP_COUNT_REG0, lower_32_bits(ns));
-}
-
-static void icss_iep_update_to_next_boundary(struct icss_iep *iep, u64 start_ns);
-
-static void icss_iep_settime(struct icss_iep *iep, u64 ns)
-{
-	unsigned long flags;
-
-	if (iep->ops && iep->ops->settime) {
-		iep->ops->settime(iep->clockops_data, ns);
-		return;
-	}
-
-	spin_lock_irqsave(&iep->irq_lock, flags);
-	if (iep->pps_enabled || iep->perout_enabled)
-		icss_iep_writel(iep, ICSS_IEP_SYNC_CTRL_REG, 0);
-
-	icss_iep_set_counter(iep, ns);
-
-	if (iep->pps_enabled || iep->perout_enabled) {
-		icss_iep_update_to_next_boundary(iep, ns);
-		icss_iep_writel(iep, ICSS_IEP_SYNC_CTRL_REG,
-			     IEP_SYNC_CTRL_SYNC_N_EN(0) | IEP_SYNC_CTRL_SYNC_EN);
-	}
-	spin_unlock_irqrestore(&iep->irq_lock, flags);
-}
-
-static u64 icss_iep_gettime(struct icss_iep *iep,
-			    struct ptp_system_timestamp *sts)
-{
-	u32 ts_hi = 0, ts_lo;
-	unsigned long flags;
-
-	if (iep->ops && iep->ops->gettime)
-		return iep->ops->gettime(iep->clockops_data);
-
-	/* use local_irq_x() to make it work for both RT/non-RT */
-	local_irq_save(flags);
-
-	/* no need to play with hi-lo, hi is latched when lo is read */
-	ptp_read_system_prets(sts);
-	ts_lo = icss_iep_readl(iep, ICSS_IEP_COUNT_REG0);
-	ptp_read_system_postts(sts);
-	if (iep->plat_data->flags & ICSS_IEP_64BIT_COUNTER_SUPPORT)
-		ts_hi = icss_iep_readl(iep, ICSS_IEP_COUNT_REG1);
-
-	local_irq_restore(flags);
-
-	return (u64)ts_lo | (u64)ts_hi << 32;
-}
-
-static void icss_iep_enable(struct icss_iep *iep)
-{
-	regmap_update_bits(iep->map, ICSS_IEP_GLOBAL_CFG_REG,
-			   IEP_GLOBAL_CFG_CNT_ENABLE,
-			   IEP_GLOBAL_CFG_CNT_ENABLE);
-}
-
-static void icss_iep_disable(struct icss_iep *iep)
-{
-	regmap_update_bits(iep->map, ICSS_IEP_GLOBAL_CFG_REG,
-			   IEP_GLOBAL_CFG_CNT_ENABLE,
-			   0);
-}
-
-static void icss_iep_enable_shadow_mode(struct icss_iep *iep)
-{
-	u32 cycle_time;
-	int cmp;
-
-	/* FIXME: check why we need to decrement by def_inc */
-	cycle_time = iep->cycle_time_ns - iep->def_inc;
-
-	icss_iep_disable(iep);
-
-	/* disable shadow mode */
-	regmap_update_bits(iep->map, ICSS_IEP_CMP_CFG_REG,
-			   IEP_CMP_CFG_SHADOW_EN, 0);
-
-	/* enable shadow mode */
-	regmap_update_bits(iep->map, ICSS_IEP_CMP_CFG_REG,
-			   IEP_CMP_CFG_SHADOW_EN, IEP_CMP_CFG_SHADOW_EN);
-
-	/* clear counters */
-	icss_iep_set_counter(iep, 0);
-
-	/* clear overflow status */
-	regmap_update_bits(iep->map, ICSS_IEP_GLOBAL_STATUS_REG,
-			   IEP_GLOBAL_STATUS_CNT_OVF,
-			   IEP_GLOBAL_STATUS_CNT_OVF);
-
-	/* clear compare status */
-	for (cmp = IEP_MIN_CMP; cmp < IEP_MAX_CMP; cmp++) {
-		regmap_update_bits(iep->map, ICSS_IEP_CMP_STAT_REG,
-				   IEP_CMP_STATUS(cmp), IEP_CMP_STATUS(cmp));
-	}
-
-	/* enable reset counter on CMP0 event */
-	regmap_update_bits(iep->map, ICSS_IEP_CMP_CFG_REG,
-			   IEP_CMP_CFG_CMP0_RST_CNT_EN,
-			   IEP_CMP_CFG_CMP0_RST_CNT_EN);
-	/* enable compare */
-	regmap_update_bits(iep->map, ICSS_IEP_CMP_CFG_REG,
-			   IEP_CMP_CFG_CMP_EN(0),
-			   IEP_CMP_CFG_CMP_EN(0));
-
-	/* set CMP0 value to cycle time */
-	regmap_write(iep->map, ICSS_IEP_CMP0_REG0, cycle_time);
-	if (iep->plat_data->flags & ICSS_IEP_64BIT_COUNTER_SUPPORT)
-		regmap_write(iep->map, ICSS_IEP_CMP0_REG1, cycle_time);
-
-	icss_iep_set_counter(iep, 0);
-	icss_iep_enable(iep);
-}
-
-static void icss_iep_set_default_inc(struct icss_iep *iep, u8 def_inc)
-{
-	regmap_update_bits(iep->map, ICSS_IEP_GLOBAL_CFG_REG,
-			   IEP_GLOBAL_CFG_DEFAULT_INC_MASK,
-			   def_inc << IEP_GLOBAL_CFG_DEFAULT_INC_SHIFT);
-}
-
-static void icss_iep_set_compensation_inc(struct icss_iep *iep, u16 compen_inc)
-{
-	struct device *dev = regmap_get_device(iep->map);
-
-	if (compen_inc > IEP_MAX_COMPEN_INC) {
-		dev_err(dev, "%s: too high compensation inc %d\n",
-			__func__, compen_inc);
-		compen_inc = IEP_MAX_COMPEN_INC;
-	}
-
-	regmap_update_bits(iep->map, ICSS_IEP_GLOBAL_CFG_REG,
-			   IEP_GLOBAL_CFG_COMPEN_INC_MASK,
-			   compen_inc << IEP_GLOBAL_CFG_COMPEN_INC_SHIFT);
-}
-
-static void icss_iep_set_compensation_count(struct icss_iep *iep,
-					    u32 compen_count)
-{
-	struct device *dev = regmap_get_device(iep->map);
-
-	if (compen_count > IEP_MAX_COMPEN_COUNT) {
-		dev_err(dev, "%s: too high compensation count %d\n",
-			__func__, compen_count);
-		compen_count = IEP_MAX_COMPEN_COUNT;
-	}
-
-	regmap_write(iep->map, ICSS_IEP_COMPEN_REG, compen_count);
-}
-
-static void icss_iep_set_slow_compensation_count(struct icss_iep *iep,
-						 u32 compen_count)
-{
-	regmap_write(iep->map, ICSS_IEP_SLOW_COMPEN_REG, compen_count);
-}
-
-/* PTP PHC operations */
-static int icss_iep_ptp_adjfreq(struct ptp_clock_info *ptp, s32 ppb)
-{
-	struct icss_iep *iep = container_of(ptp, struct icss_iep, ptp_info);
-	u32 cyc_count;
-	u16 cmp_inc;
-
-	mutex_lock(&iep->ptp_clk_mutex);
-
-	/* ppb is amount of frequency we want to adjust in 1GHz (billion)
-	 * e.g. 100ppb means we need to speed up clock by 100Hz
-	 * i.e. at end of 1 second (1 billion ns) clock time, we should be
-	 * counting 100 more ns.
-	 * We use IEP slow compensation to achieve continuous freq. adjustment.
-	 * There are 2 parts. Cycle time and adjustment per cycle.
-	 * Simplest case would be 1 sec Cycle time. Then adjustment
-	 * pre cycle would be (def_inc + ppb) value.
-	 * Cycle time will have to be chosen based on how worse the ppb is.
-	 * e.g. smaller the ppb, cycle time has to be large.
-	 * The minimum adjustment we can do is +-1ns per cycle so let's
-	 * reduce the cycle time to get 1ns per cycle adjustment.
-	 *	1ppb = 1sec cycle time & 1ns adjust
-	 *	1000ppb = 1/1000 cycle time & 1ns adjust per cycle
-	 */
-
-	if (iep->cycle_time_ns)
-		iep->slow_cmp_inc = iep->clk_tick_time;	/* 4ns adj per cycle */
-	else
-		iep->slow_cmp_inc = 1;	/* 1ns adjust per cycle */
-
-	if (ppb < 0) {
-		iep->slow_cmp_inc = -iep->slow_cmp_inc;
-		ppb = -ppb;
-	}
-
-	cyc_count = NSEC_PER_SEC;		/* 1s cycle time @1GHz */
-	cyc_count /= ppb;		/* cycle time per ppb */
-
-	/* slow_cmp_count is decremented every clock cycle, e.g. @250MHz */
-	if (!iep->cycle_time_ns)
-		cyc_count /= iep->clk_tick_time;
-	iep->slow_cmp_count = cyc_count;
-
-	/* iep->clk_tick_time is def_inc */
-	cmp_inc = iep->clk_tick_time + iep->slow_cmp_inc;
-	icss_iep_set_compensation_inc(iep, cmp_inc);
-	icss_iep_set_slow_compensation_count(iep, iep->slow_cmp_count);
-
-	mutex_unlock(&iep->ptp_clk_mutex);
-
-	return 0;
-}
-
-static int icss_iep_ptp_adjtime(struct ptp_clock_info *ptp, s64 delta)
-{
-	struct icss_iep *iep = container_of(ptp, struct icss_iep, ptp_info);
-	s64 ns;
-
-	mutex_lock(&iep->ptp_clk_mutex);
-	if (iep->ops && iep->ops->adjtime) {
-		iep->ops->adjtime(iep->clockops_data, delta);
-	} else {
-		ns = icss_iep_gettime(iep, NULL);
-		ns += delta;
-		icss_iep_settime(iep, ns);
-	}
-	mutex_unlock(&iep->ptp_clk_mutex);
-
-	return 0;
-}
-
-static int icss_iep_ptp_gettimeex(struct ptp_clock_info *ptp,
-				  struct timespec64 *ts,
-				  struct ptp_system_timestamp *sts)
-{
-	struct icss_iep *iep = container_of(ptp, struct icss_iep, ptp_info);
-	u64 ns;
-
-	mutex_lock(&iep->ptp_clk_mutex);
-	ns = icss_iep_gettime(iep, sts);
-	*ts = ns_to_timespec64(ns);
-	mutex_unlock(&iep->ptp_clk_mutex);
-
-	return 0;
-}
-
-static int icss_iep_ptp_settime(struct ptp_clock_info *ptp,
-				const struct timespec64 *ts)
-{
-	struct icss_iep *iep = container_of(ptp, struct icss_iep, ptp_info);
-	u64 ns;
-
-	mutex_lock(&iep->ptp_clk_mutex);
-	ns = timespec64_to_ns(ts);
-	icss_iep_settime(iep, ns);
-	mutex_unlock(&iep->ptp_clk_mutex);
-
-	return 0;
-}
-
-static void icss_iep_update_to_next_boundary(struct icss_iep *iep, u64 start_ns)
-{
-	u64 ns, p_ns;
-	u32 offset;
-
-	ns = icss_iep_gettime(iep, NULL);
-	if (start_ns < ns)
-		start_ns = ns;
-	p_ns = iep->period;
-	/* Round up to next period boundary */
-	start_ns += p_ns - 1;
-	offset = do_div(start_ns, p_ns);
-	start_ns = start_ns * p_ns;
-	/* If it is too close to update, shift to next boundary */
-	if (p_ns - offset < 10)
-		start_ns += p_ns;
-
-	regmap_write(iep->map, ICSS_IEP_CMP1_REG0, lower_32_bits(start_ns));
-	if (iep->plat_data->flags & ICSS_IEP_64BIT_COUNTER_SUPPORT)
-		regmap_write(iep->map, ICSS_IEP_CMP1_REG1, upper_32_bits(start_ns));
-}
-
-static int icss_iep_perout_enable_hw(struct icss_iep *iep,
-				     struct ptp_perout_request *req, int on)
-{
-	int ret;
-	u64 cmp;
-
-	if (iep->ops && iep->ops->perout_enable) {
-		ret = iep->ops->perout_enable(iep->clockops_data, req, on, &cmp);
-		if (ret)
-			return ret;
-
-		if (on) {
-			/* Configure CMP */
-			regmap_write(iep->map, ICSS_IEP_CMP1_REG0, lower_32_bits(cmp));
-			if (iep->plat_data->flags & ICSS_IEP_64BIT_COUNTER_SUPPORT)
-				regmap_write(iep->map, ICSS_IEP_CMP1_REG1, upper_32_bits(cmp));
-			/* Configure SYNC */
-			regmap_write(iep->map, ICSS_IEP_SYNC_PWIDTH_REG, 1000000); /* 1ms pulse width */
-			regmap_write(iep->map, ICSS_IEP_SYNC0_PERIOD_REG, 0);
-			regmap_write(iep->map, ICSS_IEP_SYNC_START_REG, 0);
-			regmap_write(iep->map, ICSS_IEP_SYNC_CTRL_REG, 0); /* one-shot mode */
-			/* Enable CMP 1 */
-			regmap_update_bits(iep->map, ICSS_IEP_CMP_CFG_REG,
-					   IEP_CMP_CFG_CMP_EN(1), IEP_CMP_CFG_CMP_EN(1));
-		} else {
-			/* Disable CMP 1 */
-			regmap_update_bits(iep->map, ICSS_IEP_CMP_CFG_REG,
-					   IEP_CMP_CFG_CMP_EN(1), 0);
-
-			/* clear regs */
-			regmap_write(iep->map, ICSS_IEP_CMP1_REG0, 0);
-			if (iep->plat_data->flags & ICSS_IEP_64BIT_COUNTER_SUPPORT)
-				regmap_write(iep->map, ICSS_IEP_CMP1_REG1, 0);
-		}
-	} else {
-		if (on) {
-			u64 start_ns;
-
-			iep->period = ((u64)req->period.sec * NSEC_PER_SEC) +
-				      req->period.nsec;
-			start_ns = ((u64)req->period.sec * NSEC_PER_SEC)
-				   + req->period.nsec;
-			icss_iep_update_to_next_boundary(iep, start_ns);
-
-			/* Enable Sync in single shot mode  */
-			regmap_write(iep->map, ICSS_IEP_SYNC_CTRL_REG,
-				     IEP_SYNC_CTRL_SYNC_N_EN(0) | IEP_SYNC_CTRL_SYNC_EN);
-			/* Enable CMP 1 */
-			regmap_update_bits(iep->map, ICSS_IEP_CMP_CFG_REG,
-					   IEP_CMP_CFG_CMP_EN(1), IEP_CMP_CFG_CMP_EN(1));
-		} else {
-			/* Disable CMP 1 */
-			regmap_update_bits(iep->map, ICSS_IEP_CMP_CFG_REG,
-					   IEP_CMP_CFG_CMP_EN(1), 0);
-
-			/* clear CMP regs */
-			regmap_write(iep->map, ICSS_IEP_CMP1_REG0, 0);
-			if (iep->plat_data->flags & ICSS_IEP_64BIT_COUNTER_SUPPORT)
-				regmap_write(iep->map, ICSS_IEP_CMP1_REG1, 0);
-
-			/* Disable sync */
-			regmap_write(iep->map, ICSS_IEP_SYNC_CTRL_REG, 0);
-		}
-	}
-
-	return 0;
-}
-
-static int icss_iep_perout_enable(struct icss_iep *iep,
-				  struct ptp_perout_request *req, int on)
-{
-	unsigned long flags;
-	int ret = 0;
-
-	mutex_lock(&iep->ptp_clk_mutex);
-
-	if (iep->pps_enabled) {
-		ret = -EBUSY;
-		goto exit;
-	}
-
-	if (iep->perout_enabled == !!on)
-		goto exit;
-
-	spin_lock_irqsave(&iep->irq_lock, flags);
-	if (iep->cap_cmp_irq)
-		hrtimer_cancel(&iep->sync_timer);
-	ret = icss_iep_perout_enable_hw(iep, req, on);
-	if (!ret)
-		iep->perout_enabled = !!on;
-	spin_unlock_irqrestore(&iep->irq_lock, flags);
-
-exit:
-	mutex_unlock(&iep->ptp_clk_mutex);
-
-	return ret;
-}
-
-static irqreturn_t icss_iep_cap_cmp_handler(int irq, void *dev_id)
-{
-	struct icss_iep *iep = (struct icss_iep *)dev_id;
-	unsigned int val, index = 0, i, sts;
-	struct ptp_clock_event pevent;
-	irqreturn_t ret = IRQ_NONE;
-	unsigned long flags;
-	u64 ns, ns_next;
-
-	spin_lock_irqsave(&iep->irq_lock, flags);
-
-	val = icss_iep_readl(iep, ICSS_IEP_CMP_STAT_REG);
-	if (val & BIT(CMP_INDEX(index))) {
-		icss_iep_writel(iep, ICSS_IEP_CMP_STAT_REG,
-				BIT(CMP_INDEX(index)));
-
-		if (!iep->pps_enabled && !iep->perout_enabled)
-			goto do_latch;
-
-		ns = icss_iep_readl(iep, ICSS_IEP_CMP1_REG0);
-		if (iep->plat_data->flags & ICSS_IEP_64BIT_COUNTER_SUPPORT) {
-			val = icss_iep_readl(iep, ICSS_IEP_CMP1_REG1);
-			ns |= (u64)val << 32;
-		}
-		/* set next event */
-		ns_next = ns + iep->period;
-		icss_iep_writel(iep, ICSS_IEP_CMP1_REG0,
-				lower_32_bits(ns_next));
-		if (iep->plat_data->flags & ICSS_IEP_64BIT_COUNTER_SUPPORT)
-			icss_iep_writel(iep, ICSS_IEP_CMP1_REG1,
-					upper_32_bits(ns_next));
-
-		pevent.pps_times.ts_real = ns_to_timespec64(ns);
-		pevent.type = PTP_CLOCK_PPSUSR;
-		pevent.index = index;
-		ptp_clock_event(iep->ptp_clock, &pevent);
-		dev_dbg(iep->dev, "IEP:pps ts: %llu next:%llu:\n", ns, ns_next);
-
-		hrtimer_start(&iep->sync_timer, ms_to_ktime(110), /* 100ms + buffer */
-			      HRTIMER_MODE_REL);
-
-		ret = IRQ_HANDLED;
-	}
-
-do_latch:
-	sts = icss_iep_readl(iep, ICSS_IEP_CAPTURE_STAT_REG);
-	if (!sts)
-		goto cap_cmp_exit;
-
-	for (i = 0; i < iep->ptp_info.n_ext_ts; i++) {
-		if (sts & IEP_CAP_CFG_CAPNR_1ST_EVENT_EN(i * 2)) {
-			ns = icss_iep_readl(iep,
-					    ICSS_IEP_CAP6_RISE_REG0 + (i * 2));
-			if (iep->plat_data->flags & ICSS_IEP_64BIT_COUNTER_SUPPORT) {
-				val = icss_iep_readl(iep,
-						     ICSS_IEP_CAP6_RISE_REG0 + (i * 2) + 1);
-				ns |= (u64)val << 32;
-			}
-			pevent.timestamp = ns;
-			pevent.type = PTP_CLOCK_EXTTS;
-			pevent.index = i;
-			ptp_clock_event(iep->ptp_clock, &pevent);
-			dev_dbg(iep->dev, "IEP:extts index=%d ts: %llu\n", i, ns);
-			ret = IRQ_HANDLED;
-		}
-	}
-
-cap_cmp_exit:
-	spin_unlock_irqrestore(&iep->irq_lock, flags);
-	return ret;
-}
-
-static int icss_iep_pps_enable(struct icss_iep *iep, int on)
-{
-	int ret = 0;
-	struct timespec64 ts;
-	struct ptp_clock_request rq;
-	unsigned long flags;
-	u64 ns;
-
-	mutex_lock(&iep->ptp_clk_mutex);
-
-	if (iep->perout_enabled) {
-		ret = -EBUSY;
-		goto exit;
-	}
-
-	if (iep->pps_enabled == !!on)
-		goto exit;
-
-	spin_lock_irqsave(&iep->irq_lock, flags);
-
-	rq.perout.index = 0;
-	if (on) {
-		ns = icss_iep_gettime(iep, NULL);
-		ts = ns_to_timespec64(ns);
-		rq.perout.period.sec = 1;
-		rq.perout.period.nsec = 0;
-		rq.perout.start.sec = ts.tv_sec + 2;
-		rq.perout.start.nsec = 0;
-		ret = icss_iep_perout_enable_hw(iep, &rq.perout, on);
-	} else {
-		if (iep->cap_cmp_irq)
-			hrtimer_cancel(&iep->sync_timer);
-		ret = icss_iep_perout_enable_hw(iep, &rq.perout, on);
-	}
-
-	if (!ret)
-		iep->pps_enabled = !!on;
-
-	spin_unlock_irqrestore(&iep->irq_lock, flags);
-
-exit:
-	mutex_unlock(&iep->ptp_clk_mutex);
-
-	return ret;
-}
-
-static int icss_iep_extts_enable(struct icss_iep *iep, u32 index, int on)
-{
-	u32 val, cap, ret = 0;
-
-	mutex_lock(&iep->ptp_clk_mutex);
-
-	if (iep->ops && iep->ops->extts_enable) {
-		ret = iep->ops->extts_enable(iep->clockops_data, index, on);
-		goto exit;
-	}
-
-	if (!!(iep->latch_enable & BIT(index)) == !!on)
-		goto exit;
-
-	regmap_read(iep->map, ICSS_IEP_CAPTURE_CFG_REG, &val);
-	cap = IEP_CAP_CFG_CAP_ASYNC_EN(index) | IEP_CAP_CFG_CAPNR_1ST_EVENT_EN(index);
-	if (on) {
-		val |= cap;
-		iep->latch_enable |= BIT(index);
-	} else {
-		val &= ~cap;
-		iep->latch_enable &= ~BIT(index);
-	}
-	regmap_write(iep->map, ICSS_IEP_CAPTURE_CFG_REG, val);
-
-exit:
-	mutex_unlock(&iep->ptp_clk_mutex);
-
-	return ret;
-}
-
-static int icss_iep_ptp_enable(struct ptp_clock_info *ptp,
-			       struct ptp_clock_request *rq, int on)
-{
-	struct icss_iep *iep = container_of(ptp, struct icss_iep, ptp_info);
-
-	switch (rq->type) {
-	case PTP_CLK_REQ_PEROUT:
-		return icss_iep_perout_enable(iep, &rq->perout, on);
-	case PTP_CLK_REQ_PPS:
-		return icss_iep_pps_enable(iep, on);
-	case PTP_CLK_REQ_EXTTS:
-		return icss_iep_extts_enable(iep, rq->extts.index, on);
-	default:
-		break;
-	}
-
-	return -EOPNOTSUPP;
-}
-
-static struct ptp_clock_info icss_iep_ptp_info = {
-	.owner		= THIS_MODULE,
-	.name		= "ICSS IEP timer",
-	.max_adj	= 10000000,
-	.adjfreq	= icss_iep_ptp_adjfreq,
-	.adjtime	= icss_iep_ptp_adjtime,
-	.gettimex64	= icss_iep_ptp_gettimeex,
-	.settime64	= icss_iep_ptp_settime,
-	.enable		= icss_iep_ptp_enable,
-};
-
-static enum hrtimer_restart icss_iep_sync0_work(struct hrtimer *timer)
-{
-	struct icss_iep *iep = container_of(timer, struct icss_iep, sync_timer);
-
-	icss_iep_writel(iep, ICSS_IEP_SYNC_CTRL_REG, 0);
-	icss_iep_writel(iep, ICSS_IEP_SYNC_CTRL_REG,
-			IEP_SYNC_CTRL_SYNC_N_EN(0) | IEP_SYNC_CTRL_SYNC_EN);
-	icss_iep_writel(iep, ICSS_IEP_SYNC0_STAT_REG, 1);
-
-	return HRTIMER_NORESTART;
-}
-
-struct icss_iep *icss_iep_get_idx(struct device_node *np, int idx)
-{
-	struct platform_device *pdev;
-	struct device_node *iep_np;
-	struct icss_iep *iep;
-
-	iep_np = of_parse_phandle(np, "iep", idx);
-	if (!iep_np || !of_device_is_available(iep_np))
-		return ERR_PTR(-ENODEV);
-
-	pdev = of_find_device_by_node(iep_np);
-	of_node_put(iep_np);
-
-	if (!pdev)
-		/* probably IEP not yet probed */
-		return ERR_PTR(-EPROBE_DEFER);
-
-	iep = platform_get_drvdata(pdev);
-	if (!iep)
-		return ERR_PTR(-EPROBE_DEFER);
-
-	device_lock(iep->dev);
-	if (iep->client_np) {
-		device_unlock(iep->dev);
-		dev_err(iep->dev, "IEP is already acquired by %s",
-			iep->client_np->name);
-		return ERR_PTR(-EBUSY);
-	}
-	iep->client_np = np;
-	device_unlock(iep->dev);
-	get_device(iep->dev);
-
-	return iep;
-}
-EXPORT_SYMBOL_GPL(icss_iep_get_idx);
-
-struct icss_iep *icss_iep_get(struct device_node *np)
-{
-	return icss_iep_get_idx(np, 0);
-}
-EXPORT_SYMBOL_GPL(icss_iep_get);
-
-void icss_iep_put(struct icss_iep *iep)
-{
-	device_lock(iep->dev);
-	iep->client_np = NULL;
-	device_unlock(iep->dev);
-	put_device(iep->dev);
-	if (iep->cap_cmp_irq)
-		hrtimer_cancel(&iep->sync_timer);
-}
-EXPORT_SYMBOL_GPL(icss_iep_put);
-
-void icss_iep_init_fw(struct icss_iep *iep)
-{
-	/* start IEP for FW use in raw 64bit mode, no PTP support */
-	iep->clk_tick_time = iep->def_inc;
-	iep->cycle_time_ns = 0;
-	iep->ops = NULL;
-	iep->clockops_data = NULL;
-	icss_iep_set_default_inc(iep, iep->def_inc);
-	icss_iep_set_compensation_inc(iep, iep->def_inc);
-	icss_iep_set_compensation_count(iep, 0);
-	regmap_write(iep->map, ICSS_IEP_SYNC_PWIDTH_REG, iep->refclk_freq / 10); /* 100 ms pulse */
-	regmap_write(iep->map, ICSS_IEP_SYNC0_PERIOD_REG, 0);
-	if (iep->plat_data->flags & ICSS_IEP_SLOW_COMPEN_REG_SUPPORT)
-		icss_iep_set_slow_compensation_count(iep, 0);
-
-	icss_iep_enable(iep);
-	icss_iep_settime(iep, 0);
-}
-EXPORT_SYMBOL_GPL(icss_iep_init_fw);
-
-void icss_iep_exit_fw(struct icss_iep *iep)
-{
-	icss_iep_disable(iep);
-}
-EXPORT_SYMBOL_GPL(icss_iep_exit_fw);
-
-int icss_iep_init(struct icss_iep *iep, const struct icss_iep_clockops *clkops,
-		  void *clockops_data, u32 cycle_time_ns)
-{
-	int ret = 0;
-
-	iep->cycle_time_ns = cycle_time_ns;
-	iep->clk_tick_time = iep->def_inc;
-	iep->ops = clkops;
-	iep->clockops_data = clockops_data;
-	icss_iep_set_default_inc(iep, iep->def_inc);
-	icss_iep_set_compensation_inc(iep, iep->def_inc);
-	icss_iep_set_compensation_count(iep, 0);
-	regmap_write(iep->map, ICSS_IEP_SYNC_PWIDTH_REG, iep->refclk_freq / 10); /* 100 ms pulse */
-	regmap_write(iep->map, ICSS_IEP_SYNC0_PERIOD_REG, 0);
-	if (iep->plat_data->flags & ICSS_IEP_SLOW_COMPEN_REG_SUPPORT)
-		icss_iep_set_slow_compensation_count(iep, 0);
-
-	if (!(iep->plat_data->flags & ICSS_IEP_64BIT_COUNTER_SUPPORT) ||
-	    !(iep->plat_data->flags & ICSS_IEP_SLOW_COMPEN_REG_SUPPORT))
-		goto skip_perout;
-
-	if (iep->cap_cmp_irq || (iep->ops && iep->ops->perout_enable)) {
-		iep->ptp_info.n_per_out = 1;
-		iep->ptp_info.pps = 1;
-	}
-
-	if (iep->cap_cmp_irq || (iep->ops && iep->ops->extts_enable))
-		iep->ptp_info.n_ext_ts = 2;
-
-skip_perout:
-	if (cycle_time_ns)
-		icss_iep_enable_shadow_mode(iep);
-	else
-		icss_iep_enable(iep);
-	icss_iep_settime(iep, ktime_get_real_ns());
-
-	iep->ptp_clock = ptp_clock_register(&iep->ptp_info, iep->dev);
-	if (IS_ERR(iep->ptp_clock)) {
-		ret = PTR_ERR(iep->ptp_clock);
-		iep->ptp_clock = NULL;
-		dev_err(iep->dev, "Failed to register ptp clk %d\n", ret);
-	}
-
-	return ret;
-}
-EXPORT_SYMBOL_GPL(icss_iep_init);
-
-int icss_iep_exit(struct icss_iep *iep)
-{
-	if (iep->ptp_clock) {
-		ptp_clock_unregister(iep->ptp_clock);
-		iep->ptp_clock = NULL;
-	}
-	icss_iep_disable(iep);
-
-	return 0;
-}
-EXPORT_SYMBOL_GPL(icss_iep_exit);
-
-static const struct of_device_id icss_iep_of_match[];
-
-static int icss_iep_probe(struct platform_device *pdev)
-{
-	struct device *dev = &pdev->dev;
-	struct icss_iep *iep;
-	struct clk *iep_clk;
-	int ret;
-
-	iep = devm_kzalloc(dev, sizeof(*iep), GFP_KERNEL);
-	if (!iep)
-		return -ENOMEM;
-
-	iep->dev = dev;
-	iep->base = devm_platform_ioremap_resource(pdev, 0);
-	if (IS_ERR(iep->base))
-		return -ENODEV;
-
-	iep->cap_cmp_irq = platform_get_irq_byname_optional(pdev, "iep_cap_cmp");
-	if (iep->cap_cmp_irq < 0) {
-		if (iep->cap_cmp_irq == -EPROBE_DEFER)
-			return iep->cap_cmp_irq;
-		iep->cap_cmp_irq = 0;
-	} else {
-		ret = devm_request_irq(dev, iep->cap_cmp_irq,
-				       icss_iep_cap_cmp_handler, IRQF_TRIGGER_HIGH,
-				       "iep_cap_cmp", iep);
-		if (ret) {
-			dev_err(iep->dev, "Request irq failed for cap_cmp %d\n", ret);
-			return ret;
-		}
-		hrtimer_init(&iep->sync_timer, CLOCK_MONOTONIC, HRTIMER_MODE_REL);
-		iep->sync_timer.function = icss_iep_sync0_work;
-	}
-
-	iep_clk = devm_clk_get(dev, NULL);
-	if (IS_ERR(iep_clk))
-		return PTR_ERR(iep_clk);
-
-	iep->refclk_freq = clk_get_rate(iep_clk);
-
-	iep->def_inc = NSEC_PER_SEC / iep->refclk_freq;	/* ns per clock tick */
-	if (iep->def_inc > IEP_MAX_DEF_INC) {
-		dev_err(dev, "Failed to set def_inc %d.  IEP_clock is too slow to be supported\n",
-			iep->def_inc);
-		return -EINVAL;
-	}
-
-	iep->plat_data = of_device_get_match_data(dev);
-	if (!iep->plat_data)
-		return -EINVAL;
-
-	iep->map = devm_regmap_init(dev, NULL, iep, iep->plat_data->config);
-	if (IS_ERR(iep->map)) {
-		dev_err(dev, "Failed to create regmap for IEP %ld\n",
-			PTR_ERR(iep->map));
-		return PTR_ERR(iep->map);
-	}
-
-	iep->ptp_info = icss_iep_ptp_info;
-	mutex_init(&iep->ptp_clk_mutex);
-	dev_set_drvdata(dev, iep);
-	icss_iep_disable(iep);
-
-	return 0;
-}
-
-static bool am654_icss_iep_valid_reg(struct device *dev, unsigned int reg)
-{
-	switch (reg) {
-	case ICSS_IEP_GLOBAL_CFG_REG ... ICSS_IEP_SYNC_START_REG:
-		return true;
-	default:
-		return false;
-	}
-
-	return false;
-}
-
-static int icss_iep_regmap_write(void *context, unsigned int reg,
-				 unsigned int val)
-{
-	struct icss_iep *iep = context;
-
-	writel(val, iep->base + iep->plat_data->reg_offs[reg]);
-
-	return 0;
-}
-
-static int icss_iep_regmap_read(void *context, unsigned int reg,
-				unsigned int *val)
-{
-	struct icss_iep *iep = context;
-
-	*val = readl(iep->base + iep->plat_data->reg_offs[reg]);
-
-	return 0;
-}
-
-static struct regmap_config am654_icss_iep_regmap_config = {
-	.name = "icss iep",
-	.reg_stride = 1,
-	.reg_write = icss_iep_regmap_write,
-	.reg_read = icss_iep_regmap_read,
-	.writeable_reg = am654_icss_iep_valid_reg,
-	.readable_reg = am654_icss_iep_valid_reg,
-};
-
-static const struct icss_iep_plat_data am654_icss_iep_plat_data = {
-	.flags = ICSS_IEP_64BIT_COUNTER_SUPPORT |
-		 ICSS_IEP_SLOW_COMPEN_REG_SUPPORT |
-		 ICSS_IEP_SHADOW_MODE_SUPPORT,
-	.reg_offs = {
-		[ICSS_IEP_GLOBAL_CFG_REG] = 0x00,
-		[ICSS_IEP_COMPEN_REG] = 0x08,
-		[ICSS_IEP_SLOW_COMPEN_REG] = 0x0C,
-		[ICSS_IEP_COUNT_REG0] = 0x10,
-		[ICSS_IEP_COUNT_REG1] = 0x14,
-		[ICSS_IEP_CAPTURE_CFG_REG] = 0x18,
-		[ICSS_IEP_CAPTURE_STAT_REG] = 0x1c,
-
-		[ICSS_IEP_CAP6_RISE_REG0] = 0x50,
-		[ICSS_IEP_CAP6_RISE_REG1] = 0x54,
-
-		[ICSS_IEP_CAP7_RISE_REG0] = 0x60,
-		[ICSS_IEP_CAP7_RISE_REG1] = 0x64,
-
-		[ICSS_IEP_CMP_CFG_REG] = 0x70,
-		[ICSS_IEP_CMP_STAT_REG] = 0x74,
-		[ICSS_IEP_CMP0_REG0] = 0x78,
-		[ICSS_IEP_CMP0_REG1] = 0x7c,
-		[ICSS_IEP_CMP1_REG0] = 0x80,
-		[ICSS_IEP_CMP1_REG1] = 0x84,
-
-		[ICSS_IEP_CMP8_REG0] = 0xc0,
-		[ICSS_IEP_CMP8_REG1] = 0xc4,
-		[ICSS_IEP_SYNC_CTRL_REG] = 0x180,
-		[ICSS_IEP_SYNC0_STAT_REG] = 0x188,
-		[ICSS_IEP_SYNC1_STAT_REG] = 0x18c,
-		[ICSS_IEP_SYNC_PWIDTH_REG] = 0x190,
-		[ICSS_IEP_SYNC0_PERIOD_REG] = 0x194,
-		[ICSS_IEP_SYNC1_DELAY_REG] = 0x198,
-		[ICSS_IEP_SYNC_START_REG] = 0x19c,
-	},
-	.config = &am654_icss_iep_regmap_config,
-};
-
-static const struct icss_iep_plat_data am57xx_icss_iep_plat_data = {
-	.flags = ICSS_IEP_64BIT_COUNTER_SUPPORT |
-		 ICSS_IEP_SLOW_COMPEN_REG_SUPPORT,
-	.reg_offs = {
-		[ICSS_IEP_GLOBAL_CFG_REG] = 0x00,
-		[ICSS_IEP_COMPEN_REG] = 0x08,
-		[ICSS_IEP_SLOW_COMPEN_REG] = 0x0C,
-		[ICSS_IEP_COUNT_REG0] = 0x10,
-		[ICSS_IEP_COUNT_REG1] = 0x14,
-		[ICSS_IEP_CAPTURE_CFG_REG] = 0x18,
-		[ICSS_IEP_CAPTURE_STAT_REG] = 0x1c,
-
-		[ICSS_IEP_CAP6_RISE_REG0] = 0x50,
-		[ICSS_IEP_CAP6_RISE_REG1] = 0x54,
-
-		[ICSS_IEP_CAP7_RISE_REG0] = 0x60,
-		[ICSS_IEP_CAP7_RISE_REG1] = 0x64,
-
-		[ICSS_IEP_CMP_CFG_REG] = 0x70,
-		[ICSS_IEP_CMP_STAT_REG] = 0x74,
-		[ICSS_IEP_CMP0_REG0] = 0x78,
-		[ICSS_IEP_CMP0_REG1] = 0x7c,
-		[ICSS_IEP_CMP1_REG0] = 0x80,
-		[ICSS_IEP_CMP1_REG1] = 0x84,
-
-		[ICSS_IEP_CMP8_REG0] = 0xc0,
-		[ICSS_IEP_CMP8_REG1] = 0xc4,
-		[ICSS_IEP_SYNC_CTRL_REG] = 0x180,
-		[ICSS_IEP_SYNC0_STAT_REG] = 0x188,
-		[ICSS_IEP_SYNC1_STAT_REG] = 0x18c,
-		[ICSS_IEP_SYNC_PWIDTH_REG] = 0x190,
-		[ICSS_IEP_SYNC0_PERIOD_REG] = 0x194,
-		[ICSS_IEP_SYNC1_DELAY_REG] = 0x198,
-		[ICSS_IEP_SYNC_START_REG] = 0x19c,
-	},
-	.config = &am654_icss_iep_regmap_config,
-};
-
-static bool am335x_icss_iep_valid_reg(struct device *dev, unsigned int reg)
-{
-	switch (reg) {
-	case ICSS_IEP_GLOBAL_CFG_REG ... ICSS_IEP_CAPTURE_STAT_REG:
-	case ICSS_IEP_CAP6_RISE_REG0:
-	case ICSS_IEP_CMP_CFG_REG ... ICSS_IEP_CMP0_REG0:
-	case ICSS_IEP_CMP8_REG0 ... ICSS_IEP_SYNC_START_REG:
-		return true;
-	default:
-		return false;
-	}
-
-	return false;
-}
-
-static struct regmap_config am335x_icss_iep_regmap_config = {
-	.name = "icss iep",
-	.reg_stride = 1,
-	.reg_write = icss_iep_regmap_write,
-	.reg_read = icss_iep_regmap_read,
-	.writeable_reg = am335x_icss_iep_valid_reg,
-	.readable_reg = am335x_icss_iep_valid_reg,
-};
-
-static const struct icss_iep_plat_data am335x_icss_iep_plat_data = {
-	.flags = 0,
-	.reg_offs = {
-		[ICSS_IEP_GLOBAL_CFG_REG] = 0x00,
-		[ICSS_IEP_COMPEN_REG] = 0x08,
-		[ICSS_IEP_COUNT_REG0] = 0x0C,
-		[ICSS_IEP_CAPTURE_CFG_REG] = 0x10,
-		[ICSS_IEP_CAPTURE_STAT_REG] = 0x14,
-
-		[ICSS_IEP_CAP6_RISE_REG0] = 0x30,
-
-		[ICSS_IEP_CAP7_RISE_REG0] = 0x38,
-
-		[ICSS_IEP_CMP_CFG_REG] = 0x40,
-		[ICSS_IEP_CMP_STAT_REG] = 0x44,
-		[ICSS_IEP_CMP0_REG0] = 0x48,
-
-		[ICSS_IEP_CMP8_REG0] = 0x88,
-		[ICSS_IEP_SYNC_CTRL_REG] = 0x100,
-		[ICSS_IEP_SYNC0_STAT_REG] = 0x108,
-		[ICSS_IEP_SYNC1_STAT_REG] = 0x10C,
-		[ICSS_IEP_SYNC_PWIDTH_REG] = 0x110,
-		[ICSS_IEP_SYNC0_PERIOD_REG] = 0x114,
-		[ICSS_IEP_SYNC1_DELAY_REG] = 0x118,
-		[ICSS_IEP_SYNC_START_REG] = 0x11C,
-	},
-	.config = &am335x_icss_iep_regmap_config,
-};
-
-static const struct of_device_id icss_iep_of_match[] = {
-	{
-		.compatible = "ti,am654-icss-iep",
-		.data = &am654_icss_iep_plat_data,
-	},
-	{
-		.compatible = "ti,am5728-icss-iep",
-		.data = &am57xx_icss_iep_plat_data,
-	},
-	{
-		.compatible = "ti,am3356-icss-iep",
-		.data = &am335x_icss_iep_plat_data,
-	},
-	{},
-};
-MODULE_DEVICE_TABLE(of, icss_iep_of_match);
-
-static struct platform_driver icss_iep_driver = {
-	.driver = {
-		.name = "icss-iep",
-		.of_match_table = of_match_ptr(icss_iep_of_match),
-	},
-	.probe = icss_iep_probe,
-};
-module_platform_driver(icss_iep_driver);
-
-MODULE_LICENSE("GPL v2");
-MODULE_DESCRIPTION("TI ICSS IEP driver");
-MODULE_AUTHOR("Roger Quadros <rogerq@ti.com>");
diff --git a/drivers/net/ethernet/ti/icss_iep.h b/drivers/net/ethernet/ti/icss_iep.h
deleted file mode 100644
index 1c8f74ae659a..000000000000
--- a/drivers/net/ethernet/ti/icss_iep.h
+++ /dev/null
@@ -1,40 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Texas Instruments ICSSG Industrial Ethernet Peripheral (IEP) Driver
- *
- * Copyright (C) 2019 Texas Instruments Incorporated - http://www.ti.com/
- *
- */
-
-#ifndef __NET_TI_ICSS_IEP_H
-#define __NET_TI_ICSS_IEP_H
-
-#include <linux/mutex.h>
-#include <linux/ptp_clock_kernel.h>
-#include <linux/regmap.h>
-
-struct icss_iep;
-
-/* Firmware specific clock operations */
-struct icss_iep_clockops {
-	void (*settime)(void *clockops_data, u64 ns);
-	void (*adjtime)(void *clockops_data, s64 delta);
-	u64 (*gettime)(void *clockops_data);
-	int (*perout_enable)(void *clockops_data,
-			     struct ptp_perout_request *req, int on,
-			     u64 *cmp);
-	int (*extts_enable)(void *clockops_data, u32 index, int on);
-};
-
-struct icss_iep *icss_iep_get(struct device_node *np);
-struct icss_iep *icss_iep_get_idx(struct device_node *np, int idx);
-void icss_iep_put(struct icss_iep *iep);
-int icss_iep_init(struct icss_iep *iep, const struct icss_iep_clockops *clkops,
-		  void *clockops_data, u32 cycle_time_ns);
-int icss_iep_exit(struct icss_iep *iep);
-int icss_iep_get_count_low(struct icss_iep *iep);
-int icss_iep_get_count_hi(struct icss_iep *iep);
-int icss_iep_get_ptp_clock_idx(struct icss_iep *iep);
-void icss_iep_init_fw(struct icss_iep *iep);
-void icss_iep_exit_fw(struct icss_iep *iep);
-
-#endif /* __NET_TI_ICSS_IEP_H */
diff --git a/drivers/net/ethernet/ti/icss_lre_firmware.h b/drivers/net/ethernet/ti/icss_lre_firmware.h
deleted file mode 100644
index fd2dc1b12cc9..000000000000
--- a/drivers/net/ethernet/ti/icss_lre_firmware.h
+++ /dev/null
@@ -1,136 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2017-2020 Texas Instruments Incorporated - http://www.ti.com
- *
- */
-
-#ifndef __ICSS_LRE_FIRMWARE_H
-#define __ICSS_LRE_FIRMWARE_H
-
-#define ICSS_LRE_TAG_RCT_SIZE                 6       /* HSR tag or PRP RCT size */
-
-#define ICSS_LRE_HSR_MODE		0x1E76
-#define ICSS_LRE_MODEH			0x01
-
-/* PRU0 DMEM */
-#define ICSS_LRE_DBG_START			0x1E00
-
-#define ICSS_LRE_DUPLICATE_HOST_TABLE		0x0200
-
-/* PRU1 DMEM */
-#define ICSS_LRE_DUPLICATE_PORT_TABLE_PRU0	0x0200
-#define ICSS_LRE_DUPLICATE_PORT_TABLE_PRU1	0x0E00
-
-/* Size and setup (N and M) of duplicate host table */
-#define ICSS_LRE_DUPLICATE_HOST_TABLE_SIZE	0x1C08
-/* Size and setup (N and M) of duplicate port table (HSR Only) */
-#define ICSS_LRE_DUPLICATE_PORT_TABLE_SIZE	0x1C1C
-/* Time after which an entry is removed from the dup table (10ms resolution) */
-#define ICSS_LRE_DUPLI_FORGET_TIME		0x1C24
-/* Time interval to check the port duplicate table */
-#define ICSS_LRE_DUPLI_PORT_CHECK_RESO		0x1C2C
-/* Time interval to check the host duplicate table */
-#define ICSS_LRE_DUPLI_HOST_CHECK_RESO		0x1C30
-/* NodeTable | Host | Port */
-#define ICSS_LRE_HOST_TIMER_CHECK_FLAGS		0x1C38
-/* Arbitration flag for the host duplicate t */
-#define ICSS_LRE_HOST_DUPLICATE_ARBITRATION	0x1C3C
-/* Supervision address in LRE */
-#define ICSS_LRE_SUP_ADDR			0x1C4C
-#define ICSS_LRE_SUP_ADDR_LOW			0x1C50
-
-/* Time in TimeTicks (1/100s) */
-#define ICSS_LRE_DUPLICATE_FORGET_TIME_400_MS	40
-/* Time in TimeTicks (1/100s) */
-#define ICSS_LRE_NODE_FORGET_TIME_60000_MS	6000
-#define ICSS_LRE_MAX_FORGET_TIME		0xffdf
-
-#define ICSS_LRE_DUPLICATE_PORT_TABLE_DMEM_SIZE	0x0C00
-#define ICSS_LRE_DUPLICATE_HOST_TABLE_DMEM_SIZE	0x1800
-#define ICSS_LRE_STATS_DMEM_SIZE		0x0088
-#define ICSS_LRE_DEBUG_COUNTER_DMEM_SIZE	0x0050
-
-#define ICSS_LRE_DUPLICATE_HOST_TABLE_SIZE_INIT	0x800004 /* N = 128, M = 4 */
-#define ICSS_LRE_DUPLICATE_PORT_TABLE_SIZE_INIT	0x400004 /* N = 64, M = 4 */
-#define ICSS_LRE_MASTER_SLAVE_BUSY_BITS_CLEAR	0x0
-#define ICSS_LRE_TABLE_CHECK_RESOLUTION_10_MS	0xA
-#define ICSS_LRE_SUP_ADDRESS_INIT_OCTETS_HIGH	0x4E1501 /* 01-15-4E-00- */
-#define ICSS_LRE_SUP_ADDRESS_INIT_OCTETS_LOW	0x1 /* -01-00 */
-
-/* SHARED RAM */
-
-/* 8 bytes of VLAN PCP to RX QUEUE MAPPING */
-#define ICSS_LRE_QUEUE_2_PCP_MAP_OFFSET		0x120
-#define ICSS_LRE_START				0x140
-
-/* Number of frames successfully sent over port A/B that are HSR/PRP tagged */
-
-#define ICSS_LRE_CNT_TX_A			(ICSS_LRE_START + 4)
-#define ICSS_LRE_DUPLICATE_DISCARD		(ICSS_LRE_START + 104)
-#define ICSS_LRE_TRANSPARENT_RECEPTION		(ICSS_LRE_START + 108)
-#define ICSS_LRE_CNT_NODES			(ICSS_LRE_START + 52)
-
-/* SRAM */
-
-#define ICSS_LRE_IEC62439_CONST_DUPLICATE_ACCEPT		0x01
-#define ICSS_LRE_IEC62439_CONST_DUPLICATE_DISCARD		0x02
-#define ICSS_LRE_IEC62439_CONST_TRANSP_RECEPTION_REMOVE_RCT	0x01
-#define ICSS_LRE_IEC62439_CONST_TRANSP_RECEPTION_PASS_RCT	0x02
-
-/* Enable/disable interrupts for high/low priority instead of per port.
- * 0 = disabled (default) 1 = enabled
- */
-#define ICSS_LRE_PRIORITY_INTRS_STATUS_OFFSET	0x1FAA
-/* Enable/disable timestamping of packets. 0 = disabled (default) 1 = enabled */
-#define ICSS_LRE_TIMESTAMP_PKTS_STATUS_OFFSET	0x1FAB
-#define ICSS_LRE_TIMESTAMP_ARRAY_OFFSET          0xC200
-
-/* HOST_TIMER_CHECK_FLAGS bits */
-#define ICSS_LRE_HOST_TIMER_NODE_TABLE_CHECK_BIT	BIT(0)
-#define ICSS_LRE_HOST_TIMER_NODE_TABLE_CLEAR_BIT	BIT(4)
-#define ICSS_LRE_HOST_TIMER_HOST_TABLE_CHECK_BIT	BIT(8)
-#define ICSS_LRE_HOST_TIMER_P1_TABLE_CHECK_BIT		BIT(16)
-#define ICSS_LRE_HOST_TIMER_P2_TABLE_CHECK_BIT		BIT(24)
-#define ICSS_LRE_HOST_TIMER_PORT_TABLE_CHECK_BITS \
-			(ICSS_LRE_HOST_TIMER_P1_TABLE_CHECK_BIT | \
-			 ICSS_LRE_HOST_TIMER_P2_TABLE_CHECK_BIT)
-
-#define ICSS_LRE_NODE_FREE			0x10
-/* PRU1 DMEM */
-#define ICSS_LRE_V2_1_HASH_MASK                 0xFF
-#define ICSS_LRE_V2_1_INDEX_ARRAY_NT            0x3000
-#define ICSS_LRE_V2_1_BIN_ARRAY \
-	(ICSS_LRE_V2_1_INDEX_ARRAY_NT + \
-	(ICSS_LRE_V2_1_INDEX_TBL_MAX_ENTRIES * 6))
-#define ICSS_LRE_V2_1_NODE_TABLE_NEW \
-	(ICSS_LRE_V2_1_BIN_ARRAY + \
-	(ICSS_LRE_V2_1_BIN_TBL_MAX_ENTRIES * 8))
-#define ICSS_LRE_V2_1_INDEX_ARRAY_LOC           PRUETH_MEM_SHARED_RAM
-#define ICSS_LRE_V2_1_BIN_ARRAY_LOC             PRUETH_MEM_SHARED_RAM
-#define ICSS_LRE_V2_1_NODE_TABLE_LOC            PRUETH_MEM_SHARED_RAM
-#define ICSS_LRE_V2_1_INDEX_TBL_MAX_ENTRIES     256
-#define ICSS_LRE_V2_1_BIN_TBL_MAX_ENTRIES       256
-#define ICSS_LRE_V2_1_NODE_TBL_MAX_ENTRIES      256
-
-#define ICSS_LRE_NODE_FREE			0x10
-#define ICSS_LRE_NODE_TAKEN			0x01
-#define ICSS_LRE_NT_REM_NODE_TYPE_MASK		0x1F
-#define ICSS_LRE_NT_REM_NODE_TYPE_SHIFT		0x00
-
-#define ICSS_LRE_NT_REM_NODE_TYPE_SANA		0x01
-#define ICSS_LRE_NT_REM_NODE_TYPE_SANB		0x02
-#define ICSS_LRE_NT_REM_NODE_TYPE_SANAB		0x03
-#define ICSS_LRE_NT_REM_NODE_TYPE_DAN		0x04
-#define ICSS_LRE_NT_REM_NODE_TYPE_REDBOX	0x08
-#define ICSS_LRE_NT_REM_NODE_TYPE_VDAN		0x10
-
-#define ICSS_LRE_NT_REM_NODE_HSR_BIT		0x20 /* if set node is HSR */
-
-#define ICSS_LRE_NT_REM_NODE_DUP_MASK		0xC0
-#define ICSS_LRE_NT_REM_NODE_DUP_SHIFT		0x06
-
-/* Node ent duplicate type: DupAccept */
-#define ICSS_LRE_NT_REM_NODE_DUP_ACCEPT		0x40
-/* Node ent duplicate type: DupDiscard */
-#define ICSS_LRE_NT_REM_NODE_DUP_DISCARD	0x80
-
-#endif /* __ICSS_LRE_FIRMWARE_H */
diff --git a/drivers/net/ethernet/ti/icss_mii_rt.h b/drivers/net/ethernet/ti/icss_mii_rt.h
deleted file mode 100644
index 59e59000545b..000000000000
--- a/drivers/net/ethernet/ti/icss_mii_rt.h
+++ /dev/null
@@ -1,215 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-
-/* PRU-ICSS MII_RT register definitions
- *
- * Copyright (C) 2015-2021 Texas Instruments Incorporated - https://www.ti.com
- */
-
-#ifndef __NET_PRUSS_MII_RT_H__
-#define __NET_PRUSS_MII_RT_H__
-
-#include <linux/if_ether.h>
-
-#include "icss_lre_firmware.h"
-
-/* PRUSS_MII_RT Registers */
-#define PRUSS_MII_RT_RXCFG0		0x0
-#define PRUSS_MII_RT_RXCFG1		0x4
-#define PRUSS_MII_RT_TXCFG0		0x10
-#define PRUSS_MII_RT_TXCFG1		0x14
-#define PRUSS_MII_RT_TX_CRC0		0x20
-#define PRUSS_MII_RT_TX_CRC1		0x24
-#define PRUSS_MII_RT_TX_IPG0		0x30
-#define PRUSS_MII_RT_TX_IPG1		0x34
-#define PRUSS_MII_RT_PRS0		0x38
-#define PRUSS_MII_RT_PRS1		0x3c
-#define PRUSS_MII_RT_RX_FRMS0		0x40
-#define PRUSS_MII_RT_RX_FRMS1		0x44
-#define PRUSS_MII_RT_RX_PCNT0		0x48
-#define PRUSS_MII_RT_RX_PCNT1		0x4c
-#define PRUSS_MII_RT_RX_ERR0		0x50
-#define PRUSS_MII_RT_RX_ERR1		0x54
-
-/* PRUSS_MII_RT_RXCFG0/1 bits */
-#define PRUSS_MII_RT_RXCFG_RX_ENABLE		BIT(0)
-#define PRUSS_MII_RT_RXCFG_RX_DATA_RDY_MODE_DIS	BIT(1)
-#define PRUSS_MII_RT_RXCFG_RX_CUT_PREAMBLE	BIT(2)
-#define PRUSS_MII_RT_RXCFG_RX_MUX_SEL		BIT(3)
-#define PRUSS_MII_RT_RXCFG_RX_L2_EN		BIT(4)
-#define PRUSS_MII_RT_RXCFG_RX_BYTE_SWAP		BIT(5)
-#define PRUSS_MII_RT_RXCFG_RX_AUTO_FWD_PRE	BIT(6)
-#define PRUSS_MII_RT_RXCFG_RX_L2_EOF_SCLR_DIS	BIT(9)
-
-/* PRUSS_MII_RT_TXCFG0/1 bits */
-#define PRUSS_MII_RT_TXCFG_TX_ENABLE		BIT(0)
-#define PRUSS_MII_RT_TXCFG_TX_AUTO_PREAMBLE	BIT(1)
-#define PRUSS_MII_RT_TXCFG_TX_EN_MODE		BIT(2)
-#define PRUSS_MII_RT_TXCFG_TX_BYTE_SWAP		BIT(3)
-#define PRUSS_MII_RT_TXCFG_TX_MUX_SEL		BIT(8)
-#define PRUSS_MII_RT_TXCFG_PRE_TX_AUTO_SEQUENCE	BIT(9)
-#define PRUSS_MII_RT_TXCFG_PRE_TX_AUTO_ESC_ERR	BIT(10)
-#define PRUSS_MII_RT_TXCFG_TX_32_MODE_EN	BIT(11)
-#define PRUSS_MII_RT_TXCFG_TX_IPG_WIRE_CLK_EN	BIT(12)	/* SR2.0 onwards */
-
-#define PRUSS_MII_RT_TXCFG_TX_START_DELAY_SHIFT	16
-#define PRUSS_MII_RT_TXCFG_TX_START_DELAY_MASK	GENMASK(25, 16)
-
-#define PRUSS_MII_RT_TXCFG_TX_CLK_DELAY_SHIFT	28
-#define PRUSS_MII_RT_TXCFG_TX_CLK_DELAY_MASK	GENMASK(30, 28)
-
-/* PRUSS_MII_RT_TX_IPG0/1 bits */
-#define PRUSS_MII_RT_TX_IPG_IPG_SHIFT	0
-#define PRUSS_MII_RT_TX_IPG_IPG_MASK	GENMASK(9, 0)
-
-/* PRUSS_MII_RT_PRS0/1 bits */
-#define PRUSS_MII_RT_PRS_COL	BIT(0)
-#define PRUSS_MII_RT_PRS_CRS	BIT(1)
-
-/* PRUSS_MII_RT_RX_FRMS0/1 bits */
-#define PRUSS_MII_RT_RX_FRMS_MIN_FRM_SHIFT	0
-#define PRUSS_MII_RT_RX_FRMS_MIN_FRM_MASK	GENMASK(15, 0)
-
-#define PRUSS_MII_RT_RX_FRMS_MAX_FRM_SHIFT	16
-#define PRUSS_MII_RT_RX_FRMS_MAX_FRM_MASK	GENMASK(31, 16)
-
-/* Min/Max in MII_RT_RX_FRMS */
-/* For EMAC and Switch */
-#define PRUSS_MII_RT_RX_FRMS_MAX	(VLAN_ETH_FRAME_LEN + ETH_FCS_LEN)
-#define PRUSS_MII_RT_RX_FRMS_MIN_FRM	(64)
-
-/* for HSR and PRP */
-#define PRUSS_MII_RT_RX_FRMS_MAX_FRM_LRE	(PRUSS_MII_RT_RX_FRMS_MAX + \
-						 ICSS_LRE_TAG_RCT_SIZE)
-/* PRUSS_MII_RT_RX_PCNT0/1 bits */
-#define PRUSS_MII_RT_RX_PCNT_MIN_PCNT_SHIFT	0
-#define PRUSS_MII_RT_RX_PCNT_MIN_PCNT_MASK	GENMASK(3, 0)
-
-#define PRUSS_MII_RT_RX_PCNT_MAX_PCNT_SHIFT	4
-#define PRUSS_MII_RT_RX_PCNT_MAX_PCNT_MASK	GENMASK(7, 4)
-
-/* PRUSS_MII_RT_RX_ERR0/1 bits */
-#define PRUSS_MII_RT_RX_ERR_MIN_PCNT_ERR	BIT(0)
-#define PRUSS_MII_RT_RX_ERR_MAX_PCNT_ERR	BIT(1)
-#define PRUSS_MII_RT_RX_ERR_MIN_FRM_ERR		BIT(2)
-#define PRUSS_MII_RT_RX_ERR_MAX_FRM_ERR		BIT(3)
-
-#define ICSSG_CFG_OFFSET	0
-#define RGMII_CFG_OFFSET	4
-
-/* Constant to choose between MII0 and MII1 */
-#define ICSS_MII0	0
-#define ICSS_MII1	1
-
-/* ICSSG_CFG Register bits */
-#define ICSSG_CFG_SGMII_MODE	BIT(16)
-#define ICSSG_CFG_TX_PRU_EN	BIT(11)
-#define ICSSG_CFG_RX_SFD_TX_SOF_EN	BIT(10)
-#define ICSSG_CFG_RTU_PRU_PSI_SHARE_EN	BIT(9)
-#define ICSSG_CFG_IEP1_TX_EN	BIT(8)
-#define ICSSG_CFG_MII1_MODE	GENMASK(6, 5)
-#define ICSSG_CFG_MII1_MODE_SHIFT	5
-#define ICSSG_CFG_MII0_MODE	GENMASK(4, 3)
-#define ICSSG_CFG_MII0_MODE_SHIFT	3
-#define ICSSG_CFG_RX_L2_G_EN	BIT(2)
-#define ICSSG_CFG_TX_L2_EN	BIT(1)
-#define ICSSG_CFG_TX_L1_EN	BIT(0)
-
-enum mii_mode { MII_MODE_MII = 0, MII_MODE_RGMII, MII_MODE_SGMII };
-
-/* RGMII CFG Register bits */
-#define RGMII_CFG_INBAND_EN_MII0	BIT(16)
-#define RGMII_CFG_GIG_EN_MII0	BIT(17)
-#define RGMII_CFG_INBAND_EN_MII1	BIT(20)
-#define RGMII_CFG_GIG_EN_MII1	BIT(21)
-#define RGMII_CFG_FULL_DUPLEX_MII0	BIT(18)
-#define RGMII_CFG_FULL_DUPLEX_MII1	BIT(22)
-#define RGMII_CFG_SPEED_MII0	GENMASK(2, 1)
-#define RGMII_CFG_SPEED_MII1	GENMASK(6, 5)
-#define RGMII_CFG_SPEED_MII0_SHIFT	1
-#define RGMII_CFG_SPEED_MII1_SHIFT	5
-#define RGMII_CFG_FULLDUPLEX_MII0	BIT(3)
-#define RGMII_CFG_FULLDUPLEX_MII1	BIT(7)
-#define RGMII_CFG_FULLDUPLEX_MII0_SHIFT	3
-#define RGMII_CFG_FULLDUPLEX_MII1_SHIFT	7
-#define RGMII_CFG_SPEED_10M	0
-#define RGMII_CFG_SPEED_100M	1
-#define RGMII_CFG_SPEED_1G	2
-
-static inline void icssg_mii_update_ipg(struct regmap *mii_rt, int mii, u32 ipg)
-{
-	u32 val;
-
-	if (mii == ICSS_MII0) {
-		regmap_write(mii_rt, PRUSS_MII_RT_TX_IPG0, ipg);
-	} else {
-	/* Errata workaround: IEP1 is not read by h/w unless IEP0 is written */
-		regmap_read(mii_rt, PRUSS_MII_RT_TX_IPG0, &val);
-		regmap_write(mii_rt, PRUSS_MII_RT_TX_IPG1, ipg);
-		regmap_write(mii_rt, PRUSS_MII_RT_TX_IPG0, val);
-	}
-}
-
-static inline void icssg_update_rgmii_cfg(struct regmap *miig_rt, int speed,
-					  int duplex, int mii)
-{
-	u32 gig_en_mask, gig_val = 0, full_duplex_mask, full_duplex_val = 0;
-	u32 inband_en_mask, inband_val = 0;
-
-	gig_en_mask = (mii == ICSS_MII0) ? RGMII_CFG_GIG_EN_MII0 :
-					RGMII_CFG_GIG_EN_MII1;
-	if (speed == SPEED_1000)
-		gig_val = gig_en_mask;
-	regmap_update_bits(miig_rt, RGMII_CFG_OFFSET, gig_en_mask, gig_val);
-
-	inband_en_mask = (mii == ICSS_MII0) ? RGMII_CFG_INBAND_EN_MII0 :
-					RGMII_CFG_INBAND_EN_MII1;
-	if (speed == SPEED_10)
-		inband_val = inband_en_mask;
-	regmap_update_bits(miig_rt, RGMII_CFG_OFFSET, inband_en_mask, inband_val);
-
-	full_duplex_mask = (mii == ICSS_MII0) ? RGMII_CFG_FULL_DUPLEX_MII0 :
-					   RGMII_CFG_FULL_DUPLEX_MII1;
-	if (duplex == DUPLEX_FULL)
-		full_duplex_val = full_duplex_mask;
-	regmap_update_bits(miig_rt, RGMII_CFG_OFFSET, full_duplex_mask,
-			   full_duplex_val);
-}
-
-static inline u32 icssg_rgmii_cfg_get_bitfield(struct regmap *miig_rt,
-					       u32 mask, u32 shift)
-{
-	u32 val;
-
-	regmap_read(miig_rt, RGMII_CFG_OFFSET, &val);
-	val &= mask;
-	val >>= shift;
-
-	return val;
-}
-
-static inline u32 icssg_rgmii_get_speed(struct regmap *miig_rt, int mii)
-{
-	u32 shift = RGMII_CFG_SPEED_MII0_SHIFT, mask = RGMII_CFG_SPEED_MII0;
-
-	if (mii == ICSS_MII1) {
-		shift = RGMII_CFG_SPEED_MII1_SHIFT;
-		mask = RGMII_CFG_SPEED_MII1;
-	}
-
-	return icssg_rgmii_cfg_get_bitfield(miig_rt, mask, shift);
-}
-
-static inline u32 icssg_rgmii_get_fullduplex(struct regmap *miig_rt, int mii)
-{
-	u32 shift = RGMII_CFG_FULLDUPLEX_MII0_SHIFT;
-	u32 mask = RGMII_CFG_FULLDUPLEX_MII0;
-
-	if (mii == ICSS_MII1) {
-		shift = RGMII_CFG_FULLDUPLEX_MII1_SHIFT;
-		mask = RGMII_CFG_FULLDUPLEX_MII1;
-	}
-
-	return icssg_rgmii_cfg_get_bitfield(miig_rt, mask, shift);
-}
-
-#endif /* __NET_PRUSS_MII_RT_H__ */
diff --git a/drivers/net/ethernet/ti/icss_switch.h b/drivers/net/ethernet/ti/icss_switch.h
deleted file mode 100644
index 7aa760e3702d..000000000000
--- a/drivers/net/ethernet/ti/icss_switch.h
+++ /dev/null
@@ -1,336 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-
-/* Copyright (C) 2015-2021 Texas Instruments Incorporated - https://www.ti.com
- */
-
-#ifndef __ICSS_SWITCH_H
-#define __ICSS_SWITCH_H
-
-/* Basic Switch Parameters
- * Used to auto compute offset addresses on L3 OCMC RAM. Do not modify these
- * without changing firmware accordingly
- */
-#define SWITCH_BUFFER_SIZE	(64 * 1024)	/* L3 buffer */
-#define ICSS_BLOCK_SIZE		32		/* data bytes per BD */
-#define BD_SIZE			4		/* byte buffer descriptor */
-#define NUM_QUEUES		4		/* Queues on Port 0/1/2 */
-
-#define PORT_LINK_MASK		0x1
-#define PORT_IS_HD_MASK		0x2
-
-/* Physical Port queue size (number of BDs). Same for both ports */
-#define QUEUE_1_SIZE		97	/* Network Management high */
-#define QUEUE_2_SIZE		97	/* Network Management low */
-#define QUEUE_3_SIZE		97	/* Protocol specific */
-#define QUEUE_4_SIZE		97	/* NRT (IP,ARP, ICMP) */
-
-/* Host queue size (number of BDs). Each BD points to data buffer of 32 bytes.
- * HOST PORT QUEUES can buffer up to 4 full sized frames per queue
- */
-#define	HOST_QUEUE_1_SIZE	194	/* Protocol and VLAN priority 7 & 6 */
-#define HOST_QUEUE_2_SIZE	194	/* Protocol mid */
-#define HOST_QUEUE_3_SIZE	194	/* Protocol low */
-#define HOST_QUEUE_4_SIZE	194	/* NRT (IP, ARP, ICMP) */
-
-#define COL_QUEUE_SIZE		0
-
-/* NRT Buffer descriptor definition
- * Each buffer descriptor points to a max 32 byte block and has 32 bit in size
- * to have atomic operation.
- * PRU can address bytewise into memory.
- * Definition of 32 bit descriptor is as follows
- *
- * Bits		Name			Meaning
- * =============================================================================
- * 0..7		Index		points to index in buffer queue, max 256 x 32
- *				byte blocks can be addressed
- * 6            LookupSuccess   For switch, FDB lookup was successful (source
- *                              MAC address found in FDB).
- *                              For RED, NodeTable lookup was successful.
- * 7            Flood           Packet should be flooded (destination MAC
- *                              address found in FDB). For switch only.
- * 8..12	Block_length	number of valid bytes in this specific block.
- *				Will be <=32 bytes on last block of packet
- * 13		More		"More" bit indicating that there are more blocks
- * 14		Shadow		indicates that "index" is pointing into shadow
- *				buffer
- * 15		TimeStamp	indicates that this packet has time stamp in
- *				separate buffer - only needed of PTCP runs on
- *				host
- * 16..17	Port		different meaning for ingress and egress,
- *				Ingress: Port = 0 indicates phy port 1 and
- *				Port = 1 indicates phy port 2.
- *				Egress: 0 sends on phy port 1 and 1 sends on
- *				phy port 2. Port = 2 goes over MAC table
- *				look-up
- * 18..28	Length		11 bit of total packet length which is put into
- *				first BD only so that host access only one BD
- * 29		VlanTag		indicates that packet has Length/Type field of
- *				0x08100 with VLAN tag in following byte
- * 30		Broadcast	indicates that packet goes out on both physical
- *				ports,  there will be two bd but only one buffer
- * 31		Error		indicates there was an error in the packet
- */
-#define PRUETH_BD_START_FLAG_MASK	BIT(0)
-#define PRUETH_BD_START_FLAG_SHIFT	0
-
-#define PRUETH_BD_HSR_FRAME_MASK	BIT(4)
-#define PRUETH_BD_HSR_FRAME_SHIFT	4
-
-#define PRUETH_BD_SUP_HSR_FRAME_MASK	BIT(5)
-#define PRUETH_BD_SUP_HSR_FRAME_SHIFT	5
-
-#define PRUETH_BD_LOOKUP_SUCCESS_MASK	BIT(6)
-#define PRUETH_BD_LOOKUP_SUCCESS_SHIFT	6
-
-#define PRUETH_BD_SW_FLOOD_MASK		BIT(7)
-#define PRUETH_BD_SW_FLOOD_SHIFT	7
-
-#define	PRUETH_BD_SHADOW_MASK		BIT(14)
-#define	PRUETH_BD_SHADOW_SHIFT		14
-
-#define PRUETH_BD_TIMESTAMP_MASK	BIT(15)
-#define PRUETH_BD_TIMESTAMP_SHIT	15
-
-#define PRUETH_BD_PORT_MASK		GENMASK(17, 16)
-#define PRUETH_BD_PORT_SHIFT		16
-
-#define PRUETH_BD_LENGTH_MASK		GENMASK(28, 18)
-#define PRUETH_BD_LENGTH_SHIFT		18
-
-#define PRUETH_BD_BROADCAST_MASK	BIT(30)
-#define PRUETH_BD_BROADCAST_SHIFT	30
-
-#define PRUETH_BD_ERROR_MASK		BIT(31)
-#define PRUETH_BD_ERROR_SHIFT		31
-
-/* The following offsets indicate which sections of the memory are used
- * for EMAC internal tasks
- */
-#define DRAM_START_OFFSET		0x1e98
-#define SRAM_START_OFFSET		0x400
-
-/* General Purpose Statistics
- * These are present on both PRU0 and PRU1 DRAM
- */
-/* base statistics offset */
-#define STATISTICS_OFFSET	0x1f00
-#define STAT_SIZE		0x98
-
-/* The following offsets indicate which sections of the memory are used
- * for switch internal tasks
- */
-#define SWITCH_SPECIFIC_DRAM0_START_SIZE		0x100
-#define SWITCH_SPECIFIC_DRAM0_START_OFFSET		0x1F00
-
-#define SWITCH_SPECIFIC_DRAM1_START_SIZE		0x300
-#define SWITCH_SPECIFIC_DRAM1_START_OFFSET		0x1D00
-
-/* Offset for storing
- * 1. Storm Prevention Params
- * 2. PHY Speed Offset
- * 3. Port Status Offset
- * These are present on both PRU0 and PRU1
- */
-/* 4 bytes */
-#define STORM_PREVENTION_OFFSET_BC	(STATISTICS_OFFSET + STAT_SIZE)
-/* 4 bytes */
-#define PHY_SPEED_OFFSET		(STATISTICS_OFFSET + STAT_SIZE + 4)
-/* 1 byte */
-#define PORT_STATUS_OFFSET		(STATISTICS_OFFSET + STAT_SIZE + 8)
-/* 1 byte */
-#define COLLISION_COUNTER		(STATISTICS_OFFSET + STAT_SIZE + 9)
-/* 4 bytes */
-#define RX_PKT_SIZE_OFFSET		(STATISTICS_OFFSET + STAT_SIZE + 10)
-/* 4 bytes */
-#define PORT_CONTROL_ADDR		(STATISTICS_OFFSET + STAT_SIZE + 14)
-/* 6 bytes */
-#define PORT_MAC_ADDR			(STATISTICS_OFFSET + STAT_SIZE + 18)
-/* 1 byte */
-#define RX_INT_STATUS_OFFSET		(STATISTICS_OFFSET + STAT_SIZE + 24)
-/* 4 bytes */
-#define STORM_PREVENTION_OFFSET_MC	(STATISTICS_OFFSET + STAT_SIZE + 25)
-/* 4 bytes */
-#define STORM_PREVENTION_OFFSET_UC	(STATISTICS_OFFSET + STAT_SIZE + 29)
-/* 4 bytes ? */
-#define STP_INVALID_STATE_OFFSET        (STATISTICS_OFFSET + STAT_SIZE + 33)
-
-/* DRAM1 Offsets for Switch */
-/* 4 queue descriptors for port 0 (host receive) */
-#define P0_QUEUE_DESC_OFFSET		0x1E7C
-#define P1_QUEUE_DESC_OFFSET		0x1E9C
-#define P2_QUEUE_DESC_OFFSET		0x1EBC
-/* collision descriptor of port 0 */
-#define P0_COL_QUEUE_DESC_OFFSET	0x1E64
-#define P1_COL_QUEUE_DESC_OFFSET	0x1E6C
-#define P2_COL_QUEUE_DESC_OFFSET	0x1E74
-/* Collision Status Register
- *    P0: bit 0 is pending flag, bit 1..2 inidicates which queue,
- *    P1: bit 8 is pending flag, 9..10 is queue number
- *    P2: bit 16 is pending flag, 17..18 is queue number, remaining bits are 0.
- */
-#define COLLISION_STATUS_ADDR		0x1E60
-
-#define INTERFACE_MAC_ADDR		0x1E58
-#define P2_MAC_ADDR			0x1E50
-#define P1_MAC_ADDR			0x1E48
-
-#define QUEUE_SIZE_ADDR			0x1E30
-#define QUEUE_OFFSET_ADDR		0x1E18
-#define QUEUE_DESCRIPTOR_OFFSET_ADDR	0x1E00
-
-#define COL_RX_CONTEXT_P2_OFFSET_ADDR	(COL_RX_CONTEXT_P1_OFFSET_ADDR + 12)
-#define COL_RX_CONTEXT_P1_OFFSET_ADDR	(COL_RX_CONTEXT_P0_OFFSET_ADDR + 12)
-#define COL_RX_CONTEXT_P0_OFFSET_ADDR	(P2_Q4_RX_CONTEXT_OFFSET + 8)
-
-/* Port 2 Rx Context */
-#define P2_Q4_RX_CONTEXT_OFFSET		(P2_Q3_RX_CONTEXT_OFFSET + 8)
-#define P2_Q3_RX_CONTEXT_OFFSET		(P2_Q2_RX_CONTEXT_OFFSET + 8)
-#define P2_Q2_RX_CONTEXT_OFFSET		(P2_Q1_RX_CONTEXT_OFFSET + 8)
-#define P2_Q1_RX_CONTEXT_OFFSET		RX_CONTEXT_P2_Q1_OFFSET_ADDR
-#define RX_CONTEXT_P2_Q1_OFFSET_ADDR	(P1_Q4_RX_CONTEXT_OFFSET + 8)
-
-/* Port 1 Rx Context */
-#define P1_Q4_RX_CONTEXT_OFFSET		(P1_Q3_RX_CONTEXT_OFFSET + 8)
-#define P1_Q3_RX_CONTEXT_OFFSET		(P1_Q2_RX_CONTEXT_OFFSET + 8)
-#define P1_Q2_RX_CONTEXT_OFFSET		(P1_Q1_RX_CONTEXT_OFFSET + 8)
-#define P1_Q1_RX_CONTEXT_OFFSET		(RX_CONTEXT_P1_Q1_OFFSET_ADDR)
-#define RX_CONTEXT_P1_Q1_OFFSET_ADDR	(P0_Q4_RX_CONTEXT_OFFSET + 8)
-
-/* Host Port Rx Context */
-#define P0_Q4_RX_CONTEXT_OFFSET		(P0_Q3_RX_CONTEXT_OFFSET + 8)
-#define P0_Q3_RX_CONTEXT_OFFSET		(P0_Q2_RX_CONTEXT_OFFSET + 8)
-#define P0_Q2_RX_CONTEXT_OFFSET		(P0_Q1_RX_CONTEXT_OFFSET + 8)
-#define P0_Q1_RX_CONTEXT_OFFSET		RX_CONTEXT_P0_Q1_OFFSET_ADDR
-#define RX_CONTEXT_P0_Q1_OFFSET_ADDR	(COL_TX_CONTEXT_P2_Q1_OFFSET_ADDR + 8)
-
-/* Port 2 Tx Collision Context */
-#define COL_TX_CONTEXT_P2_Q1_OFFSET_ADDR (COL_TX_CONTEXT_P1_Q1_OFFSET_ADDR + 8)
-/* Port 1 Tx Collision Context */
-#define COL_TX_CONTEXT_P1_Q1_OFFSET_ADDR (P2_Q4_TX_CONTEXT_OFFSET + 8)
-
-/* Port 2 */
-#define P2_Q4_TX_CONTEXT_OFFSET		(P2_Q3_TX_CONTEXT_OFFSET + 8)
-#define P2_Q3_TX_CONTEXT_OFFSET		(P2_Q2_TX_CONTEXT_OFFSET + 8)
-#define P2_Q2_TX_CONTEXT_OFFSET		(P2_Q1_TX_CONTEXT_OFFSET + 8)
-#define P2_Q1_TX_CONTEXT_OFFSET		TX_CONTEXT_P2_Q1_OFFSET_ADDR
-#define TX_CONTEXT_P2_Q1_OFFSET_ADDR	(P1_Q4_TX_CONTEXT_OFFSET + 8)
-
-/* Port 1 */
-#define P1_Q4_TX_CONTEXT_OFFSET		(P1_Q3_TX_CONTEXT_OFFSET + 8)
-#define P1_Q3_TX_CONTEXT_OFFSET		(P1_Q2_TX_CONTEXT_OFFSET + 8)
-#define P1_Q2_TX_CONTEXT_OFFSET		(P1_Q1_TX_CONTEXT_OFFSET + 8)
-#define P1_Q1_TX_CONTEXT_OFFSET		TX_CONTEXT_P1_Q1_OFFSET_ADDR
-#define TX_CONTEXT_P1_Q1_OFFSET_ADDR	SWITCH_SPECIFIC_DRAM1_START_OFFSET
-
-/* Shared RAM Offsets for Switch */
-/* NSP (Network Storm Prevention) timer re-uses NT timer */
-#define PRUETH_NSP_CREDIT_SHIFT       8
-#define PRUETH_NSP_ENABLE            BIT(0)
-
-/* DRAM Offsets for EMAC
- * Present on Both DRAM0 and DRAM1
- */
-
-/* 4 queue descriptors for port tx = 32 bytes */
-#define TX_CONTEXT_Q1_OFFSET_ADDR	(PORT_QUEUE_DESC_OFFSET + 32)
-#define PORT_QUEUE_DESC_OFFSET	(ICSS_EMAC_TTS_CYC_TX_SOF + 8)
-
-/* EMAC Time Triggered Send Offsets */
-#define ICSS_EMAC_TTS_CYC_TX_SOF	(ICSS_EMAC_TTS_PREV_TX_SOF + 8)
-#define ICSS_EMAC_TTS_PREV_TX_SOF	(ICSS_EMAC_TTS_MISSED_CYCLE_CNT_OFFSET + 4)
-#define ICSS_EMAC_TTS_MISSED_CYCLE_CNT_OFFSET	(ICSS_EMAC_TTS_STATUS_OFFSET + 4)
-#define ICSS_EMAC_TTS_STATUS_OFFSET	(ICSS_EMAC_TTS_CFG_TIME_OFFSET + 4)
-#define ICSS_EMAC_TTS_CFG_TIME_OFFSET	(ICSS_EMAC_TTS_CYCLE_PERIOD_OFFSET + 4)
-#define ICSS_EMAC_TTS_CYCLE_PERIOD_OFFSET	(ICSS_EMAC_TTS_CYCLE_START_OFFSET + 8)
-#define ICSS_EMAC_TTS_CYCLE_START_OFFSET	ICSS_EMAC_TTS_BASE_OFFSET
-#define ICSS_EMAC_TTS_BASE_OFFSET	DRAM_START_OFFSET
-
-/* Shared RAM offsets for EMAC */
-
-/* Queue Descriptors */
-
-/* 4 queue descriptors for port 0 (host receive). 32 bytes */
-#define HOST_QUEUE_DESC_OFFSET		(HOST_QUEUE_SIZE_ADDR + 16)
-
-/* table offset for queue size:
- * 3 ports * 4 Queues * 1 byte offset = 12 bytes
- */
-#define HOST_QUEUE_SIZE_ADDR		(HOST_QUEUE_OFFSET_ADDR + 8)
-/* table offset for queue:
- * 4 Queues * 2 byte offset = 8 bytes
- */
-#define HOST_QUEUE_OFFSET_ADDR		(HOST_QUEUE_DESCRIPTOR_OFFSET_ADDR + 8)
-/* table offset for Host queue descriptors:
- * 1 ports * 4 Queues * 2 byte offset = 8 bytes
- */
-#define HOST_QUEUE_DESCRIPTOR_OFFSET_ADDR	(HOST_Q4_RX_CONTEXT_OFFSET + 8)
-
-/* Host Port Rx Context */
-#define HOST_Q4_RX_CONTEXT_OFFSET	(HOST_Q3_RX_CONTEXT_OFFSET + 8)
-#define HOST_Q3_RX_CONTEXT_OFFSET	(HOST_Q2_RX_CONTEXT_OFFSET + 8)
-#define HOST_Q2_RX_CONTEXT_OFFSET	(HOST_Q1_RX_CONTEXT_OFFSET + 8)
-#define HOST_Q1_RX_CONTEXT_OFFSET	(EMAC_PROMISCUOUS_MODE_OFFSET + 4)
-
-/* Promiscuous mode control */
-#define EMAC_P1_PROMISCUOUS_BIT		BIT(0)
-#define EMAC_P2_PROMISCUOUS_BIT		BIT(1)
-#define EMAC_PROMISCUOUS_MODE_OFFSET	(EMAC_RESERVED + 4)
-#define EMAC_RESERVED			EOF_48K_BUFFER_BD
-
-/* allow for max 48k buffer which spans the descriptors up to 0x1800 6kB */
-#define EOF_48K_BUFFER_BD	(P0_BUFFER_DESC_OFFSET + HOST_BD_SIZE + PORT_BD_SIZE)
-
-#define HOST_BD_SIZE		((HOST_QUEUE_1_SIZE + HOST_QUEUE_2_SIZE + HOST_QUEUE_3_SIZE + HOST_QUEUE_4_SIZE) * BD_SIZE)
-#define PORT_BD_SIZE		((QUEUE_1_SIZE + QUEUE_2_SIZE + QUEUE_3_SIZE + QUEUE_4_SIZE) * 2 * BD_SIZE)
-
-#define END_OF_BD_POOL		(P2_Q4_BD_OFFSET + QUEUE_4_SIZE * BD_SIZE)
-#define P2_Q4_BD_OFFSET		(P2_Q3_BD_OFFSET + QUEUE_3_SIZE * BD_SIZE)
-#define P2_Q3_BD_OFFSET		(P2_Q2_BD_OFFSET + QUEUE_2_SIZE * BD_SIZE)
-#define P2_Q2_BD_OFFSET		(P2_Q1_BD_OFFSET + QUEUE_1_SIZE * BD_SIZE)
-#define P2_Q1_BD_OFFSET		(P1_Q4_BD_OFFSET + QUEUE_4_SIZE * BD_SIZE)
-#define P1_Q4_BD_OFFSET		(P1_Q3_BD_OFFSET + QUEUE_3_SIZE * BD_SIZE)
-#define P1_Q3_BD_OFFSET		(P1_Q2_BD_OFFSET + QUEUE_2_SIZE * BD_SIZE)
-#define P1_Q2_BD_OFFSET		(P1_Q1_BD_OFFSET + QUEUE_1_SIZE * BD_SIZE)
-#define P1_Q1_BD_OFFSET		(P0_Q4_BD_OFFSET + HOST_QUEUE_4_SIZE * BD_SIZE)
-#define P0_Q4_BD_OFFSET		(P0_Q3_BD_OFFSET + HOST_QUEUE_3_SIZE * BD_SIZE)
-#define P0_Q3_BD_OFFSET		(P0_Q2_BD_OFFSET + HOST_QUEUE_2_SIZE * BD_SIZE)
-#define P0_Q2_BD_OFFSET		(P0_Q1_BD_OFFSET + HOST_QUEUE_1_SIZE * BD_SIZE)
-#define P0_Q1_BD_OFFSET		P0_BUFFER_DESC_OFFSET
-#define P0_BUFFER_DESC_OFFSET	SRAM_START_OFFSET
-
-/* Memory Usage of L3 OCMC RAM */
-
-/* L3 64KB Memory - mainly buffer Pool */
-#define END_OF_BUFFER_POOL	(P2_Q4_BUFFER_OFFSET + QUEUE_4_SIZE * ICSS_BLOCK_SIZE)
-#define P2_Q4_BUFFER_OFFSET	(P2_Q3_BUFFER_OFFSET + QUEUE_3_SIZE * ICSS_BLOCK_SIZE)
-#define P2_Q3_BUFFER_OFFSET	(P2_Q2_BUFFER_OFFSET + QUEUE_2_SIZE * ICSS_BLOCK_SIZE)
-#define P2_Q2_BUFFER_OFFSET	(P2_Q1_BUFFER_OFFSET + QUEUE_1_SIZE * ICSS_BLOCK_SIZE)
-#define P2_Q1_BUFFER_OFFSET	(P1_Q4_BUFFER_OFFSET + QUEUE_4_SIZE * ICSS_BLOCK_SIZE)
-#define P1_Q4_BUFFER_OFFSET	(P1_Q3_BUFFER_OFFSET + QUEUE_3_SIZE * ICSS_BLOCK_SIZE)
-#define P1_Q3_BUFFER_OFFSET	(P1_Q2_BUFFER_OFFSET + QUEUE_2_SIZE * ICSS_BLOCK_SIZE)
-#define P1_Q2_BUFFER_OFFSET	(P1_Q1_BUFFER_OFFSET + QUEUE_1_SIZE * ICSS_BLOCK_SIZE)
-#define P1_Q1_BUFFER_OFFSET	(P0_Q4_BUFFER_OFFSET + HOST_QUEUE_4_SIZE * ICSS_BLOCK_SIZE)
-#define P0_Q4_BUFFER_OFFSET	(P0_Q3_BUFFER_OFFSET + HOST_QUEUE_3_SIZE * ICSS_BLOCK_SIZE)
-#define P0_Q3_BUFFER_OFFSET	(P0_Q2_BUFFER_OFFSET + HOST_QUEUE_2_SIZE * ICSS_BLOCK_SIZE)
-#define P0_Q2_BUFFER_OFFSET	(P0_Q1_BUFFER_OFFSET + HOST_QUEUE_1_SIZE * ICSS_BLOCK_SIZE)
-#define P0_COL_BUFFER_OFFSET    0xEE00
-#define P0_Q1_BUFFER_OFFSET	0x0000
-
-/* The below bit will be set in BD for EMAC mode in the egress
- * direction and reset for PRP mode
- */
-#define PRUETH_TX_PRP_EMAC_MODE	BIT(0)
-
-/* 1 byte | 0 : Interrupt Pacing disabled | 1 : Interrupt Pacing enabled */
-#define INTR_PAC_STATUS_OFFSET_PRU1             0x1FAE
-/* 1 byte | 0 : Interrupt Pacing disabled | 1 : Interrupt Pacing enabled */
-#define INTR_PAC_STATUS_OFFSET_PRU0             0x1FAF
-
-#define V2_1_FDB_TBL_LOC          PRUETH_MEM_SHARED_RAM
-#define V2_1_FDB_TBL_OFFSET       0x2000
-
-#define FDB_INDEX_TBL_MAX_ENTRIES     256
-#define FDB_MAC_TBL_MAX_ENTRIES       256
-
-#endif /* __ICSS_SWITCH_H */
diff --git a/drivers/net/ethernet/ti/icss_vlan_mcast_filter_mmap.h b/drivers/net/ethernet/ti/icss_vlan_mcast_filter_mmap.h
deleted file mode 100644
index a1a1a1da47e7..000000000000
--- a/drivers/net/ethernet/ti/icss_vlan_mcast_filter_mmap.h
+++ /dev/null
@@ -1,100 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-
-/* Copyright (C) 2015-2021 Texas Instruments Incorporated - https://www.ti.com
- *
- * This file contains VLAN/Multicast filtering feature memory map
- *
- */
-
-#ifndef ICSS_VLAN_MULTICAST_FILTER_MM_H
-#define ICSS_VLAN_MULTICAST_FILTER_MM_H
-
-/*  VLAN/Multicast filter defines & offsets, present on both PRU0 and PRU1 DRAM */
-
-/* Feature enable/disable values for multicast filtering */
-#define ICSS_EMAC_FW_MULTICAST_FILTER_CTRL_DISABLED             0x00
-#define ICSS_EMAC_FW_MULTICAST_FILTER_CTRL_ENABLED              0x01
-
-/* Feature enable/disable values  for VLAN filtering */
-#define ICSS_EMAC_FW_VLAN_FILTER_CTRL_DISABLED                  0x00
-#define ICSS_EMAC_FW_VLAN_FILTER_CTRL_ENABLED                   0x01
-
-/* Add/remove multicast mac id for filtering bin */
-#define ICSS_EMAC_FW_MULTICAST_FILTER_HOST_RCV_ALLOWED          0x01
-#define ICSS_EMAC_FW_MULTICAST_FILTER_HOST_RCV_NOT_ALLOWED      0x00
-
-/* Default HASH value for the multicast filtering Mask */
-#define ICSS_EMAC_FW_MULTICAST_FILTER_INIT_VAL                  0xFF
-
-/* Size requirements for Multicast filtering feature */
-#define ICSS_EMAC_FW_MULTICAST_TABLE_SIZE_BYTES                        256
-#define ICSS_EMAC_FW_MULTICAST_FILTER_MASK_SIZE_BYTES                    6
-#define ICSS_EMAC_FW_MULTICAST_FILTER_CTRL_SIZE_BYTES                    1
-#define ICSS_EMAC_FW_MULTICAST_FILTER_MASK_OVERRIDE_STATUS_SIZE_BYTES    1
-#define ICSS_EMAC_FW_MULTICAST_FILTER_DROP_CNT_SIZE_BYTES                4
-
-/* Size requirements for VLAN filtering feature : 4096 bits = 512 bytes */
-#define ICSS_EMAC_FW_VLAN_FILTER_TABLE_SIZE_BYTES                      512
-#define ICSS_EMAC_FW_VLAN_FILTER_CTRL_SIZE_BYTES                         1
-#define ICSS_EMAC_FW_VLAN_FILTER_DROP_CNT_SIZE_BYTES                     4
-
-/* Mask override set status */
-#define ICSS_EMAC_FW_MULTICAST_FILTER_MASK_OVERRIDE_SET                  1
-/* Mask override not set status */
-#define ICSS_EMAC_FW_MULTICAST_FILTER_MASK_OVERRIDE_NOT_SET              0
-/* 6 bytes HASH Mask for the MAC */
-#define ICSS_EMAC_FW_MULTICAST_FILTER_MASK_OFFSET         0xF4
-/* 0 -> multicast filtering disabled | 1 -> multicast filtering enabled */
-#define ICSS_EMAC_FW_MULTICAST_FILTER_CTRL_OFFSET        (ICSS_EMAC_FW_MULTICAST_FILTER_MASK_OFFSET + ICSS_EMAC_FW_MULTICAST_FILTER_MASK_SIZE_BYTES)
-/* Status indicating if the HASH override is done or not: 0: no, 1: yes */
-#define ICSS_EMAC_FW_MULTICAST_FILTER_OVERRIDE_STATUS    (ICSS_EMAC_FW_MULTICAST_FILTER_CTRL_OFFSET + ICSS_EMAC_FW_MULTICAST_FILTER_CTRL_SIZE_BYTES)
-/* Multicast drop statistics */
-#define ICSS_EMAC_FW_MULTICAST_FILTER_DROP_CNT_OFFSET    (ICSS_EMAC_FW_MULTICAST_FILTER_OVERRIDE_STATUS + ICSS_EMAC_FW_MULTICAST_FILTER_MASK_OVERRIDE_STATUS_SIZE_BYTES)
-/* Multicast table */
-#define ICSS_EMAC_FW_MULTICAST_FILTER_TABLE              (ICSS_EMAC_FW_MULTICAST_FILTER_DROP_CNT_OFFSET + ICSS_EMAC_FW_MULTICAST_FILTER_DROP_CNT_SIZE_BYTES)
-
-/* Multicast filter defines & offsets for LRE
- */
-#define ICSS_LRE_FW_MULTICAST_TABLE_SEARCH_OP_CONTROL_BIT	0xE0
-/* one byte field :
- * 0 -> multicast filtering disabled
- * 1 -> multicast filtering enabled
- */
-#define ICSS_LRE_FW_MULTICAST_FILTER_MASK                        0xE4
-#define ICSS_LRE_FW_MULTICAST_FILTER_TABLE                       0x100
-
-/* VLAN table Offsets */
-#define ICSS_EMAC_FW_VLAN_FLTR_TBL_BASE_ADDR             0x200
-#define ICSS_EMAC_FW_VLAN_FILTER_CTRL_BITMAP_OFFSET      0xEF
-#define ICSS_EMAC_FW_VLAN_FILTER_DROP_CNT_OFFSET         (ICSS_EMAC_FW_VLAN_FILTER_CTRL_BITMAP_OFFSET + ICSS_EMAC_FW_VLAN_FILTER_CTRL_SIZE_BYTES)
-
-/* VLAN filter Control Bit maps */
-/* one bit field, bit 0: | 0 : VLAN filter disabled (default), 1: VLAN filter enabled */
-#define ICSS_EMAC_FW_VLAN_FILTER_CTRL_ENABLE_BIT                       0
-/* one bit field, bit 1: | 0 : untagged host rcv allowed (default), 1: untagged host rcv not allowed */
-#define ICSS_EMAC_FW_VLAN_FILTER_UNTAG_HOST_RCV_ALLOW_CTRL_BIT         1
-/* one bit field, bit 1: | 0 : priotag host rcv allowed (default), 1: priotag host rcv not allowed */
-#define ICSS_EMAC_FW_VLAN_FILTER_PRIOTAG_HOST_RCV_ALLOW_CTRL_BIT       2
-/* one bit field, bit 1: | 0 : skip sv vlan flow   :1 : take sv vlan flow  (not applicable for dual emac */
-#define ICSS_EMAC_FW_VLAN_FILTER_SV_VLAN_FLOW_HOST_RCV_ALLOW_CTRL_BIT  3
-
-/* VLAN IDs */
-#define ICSS_EMAC_FW_VLAN_FILTER_PRIOTAG_VID                           0
-#define ICSS_EMAC_FW_VLAN_FILTER_VID_MIN                               0x0000
-#define ICSS_EMAC_FW_VLAN_FILTER_VID_MAX                               0x0FFF
-
-/* VLAN Filtering Commands */
-#define ICSS_EMAC_FW_VLAN_FILTER_ADD_VLAN_VID_CMD                      0x00
-#define ICSS_EMAC_FW_VLAN_FILTER_REMOVE_VLAN_VID_CMD                   0x01
-
-/* Switch defines for VLAN/MC filtering */
-/* SRAM
- * VLAN filter defines & offsets
- */
-#define ICSS_LRE_FW_VLAN_FLTR_CTRL_BYTE                          0x1FE
-/* one bit field | 0 : VLAN filter disabled
- *               | 1 : VLAN filter enabled
- */
-#define ICSS_LRE_FW_VLAN_FLTR_TBL_BASE_ADDR                      0x200
-
-#endif /* ICSS_MULTICAST_FILTER_MM_H */
diff --git a/drivers/net/ethernet/ti/icssg_classifier.c b/drivers/net/ethernet/ti/icssg_classifier.c
deleted file mode 100644
index ea9a1c7bb0fe..000000000000
--- a/drivers/net/ethernet/ti/icssg_classifier.c
+++ /dev/null
@@ -1,463 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/* Texas Instruments ICSSG Ethernet Driver
- *
- * Copyright (C) 2018-2021 Texas Instruments Incorporated - https://www.ti.com/
- *
- */
-
-#include <linux/etherdevice.h>
-#include <linux/types.h>
-#include <linux/regmap.h>
-
-#include "icssg_prueth.h"
-
-#define ICSSG_NUM_CLASSIFIERS	16
-#define ICSSG_NUM_FT1_SLOTS	8
-#define ICSSG_NUM_FT3_SLOTS	16
-
-#define ICSSG_NUM_CLASSIFIERS_IN_USE	5
-
-/* Filter 1 - FT1 */
-#define FT1_NUM_SLOTS	8
-#define FT1_SLOT_SIZE	0x10	/* bytes */
-
-/* offsets from FT1 slot base i.e. slot 1 start */
-#define FT1_DA0		0x0
-#define FT1_DA1		0x4
-#define FT1_DA0_MASK	0x8
-#define FT1_DA1_MASK	0xc
-
-#define FT1_N_REG(slize, n, reg)	(offs[slice].ft1_slot_base + FT1_SLOT_SIZE * (n) + (reg))
-
-#define FT1_LEN_MASK	GENMASK(19, 16)
-#define FT1_LEN_SHIFT	16
-#define FT1_LEN(len)	(((len) << FT1_LEN_SHIFT) & FT1_LEN_MASK)
-
-#define FT1_START_MASK	GENMASK(14, 0)
-#define FT1_START(start)	((start) & FT1_START_MASK)
-
-#define FT1_MATCH_SLOT(n)	(GENMASK(23, 16) & (BIT(n) << 16))
-
-enum ft1_cfg_type {
-	FT1_CFG_TYPE_DISABLED = 0,
-	FT1_CFG_TYPE_EQ,
-	FT1_CFG_TYPE_GT,
-	FT1_CFG_TYPE_LT,
-};
-
-#define FT1_CFG_SHIFT(n)	(2 * (n))
-#define FT1_CFG_MASK(n)	(0x3 << FT1_CFG_SHIFT((n)))
-
-/* Filter 3 -  FT3 */
-#define FT3_NUM_SLOTS	16
-#define FT3_SLOT_SIZE	0x20	/* bytes */
-
-/* offsets from FT3 slot n's base */
-#define FT3_START	0
-#define FT3_START_AUTO	0x4
-#define FT3_START_OFFSET	0x8
-#define FT3_JUMP_OFFSET	0xc
-#define FT3_LEN		0x10
-#define FT3_CFG		0x14
-#define FT3_T		0x18
-#define FT3_T_MASK	0x1c
-
-#define FT3_N_REG(slize, n, reg)	(offs[slice].ft3_slot_base + FT3_SLOT_SIZE * (n) + (reg))
-
-/* offsets from rx_class n's base */
-#define RX_CLASS_AND_EN	0
-#define RX_CLASS_OR_EN	0x4
-
-#define RX_CLASS_NUM_SLOTS	16
-#define RX_CLASS_EN_SIZE	0x8	/* bytes */
-
-#define RX_CLASS_N_REG(slice, n, reg)	(offs[slice].rx_class_base + RX_CLASS_EN_SIZE * (n) + (reg))
-
-/* RX Class Gates */
-#define RX_CLASS_GATES_SIZE	0x4	/* bytes */
-
-#define RX_CLASS_GATES_N_REG(slice, n)	\
-	(offs[slice].rx_class_gates_base + RX_CLASS_GATES_SIZE * (n))
-
-#define RX_CLASS_GATES_ALLOW_MASK	BIT(6)
-#define RX_CLASS_GATES_RAW_MASK		BIT(5)
-#define RX_CLASS_GATES_PHASE_MASK	BIT(4)
-
-/* RX Class traffic data matching bits */
-#define RX_CLASS_FT_UC		BIT(31)
-#define RX_CLASS_FT_MC		BIT(30)
-#define RX_CLASS_FT_BC		BIT(29)
-#define RX_CLASS_FT_FW		BIT(28)
-#define RX_CLASS_FT_RCV		BIT(27)
-#define RX_CLASS_FT_VLAN	BIT(26)
-#define RX_CLASS_FT_DA_P	BIT(25)
-#define RX_CLASS_FT_DA_I	BIT(24)
-#define RX_CLASS_FT_FT1_MATCH_MASK	GENMASK(23, 16)
-#define RX_CLASS_FT_FT1_MATCH_SHIFT	16
-#define RX_CLASS_FT_FT3_MATCH_MASK	GENMASK(15, 0)
-#define RX_CLASS_FT_FT3_MATCH_SHIFT	0
-
-#define RX_CLASS_FT_FT1_MATCH(slot)	\
-	((BIT(slot) << RX_CLASS_FT_FT1_MATCH_SHIFT) & RX_CLASS_FT_FT1_MATCH_MASK)
-
-enum rx_class_sel_type {
-	RX_CLASS_SEL_TYPE_OR = 0,
-	RX_CLASS_SEL_TYPE_AND = 1,
-	RX_CLASS_SEL_TYPE_OR_AND_AND = 2,
-	RX_CLASS_SEL_TYPE_OR_OR_AND = 3,
-};
-
-#define FT1_CFG_SHIFT(n)	(2 * (n))
-#define FT1_CFG_MASK(n)		(0x3 << FT1_CFG_SHIFT((n)))
-
-#define RX_CLASS_SEL_SHIFT(n)	(2 * (n))
-#define RX_CLASS_SEL_MASK(n)	(0x3 << RX_CLASS_SEL_SHIFT((n)))
-
-#define ICSSG_CFG_OFFSET	0
-
-#define ICSSG_CFG_RX_L2_G_EN	BIT(2)
-
-/* these are register offsets per PRU */
-struct miig_rt_offsets {
-	u32 mac0;
-	u32 mac1;
-	u32 ft1_start_len;
-	u32 ft1_cfg;
-	u32 ft1_slot_base;
-	u32 ft3_slot_base;
-	u32 ft3_p_base;
-	u32 ft_rx_ptr;
-	u32 rx_class_base;
-	u32 rx_class_cfg1;
-	u32 rx_class_cfg2;
-	u32 rx_class_gates_base;
-	u32 rx_green;
-	u32 rx_rate_cfg_base;
-	u32 rx_rate_src_sel0;
-	u32 rx_rate_src_sel1;
-	u32 tx_rate_cfg_base;
-	u32 stat_base;
-	u32 tx_hsr_tag;
-	u32 tx_hsr_seq;
-	u32 tx_vlan_type;
-	u32 tx_vlan_ins;
-};
-
-static struct miig_rt_offsets offs[] = {
-	/* PRU0 */
-	{
-		0x8,
-		0xc,
-		0x80,
-		0x84,
-		0x88,
-		0x108,
-		0x308,
-		0x408,
-		0x40c,
-		0x48c,
-		0x490,
-		0x494,
-		0x4d4,
-		0x4e4,
-		0x504,
-		0x508,
-		0x50c,
-		0x54c,
-		0x63c,
-		0x640,
-		0x644,
-		0x648,
-	},
-	/* PRU1 */
-	{
-		0x10,
-		0x14,
-		0x64c,
-		0x650,
-		0x654,
-		0x6d4,
-		0x8d4,
-		0x9d4,
-		0x9d8,
-		0xa58,
-		0xa5c,
-		0xa60,
-		0xaa0,
-		0xab0,
-		0xad0,
-		0xad4,
-		0xad8,
-		0xb18,
-		0xc08,
-		0xc0c,
-		0xc10,
-		0xc14,
-	},
-};
-
-static inline u32 addr_to_da0(const u8 *addr)
-{
-	return (u32)(addr[0] | addr[1] << 8 |
-		addr[2] << 16 | addr[3] << 24);
-};
-
-static inline u32 addr_to_da1(const u8 *addr)
-{
-	return (u32)(addr[4] | addr[5] << 8);
-};
-
-static void rx_class_ft1_set_start_len(struct regmap *miig_rt, int slice,
-				       u16 start, u8 len)
-{
-	u32 offset, val;
-
-	offset = offs[slice].ft1_start_len;
-	val = FT1_LEN(len) | FT1_START(start);
-	regmap_write(miig_rt, offset, val);
-}
-
-static void rx_class_ft1_set_da(struct regmap *miig_rt, int slice,
-				int n, const u8 *addr)
-{
-	u32 offset;
-
-	offset = FT1_N_REG(slice, n, FT1_DA0);
-	regmap_write(miig_rt, offset, addr_to_da0(addr));
-	offset = FT1_N_REG(slice, n, FT1_DA1);
-	regmap_write(miig_rt, offset, addr_to_da1(addr));
-}
-
-static void rx_class_ft1_set_da_mask(struct regmap *miig_rt, int slice,
-				     int n, const u8 *addr)
-{
-	u32 offset;
-
-	offset = FT1_N_REG(slice, n, FT1_DA0_MASK);
-	regmap_write(miig_rt, offset, addr_to_da0(addr));
-	offset = FT1_N_REG(slice, n, FT1_DA1_MASK);
-	regmap_write(miig_rt, offset, addr_to_da1(addr));
-}
-
-static void rx_class_ft1_cfg_set_type(struct regmap *miig_rt, int slice, int n,
-				      enum ft1_cfg_type type)
-{
-	u32 offset;
-
-	offset = offs[slice].ft1_cfg;
-	regmap_update_bits(miig_rt, offset, FT1_CFG_MASK(n),
-			   type << FT1_CFG_SHIFT(n));
-}
-
-static void rx_class_sel_set_type(struct regmap *miig_rt, int slice, int n,
-				  enum rx_class_sel_type type)
-{
-	u32 offset;
-
-	offset = offs[slice].rx_class_cfg1;
-	regmap_update_bits(miig_rt, offset, RX_CLASS_SEL_MASK(n),
-			   type << RX_CLASS_SEL_SHIFT(n));
-}
-
-static void rx_class_set_and(struct regmap *miig_rt, int slice, int n,
-			     u32 data)
-{
-	u32 offset;
-
-	offset = RX_CLASS_N_REG(slice, n, RX_CLASS_AND_EN);
-	regmap_write(miig_rt, offset, data);
-}
-
-static void rx_class_set_or(struct regmap *miig_rt, int slice, int n,
-			    u32 data)
-{
-	u32 offset;
-
-	offset = RX_CLASS_N_REG(slice, n, RX_CLASS_OR_EN);
-	regmap_write(miig_rt, offset, data);
-}
-
-static u32 rx_class_get_or(struct regmap *miig_rt, int slice, int n)
-{
-	u32 offset, val;
-
-	offset = RX_CLASS_N_REG(slice, n, RX_CLASS_OR_EN);
-	regmap_read(miig_rt, offset, &val);
-
-	return val;
-}
-
-void icssg_class_set_mac_addr(struct regmap *miig_rt, int slice, u8 *mac)
-{
-	regmap_write(miig_rt, offs[slice].mac0, addr_to_da0(mac));
-	regmap_write(miig_rt, offs[slice].mac1, addr_to_da1(mac));
-}
-
-static void icssg_class_ft1_add_mcast(struct regmap *miig_rt, int slice,
-				      int slot, const u8 *addr, const u8 *mask)
-{
-	int i;
-	u32 val;
-
-	WARN(slot >= FT1_NUM_SLOTS, "invalid slot: %d\n", slot);
-
-	rx_class_ft1_set_da(miig_rt, slice, slot, addr);
-	rx_class_ft1_set_da_mask(miig_rt, slice, slot, mask);
-	rx_class_ft1_cfg_set_type(miig_rt, slice, slot, FT1_CFG_TYPE_EQ);
-
-	/* Enable the FT1 slot in OR enable for all classifiers */
-	for (i = 0; i < ICSSG_NUM_CLASSIFIERS_IN_USE; i++) {
-		val = rx_class_get_or(miig_rt, slice, i);
-		val |= RX_CLASS_FT_FT1_MATCH(slot);
-		rx_class_set_or(miig_rt, slice, i, val);
-	}
-}
-
-/* disable all RX traffic */
-void icssg_class_disable(struct regmap *miig_rt, int slice)
-{
-	u32 data, offset;
-	int n;
-
-	/* Enable RX_L2_G */
-	regmap_update_bits(miig_rt, ICSSG_CFG_OFFSET, ICSSG_CFG_RX_L2_G_EN,
-			   ICSSG_CFG_RX_L2_G_EN);
-
-	for (n = 0; n < ICSSG_NUM_CLASSIFIERS; n++) {
-		/* AND_EN = 0 */
-		rx_class_set_and(miig_rt, slice, n, 0);
-		/* OR_EN = 0 */
-		rx_class_set_or(miig_rt, slice, n, 0);
-
-		/* set CFG1 to OR */
-		rx_class_sel_set_type(miig_rt, slice, n, RX_CLASS_SEL_TYPE_OR);
-
-		/* configure gate */
-		offset = RX_CLASS_GATES_N_REG(slice, n);
-		regmap_read(miig_rt, offset, &data);
-		/* clear class_raw so we go through filters */
-		data &= ~RX_CLASS_GATES_RAW_MASK;
-		/* set allow and phase mask */
-		data |= RX_CLASS_GATES_ALLOW_MASK | RX_CLASS_GATES_PHASE_MASK;
-		regmap_write(miig_rt, offset, data);
-	}
-
-	/* FT1 Disabled */
-	for (n = 0; n < ICSSG_NUM_FT1_SLOTS; n++) {
-		u8 addr[] = { 0, 0, 0, 0, 0, 0, };
-
-		rx_class_ft1_cfg_set_type(miig_rt, slice, n,
-					  FT1_CFG_TYPE_DISABLED);
-		rx_class_ft1_set_da(miig_rt, slice, n, addr);
-		rx_class_ft1_set_da_mask(miig_rt, slice, n, addr);
-	}
-
-	/* clear CFG2 */
-	regmap_write(miig_rt, offs[slice].rx_class_cfg2, 0);
-}
-
-void icssg_class_default(struct regmap *miig_rt, int slice, bool allmulti,
-			 bool is_sr1)
-{
-	u32 data;
-	int n;
-	int classifiers_in_use = ICSSG_NUM_CLASSIFIERS_IN_USE;
-
-	if (!is_sr1)
-		classifiers_in_use = 1;
-
-	/* defaults */
-	icssg_class_disable(miig_rt, slice);
-
-	/* Setup Classifier */
-	for (n = 0; n < classifiers_in_use; n++) {
-		/* match on Broadcast or MAC_PRU address */
-		data = RX_CLASS_FT_BC | RX_CLASS_FT_DA_P;
-
-		/* multicast? */
-		if (allmulti)
-			data |= RX_CLASS_FT_MC;
-
-		rx_class_set_or(miig_rt, slice, n, data);
-
-		/* set CFG1 for OR_OR_AND for classifier */
-		rx_class_sel_set_type(miig_rt, slice, n,
-				      RX_CLASS_SEL_TYPE_OR_OR_AND);
-	}
-
-	/* clear CFG2 */
-	regmap_write(miig_rt, offs[slice].rx_class_cfg2, 0);
-}
-
-void icssg_class_promiscuous_sr1(struct regmap *miig_rt, int slice)
-{
-	u32 data;
-	u32 offset;
-	int n;
-
-	/* defaults */
-	icssg_class_disable(miig_rt, slice);
-
-	/* Setup Classifier */
-	for (n = 0; n < ICSSG_NUM_CLASSIFIERS_IN_USE; n++) {
-		/* set RAW_MASK to bypass filters */
-		offset = RX_CLASS_GATES_N_REG(slice, n);
-		regmap_read(miig_rt, offset, &data);
-		data |= RX_CLASS_GATES_RAW_MASK;
-		regmap_write(miig_rt, offset, data);
-	}
-}
-
-void icssg_class_add_mcast_sr1(struct regmap *miig_rt, int slice,
-			       struct net_device *ndev)
-{
-	int slot;
-	struct netdev_hw_addr *ha;
-	u8 sr_addr[] = { 0x01, 0x80, 0xC2, 0, 0, 0, };
-	u8 cb_addr[] = { 0x01, 0x00, 0x5e, 0, 0, 0, };
-	u8 mask_addr[] = { 0, 0, 0, 0, 0, 0, };
-
-	rx_class_ft1_set_start_len(miig_rt, slice, 0, 6);
-	/* reserve first 2 slots for
-	 *	1) 01-80-C2-00-00-XX Known Service Ethernet Multicast addresses
-	 *	2) 01-00-5e-00-00-XX Local Network Control Block
-	 *			      (224.0.0.0 - 224.0.0.255  (224.0.0/24))
-	 */
-	mask_addr[5] = 0xff;
-	icssg_class_ft1_add_mcast(miig_rt, slice, 0, sr_addr, mask_addr);
-	icssg_class_ft1_add_mcast(miig_rt, slice, 1, cb_addr, mask_addr);
-	mask_addr[5] = 0;
-	slot = 2;
-	netdev_for_each_mc_addr(ha, ndev) {
-		/* skip addresses matching reserved slots */
-		if (!memcmp(sr_addr, ha->addr, 5) ||
-		    !memcmp(cb_addr, ha->addr, 5)) {
-			netdev_dbg(ndev, "mcast skip %pM\n", ha->addr);
-			continue;
-		}
-
-		if (slot >= FT1_NUM_SLOTS) {
-			netdev_dbg(ndev,
-				   "can't add more than %d MC addresses, enabling allmulti\n",
-				   FT1_NUM_SLOTS);
-			icssg_class_default(miig_rt, slice, 1, 1);
-			break;
-		}
-
-		netdev_dbg(ndev, "mcast add %pM\n", ha->addr);
-		icssg_class_ft1_add_mcast(miig_rt, slice, slot,
-					  ha->addr, mask_addr);
-		slot++;
-	}
-}
-
-/* required for SR2 for SAV check */
-void icssg_ft1_set_mac_addr(struct regmap *miig_rt, int slice, u8 *mac_addr)
-{
-	u8 mask_addr[] = { 0, 0, 0, 0, 0, 0, };
-
-	rx_class_ft1_set_start_len(miig_rt, slice, 0, 6);
-	rx_class_ft1_set_da(miig_rt, slice, 0, mac_addr);
-	rx_class_ft1_set_da_mask(miig_rt, slice, 0, mask_addr);
-	rx_class_ft1_cfg_set_type(miig_rt, slice, 0, FT1_CFG_TYPE_EQ);
-}
diff --git a/drivers/net/ethernet/ti/icssg_config.c b/drivers/net/ethernet/ti/icssg_config.c
deleted file mode 100644
index b5cef264cdf9..000000000000
--- a/drivers/net/ethernet/ti/icssg_config.c
+++ /dev/null
@@ -1,439 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/* ICSSG Ethernet driver
- *
- * Copyright (C) 2021 Texas Instruments Incorporated - https://www.ti.com
- */
-
-#include <linux/regmap.h>
-#include "icssg_config.h"
-#include "icssg_prueth.h"
-#include "icssg_switch_map.h"
-#include "icss_mii_rt.h"
-
-/* TX IPG Values to be set for 100M and 1G link speeds.  These values are
- * in ocp_clk cycles. So need change if ocp_clk is changed for a specific
- * h/w design.
- */
-
-/* IPG is in core_clk cycles */
-#define MII_RT_TX_IPG_100M_SR1	0x166
-#define MII_RT_TX_IPG_1G_SR1	0x1a
-#define MII_RT_TX_IPG_100M	0x17
-#define MII_RT_TX_IPG_1G	0xb
-
-#define	ICSSG_QUEUES_MAX		64
-#define	ICSSG_QUEUE_OFFSET		0xd00
-#define	ICSSG_QUEUE_PEEK_OFFSET		0xe00
-#define	ICSSG_QUEUE_CNT_OFFSET		0xe40
-#define	ICSSG_QUEUE_RESET_OFFSET	0xf40
-
-#define	ICSSG_NUM_TX_QUEUES	8
-
-#define	RECYCLE_Q_SLICE0	16
-#define	RECYCLE_Q_SLICE1	17
-
-#define	ICSSG_NUM_OTHER_QUEUES	5	/* port, host and special queues */
-
-#define	PORT_HI_Q_SLICE0	32
-#define	PORT_LO_Q_SLICE0	33
-#define	HOST_HI_Q_SLICE0	34
-#define	HOST_LO_Q_SLICE0	35
-#define	HOST_SPL_Q_SLICE0	40	/* Special Queue */
-
-#define	PORT_HI_Q_SLICE1	36
-#define	PORT_LO_Q_SLICE1	37
-#define	HOST_HI_Q_SLICE1	38
-#define	HOST_LO_Q_SLICE1	39
-#define	HOST_SPL_Q_SLICE1	41	/* Special Queue */
-
-#define MII_RXCFG_DEFAULT	(PRUSS_MII_RT_RXCFG_RX_ENABLE | \
-				 PRUSS_MII_RT_RXCFG_RX_DATA_RDY_MODE_DIS | \
-				 PRUSS_MII_RT_RXCFG_RX_L2_EN | \
-				 PRUSS_MII_RT_RXCFG_RX_L2_EOF_SCLR_DIS)
-
-#define MII_TXCFG_DEFAULT	(PRUSS_MII_RT_TXCFG_TX_ENABLE | \
-				 PRUSS_MII_RT_TXCFG_TX_AUTO_PREAMBLE | \
-				 PRUSS_MII_RT_TXCFG_TX_32_MODE_EN | \
-				 PRUSS_MII_RT_TXCFG_TX_IPG_WIRE_CLK_EN)
-
-#define ICSSG_CFG_DEFAULT	(ICSSG_CFG_TX_L1_EN | \
-				 ICSSG_CFG_TX_L2_EN | ICSSG_CFG_RX_L2_G_EN | \
-				 ICSSG_CFG_TX_PRU_EN | /* SR2.0 only */ \
-				 ICSSG_CFG_SGMII_MODE)
-
-struct map {
-	int queue;
-	u32 pd_addr_start;
-	u32 flags;
-	bool special;
-};
-
-struct map hwq_map[2][ICSSG_NUM_OTHER_QUEUES] = {
-	{
-		{ PORT_HI_Q_SLICE0, PORT_DESC0_HI, 0x200000, 0 },
-		{ PORT_LO_Q_SLICE0, PORT_DESC0_LO, 0, 0 },
-		{ HOST_HI_Q_SLICE0, HOST_DESC0_HI, 0x200000, 0 },
-		{ HOST_LO_Q_SLICE0, HOST_DESC0_LO, 0, 0 },
-		{ HOST_SPL_Q_SLICE0, HOST_SPPD0, 0x400000, 1 },
-	},
-	{
-		{ PORT_HI_Q_SLICE1, PORT_DESC1_HI, 0xa00000, 0 },
-		{ PORT_LO_Q_SLICE1, PORT_DESC1_LO, 0x800000, 0 },
-		{ HOST_HI_Q_SLICE1, HOST_DESC1_HI, 0xa00000, 0 },
-		{ HOST_LO_Q_SLICE1, HOST_DESC1_LO, 0x800000, 0 },
-		{ HOST_SPL_Q_SLICE1, HOST_SPPD1, 0xc00000, 1 },
-	},
-};
-
-static void icssg_config_mii_init(struct prueth *prueth, int mii)
-{
-	struct regmap *mii_rt = prueth->mii_rt;
-	u32 rxcfg_reg, txcfg_reg, pcnt_reg;
-	u32 rxcfg, txcfg;
-
-	rxcfg_reg = (mii == ICSS_MII0) ? PRUSS_MII_RT_RXCFG0 :
-				       PRUSS_MII_RT_RXCFG1;
-	txcfg_reg = (mii == ICSS_MII0) ? PRUSS_MII_RT_TXCFG0 :
-				       PRUSS_MII_RT_TXCFG1;
-	pcnt_reg = (mii == ICSS_MII0) ? PRUSS_MII_RT_RX_PCNT0 :
-				       PRUSS_MII_RT_RX_PCNT1;
-
-	icssg_config_ipg(prueth, SPEED_1000, mii);
-
-	rxcfg = MII_RXCFG_DEFAULT;
-	txcfg = MII_TXCFG_DEFAULT;
-
-	if (mii == ICSS_MII1) {
-		rxcfg |= PRUSS_MII_RT_RXCFG_RX_MUX_SEL;
-		txcfg |= PRUSS_MII_RT_TXCFG_TX_MUX_SEL;
-	}
-
-	regmap_write(mii_rt, rxcfg_reg, rxcfg);
-	regmap_write(mii_rt, txcfg_reg, txcfg);
-	regmap_write(mii_rt, pcnt_reg, 0x1);
-}
-
-static void icssg_config_rgmii_init(struct prueth *prueth, int slice)
-{
-	void __iomem *smem = prueth->shram.va;
-	struct regmap *miig_rt = prueth->miig_rt;
-	int queue = 0, i, j;
-	u8 pd[ICSSG_SPECIAL_PD_SIZE];
-	u32 *pdword;
-	u32 mii_mode;
-
-	mii_mode = MII_MODE_RGMII << ICSSG_CFG_MII0_MODE_SHIFT;
-	mii_mode |= MII_MODE_RGMII << ICSSG_CFG_MII1_MODE_SHIFT;
-	regmap_write(miig_rt, ICSSG_CFG_OFFSET, ICSSG_CFG_DEFAULT | mii_mode);
-
-	icssg_update_rgmii_cfg(miig_rt, SPEED_1000, DUPLEX_FULL, slice);
-	/* reset hwqueues */
-	if (slice)
-		queue = ICSSG_NUM_TX_QUEUES;
-
-	for (i = 0; i < ICSSG_NUM_TX_QUEUES; i++) {
-		regmap_write(miig_rt, ICSSG_QUEUE_RESET_OFFSET, queue);
-		queue++;
-	}
-
-	queue = slice ? RECYCLE_Q_SLICE1 : RECYCLE_Q_SLICE0;
-	regmap_write(miig_rt, ICSSG_QUEUE_RESET_OFFSET, queue);
-
-	for (i = 0; i < ICSSG_NUM_OTHER_QUEUES; i++) {
-		regmap_write(miig_rt, ICSSG_QUEUE_RESET_OFFSET,
-			     hwq_map[slice][i].queue);
-	}
-
-	/* initialize packet descriptors in SMEM */
-	/* push pakcet descriptors to hwqueues */
-
-	pdword = (u32 *)pd;
-	for (j = 0; j < ICSSG_NUM_OTHER_QUEUES; j++) {
-		struct map *mp;
-		int pd_size, num_pds;
-		u32 pdaddr;
-
-		mp = &hwq_map[slice][j];
-		if (mp->special) {
-			pd_size = ICSSG_SPECIAL_PD_SIZE;
-			num_pds = ICSSG_NUM_SPECIAL_PDS;
-		} else	{
-			pd_size = ICSSG_NORMAL_PD_SIZE;
-			num_pds = ICSSG_NUM_NORMAL_PDS;
-		}
-
-		for (i = 0; i < num_pds; i++) {
-			memset(pd, 0, pd_size);
-
-			pdword[0] &= cpu_to_le32(ICSSG_FLAG_MASK);
-			pdword[0] |= cpu_to_le32(mp->flags);
-			pdaddr = mp->pd_addr_start + i * pd_size;
-
-			memcpy_toio(smem + pdaddr, pd, pd_size);
-			queue = mp->queue;
-			regmap_write(miig_rt, ICSSG_QUEUE_OFFSET + 4 * queue,
-				     pdaddr);
-		}
-	}
-}
-
-void icssg_config_ipg(struct prueth *prueth, int speed, int mii)
-{
-	switch (speed) {
-	case SPEED_1000:
-		icssg_mii_update_ipg(prueth->mii_rt, mii, prueth->is_sr1 ?
-				     MII_RT_TX_IPG_1G_SR1 : MII_RT_TX_IPG_1G);
-		break;
-	case SPEED_100:
-		icssg_mii_update_ipg(prueth->mii_rt, mii, prueth->is_sr1 ?
-				     MII_RT_TX_IPG_100M_SR1 : MII_RT_TX_IPG_100M);
-		break;
-	case SPEED_10:
-		/* Firmware hardcodes IPG  for PG1. PG2 same as 100M */
-		if (!prueth->is_sr1)
-			icssg_mii_update_ipg(prueth->mii_rt, mii,
-					     MII_RT_TX_IPG_100M);
-		break;
-	default:
-		/* Other links speeds not supported */
-		pr_err("Unsupported link speed\n");
-		return;
-	}
-}
-
-/* SR1: Set buffer sizes for the pools. There are 8 internal queues
- * implemented in firmware, but only 4 tx channels/threads in the Egress
- * direction to firmware. Need a high priority queue for management
- * messages since they shouldn't be blocked even during high traffic
- * situation. So use Q0-Q2 as data queues and Q3 as management queue
- * in the max case. However for ease of configuration, use the max
- * data queue + 1 for management message if we are not using max
- * case.
- *
- * Allocate 4 MTU buffers per data queue.  Firmware requires
- * pool sizes to be set for internal queues. Set the upper 5 queue
- * pool size to min size of 128 bytes since there are only 3 tx
- * data channels and management queue requires only minimum buffer.
- * i.e lower queues are used by driver and highest priority queue
- * from that is used for management message.
- */
-
-static int emac_egress_buf_pool_size[] = {
-	PRUETH_EMAC_BUF_POOL_SIZE_SR1, PRUETH_EMAC_BUF_POOL_SIZE_SR1,
-	PRUETH_EMAC_BUF_POOL_SIZE_SR1, PRUETH_EMAC_BUF_POOL_MIN_SIZE_SR1,
-	PRUETH_EMAC_BUF_POOL_MIN_SIZE_SR1, PRUETH_EMAC_BUF_POOL_MIN_SIZE_SR1,
-	PRUETH_EMAC_BUF_POOL_MIN_SIZE_SR1, PRUETH_EMAC_BUF_POOL_MIN_SIZE_SR1};
-
-void icssg_config_sr1(struct prueth *prueth, struct prueth_emac *emac,
-		      int slice)
-{
-	void __iomem *va;
-	struct icssg_config_sr1 *config;
-	int i, index;
-
-	va = prueth->shram.va + slice * ICSSG_CONFIG_OFFSET_SLICE1;
-	config = &prueth->config[slice];
-	memset(config, 0, sizeof(*config));
-	config->addr_lo = cpu_to_le32(lower_32_bits(prueth->msmcram.pa));
-	config->addr_hi = cpu_to_le32(upper_32_bits(prueth->msmcram.pa));
-	config->num_tx_threads = 0;
-	config->rx_flow_id = emac->rx_flow_id_base; /* flow id for host port */
-	config->rx_mgr_flow_id = emac->rx_mgm_flow_id_base; /* for mgm ch */
-
-	for (i = PRUETH_EMAC_BUF_POOL_START_SR1; i < PRUETH_NUM_BUF_POOLS_SR1;
-	     i++) {
-		index =  i - PRUETH_EMAC_BUF_POOL_START_SR1;
-		config->tx_buf_sz[i] =
-			cpu_to_le32(emac_egress_buf_pool_size[index]);
-	}
-
-	memcpy_toio(va, &prueth->config[slice], sizeof(prueth->config[slice]));
-}
-
-static void emac_r30_cmd_init(struct prueth_emac *emac)
-{
-	int i;
-	struct icssg_r30_cmd *p;
-
-	p = emac->dram.va + MGR_R30_CMD_OFFSET;
-
-	for (i = 0; i < 4; i++)
-		writel(EMAC_NONE, &p->cmd[i]);
-}
-
-static int emac_r30_is_done(struct prueth_emac *emac)
-{
-	const struct icssg_r30_cmd *p;
-	int i;
-	u32 cmd;
-
-	p = emac->dram.va + MGR_R30_CMD_OFFSET;
-
-	for (i = 0; i < 4; i++) {
-		cmd = readl(&p->cmd[i]);
-		if (cmd != EMAC_NONE)
-			return 0;
-	}
-
-	return 1;
-}
-
-int icssg_config_sr2(struct prueth *prueth, struct prueth_emac *emac, int slice)
-{
-	void *config = emac->dram.va + ICSSG_CONFIG_OFFSET;
-	u8 *cfg_byte_ptr = config;
-	struct icssg_flow_cfg *flow_cfg;
-	struct icssg_buffer_pool_cfg *bpool_cfg;
-	struct icssg_rxq_ctx *rxq_ctx;
-	int i;
-	u32 addr, mask;
-
-	rxq_ctx = emac->dram.va + HOST_RX_Q_PRE_CONTEXT_OFFSET;
-	memset_io(config, 0, TAS_GATE_MASK_LIST0);
-	icssg_config_rgmii_init(prueth, slice);
-	icssg_config_mii_init(prueth, slice);
-
-	/* set GPI mode */
-	pruss_cfg_gpimode(prueth->pruss, prueth->pru_id[slice],
-			  PRUSS_GPI_MODE_MII);
-
-	/* enable XFR shift for PRU and RTU */
-	mask = PRUSS_SPP_XFER_SHIFT_EN | PRUSS_SPP_RTU_XFR_SHIFT_EN;
-	pruss_cfg_update(prueth->pruss, PRUSS_CFG_SPP, mask, mask);
-
-	/* set C28 to 0x100 */
-	pru_rproc_set_ctable(prueth->pru[slice], PRU_C28, 0x100 << 8);
-	pru_rproc_set_ctable(prueth->rtu[slice], PRU_C28, 0x100 << 8);
-	pru_rproc_set_ctable(prueth->txpru[slice], PRU_C28, 0x100 << 8);
-
-	bpool_cfg = emac->dram.va + BUFFER_POOL_0_ADDR_OFFSET;
-
-	flow_cfg = config + PSI_L_REGULAR_FLOW_ID_BASE_OFFSET;
-	flow_cfg->rx_base_flow = cpu_to_le32(emac->rx_flow_id_base);
-	flow_cfg->mgm_base_flow = 0;
-	*(cfg_byte_ptr + SPL_PKT_DEFAULT_PRIORITY) = 0;
-	*(cfg_byte_ptr + QUEUE_NUM_UNTAGGED) = 0x0;
-
-	/* Layout to have 64KB aligned buffer pool
-	 * |BPOOL0|BPOOL1|RX_CTX0|RX_CTX1|
-	 */
-
-	addr = lower_32_bits(prueth->msmcram.pa);
-	if (slice)
-		addr += PRUETH_NUM_BUF_POOLS_SR2 * PRUETH_EMAC_BUF_POOL_SIZE_SR2;
-
-	if (addr % SZ_64K) {
-		dev_warn(prueth->dev, "buffer pool needs to be 64KB aligned\n");
-		return -EINVAL;
-	}
-
-	/* workaround for f/w bug. bpool 0 needs to be initilalized */
-	bpool_cfg[0].addr = cpu_to_le32(addr);
-	bpool_cfg[0].len = 0;
-
-	for (i = PRUETH_EMAC_BUF_POOL_START_SR2;
-	     i < (PRUETH_EMAC_BUF_POOL_START_SR2 + PRUETH_NUM_BUF_POOLS_SR2);
-	     i++) {
-		bpool_cfg[i].addr = cpu_to_le32(addr);
-		bpool_cfg[i].len = cpu_to_le32(PRUETH_EMAC_BUF_POOL_SIZE_SR2);
-		addr += PRUETH_EMAC_BUF_POOL_SIZE_SR2;
-	}
-
-	addr += PRUETH_NUM_BUF_POOLS_SR2 * PRUETH_EMAC_BUF_POOL_SIZE_SR2;
-	if (slice)
-		addr += PRUETH_EMAC_RX_CTX_BUF_SIZE;
-
-	for (i = 0; i < 3; i++)
-		rxq_ctx->start[i] = cpu_to_le32(addr);
-
-	addr += PRUETH_EMAC_RX_CTX_BUF_SIZE;
-	rxq_ctx->end = cpu_to_le32(addr);
-
-	emac_r30_cmd_init(emac);
-	return 0;
-}
-
-/* commands to program ICSSG R30 registers */
-/* FIXME: fix hex magic numbers with macros */
-static struct icssg_r30_cmd emac_r32_bitmask[] = {
-	{{0xffff0004, 0xffff0100, 0xffff0100, EMAC_NONE}},	/* EMAC_PORT_DISABLE */
-	{{0xfffb0040, 0xfeff0200, 0xfeff0200, EMAC_NONE}},	/* EMAC_PORT_BLOCK */
-	{{0xffbb0000, 0xfcff0000, 0xdcff0000, EMAC_NONE}},	/* EMAC_PORT_FORWARD */
-	{{0xffbb0000, 0xfcff0000, 0xfcff2000, EMAC_NONE}},	/* EMAC_PORT_FORWARD_WO_LEARNING */
-	{{0xffff0001, EMAC_NONE,  EMAC_NONE, EMAC_NONE}},	/* ACCEPT ALL */
-	{{0xfffe0002, EMAC_NONE,  EMAC_NONE, EMAC_NONE}},	/* ACCEPT TAGGED */
-	{{0xfffc0000, EMAC_NONE,  EMAC_NONE, EMAC_NONE}},	/* ACCEPT UNTAGGED and PRIO */
-	{{EMAC_NONE,  0xffff0020, EMAC_NONE, EMAC_NONE}},	/* TAS Trigger List change */
-	{{EMAC_NONE,  0xdfff1000, EMAC_NONE, EMAC_NONE}},	/* TAS set state ENABLE*/
-	{{EMAC_NONE,  0xefff2000, EMAC_NONE, EMAC_NONE}},	/* TAS set state RESET*/
-	{{EMAC_NONE,  0xcfff0000, EMAC_NONE, EMAC_NONE}},	/* TAS set state DISABLE*/
-	{{EMAC_NONE,  EMAC_NONE,  0xffff0400, EMAC_NONE}},	/* UC flooding ENABLE*/
-	{{EMAC_NONE,  EMAC_NONE,  0xfbff0000, EMAC_NONE}},	/* UC flooding DISABLE*/
-	{{EMAC_NONE,  EMAC_NONE,  0xffff0800, EMAC_NONE}},	/* MC flooding ENABLE*/
-	{{EMAC_NONE,  EMAC_NONE,  0xf7ff0000, EMAC_NONE}},	/* MC flooding DISABLE*/
-	{{EMAC_NONE,  0xffff4000, EMAC_NONE, EMAC_NONE}},	/* Preemption on Tx ENABLE*/
-	{{EMAC_NONE,  0xbfff0000, EMAC_NONE, EMAC_NONE}}	/* Preemption on Tx DISABLE*/
-};
-
-int emac_set_port_state(struct prueth_emac *emac,
-			enum icssg_port_state_cmd cmd)
-{
-	struct icssg_r30_cmd *p;
-	int ret = -ETIMEDOUT;
-	int timeout = 10;
-	int i;
-
-	p = emac->dram.va + MGR_R30_CMD_OFFSET;
-
-	if (cmd >= ICSSG_EMAC_PORT_MAX_COMMANDS) {
-		netdev_err(emac->ndev, "invalid port command\n");
-		return -EINVAL;
-	}
-
-	/* only one command at a time allowed to firmware */
-	mutex_lock(&emac->cmd_lock);
-
-	for (i = 0; i < 4; i++)
-		writel(emac_r32_bitmask[cmd].cmd[i], &p->cmd[i]);
-
-	/* wait for done */
-	while (timeout) {
-		if (emac_r30_is_done(emac)) {
-			ret = 0;
-			break;
-		}
-
-		usleep_range(1000, 2000);
-		timeout--;
-	}
-
-	if (ret == -ETIMEDOUT)
-		netdev_err(emac->ndev, "timeout waiting for command done\n");
-
-	mutex_unlock(&emac->cmd_lock);
-
-	return ret;
-}
-
-void icssg_config_set_speed(struct prueth_emac *emac)
-{
-	u8 fw_speed;
-
-	switch (emac->speed) {
-	case SPEED_1000:
-		fw_speed = FW_LINK_SPEED_1G;
-		break;
-	case SPEED_100:
-		fw_speed = FW_LINK_SPEED_100M;
-		break;
-	case SPEED_10:
-		fw_speed = FW_LINK_SPEED_10M;
-		break;
-	default:
-		/* Other links speeds not supported */
-		pr_err("Unsupported link speed\n");
-		return;
-	}
-
-	writeb(fw_speed, emac->dram.va + PORT_LINK_SPEED_OFFSET);
-}
diff --git a/drivers/net/ethernet/ti/icssg_config.h b/drivers/net/ethernet/ti/icssg_config.h
deleted file mode 100644
index 82930383204b..000000000000
--- a/drivers/net/ethernet/ti/icssg_config.h
+++ /dev/null
@@ -1,211 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Texas Instruments ICSSG Ethernet driver
- *
- * Copyright (C) 2021 Texas Instruments Incorporated - https://www.ti.com/
- *
- */
-
-#ifndef __NET_TI_ICSSG_CONFIG_H
-#define __NET_TI_ICSSG_CONFIG_H
-
-struct icssg_buffer_pool_cfg {
-	__le32	addr;
-	__le32	len;
-} __packed;
-
-struct icssg_flow_cfg {
-	__le16 rx_base_flow;
-	__le16 mgm_base_flow;
-} __packed;
-
-/*------------------------ SR1.0 related --------------------------*/
-
-/* Port queue size in MSMC from firmware
- * PORTQSZ_HP .set (0x1800)
- * PORTQSZ_HP2 .set (PORTQSZ_HP+128) ;include barrier area
- * 0x1880 x 8 bytes per slice  (port)
- */
-
-#define MSMC_RAM_SIZE_SR1	(SZ_64K + SZ_32K + SZ_2K) /* 0x1880 x 8 x 2 */
-
-#define PRUETH_MAX_RX_MGM_DESC	8
-#define PRUETH_MAX_RX_FLOWS_SR1	4	/* excluding default flow */
-#define PRUETH_RX_FLOW_DATA_SR1	3       /* highest priority flow */
-#define PRUETH_MAX_RX_MGM_FLOWS	2	/* excluding default flow */
-#define PRUETH_RX_MGM_FLOW_RESPONSE	0
-#define PRUETH_RX_MGM_FLOW_TIMESTAMP	1
-#define PRUETH_RX_MGM_FLOW_OTHER	2
-
-#define PRUETH_NUM_BUF_POOLS_SR1	16
-#define PRUETH_EMAC_BUF_POOL_START_SR1	8
-#define PRUETH_EMAC_BUF_POOL_MIN_SIZE_SR1	128
-#define PRUETH_EMAC_BUF_SIZE_SR1	1536
-#define PRUETH_EMAC_NUM_BUF_SR1		4
-#define PRUETH_EMAC_BUF_POOL_SIZE_SR1	(PRUETH_EMAC_NUM_BUF_SR1 * \
-					 PRUETH_EMAC_BUF_SIZE_SR1)
-/* Config area lies in shared RAM */
-#define ICSSG_CONFIG_OFFSET_SLICE0   0
-#define ICSSG_CONFIG_OFFSET_SLICE1   0x8000
-
-struct icssg_config_sr1 {
-	__le32 status;	/* Firmware status */
-	__le32 addr_lo;	/* MSMC Buffer pool base address low. */
-	__le32 addr_hi;	/* MSMC Buffer pool base address high. Must be 0 */
-	__le32 tx_buf_sz[16];	/* Array of buffer pool sizes */
-	__le32 num_tx_threads;	/* Number of active egress threads, 1 to 4 */
-	__le32 tx_rate_lim_en;	/* Bitmask: Egress rate limit en per thread */
-	__le32 rx_flow_id;	/* RX flow id for first rx ring */
-	__le32 rx_mgr_flow_id;	/* RX flow id for the first management ring */
-	__le32 flags;		/* TBD */
-	__le32 n_burst;		/* for debug */
-	__le32 rtu_status;	/* RTU status */
-	__le32 info;		/* reserved */
-} __packed;
-
-/* Shutdown command to stop processing at firmware.
- * Command format : 0x8101ss00. ss - sequence number. Currently not used
- * by driver.
- */
-#define ICSSG_SHUTDOWN_CMD		0x81010000
-
-/* pstate speed/duplex command to set speed and duplex settings
- * in firmware.
- * Command format : 0x8102ssPN. ss - sequence number: currently not
- * used by driver, P - port number: For switch, N - Speed/Duplex state
- * - Possible values of N:
- * 0x0 - 10Mbps/Half duplex ;
- * 0x8 - 10Mbps/Full duplex ;
- * 0x2 - 100Mbps/Half duplex;
- * 0xa - 100Mbps/Full duplex;
- * 0xc - 1Gbps/Full duplex;
- * NOTE: The above are same as bits [3..1](slice 0) or bits [8..6](slice 1) of
- * RGMII CFG register. So suggested to read the register to populate the command
- * bits.
- */
-#define ICSSG_PSTATE_SPEED_DUPLEX_CMD	0x81020000
-
-/*------------------------ SR2.0 related --------------------------*/
-
-#define PRUETH_PKT_TYPE_CMD	0x10
-#define PRUETH_NAV_PS_DATA_SIZE	16	/* Protocol specific data size */
-#define PRUETH_NAV_SW_DATA_SIZE	16	/* SW related data size */
-#define PRUETH_MAX_TX_DESC	512
-#define PRUETH_MAX_RX_DESC	512
-#define PRUETH_MAX_RX_FLOWS_SR2	1	/* excluding default flow */
-#define PRUETH_RX_FLOW_DATA_SR2	0	/* FIXME: f/w bug to change to highest priority flow */
-
-#define PRUETH_EMAC_BUF_POOL_SIZE_SR2	SZ_8K
-#define PRUETH_EMAC_POOLS_PER_SLICE	24
-#define PRUETH_EMAC_BUF_POOL_START_SR2	8
-#define PRUETH_NUM_BUF_POOLS_SR2	8
-#define PRUETH_EMAC_RX_CTX_BUF_SIZE	SZ_16K	/* per slice */
-#define MSMC_RAM_SIZE_SR2	\
-	(2 * (PRUETH_EMAC_BUF_POOL_SIZE_SR2 * PRUETH_NUM_BUF_POOLS_SR2 + \
-	 PRUETH_EMAC_RX_CTX_BUF_SIZE))
-
-struct icssg_rxq_ctx {
-	__le32 start[3];
-	__le32 end;
-} __packed;
-
-/* Load time Fiwmware Configuration */
-
-#define ICSSG_FW_MGMT_CMD_HEADER	0x81
-#define ICSSG_FW_MGMT_FDB_CMD_TYPE	0x03
-#define ICSSG_FW_MGMT_CMD_TYPE		0x04
-#define ICSSG_FW_MGMT_PKT		0x80000000
-
-struct icssg_r30_cmd {
-	u32 cmd[4];
-} __packed;
-
-enum icssg_port_state_cmd {
-	ICSSG_EMAC_PORT_DISABLE = 0,
-	ICSSG_EMAC_PORT_BLOCK,
-	ICSSG_EMAC_PORT_FORWARD,
-	ICSSG_EMAC_PORT_FORWARD_WO_LEARNING,
-	ICSSG_EMAC_PORT_ACCEPT_ALL,
-	ICSSG_EMAC_PORT_ACCEPT_TAGGED,
-	ICSSG_EMAC_PORT_ACCEPT_UNTAGGED_N_PRIO,
-	ICSSG_EMAC_PORT_TAS_TRIGGER,
-	ICSSG_EMAC_PORT_TAS_ENABLE,
-	ICSSG_EMAC_PORT_TAS_RESET,
-	ICSSG_EMAC_PORT_TAS_DISABLE,
-	ICSSG_EMAC_PORT_UC_FLOODING_ENABLE,
-	ICSSG_EMAC_PORT_UC_FLOODING_DISABLE,
-	ICSSG_EMAC_PORT_MC_FLOODING_ENABLE,
-	ICSSG_EMAC_PORT_MC_FLOODING_DISABLE,
-	ICSSG_EMAC_PORT_PREMPT_TX_ENABLE,
-	ICSSG_EMAC_PORT_PREMPT_TX_DISABLE,
-	ICSSG_EMAC_PORT_MAX_COMMANDS
-};
-
-#define EMAC_NONE           0xffff0000
-#define EMAC_PRU0_P_DI      0xffff0004
-#define EMAC_PRU1_P_DI      0xffff0040
-#define EMAC_TX_P_DI        0xffff0100
-
-#define EMAC_PRU0_P_EN      0xfffb0000
-#define EMAC_PRU1_P_EN      0xffbf0000
-#define EMAC_TX_P_EN        0xfeff0000
-
-#define EMAC_P_BLOCK        0xffff0040
-#define EMAC_TX_P_BLOCK     0xffff0200
-#define EMAC_P_UNBLOCK      0xffbf0000
-#define EMAC_TX_P_UNBLOCK   0xfdff0000
-#define EMAC_LEAN_EN        0xfff70000
-#define EMAC_LEAN_DI        0xffff0008
-
-#define EMAC_ACCEPT_ALL     0xffff0001
-#define EMAC_ACCEPT_TAG     0xfffe0002
-#define EMAC_ACCEPT_PRIOR   0xfffc0000
-
-/* Config area lies in DRAM */
-#define ICSSG_CONFIG_OFFSET			0x0
-
-#define ICSSG_NUM_NORMAL_PDS	64
-#define ICSSG_NUM_SPECIAL_PDS	16
-
-#define ICSSG_NORMAL_PD_SIZE	8
-#define ICSSG_SPECIAL_PD_SIZE	20
-
-#define ICSSG_FLAG_MASK		0xff00ffff
-
-struct icssg_setclock_desc {
-	u8 request;
-	u8 restore;
-	u8 acknowledgment;
-	u8 cmp_status;
-	u32 margin;
-	u32 cyclecounter0_set;
-	u32 cyclecounter1_set;
-	u32 iepcount_set;
-	u32 rsvd1;
-	u32 rsvd2;
-	u32 CMP0_current;
-	u32 iepcount_current;
-	u32 difference;
-	u32 cyclecounter0_new;
-	u32 cyclecounter1_new;
-	u32 CMP0_new;
-} __packed;
-
-#define ICSSG_CMD_POP_SLICE0	56
-#define ICSSG_CMD_POP_SLICE1	60
-
-#define ICSSG_CMD_PUSH_SLICE0	57
-#define ICSSG_CMD_PUSH_SLICE1	61
-
-#define ICSSG_RSP_POP_SLICE0	58
-#define ICSSG_RSP_POP_SLICE1	62
-
-#define ICSSG_RSP_PUSH_SLICE0	56
-#define ICSSG_RSP_PUSH_SLICE1	60
-
-#define ICSSG_TS_POP_SLICE0	59
-#define ICSSG_TS_POP_SLICE1	63
-
-#define ICSSG_TS_PUSH_SLICE0	40
-#define ICSSG_TS_PUSH_SLICE1	41
-
-#endif /* __NET_TI_ICSSG_CONFIG_H */
diff --git a/drivers/net/ethernet/ti/icssg_ethtool.c b/drivers/net/ethernet/ti/icssg_ethtool.c
deleted file mode 100644
index b6f7c1a86941..000000000000
--- a/drivers/net/ethernet/ti/icssg_ethtool.c
+++ /dev/null
@@ -1,356 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/* Texas Instruments ICSSG Ethernet driver
- *
- * Copyright (C) 2018-2021 Texas Instruments Incorporated - https://www.ti.com/
- *
- */
-
-#include "icssg_prueth.h"
-#include <linux/regmap.h>
-
-static u32 stats_base[] = {	0x54c,	/* Slice 0 stats start */
-				0xb18,	/* Slice 1 stats start */
-};
-
-struct miig_stats_regs {
-	/* Rx */
-	u32 rx_good_frames;
-	u32 rx_broadcast_frames;
-	u32 rx_multicast_frames;
-	u32 rx_crc_error_frames;
-	u32 rx_mii_error_frames;
-	u32 rx_odd_nibble_frames;
-	u32 rx_frame_max_size;
-	u32 rx_max_size_error_frames;
-	u32 rx_frame_min_size;
-	u32 rx_min_size_error_frames;
-	u32 rx_overrun_frames;
-	u32 rx_class0_hits;
-	u32 rx_class1_hits;
-	u32 rx_class2_hits;
-	u32 rx_class3_hits;
-	u32 rx_class4_hits;
-	u32 rx_class5_hits;
-	u32 rx_class6_hits;
-	u32 rx_class7_hits;
-	u32 rx_class8_hits;
-	u32 rx_class9_hits;
-	u32 rx_class10_hits;
-	u32 rx_class11_hits;
-	u32 rx_class12_hits;
-	u32 rx_class13_hits;
-	u32 rx_class14_hits;
-	u32 rx_class15_hits;
-	u32 rx_smd_frags;
-	u32 rx_bucket1_size;
-	u32 rx_bucket2_size;
-	u32 rx_bucket3_size;
-	u32 rx_bucket4_size;
-	u32 rx_64B_frames;
-	u32 rx_bucket1_frames;
-	u32 rx_bucket2_frames;
-	u32 rx_bucket3_frames;
-	u32 rx_bucket4_frames;
-	u32 rx_bucket5_frames;
-	u32 rx_total_bytes;
-	u32 rx_tx_total_bytes;
-	/* Tx */
-	u32 tx_good_frames;
-	u32 tx_broadcast_frames;
-	u32 tx_multicast_frames;
-	u32 tx_odd_nibble_frames;
-	u32 tx_underflow_errors;
-	u32 tx_frame_max_size;
-	u32 tx_max_size_error_frames;
-	u32 tx_frame_min_size;
-	u32 tx_min_size_error_frames;
-	u32 tx_bucket1_size;
-	u32 tx_bucket2_size;
-	u32 tx_bucket3_size;
-	u32 tx_bucket4_size;
-	u32 tx_64B_frames;
-	u32 tx_bucket1_frames;
-	u32 tx_bucket2_frames;
-	u32 tx_bucket3_frames;
-	u32 tx_bucket4_frames;
-	u32 tx_bucket5_frames;
-	u32 tx_total_bytes;
-};
-
-#define ICSSG_STATS(field)				\
-{							\
-	#field,						\
-	offsetof(struct miig_stats_regs, field),	\
-}
-
-struct icssg_stats {
-	char name[ETH_GSTRING_LEN];
-	u32 offset;
-};
-
-static const struct icssg_stats icssg_ethtool_stats[] = {
-	/* Rx */
-	ICSSG_STATS(rx_good_frames),
-	ICSSG_STATS(rx_broadcast_frames),
-	ICSSG_STATS(rx_multicast_frames),
-	ICSSG_STATS(rx_crc_error_frames),
-	ICSSG_STATS(rx_mii_error_frames),
-	ICSSG_STATS(rx_odd_nibble_frames),
-	ICSSG_STATS(rx_frame_max_size),
-	ICSSG_STATS(rx_max_size_error_frames),
-	ICSSG_STATS(rx_frame_min_size),
-	ICSSG_STATS(rx_min_size_error_frames),
-	ICSSG_STATS(rx_overrun_frames),
-	ICSSG_STATS(rx_class0_hits),
-	ICSSG_STATS(rx_class1_hits),
-	ICSSG_STATS(rx_class2_hits),
-	ICSSG_STATS(rx_class3_hits),
-	ICSSG_STATS(rx_class4_hits),
-	ICSSG_STATS(rx_class5_hits),
-	ICSSG_STATS(rx_class6_hits),
-	ICSSG_STATS(rx_class7_hits),
-	ICSSG_STATS(rx_class8_hits),
-	ICSSG_STATS(rx_class9_hits),
-	ICSSG_STATS(rx_class10_hits),
-	ICSSG_STATS(rx_class11_hits),
-	ICSSG_STATS(rx_class12_hits),
-	ICSSG_STATS(rx_class13_hits),
-	ICSSG_STATS(rx_class14_hits),
-	ICSSG_STATS(rx_class15_hits),
-	ICSSG_STATS(rx_smd_frags),
-	ICSSG_STATS(rx_bucket1_size),
-	ICSSG_STATS(rx_bucket2_size),
-	ICSSG_STATS(rx_bucket3_size),
-	ICSSG_STATS(rx_bucket4_size),
-	ICSSG_STATS(rx_64B_frames),
-	ICSSG_STATS(rx_bucket1_frames),
-	ICSSG_STATS(rx_bucket2_frames),
-	ICSSG_STATS(rx_bucket3_frames),
-	ICSSG_STATS(rx_bucket4_frames),
-	ICSSG_STATS(rx_bucket5_frames),
-	ICSSG_STATS(rx_total_bytes),
-	ICSSG_STATS(rx_tx_total_bytes),
-	/* Tx */
-	ICSSG_STATS(tx_good_frames),
-	ICSSG_STATS(tx_broadcast_frames),
-	ICSSG_STATS(tx_multicast_frames),
-	ICSSG_STATS(tx_odd_nibble_frames),
-	ICSSG_STATS(tx_underflow_errors),
-	ICSSG_STATS(tx_frame_max_size),
-	ICSSG_STATS(tx_max_size_error_frames),
-	ICSSG_STATS(tx_frame_min_size),
-	ICSSG_STATS(tx_min_size_error_frames),
-	ICSSG_STATS(tx_bucket1_size),
-	ICSSG_STATS(tx_bucket2_size),
-	ICSSG_STATS(tx_bucket3_size),
-	ICSSG_STATS(tx_bucket4_size),
-	ICSSG_STATS(tx_64B_frames),
-	ICSSG_STATS(tx_bucket1_frames),
-	ICSSG_STATS(tx_bucket2_frames),
-	ICSSG_STATS(tx_bucket3_frames),
-	ICSSG_STATS(tx_bucket4_frames),
-	ICSSG_STATS(tx_bucket5_frames),
-	ICSSG_STATS(tx_total_bytes),
-};
-
-static void emac_get_drvinfo(struct net_device *ndev,
-			     struct ethtool_drvinfo *info)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-
-	strlcpy(info->driver, dev_driver_string(prueth->dev),
-		sizeof(info->driver));
-	/* TODO: info->fw_version */
-	strlcpy(info->bus_info, dev_name(prueth->dev), sizeof(info->bus_info));
-}
-
-static u32 emac_get_msglevel(struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	return emac->msg_enable;
-}
-
-static void emac_set_msglevel(struct net_device *ndev, u32 value)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	emac->msg_enable = value;
-}
-
-static int emac_get_link_ksettings(struct net_device *ndev,
-				   struct ethtool_link_ksettings *ecmd)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	if (!emac->phydev)
-		return -EOPNOTSUPP;
-
-	phy_ethtool_ksettings_get(emac->phydev, ecmd);
-	return 0;
-}
-
-static int emac_set_link_ksettings(struct net_device *ndev,
-				   const struct ethtool_link_ksettings *ecmd)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	if (!emac->phydev || phy_is_pseudo_fixed_link(emac->phydev))
-		return -EOPNOTSUPP;
-
-	return phy_ethtool_ksettings_set(emac->phydev, ecmd);
-}
-
-static int emac_get_eee(struct net_device *ndev, struct ethtool_eee *edata)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	if (!emac->phydev || phy_is_pseudo_fixed_link(emac->phydev))
-		return -EOPNOTSUPP;
-
-	return phy_ethtool_get_eee(emac->phydev, edata);
-}
-
-static int emac_set_eee(struct net_device *ndev, struct ethtool_eee *edata)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	if (!emac->phydev || phy_is_pseudo_fixed_link(emac->phydev))
-		return -EOPNOTSUPP;
-
-	return phy_ethtool_set_eee(emac->phydev, edata);
-}
-
-static int emac_nway_reset(struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	if (!emac->phydev || phy_is_pseudo_fixed_link(emac->phydev))
-		return -EOPNOTSUPP;
-
-	return genphy_restart_aneg(emac->phydev);
-}
-
-static int emac_get_sset_count(struct net_device *ndev, int stringset)
-{
-	switch (stringset) {
-	case ETH_SS_STATS:
-		return ARRAY_SIZE(icssg_ethtool_stats);
-	default:
-		return -EOPNOTSUPP;
-	}
-}
-
-static void emac_get_strings(struct net_device *ndev, u32 stringset, u8 *data)
-{
-	u8 *p = data;
-	int i;
-
-	switch (stringset) {
-	case ETH_SS_STATS:
-		for (i = 0; i < ARRAY_SIZE(icssg_ethtool_stats); i++) {
-			memcpy(p, icssg_ethtool_stats[i].name,
-			       ETH_GSTRING_LEN);
-			p += ETH_GSTRING_LEN;
-		}
-		break;
-	default:
-		break;
-	}
-}
-
-static void emac_get_ethtool_stats(struct net_device *ndev,
-				   struct ethtool_stats *stats, u64 *data)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	int i;
-	int slice = prueth_emac_slice(emac);
-	u32 base = stats_base[slice];
-	u32 val;
-
-	for (i = 0; i < ARRAY_SIZE(icssg_ethtool_stats); i++) {
-		regmap_read(prueth->miig_rt,
-			    base + icssg_ethtool_stats[i].offset,
-			    &val);
-		data[i] = val;
-	}
-}
-
-static int emac_get_ts_info(struct net_device *ndev,
-			    struct ethtool_ts_info *info)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	info->so_timestamping =
-		SOF_TIMESTAMPING_TX_HARDWARE |
-		SOF_TIMESTAMPING_TX_SOFTWARE |
-		SOF_TIMESTAMPING_RX_HARDWARE |
-		SOF_TIMESTAMPING_RX_SOFTWARE |
-		SOF_TIMESTAMPING_SOFTWARE |
-		SOF_TIMESTAMPING_RAW_HARDWARE;
-
-	info->phc_index = icss_iep_get_ptp_clock_idx(emac->iep);
-	info->tx_types = BIT(HWTSTAMP_TX_OFF) | BIT(HWTSTAMP_TX_ON);
-	info->rx_filters = BIT(HWTSTAMP_FILTER_NONE) | BIT(HWTSTAMP_FILTER_ALL);
-
-	return 0;
-}
-
-static void emac_get_channels(struct net_device *ndev,
-			      struct ethtool_channels *ch)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	ch->max_rx = 1;
-	/* SR1 use high priority channel for management messages */
-	ch->max_tx = emac->is_sr1 ? PRUETH_MAX_TX_QUEUES - 1 :
-				    PRUETH_MAX_TX_QUEUES;
-	ch->rx_count = 1;
-	ch->tx_count = emac->is_sr1 ? emac->tx_ch_num - 1 :
-				      emac->tx_ch_num;
-}
-
-static int emac_set_channels(struct net_device *ndev,
-			     struct ethtool_channels *ch)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	/* verify we have at least one channel in each direction */
-	/* TODO: remove below check before sending to LKML */
-	if (!ch->rx_count || !ch->tx_count)
-		return -EINVAL;
-
-	/* Check if interface is up. Can change the num queues when
-	 * the interface is down.
-	 */
-	if (netif_running(emac->ndev))
-		return -EBUSY;
-
-	emac->tx_ch_num = ch->tx_count;
-	/* highest channel number for management messaging on SR1 */
-	if (emac->is_sr1)
-		emac->tx_ch_num++;
-
-	return 0;
-}
-
-const struct ethtool_ops icssg_ethtool_ops = {
-	.get_drvinfo = emac_get_drvinfo,
-	.get_msglevel = emac_get_msglevel,
-	.set_msglevel = emac_set_msglevel,
-	.get_sset_count = emac_get_sset_count,
-	.get_strings = emac_get_strings,
-	.get_ethtool_stats = emac_get_ethtool_stats,
-	.get_ts_info = emac_get_ts_info,
-
-	.get_channels = emac_get_channels,
-	.set_channels = emac_set_channels,
-	.get_link_ksettings = emac_get_link_ksettings,
-	.set_link_ksettings = emac_set_link_ksettings,
-	.get_link = ethtool_op_get_link,
-	.get_eee = emac_get_eee,
-	.set_eee = emac_set_eee,
-	.nway_reset = emac_nway_reset,
-};
diff --git a/drivers/net/ethernet/ti/icssg_prueth.c b/drivers/net/ethernet/ti/icssg_prueth.c
deleted file mode 100644
index abd062bedebb..000000000000
--- a/drivers/net/ethernet/ti/icssg_prueth.c
+++ /dev/null
@@ -1,2729 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-
-/* Texas Instruments ICSSG Ethernet Driver
- *
- * Copyright (C) 2018-2021 Texas Instruments Incorporated - https://www.ti.com/
- *
- */
-
-#include <linux/bitops.h>
-#include <linux/clk.h>
-#include <linux/etherdevice.h>
-#include <linux/dma-mapping.h>
-#include <linux/genalloc.h>
-#include <linux/if_vlan.h>
-#include <linux/interrupt.h>
-#include <linux/kernel.h>
-#include <linux/mfd/syscon.h>
-#include <linux/module.h>
-#include <linux/of.h>
-#include <linux/of_irq.h>
-#include <linux/of_mdio.h>
-#include <linux/of_net.h>
-#include <linux/of_platform.h>
-#include <linux/phy.h>
-#include <linux/pruss.h>
-#include <linux/regmap.h>
-#include <linux/remoteproc.h>
-#include <linux/dma/ti-cppi5.h>
-
-#include "icssg_prueth.h"
-#include "icss_mii_rt.h"
-#include "k3-cppi-desc-pool.h"
-
-#define PRUETH_MODULE_VERSION "0.1"
-#define PRUETH_MODULE_DESCRIPTION "PRUSS ICSSG Ethernet driver"
-
-#define PRUETH_MIN_PKT_SIZE	(VLAN_ETH_ZLEN)
-#define PRUETH_MAX_PKT_SIZE	(VLAN_ETH_FRAME_LEN + ETH_FCS_LEN)
-
-/* Netif debug messages possible */
-#define PRUETH_EMAC_DEBUG	(NETIF_MSG_DRV | \
-				 NETIF_MSG_PROBE | \
-				 NETIF_MSG_LINK | \
-				 NETIF_MSG_TIMER | \
-				 NETIF_MSG_IFDOWN | \
-				 NETIF_MSG_IFUP | \
-				 NETIF_MSG_RX_ERR | \
-				 NETIF_MSG_TX_ERR | \
-				 NETIF_MSG_TX_QUEUED | \
-				 NETIF_MSG_INTR | \
-				 NETIF_MSG_TX_DONE | \
-				 NETIF_MSG_RX_STATUS | \
-				 NETIF_MSG_PKTDATA | \
-				 NETIF_MSG_HW | \
-				 NETIF_MSG_WOL)
-
-#define prueth_napi_to_emac(napi) container_of(napi, struct prueth_emac, napi)
-
-/* CTRLMMR_ICSSG_RGMII_CTRL register bits */
-#define ICSSG_CTRL_RGMII_ID_MODE		BIT(24)
-
-#define IEP_DEFAULT_CYCLE_TIME_NS	1000000	/* 1 ms */
-
-static int debug_level = -1;
-module_param(debug_level, int, 0644);
-MODULE_PARM_DESC(debug_level, "PRUETH debug level (NETIF_MSG bits)");
-
-static void prueth_cleanup_rx_chns(struct prueth_emac *emac,
-				   struct prueth_rx_chn *rx_chn,
-				   int max_rflows)
-{
-	if (rx_chn->desc_pool)
-		k3_cppi_desc_pool_destroy(rx_chn->desc_pool);
-
-	if (rx_chn->rx_chn)
-		k3_udma_glue_release_rx_chn(rx_chn->rx_chn);
-}
-
-static void prueth_cleanup_tx_chns(struct prueth_emac *emac)
-{
-	int i;
-
-	for (i = 0; i < emac->tx_ch_num; i++) {
-		struct prueth_tx_chn *tx_chn = &emac->tx_chns[i];
-
-		if (tx_chn->desc_pool)
-			k3_cppi_desc_pool_destroy(tx_chn->desc_pool);
-
-		if (tx_chn->tx_chn)
-			k3_udma_glue_release_tx_chn(tx_chn->tx_chn);
-
-		/* Assume prueth_cleanup_tx_chns() is called at the
-		 * end after all channel resources are freed
-		 */
-		memset(tx_chn, 0, sizeof(*tx_chn));
-	}
-}
-
-static void prueth_ndev_del_tx_napi(struct prueth_emac *emac, int num)
-{
-	int i;
-
-	for (i = 0; i < num; i++) {
-		struct prueth_tx_chn *tx_chn = &emac->tx_chns[i];
-
-		if (tx_chn->irq)
-			free_irq(tx_chn->irq, tx_chn);
-		netif_napi_del(&tx_chn->napi_tx);
-	}
-}
-
-static void prueth_xmit_free(struct prueth_tx_chn *tx_chn,
-			     struct cppi5_host_desc_t *desc)
-{
-	struct cppi5_host_desc_t *first_desc, *next_desc;
-	dma_addr_t buf_dma, next_desc_dma;
-	u32 buf_dma_len;
-
-	first_desc = desc;
-	next_desc = first_desc;
-
-	cppi5_hdesc_get_obuf(first_desc, &buf_dma, &buf_dma_len);
-
-	dma_unmap_single(tx_chn->dma_dev, buf_dma, buf_dma_len,
-			 DMA_TO_DEVICE);
-
-	next_desc_dma = cppi5_hdesc_get_next_hbdesc(first_desc);
-	while (next_desc_dma) {
-		next_desc = k3_cppi_desc_pool_dma2virt(tx_chn->desc_pool,
-						       next_desc_dma);
-		cppi5_hdesc_get_obuf(next_desc, &buf_dma, &buf_dma_len);
-
-		dma_unmap_page(tx_chn->dma_dev, buf_dma, buf_dma_len,
-			       DMA_TO_DEVICE);
-
-		next_desc_dma = cppi5_hdesc_get_next_hbdesc(next_desc);
-
-		k3_cppi_desc_pool_free(tx_chn->desc_pool, next_desc);
-	}
-
-	k3_cppi_desc_pool_free(tx_chn->desc_pool, first_desc);
-}
-
-static int emac_tx_complete_packets(struct prueth_emac *emac, int chn,
-				    int budget)
-{
-	struct net_device *ndev = emac->ndev;
-	struct cppi5_host_desc_t *desc_tx;
-	struct netdev_queue *netif_txq;
-	struct prueth_tx_chn *tx_chn;
-	unsigned int total_bytes = 0;
-	struct sk_buff *skb;
-	dma_addr_t desc_dma;
-	int res, num_tx = 0;
-	void **swdata;
-
-	tx_chn = &emac->tx_chns[chn];
-
-	while (budget--) {
-		res = k3_udma_glue_pop_tx_chn(tx_chn->tx_chn, &desc_dma);
-		if (res == -ENODATA)
-			break;
-
-		/* teardown completion */
-		if (cppi5_desc_is_tdcm(desc_dma)) {
-			if (atomic_dec_and_test(&emac->tdown_cnt))
-				complete(&emac->tdown_complete);
-			break;
-		}
-
-		desc_tx = k3_cppi_desc_pool_dma2virt(tx_chn->desc_pool,
-						     desc_dma);
-		swdata = cppi5_hdesc_get_swdata(desc_tx);
-
-		/* was this command's TX complete? */
-		if (emac->is_sr1 && *(swdata) == emac->cmd_data) {
-			prueth_xmit_free(tx_chn, desc_tx);
-			budget++;	/* not a data packet */
-			continue;
-		}
-
-		skb = *(swdata);
-		prueth_xmit_free(tx_chn, desc_tx);
-
-		ndev = skb->dev;
-		ndev->stats.tx_packets++;
-		ndev->stats.tx_bytes += skb->len;
-		total_bytes += skb->len;
-		napi_consume_skb(skb, budget);
-		num_tx++;
-	}
-
-	if (!num_tx)
-		return 0;
-
-	netif_txq = netdev_get_tx_queue(ndev, chn);
-	netdev_tx_completed_queue(netif_txq, num_tx, total_bytes);
-
-	if (netif_tx_queue_stopped(netif_txq)) {
-		/* If the TX queue was stopped, wake it now
-		 * if we have enough room.
-		 */
-		__netif_tx_lock(netif_txq, smp_processor_id());
-		if (netif_running(ndev) &&
-		    (k3_cppi_desc_pool_avail(tx_chn->desc_pool) >=
-		     MAX_SKB_FRAGS))
-			netif_tx_wake_queue(netif_txq);
-		__netif_tx_unlock(netif_txq);
-	}
-
-	return num_tx;
-}
-
-static int emac_napi_tx_poll(struct napi_struct *napi_tx, int budget)
-{
-	struct prueth_tx_chn *tx_chn = prueth_napi_to_tx_chn(napi_tx);
-	struct prueth_emac *emac = tx_chn->emac;
-	int num_tx_packets;
-
-	num_tx_packets = emac_tx_complete_packets(emac, tx_chn->id, budget);
-
-	if (num_tx_packets < budget) {
-		napi_complete(napi_tx);
-		enable_irq(tx_chn->irq);
-	}
-
-	return num_tx_packets;
-}
-
-static irqreturn_t prueth_tx_irq(int irq, void *dev_id)
-{
-	struct prueth_tx_chn *tx_chn = dev_id;
-
-	disable_irq_nosync(irq);
-	napi_schedule(&tx_chn->napi_tx);
-
-	return IRQ_HANDLED;
-}
-
-static int prueth_ndev_add_tx_napi(struct prueth_emac *emac)
-{
-	struct prueth *prueth = emac->prueth;
-	int i, ret;
-
-	for (i = 0; i < emac->tx_ch_num; i++) {
-		struct prueth_tx_chn *tx_chn = &emac->tx_chns[i];
-
-		netif_tx_napi_add(emac->ndev, &tx_chn->napi_tx,
-				  emac_napi_tx_poll, NAPI_POLL_WEIGHT);
-		ret = request_irq(tx_chn->irq, prueth_tx_irq,
-				  IRQF_TRIGGER_HIGH, tx_chn->name,
-				  tx_chn);
-		if (ret) {
-			netif_napi_del(&tx_chn->napi_tx);
-			dev_err(prueth->dev, "unable to request TX IRQ %d\n",
-				tx_chn->irq);
-			goto fail;
-		}
-	}
-
-	return 0;
-fail:
-	prueth_ndev_del_tx_napi(emac, i);
-	return ret;
-}
-
-static int prueth_init_tx_chns(struct prueth_emac *emac)
-{
-	struct net_device *ndev = emac->ndev;
-	struct device *dev = emac->prueth->dev;
-	struct k3_udma_glue_tx_channel_cfg tx_cfg;
-	static const struct k3_ring_cfg ring_cfg = {
-		.elm_size = K3_RINGACC_RING_ELSIZE_8,
-		.mode = K3_RINGACC_RING_MODE_RING,
-		.flags = 0,
-		.size = PRUETH_MAX_TX_DESC,
-	};
-	int ret, slice, i;
-	u32 hdesc_size;
-
-	slice = prueth_emac_slice(emac);
-	if (slice < 0)
-		return slice;
-
-	init_completion(&emac->tdown_complete);
-
-	hdesc_size = cppi5_hdesc_calc_size(true, PRUETH_NAV_PS_DATA_SIZE,
-					   PRUETH_NAV_SW_DATA_SIZE);
-	memset(&tx_cfg, 0, sizeof(tx_cfg));
-	tx_cfg.swdata_size = PRUETH_NAV_SW_DATA_SIZE;
-	tx_cfg.tx_cfg = ring_cfg;
-	tx_cfg.txcq_cfg = ring_cfg;
-
-	for (i = 0; i < emac->tx_ch_num; i++) {
-		struct prueth_tx_chn *tx_chn = &emac->tx_chns[i];
-
-		/* To differentiate channels for SLICE0 vs SLICE1 */
-		snprintf(tx_chn->name, sizeof(tx_chn->name),
-			 "tx%d-%d", slice, i);
-
-		tx_chn->emac = emac;
-		tx_chn->id = i;
-		tx_chn->descs_num = PRUETH_MAX_TX_DESC;
-
-		tx_chn->tx_chn =
-			k3_udma_glue_request_tx_chn(dev, tx_chn->name,
-						    &tx_cfg);
-		if (IS_ERR(tx_chn->tx_chn)) {
-			ret = PTR_ERR(tx_chn->tx_chn);
-			tx_chn->tx_chn = NULL;
-			netdev_err(ndev,
-				   "Failed to request tx dma ch: %d\n", ret);
-			goto fail;
-		}
-
-		tx_chn->dma_dev = k3_udma_glue_tx_get_dma_device(tx_chn->tx_chn);
-		tx_chn->desc_pool =
-			k3_cppi_desc_pool_create_name(tx_chn->dma_dev,
-						      tx_chn->descs_num,
-						      hdesc_size,
-						      tx_chn->name);
-		if (IS_ERR(tx_chn->desc_pool)) {
-			ret = PTR_ERR(tx_chn->desc_pool);
-			tx_chn->desc_pool = NULL;
-			netdev_err(ndev, "Failed to create tx pool: %d\n", ret);
-			goto fail;
-		}
-
-		tx_chn->irq = k3_udma_glue_tx_get_irq(tx_chn->tx_chn);
-		if (tx_chn->irq <= 0) {
-			ret = -EINVAL;
-			netdev_err(ndev, "failed to get tx irq\n");
-			goto fail;
-		}
-
-		snprintf(tx_chn->name, sizeof(tx_chn->name), "%s-tx%d",
-			 dev_name(dev), tx_chn->id);
-	}
-
-	return 0;
-
-fail:
-	prueth_cleanup_tx_chns(emac);
-	return ret;
-}
-
-static int prueth_init_rx_chns(struct prueth_emac *emac,
-			       struct prueth_rx_chn *rx_chn,
-			       char *name, u32 max_rflows,
-			       u32 max_desc_num)
-{
-	struct net_device *ndev = emac->ndev;
-	struct device *dev = emac->prueth->dev;
-	struct k3_udma_glue_rx_channel_cfg rx_cfg;
-	u32 fdqring_id;
-	u32 hdesc_size;
-	int i, ret = 0, slice;
-
-	slice = prueth_emac_slice(emac);
-	if (slice < 0)
-		return slice;
-
-	/* To differentiate channels for SLICE0 vs SLICE1 */
-	snprintf(rx_chn->name, sizeof(rx_chn->name), "%s%d", name, slice);
-
-	hdesc_size = cppi5_hdesc_calc_size(true, PRUETH_NAV_PS_DATA_SIZE,
-					   PRUETH_NAV_SW_DATA_SIZE);
-	memset(&rx_cfg, 0, sizeof(rx_cfg));
-	rx_cfg.swdata_size = PRUETH_NAV_SW_DATA_SIZE;
-	rx_cfg.flow_id_num = max_rflows;
-	rx_cfg.flow_id_base = -1; /* udmax will auto select flow id base */
-
-	/* init all flows */
-	rx_chn->dev = dev;
-	rx_chn->descs_num = max_desc_num;
-
-	rx_chn->rx_chn = k3_udma_glue_request_rx_chn(dev, rx_chn->name,
-						     &rx_cfg);
-	if (IS_ERR(rx_chn->rx_chn)) {
-		ret = PTR_ERR(rx_chn->rx_chn);
-		rx_chn->rx_chn = NULL;
-		netdev_err(ndev, "Failed to request rx dma ch: %d\n", ret);
-		goto fail;
-	}
-
-	rx_chn->dma_dev = k3_udma_glue_rx_get_dma_device(rx_chn->rx_chn);
-	rx_chn->desc_pool = k3_cppi_desc_pool_create_name(rx_chn->dma_dev,
-							  rx_chn->descs_num,
-							  hdesc_size,
-							  rx_chn->name);
-	if (IS_ERR(rx_chn->desc_pool)) {
-		ret = PTR_ERR(rx_chn->desc_pool);
-		rx_chn->desc_pool = NULL;
-		netdev_err(ndev, "Failed to create rx pool: %d\n", ret);
-		goto fail;
-	}
-
-	if (!strncmp(name, "rxmgm", 5)) {
-		emac->rx_mgm_flow_id_base = k3_udma_glue_rx_get_flow_id_base(rx_chn->rx_chn);
-		netdev_dbg(ndev, "mgm flow id base = %d\n",
-			   emac->rx_mgm_flow_id_base);
-	} else {
-		emac->rx_flow_id_base = k3_udma_glue_rx_get_flow_id_base(rx_chn->rx_chn);
-		netdev_dbg(ndev, "flow id base = %d\n",
-			   emac->rx_flow_id_base);
-	}
-
-	fdqring_id = K3_RINGACC_RING_ID_ANY;
-	for (i = 0; i < rx_cfg.flow_id_num; i++) {
-		struct k3_ring_cfg rxring_cfg = {
-			.elm_size = K3_RINGACC_RING_ELSIZE_8,
-			.mode = K3_RINGACC_RING_MODE_RING,
-			.flags = 0,
-		};
-		struct k3_ring_cfg fdqring_cfg = {
-			.elm_size = K3_RINGACC_RING_ELSIZE_8,
-			.flags = K3_RINGACC_RING_SHARED,
-		};
-		struct k3_udma_glue_rx_flow_cfg rx_flow_cfg = {
-			.rx_cfg = rxring_cfg,
-			.rxfdq_cfg = fdqring_cfg,
-			.ring_rxq_id = K3_RINGACC_RING_ID_ANY,
-			.src_tag_lo_sel =
-				K3_UDMA_GLUE_SRC_TAG_LO_USE_REMOTE_SRC_TAG,
-		};
-
-		rx_flow_cfg.ring_rxfdq0_id = fdqring_id;
-		rx_flow_cfg.rx_cfg.size = max_desc_num;
-		rx_flow_cfg.rxfdq_cfg.size = max_desc_num;
-		rx_flow_cfg.rxfdq_cfg.mode = emac->prueth->pdata.fdqring_mode;
-
-		ret = k3_udma_glue_rx_flow_init(rx_chn->rx_chn,
-						i, &rx_flow_cfg);
-		if (ret) {
-			netdev_err(ndev, "Failed to init rx flow%d %d\n",
-				   i, ret);
-			goto fail;
-		}
-		if (!i)
-			fdqring_id = k3_udma_glue_rx_flow_get_fdq_id(rx_chn->rx_chn,
-								     i);
-		rx_chn->irq[i] = k3_udma_glue_rx_get_irq(rx_chn->rx_chn, i);
-		if (rx_chn->irq[i] <= 0) {
-			netdev_err(ndev, "Failed to get rx dma irq");
-			goto fail;
-		}
-	}
-
-	return 0;
-
-fail:
-	prueth_cleanup_rx_chns(emac, rx_chn, max_rflows);
-	return ret;
-}
-
-static int prueth_dma_rx_push(struct prueth_emac *emac,
-			      struct sk_buff *skb,
-			      struct prueth_rx_chn *rx_chn)
-{
-	struct cppi5_host_desc_t *desc_rx;
-	struct net_device *ndev = emac->ndev;
-	dma_addr_t desc_dma;
-	dma_addr_t buf_dma;
-	u32 pkt_len = skb_tailroom(skb);
-	void **swdata;
-
-	desc_rx = k3_cppi_desc_pool_alloc(rx_chn->desc_pool);
-	if (!desc_rx) {
-		netdev_err(ndev, "rx push: failed to allocate descriptor\n");
-		return -ENOMEM;
-	}
-	desc_dma = k3_cppi_desc_pool_virt2dma(rx_chn->desc_pool, desc_rx);
-
-	buf_dma = dma_map_single(rx_chn->dma_dev, skb->data, pkt_len, DMA_FROM_DEVICE);
-	if (unlikely(dma_mapping_error(rx_chn->dma_dev, buf_dma))) {
-		k3_cppi_desc_pool_free(rx_chn->desc_pool, desc_rx);
-		netdev_err(ndev, "rx push: failed to map rx pkt buffer\n");
-		return -EINVAL;
-	}
-
-	cppi5_hdesc_init(desc_rx, CPPI5_INFO0_HDESC_EPIB_PRESENT,
-			 PRUETH_NAV_PS_DATA_SIZE);
-	cppi5_hdesc_attach_buf(desc_rx, buf_dma, skb_tailroom(skb), buf_dma, skb_tailroom(skb));
-
-	swdata = cppi5_hdesc_get_swdata(desc_rx);
-	*swdata = skb;
-
-	return k3_udma_glue_push_rx_chn(rx_chn->rx_chn, 0,
-					desc_rx, desc_dma);
-}
-
-static u64 icssg_ts_to_ns(u32 hi_sw, u32 hi, u32 lo, u32 cycle_time_ns)
-{
-	u32 iepcount_lo, iepcount_hi, hi_rollover_count;
-	u64 ns;
-
-	iepcount_lo = lo & GENMASK(19, 0);
-	iepcount_hi = (hi & GENMASK(11, 0)) << 12 | lo >> 20;
-	hi_rollover_count = hi >> 11;
-
-	ns = ((u64)hi_rollover_count) << 23 | (iepcount_hi + hi_sw);
-	ns = ns * cycle_time_ns + iepcount_lo;
-
-	return ns;
-}
-
-static void emac_rx_timestamp(struct prueth_emac *emac,
-			      struct sk_buff *skb, u32 *psdata)
-{
-	struct skb_shared_hwtstamps *ssh;
-	u64 ns;
-
-	if (emac->is_sr1) {
-		ns = (u64)psdata[1] << 32 | psdata[0];
-	} else {
-		u32 hi_sw = readl(emac->prueth->shram.va +
-				  TIMESYNC_FW_WC_COUNT_HI_SW_OFFSET_OFFSET);
-		ns = icssg_ts_to_ns(hi_sw, psdata[1], psdata[0],
-				    IEP_DEFAULT_CYCLE_TIME_NS);
-	}
-
-	ssh = skb_hwtstamps(skb);
-	memset(ssh, 0, sizeof(*ssh));
-	ssh->hwtstamp = ns_to_ktime(ns);
-}
-
-static int emac_rx_packet(struct prueth_emac *emac, u32 flow_id)
-{
-	struct prueth_rx_chn *rx_chn = &emac->rx_chns;
-	struct net_device *ndev = emac->ndev;
-	struct cppi5_host_desc_t *desc_rx;
-	dma_addr_t desc_dma, buf_dma;
-	u32 buf_dma_len, pkt_len, port_id = 0;
-	int ret;
-	void **swdata;
-	struct sk_buff *skb, *new_skb;
-	u32 *psdata;
-
-	ret = k3_udma_glue_pop_rx_chn(rx_chn->rx_chn, flow_id, &desc_dma);
-	if (ret) {
-		if (ret != -ENODATA)
-			netdev_err(ndev, "rx pop: failed: %d\n", ret);
-		return ret;
-	}
-
-	if (cppi5_desc_is_tdcm(desc_dma)) /* Teardown ? */
-		return 0;
-
-	desc_rx = k3_cppi_desc_pool_dma2virt(rx_chn->desc_pool, desc_dma);
-
-	swdata = cppi5_hdesc_get_swdata(desc_rx);
-	skb = *swdata;
-
-	psdata = cppi5_hdesc_get_psdata(desc_rx);
-	/* RX HW timestamp */
-	if (emac->rx_ts_enabled)
-		emac_rx_timestamp(emac, skb, psdata);
-
-	cppi5_hdesc_get_obuf(desc_rx, &buf_dma, &buf_dma_len);
-	pkt_len = cppi5_hdesc_get_pktlen(desc_rx);
-	/* firmware adds 4 CRC bytes, strip them */
-	pkt_len -= 4;
-	cppi5_desc_get_tags_ids(&desc_rx->hdr, &port_id, NULL);
-
-	dma_unmap_single(rx_chn->dma_dev, buf_dma, buf_dma_len, DMA_FROM_DEVICE);
-	k3_cppi_desc_pool_free(rx_chn->desc_pool, desc_rx);
-
-	skb->dev = ndev;
-	if (!netif_running(skb->dev)) {
-		dev_kfree_skb_any(skb);
-		return 0;
-	}
-
-	new_skb = netdev_alloc_skb_ip_align(ndev, PRUETH_MAX_PKT_SIZE);
-	/* if allocation fails we drop the packet but push the
-	 * descriptor back to the ring with old skb to prevent a stall
-	 */
-	if (!new_skb) {
-		ndev->stats.rx_dropped++;
-		new_skb = skb;
-	} else {
-		/* send the filled skb up the n/w stack */
-		skb_put(skb, pkt_len);
-		skb->protocol = eth_type_trans(skb, ndev);
-		netif_receive_skb(skb);
-		ndev->stats.rx_bytes += pkt_len;
-		ndev->stats.rx_packets++;
-	}
-
-	/* queue another RX DMA */
-	ret = prueth_dma_rx_push(emac, new_skb, &emac->rx_chns);
-	if (WARN_ON(ret < 0)) {
-		dev_kfree_skb_any(new_skb);
-		ndev->stats.rx_errors++;
-		ndev->stats.rx_dropped++;
-	}
-
-	return ret;
-}
-
-static void prueth_rx_cleanup(void *data, dma_addr_t desc_dma)
-{
-	struct prueth_rx_chn *rx_chn = data;
-	struct cppi5_host_desc_t *desc_rx;
-	struct sk_buff *skb;
-	dma_addr_t buf_dma;
-	u32 buf_dma_len;
-	void **swdata;
-
-	desc_rx = k3_cppi_desc_pool_dma2virt(rx_chn->desc_pool, desc_dma);
-	swdata = cppi5_hdesc_get_swdata(desc_rx);
-	skb = *swdata;
-	cppi5_hdesc_get_obuf(desc_rx, &buf_dma, &buf_dma_len);
-
-	dma_unmap_single(rx_chn->dma_dev, buf_dma, buf_dma_len,
-			 DMA_FROM_DEVICE);
-	k3_cppi_desc_pool_free(rx_chn->desc_pool, desc_rx);
-
-	dev_kfree_skb_any(skb);
-}
-
-static int emac_get_tx_ts(struct prueth_emac *emac,
-			  struct emac_tx_ts_response *rsp)
-{
-	struct prueth *prueth = emac->prueth;
-	int slice = prueth_emac_slice(emac);
-	int addr;
-
-	addr = icssg_queue_pop(prueth, slice == 0 ?
-			       ICSSG_TS_POP_SLICE0 : ICSSG_TS_POP_SLICE1);
-	if (addr < 0)
-		return addr;
-
-	memcpy_fromio(rsp, prueth->shram.va + addr, sizeof(*rsp));
-	/* return buffer back for to pool */
-	icssg_queue_push(prueth, slice == 0 ?
-			 ICSSG_TS_PUSH_SLICE0 : ICSSG_TS_PUSH_SLICE1, addr);
-
-	return 0;
-}
-
-/* TODO: Convert this to use worker/workqueue mechanism to serialize the
- * request to firmware
- */
-static int emac_send_command_sr1(struct prueth_emac *emac, u32 cmd)
-{
-	dma_addr_t desc_dma, buf_dma;
-	struct prueth_tx_chn *tx_chn;
-	struct cppi5_host_desc_t *first_desc;
-	int ret = 0;
-	u32 *epib;
-	u32 *data = emac->cmd_data;
-	u32 pkt_len = sizeof(emac->cmd_data);
-	void **swdata;
-
-	netdev_dbg(emac->ndev, "Sending cmd %x\n", cmd);
-
-	/* only one command at a time allowed to firmware */
-	mutex_lock(&emac->cmd_lock);
-	data[0] = cpu_to_le32(cmd);
-
-	/* highest priority channel for management messages */
-	tx_chn = &emac->tx_chns[emac->tx_ch_num - 1];
-
-	/* Map the linear buffer */
-	buf_dma = dma_map_single(tx_chn->dma_dev, data, pkt_len, DMA_TO_DEVICE);
-	if (dma_mapping_error(tx_chn->dma_dev, buf_dma)) {
-		netdev_err(emac->ndev, "cmd %x: failed to map cmd buffer\n", cmd);
-		ret = -EINVAL;
-		goto err_unlock;
-	}
-
-	first_desc = k3_cppi_desc_pool_alloc(tx_chn->desc_pool);
-	if (!first_desc) {
-		netdev_err(emac->ndev, "cmd %x: failed to allocate descriptor\n", cmd);
-		dma_unmap_single(tx_chn->dma_dev, buf_dma, pkt_len, DMA_TO_DEVICE);
-		ret = -ENOMEM;
-		goto err_unlock;
-	}
-
-	cppi5_hdesc_init(first_desc, CPPI5_INFO0_HDESC_EPIB_PRESENT,
-			 PRUETH_NAV_PS_DATA_SIZE);
-	cppi5_hdesc_set_pkttype(first_desc, PRUETH_PKT_TYPE_CMD);
-	epib = first_desc->epib;
-	epib[0] = 0;
-	epib[1] = 0;
-
-	cppi5_hdesc_attach_buf(first_desc, buf_dma, pkt_len, buf_dma, pkt_len);
-	swdata = cppi5_hdesc_get_swdata(first_desc);
-	*swdata = data;
-
-	cppi5_hdesc_set_pktlen(first_desc, pkt_len);
-	desc_dma = k3_cppi_desc_pool_virt2dma(tx_chn->desc_pool, first_desc);
-
-	/* send command */
-	reinit_completion(&emac->cmd_complete);
-	ret = k3_udma_glue_push_tx_chn(tx_chn->tx_chn, first_desc, desc_dma);
-	if (ret) {
-		netdev_err(emac->ndev, "cmd %x: push failed: %d\n", cmd, ret);
-		goto free_desc;
-	}
-	ret = wait_for_completion_timeout(&emac->cmd_complete, msecs_to_jiffies(100));
-	if (!ret)
-		netdev_err(emac->ndev, "cmd %x: completion timeout\n", cmd);
-
-	mutex_unlock(&emac->cmd_lock);
-
-	return ret;
-free_desc:
-	prueth_xmit_free(tx_chn, first_desc);
-err_unlock:
-	mutex_unlock(&emac->cmd_lock);
-
-	return ret;
-}
-
-static void emac_change_port_speed_duplex(struct prueth_emac *emac)
-{
-	u32 cmd = ICSSG_PSTATE_SPEED_DUPLEX_CMD, val;
-	struct prueth *prueth = emac->prueth;
-	int slice = prueth_emac_slice(emac);
-
-	/* only full duplex supported for now */
-	if (emac->duplex != DUPLEX_FULL)
-		return;
-
-	if (!emac->is_sr1)
-		return;
-
-	val = icssg_rgmii_get_speed(prueth->miig_rt, slice);
-	/* firmware expects full duplex settings in bit 2-1 */
-	val <<= 1;
-	cmd |= val;
-
-	val = icssg_rgmii_get_fullduplex(prueth->miig_rt, slice);
-	/* firmware expects full duplex settings in bit 3 */
-	val <<= 3;
-	cmd |= val;
-
-	emac_send_command_sr1(emac, cmd);
-}
-
-static int emac_shutdown(struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	/* FIXME for SR2.0 */
-	if (!emac->is_sr1)
-		return 0;
-
-	return emac_send_command_sr1(emac, ICSSG_SHUTDOWN_CMD);
-}
-
-static void tx_ts_work(struct prueth_emac *emac)
-{
-	u64 ns;
-	struct skb_shared_hwtstamps ssh;
-	struct sk_buff *skb;
-	int timeout = 10;
-	int ret = 0;
-	struct emac_tx_ts_response tsr;
-	u32 hi_sw;
-
-	if (!test_bit(__STATE_TX_TS_IN_PROGRESS, &emac->state)) {
-		netdev_err(emac->ndev, "unexpected TS response\n");
-		return;
-	}
-
-	skb = emac->tx_ts_skb;
-	while (timeout-- > 0) {
-		/* wait for response or timeout */
-		ret = emac_get_tx_ts(emac, &tsr);
-		if (!ret)
-			break;
-		usleep_range(10, 20);
-	}
-
-	if (ret) {
-		netdev_err(emac->ndev, "TX timestamp timeout\n");
-		goto error;
-	}
-
-	if (tsr.cookie != emac->tx_ts_cookie) {
-		netdev_err(emac->ndev, "TX TS cookie mismatch 0x%x:0x%x\n",
-			   tsr.cookie, emac->tx_ts_cookie);
-		goto error;
-	}
-
-	hi_sw = readl(emac->prueth->shram.va +
-		      TIMESYNC_FW_WC_COUNT_HI_SW_OFFSET_OFFSET);
-	ns = icssg_ts_to_ns(hi_sw, tsr.hi_ts, tsr.lo_ts,
-			    IEP_DEFAULT_CYCLE_TIME_NS);
-
-	emac->tx_ts_cookie++;
-	memset(&ssh, 0, sizeof(ssh));
-	ssh.hwtstamp = ns_to_ktime(ns);
-	clear_bit_unlock(__STATE_TX_TS_IN_PROGRESS, &emac->state);
-
-	skb_tstamp_tx(skb, &ssh);
-	dev_consume_skb_any(skb);
-
-	return;
-
-error:
-	dev_kfree_skb_any(skb);
-	emac->tx_ts_skb = NULL;
-	clear_bit_unlock(__STATE_TX_TS_IN_PROGRESS, &emac->state);
-}
-
-/**
- * emac_ndo_start_xmit - EMAC Transmit function
- * @skb: SKB pointer
- * @ndev: EMAC network adapter
- *
- * Called by the system to transmit a packet  - we queue the packet in
- * EMAC hardware transmit queue
- * Doesn't wait for completion we'll check for TX completion in
- * emac_tx_complete_packets().
- *
- * Returns success(NETDEV_TX_OK) or error code (typically out of descs)
- */
-static int emac_ndo_start_xmit(struct sk_buff *skb, struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct cppi5_host_desc_t *first_desc, *next_desc, *cur_desc;
-	struct netdev_queue *netif_txq;
-	struct prueth_tx_chn *tx_chn;
-	dma_addr_t desc_dma, buf_dma;
-	int i, ret = 0, q_idx;
-	bool in_tx_ts = 0;
-	void **swdata;
-	u32 pkt_len;
-	u32 *epib;
-
-	pkt_len = skb_headlen(skb);
-	q_idx = skb_get_queue_mapping(skb);
-
-	tx_chn = &emac->tx_chns[q_idx];
-	netif_txq = netdev_get_tx_queue(ndev, q_idx);
-
-	/* Map the linear buffer */
-	buf_dma = dma_map_single(tx_chn->dma_dev, skb->data, pkt_len, DMA_TO_DEVICE);
-	if (dma_mapping_error(tx_chn->dma_dev, buf_dma)) {
-		netdev_err(ndev, "tx: failed to map skb buffer\n");
-		ret = -EINVAL;
-		goto drop_stop_q;
-	}
-
-	first_desc = k3_cppi_desc_pool_alloc(tx_chn->desc_pool);
-	if (!first_desc) {
-		netdev_dbg(ndev, "tx: failed to allocate descriptor\n");
-		dma_unmap_single(tx_chn->dma_dev, buf_dma, pkt_len, DMA_TO_DEVICE);
-		ret = -ENOMEM;
-		goto drop_stop_q_busy;
-	}
-
-	cppi5_hdesc_init(first_desc, CPPI5_INFO0_HDESC_EPIB_PRESENT,
-			 PRUETH_NAV_PS_DATA_SIZE);
-	cppi5_hdesc_set_pkttype(first_desc, 0);
-	epib = first_desc->epib;
-	epib[0] = 0;
-	epib[1] = 0;
-	if (skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP &&
-	    emac->tx_ts_enabled) {
-		/* We currently support only one TX HW timestamp at a time */
-		if (!test_and_set_bit_lock(__STATE_TX_TS_IN_PROGRESS,
-					   &emac->state)) {
-			skb_shinfo(skb)->tx_flags |= SKBTX_IN_PROGRESS;
-			/* Request TX timestamp */
-			epib[0] = emac->tx_ts_cookie;
-			epib[1] = 0x80000000;	/* TX TS request */
-			emac->tx_ts_skb = skb_get(skb);
-			in_tx_ts = 1;
-		}
-	}
-
-	/* set dst tag to indicate internal qid at the firmware which is at
-	 * bit8..bit15
-	 */
-	cppi5_desc_set_tags_ids(&first_desc->hdr, 0, (q_idx << 8));
-	cppi5_hdesc_attach_buf(first_desc, buf_dma, pkt_len, buf_dma, pkt_len);
-	swdata = cppi5_hdesc_get_swdata(first_desc);
-	*swdata = skb;
-
-	if (!skb_is_nonlinear(skb))
-		goto tx_push;
-
-	/* Handle the case where skb is fragmented in pages */
-	cur_desc = first_desc;
-	for (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {
-		skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
-		u32 frag_size = skb_frag_size(frag);
-
-		next_desc = k3_cppi_desc_pool_alloc(tx_chn->desc_pool);
-		if (!next_desc) {
-			netdev_err(ndev,
-				   "tx: failed to allocate frag. descriptor\n");
-			ret = -ENOMEM;
-			goto cleanup_tx_ts;
-		}
-
-		buf_dma = skb_frag_dma_map(tx_chn->dma_dev, frag, 0, frag_size,
-					   DMA_TO_DEVICE);
-		if (dma_mapping_error(tx_chn->dma_dev, buf_dma)) {
-			netdev_err(ndev, "tx: Failed to map skb page\n");
-			k3_cppi_desc_pool_free(tx_chn->desc_pool, next_desc);
-			ret = -EINVAL;
-			goto cleanup_tx_ts;
-		}
-
-		cppi5_hdesc_reset_hbdesc(next_desc);
-		cppi5_hdesc_attach_buf(next_desc,
-				       buf_dma, frag_size, buf_dma, frag_size);
-
-		desc_dma = k3_cppi_desc_pool_virt2dma(tx_chn->desc_pool,
-						      next_desc);
-		cppi5_hdesc_link_hbdesc(cur_desc, desc_dma);
-
-		pkt_len += frag_size;
-		cur_desc = next_desc;
-	}
-	WARN_ON(pkt_len != skb->len);
-
-tx_push:
-	/* report bql before sending packet */
-	netdev_tx_sent_queue(netif_txq, pkt_len);
-
-	cppi5_hdesc_set_pktlen(first_desc, pkt_len);
-	desc_dma = k3_cppi_desc_pool_virt2dma(tx_chn->desc_pool, first_desc);
-	/* cppi5_desc_dump(first_desc, 64); */
-
-	skb_tx_timestamp(skb);	/* SW timestamp if SKBTX_IN_PROGRESS not set */
-	ret = k3_udma_glue_push_tx_chn(tx_chn->tx_chn, first_desc, desc_dma);
-	if (ret) {
-		netdev_err(ndev, "tx: push failed: %d\n", ret);
-		goto drop_free_descs;
-	}
-
-	if (k3_cppi_desc_pool_avail(tx_chn->desc_pool) < MAX_SKB_FRAGS) {
-		netif_tx_stop_queue(netif_txq);
-		/* Barrier, so that stop_queue visible to other cpus */
-		smp_mb__after_atomic();
-
-		if (k3_cppi_desc_pool_avail(tx_chn->desc_pool) >=
-		    MAX_SKB_FRAGS)
-			netif_tx_wake_queue(netif_txq);
-	}
-
-	return NETDEV_TX_OK;
-
-cleanup_tx_ts:
-	if (in_tx_ts) {
-		dev_kfree_skb_any(emac->tx_ts_skb);
-		emac->tx_ts_skb = NULL;
-		clear_bit_unlock(__STATE_TX_TS_IN_PROGRESS, &emac->state);
-	}
-
-drop_free_descs:
-	prueth_xmit_free(tx_chn, first_desc);
-drop_stop_q:
-	netif_tx_stop_queue(netif_txq);
-	dev_kfree_skb_any(skb);
-
-	/* error */
-	ndev->stats.tx_dropped++;
-	netdev_err(ndev, "tx: error: %d\n", ret);
-
-	return ret;
-
-drop_stop_q_busy:
-	netif_tx_stop_queue(netif_txq);
-	return NETDEV_TX_BUSY;
-}
-
-static void prueth_tx_cleanup(void *data, dma_addr_t desc_dma)
-{
-	struct prueth_tx_chn *tx_chn = data;
-	struct cppi5_host_desc_t *desc_tx;
-	struct sk_buff *skb;
-	void **swdata;
-
-	desc_tx = k3_cppi_desc_pool_dma2virt(tx_chn->desc_pool, desc_dma);
-	swdata = cppi5_hdesc_get_swdata(desc_tx);
-	skb = *(swdata);
-	prueth_xmit_free(tx_chn, desc_tx);
-
-	dev_kfree_skb_any(skb);
-}
-
-static irqreturn_t prueth_tx_ts_irq(int irq, void *dev_id)
-{
-	struct prueth_emac *emac = dev_id;
-
-	/* currently only TX timestamp is being returned */
-	tx_ts_work(emac);
-
-	return IRQ_HANDLED;
-}
-
-/* get one packet from requested flow_id
- *
- * Returns skb pointer if packet found else NULL
- * Caller must free the returned skb.
- */
-static struct sk_buff *prueth_process_rx_mgm(struct prueth_emac *emac,
-					     u32 flow_id)
-{
-	struct prueth_rx_chn *rx_chn = &emac->rx_mgm_chn;
-	struct net_device *ndev = emac->ndev;
-	struct cppi5_host_desc_t *desc_rx;
-	dma_addr_t desc_dma, buf_dma;
-	u32 buf_dma_len, pkt_len;
-	int ret;
-	void **swdata;
-	struct sk_buff *skb, *new_skb;
-
-	ret = k3_udma_glue_pop_rx_chn(rx_chn->rx_chn, flow_id, &desc_dma);
-	if (ret) {
-		if (ret != -ENODATA)
-			netdev_err(ndev, "rx mgm pop: failed: %d\n", ret);
-		return NULL;
-	}
-
-	if (cppi5_desc_is_tdcm(desc_dma)) /* Teardown */
-		return NULL;
-
-	desc_rx = k3_cppi_desc_pool_dma2virt(rx_chn->desc_pool, desc_dma);
-
-	/* Fix FW bug about incorrect PSDATA size */
-	if (cppi5_hdesc_get_psdata_size(desc_rx) != PRUETH_NAV_PS_DATA_SIZE) {
-		cppi5_hdesc_update_psdata_size(desc_rx,
-					       PRUETH_NAV_PS_DATA_SIZE);
-	}
-
-	swdata = cppi5_hdesc_get_swdata(desc_rx);
-	skb = *swdata;
-	cppi5_hdesc_get_obuf(desc_rx, &buf_dma, &buf_dma_len);
-	pkt_len = cppi5_hdesc_get_pktlen(desc_rx);
-
-	dma_unmap_single(rx_chn->dma_dev, buf_dma, buf_dma_len, DMA_FROM_DEVICE);
-	k3_cppi_desc_pool_free(rx_chn->desc_pool, desc_rx);
-
-	new_skb = netdev_alloc_skb_ip_align(ndev, PRUETH_MAX_PKT_SIZE);
-	/* if allocation fails we drop the packet but push the
-	 * descriptor back to the ring with old skb to prevent a stall
-	 */
-	if (!new_skb) {
-		netdev_err(ndev,
-			   "skb alloc failed, dropped mgm pkt from flow %d\n",
-			   flow_id);
-		new_skb = skb;
-		skb = NULL;	/* return NULL */
-	} else {
-		/* return the filled skb */
-		skb_put(skb, pkt_len);
-	}
-
-	/* queue another DMA */
-	ret = prueth_dma_rx_push(emac, new_skb, &emac->rx_mgm_chn);
-	if (WARN_ON(ret < 0))
-		dev_kfree_skb_any(new_skb);
-
-	return skb;
-}
-
-static void prueth_tx_ts_sr1(struct prueth_emac *emac,
-			     struct emac_tx_ts_response_sr1 *tsr)
-{
-	u64 ns;
-	struct skb_shared_hwtstamps ssh;
-	struct sk_buff *skb;
-
-	ns = (u64)tsr->hi_ts << 32 | tsr->lo_ts;
-
-	if (!test_bit(__STATE_TX_TS_IN_PROGRESS, &emac->state)) {
-		netdev_err(emac->ndev, "unexpected TS response\n");
-		return;
-	}
-
-	skb = emac->tx_ts_skb;
-	if (tsr->cookie != emac->tx_ts_cookie) {
-		netdev_err(emac->ndev, "TX TS cookie mismatch 0x%x:0x%x\n",
-			   tsr->cookie, emac->tx_ts_cookie);
-		goto error;
-	}
-
-	emac->tx_ts_cookie++;
-	memset(&ssh, 0, sizeof(ssh));
-	ssh.hwtstamp = ns_to_ktime(ns);
-	clear_bit_unlock(__STATE_TX_TS_IN_PROGRESS, &emac->state);
-
-	skb_tstamp_tx(skb, &ssh);
-	dev_consume_skb_any(skb);
-
-	return;
-
-error:
-	dev_kfree_skb_any(skb);
-	emac->tx_ts_skb = NULL;
-	clear_bit_unlock(__STATE_TX_TS_IN_PROGRESS, &emac->state);
-}
-
-static irqreturn_t prueth_rx_mgm_ts_thread_sr1(int irq, void *dev_id)
-{
-	struct prueth_emac *emac = dev_id;
-	struct sk_buff *skb;
-
-	skb = prueth_process_rx_mgm(emac, PRUETH_RX_MGM_FLOW_TIMESTAMP);
-	if (!skb)
-		return IRQ_NONE;
-
-	prueth_tx_ts_sr1(emac, (void *)skb->data);
-	dev_kfree_skb_any(skb);
-
-	return IRQ_HANDLED;
-}
-
-static irqreturn_t prueth_rx_mgm_rsp_thread(int irq, void *dev_id)
-{
-	struct prueth_emac *emac = dev_id;
-	struct sk_buff *skb;
-	u32 rsp;
-
-	skb = prueth_process_rx_mgm(emac, PRUETH_RX_MGM_FLOW_RESPONSE);
-	if (!skb)
-		return IRQ_NONE;
-
-	/* Process command response */
-	rsp = le32_to_cpu(*(u32 *)skb->data);
-	if ((rsp & 0xffff0000) == ICSSG_SHUTDOWN_CMD) {
-		netdev_dbg(emac->ndev,
-			   "f/w Shutdown cmd resp %x\n", rsp);
-		complete(&emac->cmd_complete);
-	} else if ((rsp & 0xffff0000) ==
-		ICSSG_PSTATE_SPEED_DUPLEX_CMD) {
-		netdev_dbg(emac->ndev,
-			   "f/w Speed/Duplex cmd rsp %x\n",
-			    rsp);
-		complete(&emac->cmd_complete);
-	}
-
-	dev_kfree_skb_any(skb);
-
-	return IRQ_HANDLED;
-}
-
-static irqreturn_t prueth_rx_irq(int irq, void *dev_id)
-{
-	struct prueth_emac *emac = dev_id;
-
-	disable_irq_nosync(irq);
-	napi_schedule(&emac->napi_rx);
-
-	return IRQ_HANDLED;
-}
-
-static int prueth_emac_start(struct prueth *prueth, struct prueth_emac *emac)
-{
-	struct device *dev = prueth->dev;
-	int slice, ret;
-
-	slice = prueth_emac_slice(emac);
-	if (slice < 0) {
-		netdev_err(emac->ndev, "invalid port\n");
-		return -EINVAL;
-	}
-
-	/* Set Load time configuration */
-	if (emac->is_sr1) {
-		icssg_config_sr1(prueth, emac, slice);
-	} else {
-		ret = icssg_config_sr2(prueth, emac, slice);
-		if (ret)
-			return ret;
-	}
-
-	ret = rproc_boot(prueth->pru[slice]);
-	if (ret) {
-		dev_err(dev, "failed to boot PRU%d: %d\n", slice, ret);
-		return -EINVAL;
-	}
-
-	ret = rproc_boot(prueth->rtu[slice]);
-	if (ret) {
-		dev_err(dev, "failed to boot RTU%d: %d\n", slice, ret);
-		goto halt_pru;
-	}
-
-	if (emac->is_sr1)
-		goto done;
-
-	ret = rproc_boot(prueth->txpru[slice]);
-	if (ret) {
-		dev_err(dev, "failed to boot TX_PRU%d: %d\n", slice, ret);
-		goto halt_rtu;
-	}
-
-done:
-	emac->fw_running = 1;
-	return 0;
-
-halt_rtu:
-	rproc_shutdown(prueth->rtu[slice]);
-
-halt_pru:
-	rproc_shutdown(prueth->pru[slice]);
-
-	return ret;
-}
-
-static void prueth_emac_stop(struct prueth_emac *emac)
-{
-	struct prueth *prueth = emac->prueth;
-	int slice;
-
-	switch (emac->port_id) {
-	case PRUETH_PORT_MII0:
-		slice = ICSS_SLICE0;
-		break;
-	case PRUETH_PORT_MII1:
-		slice = ICSS_SLICE1;
-		break;
-	default:
-		netdev_err(emac->ndev, "invalid port\n");
-		return;
-	}
-
-	emac->fw_running = 0;
-	if (!emac->is_sr1)
-		rproc_shutdown(prueth->txpru[slice]);
-	rproc_shutdown(prueth->rtu[slice]);
-	rproc_shutdown(prueth->pru[slice]);
-}
-
-/* called back by PHY layer if there is change in link state of hw port*/
-static void emac_adjust_link(struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct phy_device *phydev = emac->phydev;
-	struct prueth *prueth = emac->prueth;
-	int slice = prueth_emac_slice(emac);
-	bool new_state = false;
-	unsigned long flags;
-
-	if (phydev->link) {
-		/* check the mode of operation - full/half duplex */
-		if (phydev->duplex != emac->duplex) {
-			new_state = true;
-			emac->duplex = phydev->duplex;
-		}
-		if (phydev->speed != emac->speed) {
-			new_state = true;
-			emac->speed = phydev->speed;
-		}
-		if (!emac->link) {
-			new_state = true;
-			emac->link = 1;
-		}
-	} else if (emac->link) {
-		new_state = true;
-		emac->link = 0;
-		/* defaults for no link */
-
-		/* f/w should support 100 & 1000 */
-		emac->speed = SPEED_1000;
-
-		/* half duplex may not be supported by f/w */
-		emac->duplex = DUPLEX_FULL;
-	}
-
-	if (new_state) {
-		phy_print_status(phydev);
-
-		/* update RGMII and MII configuration based on PHY negotiated
-		 * values
-		 */
-		if (emac->link) {
-			/* Set the RGMII cfg for gig en and full duplex */
-			icssg_update_rgmii_cfg(prueth->miig_rt, emac->speed,
-					       emac->duplex, slice);
-
-			/* update the Tx IPG based on 100M/1G speed */
-			spin_lock_irqsave(&emac->lock, flags);
-			icssg_config_ipg(prueth, emac->speed, slice);
-			spin_unlock_irqrestore(&emac->lock, flags);
-			icssg_config_set_speed(emac);
-			if (!emac->is_sr1)
-				emac_set_port_state(emac, ICSSG_EMAC_PORT_FORWARD);
-
-		} else {
-			if (!emac->is_sr1)
-				emac_set_port_state(emac, ICSSG_EMAC_PORT_DISABLE);
-		}
-
-		/* send command to firmware to change speed and duplex
-		 * setting when link is up.
-		 */
-		if (emac->link)
-			emac_change_port_speed_duplex(emac);
-	}
-
-	if (emac->link) {
-		/* link ON */
-		netif_carrier_on(ndev);
-		/* reactivate the transmit queue */
-		netif_tx_wake_all_queues(ndev);
-	} else {
-		/* link OFF */
-		netif_carrier_off(ndev);
-		netif_tx_stop_all_queues(ndev);
-	}
-}
-
-static int emac_napi_rx_poll(struct napi_struct *napi_rx, int budget)
-{
-	struct prueth_emac *emac = prueth_napi_to_emac(napi_rx);
-	int num_rx = 0;
-	int flow = emac->is_sr1 ?
-			PRUETH_MAX_RX_FLOWS_SR1 : PRUETH_MAX_RX_FLOWS_SR2;
-	int rx_flow = emac->is_sr1 ?
-			PRUETH_RX_FLOW_DATA_SR1 : PRUETH_RX_FLOW_DATA_SR2;
-	int cur_budget;
-	int ret;
-
-	while (flow--) {
-		cur_budget = budget - num_rx;
-
-		while (cur_budget--) {
-			ret = emac_rx_packet(emac, flow);
-			if (ret)
-				break;
-			num_rx++;
-		}
-
-		if (num_rx >= budget)
-			break;
-	}
-
-	if (num_rx < budget) {
-		napi_complete(napi_rx);
-		enable_irq(emac->rx_chns.irq[rx_flow]);
-	}
-
-	return num_rx;
-}
-
-static int prueth_prepare_rx_chan(struct prueth_emac *emac,
-				  struct prueth_rx_chn *chn,
-				  int buf_size)
-{
-	struct sk_buff *skb;
-	int i, ret;
-
-	for (i = 0; i < chn->descs_num; i++) {
-		skb = __netdev_alloc_skb_ip_align(NULL, buf_size, GFP_KERNEL);
-		if (!skb)
-			return -ENOMEM;
-
-		ret = prueth_dma_rx_push(emac, skb, chn);
-		if (ret < 0) {
-			netdev_err(emac->ndev,
-				   "cannot submit skb for rx chan %s ret %d\n",
-				   chn->name, ret);
-			kfree_skb(skb);
-			return ret;
-		}
-	}
-
-	return 0;
-}
-
-static void prueth_reset_tx_chan(struct prueth_emac *emac, int ch_num,
-				 bool free_skb)
-{
-	int i;
-
-	for (i = 0; i < ch_num; i++) {
-		if (free_skb)
-			k3_udma_glue_reset_tx_chn(emac->tx_chns[i].tx_chn,
-						  &emac->tx_chns[i],
-						  prueth_tx_cleanup);
-		k3_udma_glue_disable_tx_chn(emac->tx_chns[i].tx_chn);
-	}
-}
-
-static void prueth_reset_rx_chan(struct prueth_rx_chn *chn,
-				 int num_flows, bool disable)
-{
-	int i;
-
-	for (i = 0; i < num_flows; i++)
-		k3_udma_glue_reset_rx_chn(chn->rx_chn, i, chn,
-					  prueth_rx_cleanup, !!i);
-	if (disable)
-		k3_udma_glue_disable_rx_chn(chn->rx_chn);
-}
-
-static u64 prueth_iep_gettime(void *clockops_data)
-{
-	u32 hi_rollover_count, hi_rollover_count_r;
-	struct prueth_emac *emac = clockops_data;
-	struct prueth *prueth = emac->prueth;
-	void __iomem *fw_hi_r_count_addr;
-	void __iomem *fw_count_hi_addr;
-	u32 iepcount_hi, iepcount_hi_r;
-	u32 iepcount_lo;
-	u64 ts = 0;
-
-	fw_count_hi_addr = prueth->shram.va + TIMESYNC_FW_WC_COUNT_HI_SW_OFFSET_OFFSET;
-	fw_hi_r_count_addr = prueth->shram.va + TIMESYNC_FW_WC_HI_ROLLOVER_COUNT_OFFSET;
-
-	do {
-		iepcount_hi = icss_iep_get_count_hi(emac->iep);
-		iepcount_hi += readl(fw_count_hi_addr);
-		hi_rollover_count = readl(fw_hi_r_count_addr);
-		iepcount_lo = icss_iep_get_count_low(emac->iep);
-
-		iepcount_hi_r = icss_iep_get_count_hi(emac->iep);
-		iepcount_hi_r += readl(fw_count_hi_addr);
-		hi_rollover_count_r = readl(fw_hi_r_count_addr);
-	} while ((iepcount_hi_r != iepcount_hi) ||
-		 (hi_rollover_count != hi_rollover_count_r));
-
-	ts = ((u64)hi_rollover_count) << 23 | iepcount_hi;
-	ts = ts * (u64)IEP_DEFAULT_CYCLE_TIME_NS + iepcount_lo;
-
-	return ts;
-}
-
-static void prueth_iep_settime(void *clockops_data, u64 ns)
-{
-	struct icssg_setclock_desc sc_desc, *sc_descp;
-	struct prueth_emac *emac = clockops_data;
-	u64 cyclecount;
-	u32 cycletime;
-	int timeout;
-
-	if (!emac->fw_running)
-		return;
-
-	sc_descp = emac->prueth->shram.va + TIMESYNC_FW_WC_SETCLOCK_DESC_OFFSET;
-
-	cycletime = IEP_DEFAULT_CYCLE_TIME_NS;
-	cyclecount = ns / cycletime;
-
-	memset(&sc_desc, 0, sizeof(sc_desc));
-	sc_desc.margin = cycletime - 1000;
-	sc_desc.cyclecounter0_set = cyclecount & GENMASK(31, 0);
-	sc_desc.cyclecounter1_set = (cyclecount & GENMASK(63, 32)) >> 32;
-	sc_desc.iepcount_set = ns % cycletime;
-	sc_desc.CMP0_current = cycletime - 4; //Count from 0 to (cycle time)-4
-
-	memcpy_toio(sc_descp, &sc_desc, sizeof(sc_desc));
-
-	writeb(1, &sc_descp->request);
-
-	timeout = 5;	/* fw should take 2-3 ms */
-	while (timeout--) {
-		if (readb(&sc_descp->acknowledgment))
-			return;
-
-		usleep_range(500, 1000);
-	}
-
-	dev_err(emac->prueth->dev, "settime timeout\n");
-}
-
-static int prueth_perout_enable(void *clockops_data,
-				struct ptp_perout_request *req, int on,
-				u64 *cmp)
-{
-	struct prueth_emac *emac = clockops_data;
-	u32 reduction_factor = 0, offset = 0;
-	struct timespec64 ts;
-	u64 ns_period;
-
-	if (!on)
-		return 0;
-
-	/* Any firmware specific stuff for PPS/PEROUT handling */
-	ts.tv_sec = req->period.sec;
-	ts.tv_nsec = req->period.nsec;
-	ns_period = timespec64_to_ns(&ts);
-
-	/* f/w doesn't support period less than cycle time */
-	if (ns_period < IEP_DEFAULT_CYCLE_TIME_NS)
-		return -ENXIO;
-
-	reduction_factor = ns_period / IEP_DEFAULT_CYCLE_TIME_NS;
-	offset = ns_period % IEP_DEFAULT_CYCLE_TIME_NS;
-
-	/* f/w requires at least 1uS within a cycle so CMP
-	 * can trigger after SYNC is enabled
-	 */
-	if (offset < 5 * NSEC_PER_USEC)
-		offset = 5 * NSEC_PER_USEC;
-
-	/* if offset is close to cycle time then we will miss
-	 * the CMP event for last tick when IEP rolls over.
-	 * In normal mode, IEP tick is 4ns.
-	 * In slow compensation it could be 0ns or 8ns at
-	 * every slow compensation cycle.
-	 */
-	if (offset > IEP_DEFAULT_CYCLE_TIME_NS - 8)
-		offset = IEP_DEFAULT_CYCLE_TIME_NS - 8;
-
-	/* we're in shadow mode so need to set upper 32-bits */
-	*cmp = (u64)offset << 32;
-
-	writel(reduction_factor, emac->prueth->shram.va +
-		TIMESYNC_FW_WC_SYNCOUT_REDUCTION_FACTOR_OFFSET);
-
-	/* HACK: till f/w supports START_TIME cyclcount we set it to 0 */
-	writel(0, emac->prueth->shram.va +
-		TIMESYNC_FW_WC_SYNCOUT_START_TIME_CYCLECOUNT_OFFSET);
-
-	return 0;
-}
-
-const struct icss_iep_clockops prueth_iep_clockops = {
-	.settime = prueth_iep_settime,
-	.gettime = prueth_iep_gettime,
-	/* FIXME: add adjtime to use relative mode */
-	.perout_enable = prueth_perout_enable,
-};
-
-/**
- * emac_ndo_open - EMAC device open
- * @ndev: network adapter device
- *
- * Called when system wants to start the interface.
- *
- * Returns 0 for a successful open, or appropriate error code
- */
-static int emac_ndo_open(struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	int ret, i, num_data_chn = emac->tx_ch_num;
-	struct prueth *prueth = emac->prueth;
-	int slice = prueth_emac_slice(emac);
-	struct device *dev = prueth->dev;
-	int max_rx_flows;
-	int rx_flow;
-
-	/* clear SMEM of this slice */
-	if (emac->is_sr1) {
-		memset_io(prueth->shram.va + slice * ICSSG_CONFIG_OFFSET_SLICE1,
-			  0, ICSSG_CONFIG_OFFSET_SLICE1);
-		/* For SR1, high priority channel is used exclusively for
-		 * management messages. Do reduce number of data channels.
-		 */
-		num_data_chn--;
-	}
-
-	/* set h/w MAC as user might have re-configured */
-	ether_addr_copy(emac->mac_addr, ndev->dev_addr);
-
-	icssg_class_set_mac_addr(prueth->miig_rt, slice, emac->mac_addr);
-	if (!emac->is_sr1)
-		icssg_ft1_set_mac_addr(prueth->miig_rt, slice, emac->mac_addr);
-
-	icssg_class_default(prueth->miig_rt, slice, 0, emac->is_sr1);
-
-	netif_carrier_off(ndev);
-
-	/* Notify the stack of the actual queue counts. */
-	ret = netif_set_real_num_tx_queues(ndev, num_data_chn);
-	if (ret) {
-		dev_err(dev, "cannot set real number of tx queues\n");
-		return ret;
-	}
-
-	init_completion(&emac->cmd_complete);
-	ret = prueth_init_tx_chns(emac);
-	if (ret) {
-		dev_err(dev, "failed to init tx channel: %d\n", ret);
-		return ret;
-	}
-
-	max_rx_flows = emac->is_sr1 ?
-			PRUETH_MAX_RX_FLOWS_SR1 : PRUETH_MAX_RX_FLOWS_SR2;
-	ret = prueth_init_rx_chns(emac, &emac->rx_chns, "rx",
-				  max_rx_flows, PRUETH_MAX_RX_DESC);
-	if (ret) {
-		dev_err(dev, "failed to init rx channel: %d\n", ret);
-		goto cleanup_tx;
-	}
-
-	if (emac->is_sr1) {
-		ret = prueth_init_rx_chns(emac, &emac->rx_mgm_chn, "rxmgm",
-					  PRUETH_MAX_RX_MGM_FLOWS,
-					  PRUETH_MAX_RX_MGM_DESC);
-		if (ret) {
-			dev_err(dev, "failed to init rx mgmt channel: %d\n",
-				ret);
-			goto cleanup_rx;
-		}
-	}
-
-	ret = prueth_ndev_add_tx_napi(emac);
-	if (ret)
-		goto cleanup_rx_mgm;
-
-	/* we use only the highest priority flow for now i.e. @irq[3] */
-	rx_flow = emac->is_sr1 ?
-			PRUETH_RX_FLOW_DATA_SR1 : PRUETH_RX_FLOW_DATA_SR2;
-	ret = request_irq(emac->rx_chns.irq[rx_flow], prueth_rx_irq,
-			  IRQF_TRIGGER_HIGH, dev_name(dev), emac);
-	if (ret) {
-		dev_err(dev, "unable to request RX IRQ\n");
-		goto cleanup_napi;
-	}
-
-	if (!emac->is_sr1)
-		goto skip_mgm_irq;
-
-	ret = request_threaded_irq(emac->rx_mgm_chn.irq[PRUETH_RX_MGM_FLOW_RESPONSE],
-				   NULL, prueth_rx_mgm_rsp_thread,
-				   IRQF_ONESHOT | IRQF_TRIGGER_HIGH,
-				   dev_name(dev), emac);
-	if (ret) {
-		dev_err(dev, "unable to request RX Management RSP IRQ\n");
-		goto free_rx_irq;
-	}
-
-	ret = request_threaded_irq(emac->rx_mgm_chn.irq[PRUETH_RX_MGM_FLOW_TIMESTAMP],
-				   NULL, prueth_rx_mgm_ts_thread_sr1,
-				   IRQF_ONESHOT | IRQF_TRIGGER_HIGH,
-				   dev_name(dev), emac);
-	if (ret) {
-		dev_err(dev, "unable to request RX Management TS IRQ\n");
-		goto free_rx_mgm_rsp_irq;
-	}
-
-skip_mgm_irq:
-	/* reset and start PRU firmware */
-	ret = prueth_emac_start(prueth, emac);
-	if (ret)
-		goto free_rx_mgmt_ts_irq;
-
-	if (!emac->is_sr1 && !prueth->iep_initialized) {
-		ret = icss_iep_init(emac->iep, &prueth_iep_clockops,
-				    emac, IEP_DEFAULT_CYCLE_TIME_NS);
-	}
-	prueth->iep_initialized++;
-
-	if (!emac->is_sr1) {
-		ret = request_threaded_irq(emac->tx_ts_irq, NULL, prueth_tx_ts_irq,
-					   IRQF_ONESHOT, dev_name(dev), emac);
-		if (ret)
-			goto stop;
-	}
-
-	/* Prepare RX */
-	ret = prueth_prepare_rx_chan(emac, &emac->rx_chns, PRUETH_MAX_PKT_SIZE);
-	if (ret)
-		goto free_rx_ts_irq;
-
-	if (emac->is_sr1) {
-		ret = prueth_prepare_rx_chan(emac, &emac->rx_mgm_chn, 64);
-		if (ret)
-			goto reset_rx_chn;
-
-		ret = k3_udma_glue_enable_rx_chn(emac->rx_mgm_chn.rx_chn);
-		if (ret)
-			goto reset_rx_chn;
-	}
-
-	ret = k3_udma_glue_enable_rx_chn(emac->rx_chns.rx_chn);
-	if (ret)
-		goto reset_rx_mgm_chn;
-
-	for (i = 0; i < emac->tx_ch_num; i++) {
-		ret = k3_udma_glue_enable_tx_chn(emac->tx_chns[i].tx_chn);
-		if (ret)
-			goto reset_tx_chan;
-	}
-
-	/* Enable NAPI in Tx and Rx direction */
-	for (i = 0; i < emac->tx_ch_num; i++)
-		napi_enable(&emac->tx_chns[i].napi_tx);
-	napi_enable(&emac->napi_rx);
-
-	/* Get attached phy details */
-	phy_attached_info(emac->phydev);
-
-	/* start PHY */
-	phy_start(emac->phydev);
-
-	if (netif_msg_drv(emac))
-		dev_notice(&ndev->dev, "started\n");
-
-	return 0;
-
-reset_tx_chan:
-	/* Since interface is not yet up, there is wouldn't be
-	 * any SKB for completion. So set false to free_skb
-	 */
-	prueth_reset_tx_chan(emac, i, false);
-reset_rx_mgm_chn:
-	if (emac->is_sr1)
-		prueth_reset_rx_chan(&emac->rx_mgm_chn,
-				     PRUETH_MAX_RX_MGM_FLOWS, true);
-reset_rx_chn:
-	prueth_reset_rx_chan(&emac->rx_chns, max_rx_flows, false);
-free_rx_ts_irq:
-	if (!emac->is_sr1)
-		free_irq(emac->tx_ts_irq, emac);
-stop:
-	prueth_emac_stop(emac);
-free_rx_mgmt_ts_irq:
-	if (emac->is_sr1)
-		free_irq(emac->rx_mgm_chn.irq[PRUETH_RX_MGM_FLOW_TIMESTAMP],
-			 emac);
-free_rx_mgm_rsp_irq:
-	if (emac->is_sr1)
-		free_irq(emac->rx_mgm_chn.irq[PRUETH_RX_MGM_FLOW_RESPONSE],
-			 emac);
-free_rx_irq:
-	free_irq(emac->rx_chns.irq[rx_flow], emac);
-cleanup_napi:
-	prueth_ndev_del_tx_napi(emac, emac->tx_ch_num);
-cleanup_rx_mgm:
-	if (emac->is_sr1)
-		prueth_cleanup_rx_chns(emac, &emac->rx_mgm_chn,
-				       PRUETH_MAX_RX_MGM_FLOWS);
-cleanup_rx:
-	prueth_cleanup_rx_chns(emac, &emac->rx_chns, max_rx_flows);
-cleanup_tx:
-	prueth_cleanup_tx_chns(emac);
-
-	return ret;
-}
-
-/**
- * emac_ndo_stop - EMAC device stop
- * @ndev: network adapter device
- *
- * Called when system wants to stop or down the interface.
- */
-static int emac_ndo_stop(struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	int ret, i;
-	int max_rx_flows;
-	int rx_flow = emac->is_sr1 ?
-			PRUETH_RX_FLOW_DATA_SR1 : PRUETH_RX_FLOW_DATA_SR2;
-
-	/* inform the upper layers. */
-	netif_tx_stop_all_queues(ndev);
-
-	/* block packets from wire */
-	phy_stop(emac->phydev);
-	icssg_class_disable(prueth->miig_rt, prueth_emac_slice(emac));
-
-	/* send shutdown command */
-	emac_shutdown(ndev);
-
-	atomic_set(&emac->tdown_cnt, emac->tx_ch_num);
-	/* ensure new tdown_cnt value is visible */
-	smp_mb__after_atomic();
-	/* tear down and disable UDMA channels */
-	reinit_completion(&emac->tdown_complete);
-	for (i = 0; i < emac->tx_ch_num; i++)
-		k3_udma_glue_tdown_tx_chn(emac->tx_chns[i].tx_chn, false);
-
-	ret = wait_for_completion_timeout(&emac->tdown_complete,
-					  msecs_to_jiffies(1000));
-	if (!ret)
-		netdev_err(ndev, "tx teardown timeout\n");
-
-	prueth_reset_tx_chan(emac, emac->tx_ch_num, true);
-	for (i = 0; i < emac->tx_ch_num; i++)
-		napi_disable(&emac->tx_chns[i].napi_tx);
-
-	max_rx_flows = emac->is_sr1 ?
-			PRUETH_MAX_RX_FLOWS_SR1 : PRUETH_MAX_RX_FLOWS_SR2;
-	k3_udma_glue_tdown_rx_chn(emac->rx_chns.rx_chn, true);
-
-	prueth_reset_rx_chan(&emac->rx_chns, max_rx_flows, true);
-	if (emac->is_sr1) {
-		/* Teardown RX MGM channel */
-		k3_udma_glue_tdown_rx_chn(emac->rx_mgm_chn.rx_chn, true);
-		prueth_reset_rx_chan(&emac->rx_mgm_chn,
-				     PRUETH_MAX_RX_MGM_FLOWS, true);
-	}
-
-	napi_disable(&emac->napi_rx);
-
-	if (!emac->is_sr1 && prueth->iep_initialized == 1)
-		icss_iep_exit(emac->iep);
-
-	prueth->iep_initialized--;
-
-	cancel_work_sync(&emac->rx_mode_work);
-	/* stop PRUs */
-	prueth_emac_stop(emac);
-
-	if (!emac->is_sr1)
-		free_irq(emac->tx_ts_irq, emac);
-
-	if (emac->is_sr1) {
-		free_irq(emac->rx_mgm_chn.irq[PRUETH_RX_MGM_FLOW_TIMESTAMP],
-			 emac);
-		free_irq(emac->rx_mgm_chn.irq[PRUETH_RX_MGM_FLOW_RESPONSE],
-			 emac);
-	}
-	free_irq(emac->rx_chns.irq[rx_flow], emac);
-	prueth_ndev_del_tx_napi(emac, emac->tx_ch_num);
-	prueth_cleanup_tx_chns(emac);
-
-	if (emac->is_sr1)
-		prueth_cleanup_rx_chns(emac, &emac->rx_mgm_chn,
-				       PRUETH_MAX_RX_MGM_FLOWS);
-	prueth_cleanup_rx_chns(emac, &emac->rx_chns, max_rx_flows);
-	prueth_cleanup_tx_chns(emac);
-
-	if (netif_msg_drv(emac))
-		dev_notice(&ndev->dev, "stopped\n");
-
-	return 0;
-}
-
-static void emac_ndo_tx_timeout(struct net_device *ndev, unsigned int txqueue)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	if (netif_msg_tx_err(emac))
-		netdev_err(ndev, "xmit timeout");
-
-	ndev->stats.tx_errors++;
-
-	/* TODO: can we recover or need to reboot firmware? */
-}
-
-static void emac_ndo_set_rx_mode_sr1(struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	int slice = prueth_emac_slice(emac);
-	bool promisc = ndev->flags & IFF_PROMISC;
-	bool allmulti = ndev->flags & IFF_ALLMULTI;
-
-	if (promisc) {
-		icssg_class_promiscuous_sr1(prueth->miig_rt, slice);
-		return;
-	}
-
-	if (allmulti) {
-		icssg_class_default(prueth->miig_rt, slice, 1, emac->is_sr1);
-		return;
-	}
-
-	icssg_class_default(prueth->miig_rt, slice, 0, emac->is_sr1);
-	if (!netdev_mc_empty(ndev)) {
-		/* program multicast address list into Classifier */
-		icssg_class_add_mcast_sr1(prueth->miig_rt, slice, ndev);
-		return;
-	}
-}
-
-static void emac_ndo_set_rx_mode_work(struct work_struct *work)
-{
-	struct prueth_emac *emac = container_of(work, struct prueth_emac, rx_mode_work);
-	struct net_device *ndev = emac->ndev;
-	bool promisc, allmulti;
-
-	if (!(ndev->flags & IFF_UP))
-		return;
-
-	promisc = ndev->flags & IFF_PROMISC;
-	allmulti = ndev->flags & IFF_ALLMULTI;
-	emac_set_port_state(emac, ICSSG_EMAC_PORT_UC_FLOODING_DISABLE);
-	emac_set_port_state(emac, ICSSG_EMAC_PORT_MC_FLOODING_DISABLE);
-
-	if (promisc) {
-		emac_set_port_state(emac, ICSSG_EMAC_PORT_UC_FLOODING_ENABLE);
-		emac_set_port_state(emac, ICSSG_EMAC_PORT_MC_FLOODING_ENABLE);
-		return;
-	}
-
-	if (allmulti) {
-		emac_set_port_state(emac, ICSSG_EMAC_PORT_MC_FLOODING_ENABLE);
-		return;
-	}
-
-	if (!netdev_mc_empty(ndev)) {
-	/* TODO: Add FDB entries for multicast. till then enable allmulti */
-		emac_set_port_state(emac, ICSSG_EMAC_PORT_MC_FLOODING_ENABLE);
-		return;
-	}
-}
-
-/**
- * emac_ndo_set_rx_mode - EMAC set receive mode function
- * @ndev: The EMAC network adapter
- *
- * Called when system wants to set the receive mode of the device.
- *
- */
-static void emac_ndo_set_rx_mode(struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-
-	if (prueth->is_sr1) {
-		emac_ndo_set_rx_mode_sr1(ndev);
-		return;
-	}
-
-	queue_work(emac->cmd_wq, &emac->rx_mode_work);
-}
-
-static int emac_set_ts_config(struct net_device *ndev, struct ifreq *ifr)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct hwtstamp_config config;
-
-	if (copy_from_user(&config, ifr->ifr_data, sizeof(config)))
-		return -EFAULT;
-
-	switch (config.tx_type) {
-	case HWTSTAMP_TX_OFF:
-		emac->tx_ts_enabled = 0;
-		break;
-	case HWTSTAMP_TX_ON:
-		emac->tx_ts_enabled = 1;
-		break;
-	default:
-		return -ERANGE;
-	}
-
-	switch (config.rx_filter) {
-	case HWTSTAMP_FILTER_NONE:
-		emac->rx_ts_enabled = 0;
-		break;
-	case HWTSTAMP_FILTER_ALL:
-	case HWTSTAMP_FILTER_SOME:
-	case HWTSTAMP_FILTER_PTP_V1_L4_EVENT:
-	case HWTSTAMP_FILTER_PTP_V1_L4_SYNC:
-	case HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ:
-	case HWTSTAMP_FILTER_PTP_V2_L4_EVENT:
-	case HWTSTAMP_FILTER_PTP_V2_L4_SYNC:
-	case HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ:
-	case HWTSTAMP_FILTER_PTP_V2_L2_EVENT:
-	case HWTSTAMP_FILTER_PTP_V2_L2_SYNC:
-	case HWTSTAMP_FILTER_PTP_V2_L2_DELAY_REQ:
-	case HWTSTAMP_FILTER_PTP_V2_EVENT:
-	case HWTSTAMP_FILTER_PTP_V2_SYNC:
-	case HWTSTAMP_FILTER_PTP_V2_DELAY_REQ:
-	case HWTSTAMP_FILTER_NTP_ALL:
-		emac->rx_ts_enabled = 1;
-		config.rx_filter = HWTSTAMP_FILTER_ALL;
-		break;
-	default:
-		return -ERANGE;
-	}
-
-	return copy_to_user(ifr->ifr_data, &config, sizeof(config)) ?
-		-EFAULT : 0;
-}
-
-static int emac_get_ts_config(struct net_device *ndev, struct ifreq *ifr)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct hwtstamp_config config;
-
-	config.flags = 0;
-	config.tx_type = emac->tx_ts_enabled ? HWTSTAMP_TX_ON : HWTSTAMP_TX_OFF;
-	config.rx_filter = emac->rx_ts_enabled ? HWTSTAMP_FILTER_ALL : HWTSTAMP_FILTER_NONE;
-
-	return copy_to_user(ifr->ifr_data, &config, sizeof(config)) ?
-			    -EFAULT : 0;
-}
-
-static int emac_ndo_ioctl(struct net_device *ndev, struct ifreq *ifr, int cmd)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	switch (cmd) {
-	case SIOCGHWTSTAMP:
-		return emac_get_ts_config(ndev, ifr);
-	case SIOCSHWTSTAMP:
-		return emac_set_ts_config(ndev, ifr);
-	default:
-		break;
-	}
-
-	return phy_mii_ioctl(emac->phydev, ifr, cmd);
-}
-
-static int emac_ndo_get_phys_port_name(struct net_device *ndev, char *name, size_t len)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	int err;
-
-	err = snprintf(name, len, "p%d", emac->port_id);
-
-	if (err >= len)
-		return -EINVAL;
-
-	return 0;
-}
-
-static const struct net_device_ops emac_netdev_ops = {
-	.ndo_open = emac_ndo_open,
-	.ndo_stop = emac_ndo_stop,
-	.ndo_start_xmit = emac_ndo_start_xmit,
-	.ndo_set_mac_address = eth_mac_addr,
-	.ndo_validate_addr = eth_validate_addr,
-	.ndo_tx_timeout = emac_ndo_tx_timeout,
-	.ndo_set_rx_mode = emac_ndo_set_rx_mode,
-	.ndo_do_ioctl = emac_ndo_ioctl,
-	.ndo_get_phys_port_name = emac_ndo_get_phys_port_name,
-};
-
-/* get emac_port corresponding to eth_node name */
-static int prueth_node_port(struct device_node *eth_node)
-{
-	if (!strcmp(eth_node->name, "ethernet-mii0"))
-		return PRUETH_PORT_MII0;
-	else if (!strcmp(eth_node->name, "ethernet-mii1"))
-		return PRUETH_PORT_MII1;
-	else
-		return -EINVAL;
-}
-
-/* get MAC instance corresponding to eth_node name */
-static int prueth_node_mac(struct device_node *eth_node)
-{
-	if (!strcmp(eth_node->name, "ethernet-mii0"))
-		return PRUETH_MAC0;
-	else if (!strcmp(eth_node->name, "ethernet-mii1"))
-		return PRUETH_MAC1;
-	else
-		return -EINVAL;
-}
-
-static int prueth_config_rgmiidelay(struct prueth *prueth,
-				    struct device_node *eth_np,
-				    phy_interface_t phy_if)
-{
-	struct device *dev = prueth->dev;
-	struct regmap *ctrl_mmr;
-	u32 rgmii_tx_id = 0;
-	u32 icssgctrl_reg;
-
-	ctrl_mmr = syscon_regmap_lookup_by_phandle(eth_np, "syscon-rgmii-delay");
-	if (IS_ERR(ctrl_mmr)) {
-		dev_err(dev, "couldn't get syscon-rgmii-delay\n");
-		return -ENODEV;
-	}
-
-	if (of_property_read_u32_index(eth_np, "syscon-rgmii-delay", 1,
-				       &icssgctrl_reg)) {
-		dev_err(dev, "couldn't get rgmii-delay reg. offset\n");
-		return -ENODEV;
-	}
-
-	if (phy_if == PHY_INTERFACE_MODE_RGMII_ID ||
-	    phy_if == PHY_INTERFACE_MODE_RGMII_TXID)
-		rgmii_tx_id |= ICSSG_CTRL_RGMII_ID_MODE;
-
-	regmap_update_bits(ctrl_mmr, icssgctrl_reg, ICSSG_CTRL_RGMII_ID_MODE, rgmii_tx_id);
-
-	return 0;
-}
-
-extern const struct ethtool_ops icssg_ethtool_ops;
-
-static int prueth_netdev_init(struct prueth *prueth,
-			      struct device_node *eth_node)
-{
-	int ret, num_tx_chn = PRUETH_MAX_TX_QUEUES;
-	struct prueth_emac *emac;
-	struct net_device *ndev;
-	enum prueth_port port;
-	const char *irq_name;
-	enum prueth_mac mac;
-	const u8 *mac_addr;
-
-	port = prueth_node_port(eth_node);
-	if (port < 0)
-		return -EINVAL;
-
-	mac = prueth_node_mac(eth_node);
-	if (mac < 0)
-		return -EINVAL;
-
-	/* Use 1 channel for management messages on SR1 */
-	if (prueth->is_sr1)
-		num_tx_chn--;
-
-	ndev = alloc_etherdev_mq(sizeof(*emac), num_tx_chn);
-	if (!ndev)
-		return -ENOMEM;
-
-	emac = netdev_priv(ndev);
-	prueth->emac[mac] = emac;
-	emac->prueth = prueth;
-	emac->ndev = ndev;
-	emac->port_id = port;
-	emac->cmd_wq = create_singlethread_workqueue("icssg_cmd_wq");
-	if (!emac->cmd_wq)
-		goto free_ndev;
-	INIT_WORK(&emac->rx_mode_work, emac_ndo_set_rx_mode_work);
-
-	ret = pruss_request_mem_region(prueth->pruss,
-				       port == PRUETH_PORT_MII0 ?
-				       PRUSS_MEM_DRAM0 : PRUSS_MEM_DRAM1,
-				       &emac->dram);
-	if (ret) {
-		dev_err(prueth->dev, "unable to get DRAM: %d\n", ret);
-		return -ENOMEM;
-	}
-
-	emac->is_sr1 = prueth->is_sr1;
-	emac->tx_ch_num = 1;
-	if (emac->is_sr1) {
-		/* use a dedicated high priority channel for management
-		 * messages which is +1 of highest priority data channel.
-		 */
-		emac->tx_ch_num++;
-		goto skip_irq;
-	}
-
-	irq_name = "tx_ts0";
-	if (emac->port_id == PRUETH_PORT_MII1)
-		irq_name = "tx_ts1";
-	emac->tx_ts_irq = platform_get_irq_byname_optional(prueth->pdev, irq_name);
-	if (emac->tx_ts_irq < 0) {
-		ret = dev_err_probe(prueth->dev, emac->tx_ts_irq, "could not get tx_ts_irq\n");
-		goto free;
-	}
-
-skip_irq:
-	SET_NETDEV_DEV(ndev, prueth->dev);
-	emac->msg_enable = netif_msg_init(debug_level, PRUETH_EMAC_DEBUG);
-	spin_lock_init(&emac->lock);
-	mutex_init(&emac->cmd_lock);
-
-	emac->phy_node = of_parse_phandle(eth_node, "phy-handle", 0);
-	if (!emac->phy_node && !of_phy_is_fixed_link(eth_node)) {
-		dev_err(prueth->dev, "couldn't find phy-handle\n");
-		ret = -ENODEV;
-		goto free;
-	} else if (of_phy_is_fixed_link(eth_node)) {
-		ret = of_phy_register_fixed_link(eth_node);
-		if (ret) {
-			ret = dev_err_probe(prueth->dev, ret,
-					    "failed to register fixed-link phy\n");
-			goto free;
-		}
-
-		emac->phy_node = eth_node;
-	}
-
-	ret = of_get_phy_mode(eth_node, &emac->phy_if);
-	if (ret) {
-		dev_err(prueth->dev, "could not get phy-mode property\n");
-		goto free;
-	}
-
-	ret = prueth_config_rgmiidelay(prueth, eth_node, emac->phy_if);
-	if (ret)
-		goto free;
-
-	/* connect PHY */
-	emac->phydev = of_phy_connect(ndev, emac->phy_node,
-				      &emac_adjust_link, 0, emac->phy_if);
-	if (!emac->phydev) {
-		dev_err(prueth->dev, "couldn't connect to phy %s\n",
-			emac->phy_node->full_name);
-		ret = -EPROBE_DEFER;
-		goto free;
-	}
-
-	/* remove unsupported modes */
-	phy_remove_link_mode(emac->phydev, ETHTOOL_LINK_MODE_10baseT_Half_BIT);
-	phy_remove_link_mode(emac->phydev, ETHTOOL_LINK_MODE_100baseT_Half_BIT);
-	phy_remove_link_mode(emac->phydev, ETHTOOL_LINK_MODE_1000baseT_Half_BIT);
-	phy_remove_link_mode(emac->phydev, ETHTOOL_LINK_MODE_Pause_BIT);
-	phy_remove_link_mode(emac->phydev, ETHTOOL_LINK_MODE_Asym_Pause_BIT);
-
-	/* get mac address from DT and set private and netdev addr */
-	mac_addr = of_get_mac_address(eth_node);
-	if (!IS_ERR(mac_addr))
-		ether_addr_copy(ndev->dev_addr, mac_addr);
-	if (!is_valid_ether_addr(ndev->dev_addr)) {
-		eth_hw_addr_random(ndev);
-		dev_warn(prueth->dev, "port %d: using random MAC addr: %pM\n",
-			 port, ndev->dev_addr);
-	}
-	ether_addr_copy(emac->mac_addr, ndev->dev_addr);
-
-	ndev->netdev_ops = &emac_netdev_ops;
-	ndev->ethtool_ops = &icssg_ethtool_ops;
-
-	netif_napi_add(ndev, &emac->napi_rx,
-		       emac_napi_rx_poll, NAPI_POLL_WEIGHT);
-
-	return 0;
-
-free:
-	pruss_release_mem_region(prueth->pruss, &emac->dram);
-	destroy_workqueue(emac->cmd_wq);
-free_ndev:
-	free_netdev(ndev);
-	prueth->emac[mac] = NULL;
-
-	return ret;
-}
-
-static void prueth_netdev_exit(struct prueth *prueth,
-			       struct device_node *eth_node)
-{
-	struct prueth_emac *emac;
-	enum prueth_mac mac;
-
-	mac = prueth_node_mac(eth_node);
-	if (mac < 0)
-		return;
-
-	emac = prueth->emac[mac];
-	if (!emac)
-		return;
-
-	phy_disconnect(emac->phydev);
-
-	if (of_phy_is_fixed_link(emac->phy_node))
-		of_phy_deregister_fixed_link(emac->phy_node);
-
-	netif_napi_del(&emac->napi_rx);
-
-	pruss_release_mem_region(prueth->pruss, &emac->dram);
-	destroy_workqueue(emac->cmd_wq);
-	free_netdev(emac->ndev);
-	prueth->emac[mac] = NULL;
-}
-
-static int prueth_get_cores(struct prueth *prueth, int slice)
-{
-	enum pruss_pru_id pruss_id;
-	struct device *dev = prueth->dev;
-	struct device_node *np = dev->of_node;
-	int pru, rtu, txpru = -1, ret;
-
-	switch (slice) {
-	case ICSS_SLICE0:
-		pru = 0;
-		rtu = 1;
-		if (!prueth->is_sr1)
-			txpru = 2;
-		break;
-	case ICSS_SLICE1:
-		if (prueth->is_sr1) {
-			pru = 2;
-			rtu = 3;
-		} else {
-			pru = 3;
-			rtu = 4;
-			txpru = 5;
-		}
-		break;
-	default:
-		return -EINVAL;
-	}
-
-	prueth->pru[slice] = pru_rproc_get(np, pru, &pruss_id);
-	if (IS_ERR(prueth->pru[slice])) {
-		ret = PTR_ERR(prueth->pru[slice]);
-		prueth->pru[slice] = NULL;
-		if (ret != -EPROBE_DEFER)
-			dev_err(dev, "unable to get PRU%d: %d\n", slice, ret);
-		return ret;
-	}
-	prueth->pru_id[slice] = pruss_id;
-
-	prueth->rtu[slice] = pru_rproc_get(np, rtu, NULL);
-	if (IS_ERR(prueth->rtu[slice])) {
-		ret = PTR_ERR(prueth->rtu[slice]);
-		prueth->rtu[slice] = NULL;
-		if (ret != -EPROBE_DEFER)
-			dev_err(dev, "unable to get RTU%d: %d\n", slice, ret);
-		return ret;
-	}
-
-	if (prueth->is_sr1)
-		return 0;
-
-	prueth->txpru[slice] = pru_rproc_get(np, txpru, NULL);
-	if (IS_ERR(prueth->txpru[slice])) {
-		ret = PTR_ERR(prueth->txpru[slice]);
-		prueth->txpru[slice] = NULL;
-		if (ret != -EPROBE_DEFER)
-			dev_err(dev, "unable to get TX_PRU%d: %d\n",
-				slice, ret);
-		return ret;
-	}
-
-	return 0;
-}
-
-static void prueth_put_cores(struct prueth *prueth, int slice)
-{
-	if (prueth->txpru[slice])
-		pru_rproc_put(prueth->txpru[slice]);
-
-	if (prueth->rtu[slice])
-		pru_rproc_put(prueth->rtu[slice]);
-
-	if (prueth->pru[slice])
-		pru_rproc_put(prueth->pru[slice]);
-}
-
-static const struct of_device_id prueth_dt_match[];
-
-static int prueth_probe(struct platform_device *pdev)
-{
-	struct prueth *prueth;
-	struct device *dev = &pdev->dev;
-	struct device_node *np = dev->of_node;
-	struct device_node *eth0_node, *eth1_node;
-	const struct of_device_id *match;
-	struct pruss *pruss;
-	int i, ret;
-	u32 msmc_ram_size;
-	struct genpool_data_align gp_data = {
-		.align = SZ_64K,
-	};
-
-	match = of_match_device(prueth_dt_match, dev);
-	if (!match)
-		return -ENODEV;
-
-	prueth = devm_kzalloc(dev, sizeof(*prueth), GFP_KERNEL);
-	if (!prueth)
-		return -ENOMEM;
-
-	dev_set_drvdata(dev, prueth);
-	prueth->pdev = pdev;
-	prueth->pdata = *(const struct prueth_pdata *)match->data;
-
-	if (of_device_is_compatible(np, "ti,am654-icssg-prueth-sr1"))
-		prueth->is_sr1 = true;
-
-	prueth->dev = dev;
-	eth0_node = of_get_child_by_name(np, "ethernet-mii0");
-	if (!of_device_is_available(eth0_node)) {
-		of_node_put(eth0_node);
-		eth0_node = NULL;
-	}
-
-	eth1_node = of_get_child_by_name(np, "ethernet-mii1");
-	if (!of_device_is_available(eth1_node)) {
-		of_node_put(eth1_node);
-		eth1_node = NULL;
-	}
-
-	/* At least one node must be present and available else we fail */
-	if (!eth0_node && !eth1_node) {
-		dev_err(dev, "neither ethernet-mii0 nor ethernet-mii1 node available\n");
-		return -ENODEV;
-	}
-
-	prueth->eth_node[PRUETH_MAC0] = eth0_node;
-	prueth->eth_node[PRUETH_MAC1] = eth1_node;
-
-	prueth->miig_rt = syscon_regmap_lookup_by_phandle(np, "mii-g-rt");
-	if (IS_ERR(prueth->miig_rt)) {
-		dev_err(dev, "couldn't get mii-g-rt syscon regmap\n");
-		return -ENODEV;
-	}
-
-	prueth->mii_rt = syscon_regmap_lookup_by_phandle(np, "mii-rt");
-	if (IS_ERR(prueth->mii_rt)) {
-		dev_err(dev, "couldn't get mii-rt syscon regmap\n");
-		return -ENODEV;
-	}
-
-	if (eth0_node) {
-		ret = prueth_get_cores(prueth, ICSS_SLICE0);
-		if (ret)
-			goto put_cores;
-	}
-
-	if (eth1_node) {
-		ret = prueth_get_cores(prueth, ICSS_SLICE1);
-		if (ret)
-			goto put_cores;
-	}
-
-	pruss = pruss_get(eth0_node ?
-			  prueth->pru[ICSS_SLICE0] : prueth->pru[ICSS_SLICE1]);
-	if (IS_ERR(pruss)) {
-		ret = PTR_ERR(pruss);
-		dev_err(dev, "unable to get pruss handle\n");
-		goto put_cores;
-	}
-
-	prueth->pruss = pruss;
-
-	ret = pruss_request_mem_region(pruss, PRUSS_MEM_SHRD_RAM2,
-				       &prueth->shram);
-	if (ret) {
-		dev_err(dev, "unable to get PRUSS SHRD RAM2: %d\n", ret);
-		goto put_mem;
-	}
-
-	prueth->sram_pool = of_gen_pool_get(np, "sram", 0);
-	if (!prueth->sram_pool) {
-		dev_err(dev, "unable to get SRAM pool\n");
-		ret = -ENODEV;
-
-		goto put_mem;
-	}
-
-	msmc_ram_size = prueth->is_sr1 ? MSMC_RAM_SIZE_SR1 : MSMC_RAM_SIZE_SR2;
-	if (prueth->is_sr1) {
-		prueth->msmcram.va =
-			(void __iomem *)gen_pool_alloc(prueth->sram_pool,
-						       msmc_ram_size);
-	} else {
-		/* TEMP: FW bug needs buffer base to be 64KB aligned */
-		prueth->msmcram.va =
-			(void __iomem *)gen_pool_alloc_algo(prueth->sram_pool,
-							    msmc_ram_size,
-							    gen_pool_first_fit_align,
-							    &gp_data);
-	}
-
-	if (!prueth->msmcram.va) {
-		ret = -ENOMEM;
-		dev_err(dev, "unable to allocate MSMC resource\n");
-		goto put_mem;
-	}
-	prueth->msmcram.pa = gen_pool_virt_to_phys(prueth->sram_pool,
-						   (unsigned long)prueth->msmcram.va);
-	prueth->msmcram.size = msmc_ram_size;
-	memset(prueth->msmcram.va, 0, msmc_ram_size);
-	dev_dbg(dev, "sram: pa %llx va %p size %zx\n", prueth->msmcram.pa,
-		prueth->msmcram.va, prueth->msmcram.size);
-
-	prueth->iep0 = icss_iep_get_idx(np, 0);
-	if (IS_ERR(prueth->iep0)) {
-		ret = dev_err_probe(dev, PTR_ERR(prueth->iep0), "iep0 get failed\n");
-		prueth->iep0 = NULL;
-		goto free_pool;
-	}
-
-	prueth->iep1 = icss_iep_get_idx(np, 1);
-	if (IS_ERR(prueth->iep1)) {
-		ret = dev_err_probe(dev, PTR_ERR(prueth->iep1), "iep1 get failed\n");
-		icss_iep_put(prueth->iep1);
-		prueth->iep0 = NULL;
-		prueth->iep1 = NULL;
-		goto free_pool;
-	}
-
-	if (prueth->is_sr1) {
-		ret = icss_iep_init(prueth->iep0, NULL, NULL, 0);
-		if (ret) {
-			dev_err(dev, "failed to init iep0\n");
-			goto free_iep;
-		}
-
-		ret = icss_iep_init(prueth->iep1, NULL, NULL, 0);
-		if (ret) {
-			dev_err(dev, "failed to init iep1\n");
-			icss_iep_exit(prueth->iep1);
-			goto free_iep;
-		}
-	} else if (prueth->pdata.quirk_10m_link_issue) {
-		/* Enable IEP1 for FW in 64bit mode as W/A for 10M FD link detect issue under TX
-		 * traffic.
-		 */
-		icss_iep_init_fw(prueth->iep1);
-	}
-
-	/* setup netdev interfaces */
-	if (eth0_node) {
-		ret = prueth_netdev_init(prueth, eth0_node);
-		if (ret) {
-			if (ret != -EPROBE_DEFER) {
-				dev_err(dev, "netdev init %s failed: %d\n",
-					eth0_node->name, ret);
-			}
-			goto exit_iep;
-		}
-		prueth->emac[PRUETH_MAC0]->iep = prueth->iep0;
-	}
-
-	if (eth1_node) {
-		ret = prueth_netdev_init(prueth, eth1_node);
-		if (ret) {
-			if (ret != -EPROBE_DEFER) {
-				dev_err(dev, "netdev init %s failed: %d\n",
-					eth1_node->name, ret);
-			}
-			goto netdev_exit;
-		}
-
-		if (prueth->is_sr1)
-			prueth->emac[PRUETH_MAC1]->iep = prueth->iep1;
-		else
-			prueth->emac[PRUETH_MAC1]->iep = prueth->iep0;
-	}
-
-	/* register the network devices */
-	if (eth0_node) {
-		ret = register_netdev(prueth->emac[PRUETH_MAC0]->ndev);
-		if (ret) {
-			dev_err(dev, "can't register netdev for port MII0");
-			goto netdev_exit;
-		}
-
-		prueth->registered_netdevs[PRUETH_MAC0] = prueth->emac[PRUETH_MAC0]->ndev;
-	}
-
-	if (eth1_node) {
-		ret = register_netdev(prueth->emac[PRUETH_MAC1]->ndev);
-		if (ret) {
-			dev_err(dev, "can't register netdev for port MII1");
-			goto netdev_unregister;
-		}
-
-		prueth->registered_netdevs[PRUETH_MAC1] = prueth->emac[PRUETH_MAC1]->ndev;
-	}
-
-	dev_info(dev, "TI PRU ethernet driver initialized: %s EMAC mode\n",
-		 (!eth0_node || !eth1_node) ? "single" : "dual");
-
-	if (eth1_node)
-		of_node_put(eth1_node);
-	if (eth0_node)
-		of_node_put(eth0_node);
-
-	return 0;
-
-netdev_unregister:
-	for (i = 0; i < PRUETH_NUM_MACS; i++) {
-		if (!prueth->registered_netdevs[i])
-			continue;
-		unregister_netdev(prueth->registered_netdevs[i]);
-	}
-
-netdev_exit:
-	for (i = 0; i < PRUETH_NUM_MACS; i++) {
-		struct device_node *eth_node;
-
-		eth_node = prueth->eth_node[i];
-		if (!eth_node)
-			continue;
-
-		prueth_netdev_exit(prueth, eth_node);
-	}
-exit_iep:
-	if (prueth->is_sr1) {
-		icss_iep_exit(prueth->iep1);
-		icss_iep_exit(prueth->iep0);
-	} else if (prueth->pdata.quirk_10m_link_issue) {
-		icss_iep_exit_fw(prueth->iep1);
-	}
-
-free_iep:
-	icss_iep_put(prueth->iep1);
-	icss_iep_put(prueth->iep0);
-
-free_pool:
-	gen_pool_free(prueth->sram_pool,
-		      (unsigned long)prueth->msmcram.va, msmc_ram_size);
-
-put_mem:
-	pruss_release_mem_region(prueth->pruss, &prueth->shram);
-	pruss_put(prueth->pruss);
-
-put_cores:
-	if (eth1_node) {
-		prueth_put_cores(prueth, ICSS_SLICE1);
-		of_node_put(eth1_node);
-	}
-
-	if (eth0_node) {
-		prueth_put_cores(prueth, ICSS_SLICE0);
-		of_node_put(eth0_node);
-	}
-
-	return ret;
-}
-
-static int prueth_remove(struct platform_device *pdev)
-{
-	struct device_node *eth_node;
-	struct prueth *prueth = platform_get_drvdata(pdev);
-	int i;
-
-	for (i = 0; i < PRUETH_NUM_MACS; i++) {
-		if (!prueth->registered_netdevs[i])
-			continue;
-		unregister_netdev(prueth->registered_netdevs[i]);
-	}
-
-	for (i = 0; i < PRUETH_NUM_MACS; i++) {
-		eth_node = prueth->eth_node[i];
-		if (!eth_node)
-			continue;
-
-		prueth_netdev_exit(prueth, eth_node);
-	}
-
-	if (prueth->is_sr1) {
-		icss_iep_exit(prueth->iep1);
-		icss_iep_exit(prueth->iep0);
-	} else if (prueth->pdata.quirk_10m_link_issue) {
-		icss_iep_exit_fw(prueth->iep1);
-	}
-
-	icss_iep_put(prueth->iep1);
-	icss_iep_put(prueth->iep0);
-
-	gen_pool_free(prueth->sram_pool,
-		      (unsigned long)prueth->msmcram.va,
-		      prueth->is_sr1 ? MSMC_RAM_SIZE_SR1 : MSMC_RAM_SIZE_SR2);
-
-	pruss_release_mem_region(prueth->pruss, &prueth->shram);
-
-	pruss_put(prueth->pruss);
-
-	if (prueth->eth_node[PRUETH_MAC1])
-		prueth_put_cores(prueth, ICSS_SLICE1);
-
-	if (prueth->eth_node[PRUETH_MAC0])
-		prueth_put_cores(prueth, ICSS_SLICE0);
-
-	return 0;
-}
-
-#ifdef CONFIG_PM_SLEEP
-static int prueth_suspend(struct device *dev)
-{
-	struct prueth *prueth = dev_get_drvdata(dev);
-	struct net_device *ndev;
-	int i, ret;
-
-	for (i = 0; i < PRUETH_NUM_MACS; i++) {
-		ndev = prueth->registered_netdevs[i];
-
-		if (!ndev)
-			continue;
-
-		if (netif_running(ndev)) {
-			netif_device_detach(ndev);
-			ret = emac_ndo_stop(ndev);
-			if (ret < 0) {
-				netdev_err(ndev, "failed to stop: %d", ret);
-				return ret;
-			}
-		}
-	}
-
-	return 0;
-}
-
-static int prueth_resume(struct device *dev)
-{
-	struct prueth *prueth = dev_get_drvdata(dev);
-	struct net_device *ndev;
-	int i, ret;
-
-	for (i = 0; i < PRUETH_NUM_MACS; i++) {
-		ndev = prueth->registered_netdevs[i];
-
-		if (!ndev)
-			continue;
-
-		if (netif_running(ndev)) {
-			ret = emac_ndo_open(ndev);
-			if (ret < 0) {
-				netdev_err(ndev, "failed to start: %d", ret);
-				return ret;
-			}
-			netif_device_attach(ndev);
-		}
-	}
-
-	return 0;
-}
-#endif /* CONFIG_PM_SLEEP */
-
-static const struct dev_pm_ops prueth_dev_pm_ops = {
-	SET_SYSTEM_SLEEP_PM_OPS(prueth_suspend, prueth_resume)
-};
-
-static const struct prueth_pdata am654_icssg_pdata_sr1 = {
-	.fdqring_mode = K3_RINGACC_RING_MODE_MESSAGE,
-};
-
-static const struct prueth_pdata am654_icssg_pdata = {
-	.fdqring_mode = K3_RINGACC_RING_MODE_MESSAGE,
-	.quirk_10m_link_issue = 1,
-};
-
-static const struct prueth_pdata am64x_icssg_pdata = {
-	.fdqring_mode = K3_RINGACC_RING_MODE_RING,
-};
-
-static const struct of_device_id prueth_dt_match[] = {
-	{ .compatible = "ti,am654-icssg-prueth-sr1", .data = &am654_icssg_pdata_sr1 },
-	{ .compatible = "ti,am654-icssg-prueth", .data = &am654_icssg_pdata },
-	{ .compatible = "ti,am642-icssg-prueth", .data = &am64x_icssg_pdata },
-	{ /* sentinel */ }
-};
-MODULE_DEVICE_TABLE(of, prueth_dt_match);
-
-static struct platform_driver prueth_driver = {
-	.probe = prueth_probe,
-	.remove = prueth_remove,
-	.driver = {
-		.name = "icssg-prueth",
-		.of_match_table = prueth_dt_match,
-		.pm = &prueth_dev_pm_ops,
-	},
-};
-module_platform_driver(prueth_driver);
-
-MODULE_AUTHOR("Roger Quadros <rogerq@ti.com>");
-MODULE_DESCRIPTION("PRUSS ICSSG Ethernet Driver");
-MODULE_LICENSE("GPL v2");
diff --git a/drivers/net/ethernet/ti/icssg_prueth.h b/drivers/net/ethernet/ti/icssg_prueth.h
deleted file mode 100644
index 59dec45a3c86..000000000000
--- a/drivers/net/ethernet/ti/icssg_prueth.h
+++ /dev/null
@@ -1,287 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Texas Instruments ICSSG Ethernet driver
- *
- * Copyright (C) 2018-2021 Texas Instruments Incorporated - https://www.ti.com/
- *
- */
-
-#ifndef __NET_TI_ICSSG_PRUETH_H
-#define __NET_TI_ICSSG_PRUETH_H
-
-#include <linux/etherdevice.h>
-#include <linux/genalloc.h>
-#include <linux/if_vlan.h>
-#include <linux/interrupt.h>
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/of.h>
-#include <linux/of_irq.h>
-#include <linux/of_mdio.h>
-#include <linux/of_net.h>
-#include <linux/of_platform.h>
-#include <linux/mfd/syscon.h>
-#include <linux/mutex.h>
-#include <linux/net_tstamp.h>
-#include <linux/phy.h>
-#include <linux/pruss.h>
-#include <linux/ptp_clock_kernel.h>
-#include <linux/remoteproc.h>
-
-#include <linux/dma-mapping.h>
-#include <linux/dma/ti-cppi5.h>
-#include <linux/dma/k3-udma-glue.h>
-
-#include "icssg_config.h"
-#include "icss_iep.h"
-#include "icssg_switch_map.h"
-
-#define ICSS_SLICE0	0
-#define ICSS_SLICE1	1
-
-#define ICSS_FW_PRU	0
-#define ICSS_FW_RTU	1
-
-#define ICSSG_MAX_RFLOWS	8	/* per slice */
-
-/* Firmware status codes */
-#define ICSS_HS_FW_READY 0x55555555
-#define ICSS_HS_FW_DEAD 0xDEAD0000	/* lower 16 bits contain error code */
-
-/* Firmware command codes */
-#define ICSS_HS_CMD_BUSY 0x40000000
-#define ICSS_HS_CMD_DONE 0x80000000
-#define ICSS_HS_CMD_CANCEL 0x10000000
-
-/* Firmware commands */
-#define ICSS_CMD_SPAD 0x20
-#define ICSS_CMD_RXTX 0x10
-#define ICSS_CMD_ADD_FDB 0x1
-#define ICSS_CMD_SET_RUN 0x4
-#define ICSS_CMD_ENABLE_VLAN 0x5
-#define ICSS_CMD_DISABLE_VLAN 0x6
-#define ICSS_CMD_ADD_FILTER 0x7
-#define ICSS_CMD_ADD_MAC 0x8
-
-/* Firmware flags */
-#define ICSS_SET_RUN_FLAG_VLAN_ENABLE		BIT(0)	/* switch only */
-#define ICSS_SET_RUN_FLAG_FLOOD_UNICAST		BIT(1)	/* switch only */
-#define ICSS_SET_RUN_FLAG_PROMISC		BIT(2)	/* MAC only */
-#define ICSS_SET_RUN_FLAG_MULTICAST_PROMISC	BIT(3)	/* MAC only */
-
-/* In switch mode there are 3 real ports i.e. 3 mac addrs.
- * however Linux sees only the host side port. The other 2 ports
- * are the switch ports.
- * In emac mode there are 2 real ports i.e. 2 mac addrs.
- * Linux sees both the ports.
- */
-enum prueth_port {
-	PRUETH_PORT_HOST = 0,	/* host side port */
-	PRUETH_PORT_MII0,	/* physical port RG/SG MII 0 */
-	PRUETH_PORT_MII1,	/* physical port RG/SG MII 1 */
-};
-
-enum prueth_mac {
-	PRUETH_MAC0 = 0,
-	PRUETH_MAC1,
-	PRUETH_NUM_MACS,
-};
-
-struct prueth_tx_chn {
-	struct device *dma_dev;
-	struct napi_struct napi_tx;
-	struct k3_cppi_desc_pool *desc_pool;
-	struct k3_udma_glue_tx_channel *tx_chn;
-	struct prueth_emac *emac;
-	u32 id;
-	u32 descs_num;
-	unsigned int irq;
-	char name[32];
-};
-
-struct prueth_rx_chn {
-	struct device *dev;
-	struct device *dma_dev;
-	struct k3_cppi_desc_pool *desc_pool;
-	struct k3_udma_glue_rx_channel *rx_chn;
-	u32 descs_num;
-	unsigned int irq[ICSSG_MAX_RFLOWS];	/* separate irq per flow */
-	char name[32];
-};
-
-enum prueth_state_flags {
-	__STATE_TX_TS_IN_PROGRESS,
-};
-
-/* There are 4 Tx DMA channels, but the highest priority is CH3 (thread 3)
- * and lower three are lower priority channels or threads.
- */
-#define PRUETH_MAX_TX_QUEUES	4
-
-/* data for each emac port */
-struct prueth_emac {
-	bool is_sr1;
-	bool fw_running;
-	struct prueth *prueth;
-	struct net_device *ndev;
-	u8 mac_addr[6];
-	struct napi_struct napi_rx;
-	u32 msg_enable;
-
-	int link;
-	int speed;
-	int duplex;
-
-	const char *phy_id;
-	struct device_node *phy_node;
-	phy_interface_t phy_if;
-	struct phy_device *phydev;
-	enum prueth_port port_id;
-	struct icss_iep *iep;
-	unsigned int rx_ts_enabled : 1;
-	unsigned int tx_ts_enabled : 1;
-
-	/* DMA related */
-	struct prueth_tx_chn tx_chns[PRUETH_MAX_TX_QUEUES];
-	struct completion tdown_complete;
-	atomic_t tdown_cnt;
-	struct prueth_rx_chn rx_chns;
-	int rx_flow_id_base;
-	int tx_ch_num;
-
-	/* SR1.0 Management channel */
-	struct prueth_rx_chn rx_mgm_chn;
-	int rx_mgm_flow_id_base;
-
-	spinlock_t lock;	/* serialize access */
-
-	/* TX HW Timestamping */
-	u32 tx_ts_cookie;
-	struct sk_buff *tx_ts_skb;
-	unsigned long state;
-	int tx_ts_irq;
-
-	u8 cmd_seq;
-	/* shutdown related */
-	u32 cmd_data[4];
-	struct completion cmd_complete;
-	/* Mutex to serialize access to firmware command interface */
-	struct mutex cmd_lock;
-	struct work_struct rx_mode_work;
-	struct workqueue_struct	*cmd_wq;
-
-	struct pruss_mem_region dram;
-};
-
-/**
- * struct prueth - PRUeth platform data
- * @fdqring_mode: Free desc queue mode
- * @quirk_10m_link_issue: 10M link detect errata
- */
-struct prueth_pdata {
-	enum k3_ring_mode fdqring_mode;
-
-	u32	quirk_10m_link_issue:1;
-};
-
-/**
- * struct prueth - PRUeth structure
- * @is_sr1: device is pg1.0 (pg1.0 will be deprecated upstream)
- * @dev: device
- * @pruss: pruss handle
- * @pru: rproc instances of PRUs
- * @rtu: rproc instances of RTUs
- * @rtu: rproc instances of TX_PRUs
- * @shram: PRUSS shared RAM region
- * @sram_pool: MSMC RAM pool for buffers
- * @msmcram: MSMC RAM region
- * @eth_node: DT node for the port
- * @emac: private EMAC data structure
- * @registered_netdevs: list of registered netdevs
- * @fw_data: firmware names to be used with PRU remoteprocs
- * @config: firmware load time configuration per slice
- * @miig_rt: regmap to mii_g_rt block
- * @pa_stats: regmap to pa_stats block
- */
-struct prueth {
-	bool is_sr1;
-	struct device *dev;
-	struct pruss *pruss;
-	struct rproc *pru[PRUSS_NUM_PRUS];
-	struct rproc *rtu[PRUSS_NUM_PRUS];
-	struct rproc *txpru[PRUSS_NUM_PRUS];
-	struct pruss_mem_region shram;
-	struct gen_pool *sram_pool;
-	struct pruss_mem_region msmcram;
-
-	struct device_node *eth_node[PRUETH_NUM_MACS];
-	struct prueth_emac *emac[PRUETH_NUM_MACS];
-	struct net_device *registered_netdevs[PRUETH_NUM_MACS];
-	const struct prueth_private_data *fw_data;
-	struct icssg_config_sr1 config[PRUSS_NUM_PRUS];
-	struct regmap *miig_rt;
-	struct regmap *mii_rt;
-	struct regmap *pa_stats;
-
-	enum pruss_pru_id pru_id[PRUSS_NUM_PRUS];
-	struct platform_device *pdev;
-	struct icss_iep *iep0;
-	struct icss_iep *iep1;
-	int iep_initialized;
-	struct prueth_pdata pdata;
-};
-
-struct emac_tx_ts_response_sr1 {
-	u32 lo_ts;
-	u32 hi_ts;
-	u32 reserved;
-	u32 cookie;
-};
-
-struct emac_tx_ts_response {
-	u32 reserved[2];
-	u32 cookie;
-	u32 lo_ts;
-	u32 hi_ts;
-};
-
-/* Classifier helpers */
-void icssg_class_set_mac_addr(struct regmap *miig_rt, int slice, u8 *mac);
-void icssg_class_disable(struct regmap *miig_rt, int slice);
-void icssg_class_default(struct regmap *miig_rt, int slice, bool allmulti,
-			 bool is_sr1);
-void icssg_class_promiscuous_sr1(struct regmap *miig_rt, int slice);
-void icssg_class_add_mcast_sr1(struct regmap *miig_rt, int slice,
-			       struct net_device *ndev);
-void icssg_ft1_set_mac_addr(struct regmap *miig_rt, int slice, u8 *mac_addr);
-
-/* Buffer queue helpers */
-int icssg_queue_pop(struct prueth *prueth, u8 queue);
-void icssg_queue_push(struct prueth *prueth, int queue, u16 addr);
-u32 icssg_queue_level(struct prueth *prueth, int queue);
-
-/* get PRUSS SLICE number from prueth_emac */
-static inline int prueth_emac_slice(struct prueth_emac *emac)
-{
-	switch (emac->port_id) {
-	case PRUETH_PORT_MII0:
-		return ICSS_SLICE0;
-	case PRUETH_PORT_MII1:
-		return ICSS_SLICE1;
-	default:
-		return -EINVAL;
-	}
-}
-
-/* config helpers */
-void icssg_config_ipg(struct prueth *prueth, int speed, int mii);
-void icssg_config_sr1(struct prueth *prueth, struct prueth_emac *emac,
-		      int slice);
-int icssg_config_sr2(struct prueth *prueth, struct prueth_emac *emac,
-		     int slice);
-int emac_set_port_state(struct prueth_emac *emac,
-			enum icssg_port_state_cmd state);
-void icssg_config_set_speed(struct prueth_emac *emac);
-#define prueth_napi_to_tx_chn(pnapi) \
-	container_of(pnapi, struct prueth_tx_chn, napi_tx)
-
-#endif /* __NET_TI_ICSSG_PRUETH_H */
diff --git a/drivers/net/ethernet/ti/icssg_queues.c b/drivers/net/ethernet/ti/icssg_queues.c
deleted file mode 100644
index 3c34f61ad40b..000000000000
--- a/drivers/net/ethernet/ti/icssg_queues.c
+++ /dev/null
@@ -1,50 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/* ICSSG Buffer queue helpers
- *
- * Copyright (C) 2021 Texas Instruments Incorporated - https://www.ti.com
- */
-
-#include <linux/regmap.h>
-#include "icssg_prueth.h"
-
-#define ICSSG_QUEUES_MAX		64
-#define ICSSG_QUEUE_OFFSET		0xd00
-#define ICSSG_QUEUE_PEEK_OFFSET		0xe00
-#define ICSSG_QUEUE_CNT_OFFSET		0xe40
-#define	ICSSG_QUEUE_RESET_OFFSET	0xf40
-
-int icssg_queue_pop(struct prueth *prueth, u8 queue)
-{
-	u32 val, cnt;
-
-	if (queue >= ICSSG_QUEUES_MAX)
-		return -EINVAL;
-
-	regmap_read(prueth->miig_rt, ICSSG_QUEUE_CNT_OFFSET + 4 * queue, &cnt);
-	if (!cnt)
-		return -EINVAL;
-
-	regmap_read(prueth->miig_rt, ICSSG_QUEUE_OFFSET + 4 * queue, &val);
-
-	return val;
-}
-
-void icssg_queue_push(struct prueth *prueth, int queue, u16 addr)
-{
-	if (queue >= ICSSG_QUEUES_MAX)
-		return;
-
-	regmap_write(prueth->miig_rt, ICSSG_QUEUE_OFFSET + 4 * queue, addr);
-}
-
-u32 icssg_queue_level(struct prueth *prueth, int queue)
-{
-	u32 reg;
-
-	if (queue >= ICSSG_QUEUES_MAX)
-		return 0;
-
-	regmap_read(prueth->miig_rt, ICSSG_QUEUE_CNT_OFFSET + 4 * queue, &reg);
-
-	return reg;
-}
diff --git a/drivers/net/ethernet/ti/icssg_switch_map.h b/drivers/net/ethernet/ti/icssg_switch_map.h
deleted file mode 100644
index 644a22b53424..000000000000
--- a/drivers/net/ethernet/ti/icssg_switch_map.h
+++ /dev/null
@@ -1,169 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Texas Instruments ICSSG Ethernet driver
- *
- * Copyright (C) 2021 Texas Instruments Incorporated - https://www.ti.com/
- *
- *
- */
-
-#ifndef __NET_TI_ICSSG_SWITCH_MAP_H
-#define __NET_TI_ICSSG_SWITCH_MAP_H
-
-/* Memory Usage of : SHARED_MEMORY
- *
- */
-
-#define FW_LINK_SPEED_1G                           (0x00)
-#define FW_LINK_SPEED_100M                         (0x01)
-#define FW_LINK_SPEED_10M                          (0x02)
-
-/*Time after which FDB entries are checked for aged out values. Value in nanoseconds*/
-#define FDB_AGEING_TIMEOUT_OFFSET                          0x0014
-/*default VLAN tag for Host Port*/
-#define HOST_PORT_DF_VLAN_OFFSET                           0x001C
-/*Same as HOST_PORT_DF_VLAN_OFFSET*/
-#define EMAC_ICSSG_SWITCH_PORT0_DEFAULT_VLAN_OFFSET        HOST_PORT_DF_VLAN_OFFSET
-/*default VLAN tag for P1 Port*/
-#define P1_PORT_DF_VLAN_OFFSET                             0x0020
-/*Same as P1_PORT_DF_VLAN_OFFSET*/
-#define EMAC_ICSSG_SWITCH_PORT1_DEFAULT_VLAN_OFFSET        P1_PORT_DF_VLAN_OFFSET
-/*default VLAN tag for P2 Port*/
-#define P2_PORT_DF_VLAN_OFFSET                             0x0024
-/*Same as P2_PORT_DF_VLAN_OFFSET*/
-#define EMAC_ICSSG_SWITCH_PORT2_DEFAULT_VLAN_OFFSET        P2_PORT_DF_VLAN_OFFSET
-/*VLAN-FID Table offset. 4096 VIDs. 2B per VID = 8KB = 0x2000*/
-#define VLAN_STATIC_REG_TABLE_OFFSET                       0x0100
-/*VLAN-FID Table offset for EMAC*/
-#define EMAC_ICSSG_SWITCH_DEFAULT_VLAN_TABLE_OFFSET        VLAN_STATIC_REG_TABLE_OFFSET
-/*packet descriptor Q reserved memory*/
-#define PORT_DESC0_HI                                      0x2104
-/*packet descriptor Q reserved memory*/
-#define PORT_DESC0_LO                                      0x2F6C
-/*packet descriptor Q reserved memory*/
-#define PORT_DESC1_HI                                      0x3DD4
-/*packet descriptor Q reserved memory*/
-#define PORT_DESC1_LO                                      0x4C3C
-/*packet descriptor Q reserved memory*/
-#define HOST_DESC0_HI                                      0x5AA4
-/*packet descriptor Q reserved memory*/
-#define HOST_DESC0_LO                                      0x5F0C
-/*packet descriptor Q reserved memory*/
-#define HOST_DESC1_HI                                      0x6374
-/*packet descriptor Q reserved memory*/
-#define HOST_DESC1_LO                                      0x67DC
-/*special packet descriptor Q reserved memory*/
-#define HOST_SPPD0                                         0x7AAC
-/*special packet descriptor Q reserved memory*/
-#define HOST_SPPD1                                         0x7EAC
-/*_Small_Description_*/
-#define TIMESYNC_FW_WC_CYCLECOUNT_OFFSET                   0x83EC
-/*IEP count hi roll over count*/
-#define TIMESYNC_FW_WC_HI_ROLLOVER_COUNT_OFFSET            0x83F4
-/*_Small_Description_*/
-#define TIMESYNC_FW_WC_COUNT_HI_SW_OFFSET_OFFSET           0x83F8
-/*Set clock descriptor*/
-#define TIMESYNC_FW_WC_SETCLOCK_DESC_OFFSET                0x83FC
-/*_Small_Description_*/
-#define TIMESYNC_FW_WC_SYNCOUT_REDUCTION_FACTOR_OFFSET     0x843C
-/*_Small_Description_*/
-#define TIMESYNC_FW_WC_SYNCOUT_REDUCTION_COUNT_OFFSET      0x8440
-/*_Small_Description_*/
-#define TIMESYNC_FW_WC_SYNCOUT_START_TIME_CYCLECOUNT_OFFSET 0x8444
-/*Control variable to generate SYNC1*/
-#define TIMESYNC_FW_WC_ISOM_PIN_SIGNAL_EN_OFFSET           0x844C
-/*SystemTime Sync0 periodicity*/
-#define TIMESYNC_FW_ST_SYNCOUT_PERIOD_OFFSET               0x8450
-/*pktTxDelay for P1 = link speed dependent p1 mac delay + p1 phy delay*/
-#define TIMESYNC_FW_WC_PKTTXDELAY_P1_OFFSET                0x8454
-/*pktTxDelay for P2 = link speed dependent p2 mac delay + p2 phy delay*/
-#define TIMESYNC_FW_WC_PKTTXDELAY_P2_OFFSET                0x8458
-/*Set clock operation done signal for next task*/
-#define TIMESYNC_FW_SIG_PNFW_OFFSET                        0x845C
-/*Set clock operation done signal for next task*/
-#define TIMESYNC_FW_SIG_TIMESYNCFW_OFFSET                  0x8460
-
-/* Memory Usage of : MSMC
- *
- */
-
-/* Memory Usage of : DMEM0
- *
- */
-
-/*New list is copied at this time*/
-#define TAS_CONFIG_CHANGE_TIME                             0x000C
-/*config change error counter*/
-#define TAS_CONFIG_CHANGE_ERROR_COUNTER                    0x0014
-/*TAS List update pending flag*/
-#define TAS_CONFIG_PENDING                                 0x0018
-/*TAS list update trigger flag*/
-#define TAS_CONFIG_CHANGE                                  0x0019
-/*List length for new TAS schedule*/
-#define TAS_ADMIN_LIST_LENGTH                              0x001A
-/*Currently active TAS list index*/
-#define TAS_ACTIVE_LIST_INDEX                              0x001B
-/*Cycle time for the new TAS schedule*/
-#define TAS_ADMIN_CYCLE_TIME                               0x001C
-/*Cycle counts remaining till the TAS list update*/
-#define TAS_CONFIG_CHANGE_CYCLE_COUNT                      0x0020
-/*Base Flow ID for sending packets to Host for Slice0*/
-#define PSI_L_REGULAR_FLOW_ID_BASE_OFFSET                  0x0024
-/*Same as PSI_L_REGULAR_FLOW_ID_BASE_OFFSET*/
-#define EMAC_ICSSG_SWITCH_PSI_L_REGULAR_FLOW_ID_BASE_OFFSET PSI_L_REGULAR_FLOW_ID_BASE_OFFSET
-/*Base Flow ID for sending mgmt and Tx TS to Host for Slice0*/
-#define PSI_L_MGMT_FLOW_ID_OFFSET                          0x0026
-/*Same as PSI_L_MGMT_FLOW_ID_OFFSET*/
-#define EMAC_ICSSG_SWITCH_PSI_L_MGMT_FLOW_ID_BASE_OFFSET   PSI_L_MGMT_FLOW_ID_OFFSET
-/*Queue number for Special packets written here*/
-#define SPL_PKT_DEFAULT_PRIORITY                           0x0028
-/*Express Preemptible Queue Mask*/
-#define EXPRESS_PRE_EMPTIVE_Q_MASK                         0x0029
-/*Port1/Port2 Default Queue number for untagged packets, only 1B is used*/
-#define QUEUE_NUM_UNTAGGED                                 0x002A
-/*Stores the table used for priority regeneration. 1B per PCP/Queue*/
-#define PORT_Q_PRIORITY_REGEN_OFFSET                       0x002C
-/*For marking packet as priority/express (this feature is disabled) or cut-through/S&F.*/
-#define EXPRESS_PRE_EMPTIVE_Q_MAP                          0x0034
-/*Stores the table used for priority mapping. 1B per PCP/Queue*/
-#define PORT_Q_PRIORITY_MAPPING_OFFSET                     0x003C
-/*Used to notify the FW of the current link speed*/
-#define PORT_LINK_SPEED_OFFSET                             0x00A8
-/*TAS gate mask for windows list0*/
-#define TAS_GATE_MASK_LIST0                                0x0100
-/*TAS gate mask for windows list1*/
-#define TAS_GATE_MASK_LIST1                                0x0350
-/*Memory to Enable/Disable Preemption on TX side*/
-#define PRE_EMPTION_ENABLE_TX                              0x05A0
-/*Active State of Preemption on TX side*/
-#define PRE_EMPTION_ACTIVE_TX                              0x05A1
-/*Memory to Enable/Disable Verify State Machine Preemption*/
-#define PRE_EMPTION_ENABLE_VERIFY                          0x05A2
-/*Verify Status of State Machine*/
-#define PRE_EMPTION_VERIFY_STATUS                          0x05A3
-/*Non Final Fragment Size supported by Link Partner*/
-#define PRE_EMPTION_ADD_FRAG_SIZE_REMOTE                   0x05A4
-/*Non Final Fragment Size supported by Firmware*/
-#define PRE_EMPTION_ADD_FRAG_SIZE_LOCAL                    0x05A6
-/*Time in ms the State machine waits for respond packet*/
-#define PRE_EMPTION_VERIFY_TIME                            0x05A8
-/*Memory used for R30 related management commands*/
-#define MGR_R30_CMD_OFFSET                                 0x05AC
-/*HW Buffer Pool0 base address*/
-#define BUFFER_POOL_0_ADDR_OFFSET                          0x05BC
-/*16B for Host Egress MSMC Q (Pre-emptible) context*/
-#define HOST_RX_Q_PRE_CONTEXT_OFFSET                       0x0684
-/*Buffer for 8 FDB entries to be added by 'Add Multiple FDB entries IOCTL*/
-#define FDB_CMD_BUFFER                                     0x0894
-
-/* Memory Usage of : DMEM1
- *
- */
-
-/* Memory Usage of : PA_STAT
- *
- */
-
-/*Start of 32 bits PA_STAT counters*/
-#define PA_STAT_32b_START_OFFSET                           0x0080
-
-#endif /* __NET_TI_ICSSG_SWITCH_MAP_H */
diff --git a/drivers/net/ethernet/ti/j721e-cpsw-virt-mac.c b/drivers/net/ethernet/ti/j721e-cpsw-virt-mac.c
deleted file mode 100644
index 2d1d76cc323e..000000000000
--- a/drivers/net/ethernet/ti/j721e-cpsw-virt-mac.c
+++ /dev/null
@@ -1,1499 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/* Texas Instruments K3 J721 Virt Ethernet Switch MAC Driver
- *
- * Copyright (C) 2020 Texas Instruments Incorporated - http://www.ti.com/
- */
-
-#include <linux/etherdevice.h>
-#include <linux/if_vlan.h>
-#include <linux/interrupt.h>
-#include <linux/inetdevice.h>
-#include <linux/kernel.h>
-#include <linux/kmemleak.h>
-#include <linux/module.h>
-#include <linux/netdevice.h>
-#include <linux/of.h>
-#include <linux/of_net.h>
-#include <linux/of_device.h>
-#include <linux/platform_device.h>
-#include <linux/dma/ti-cppi5.h>
-#include <linux/dma/k3-udma-glue.h>
-#include <linux/rpmsg-remotedev/rpmsg-remotedev.h>
-
-#include "k3-cppi-desc-pool.h"
-
-#define VIRT_CPSW_DRV_VER "0.1"
-
-#define VIRT_CPSW_MAX_TX_QUEUES	1
-#define VIRT_CPSW_MAX_RX_QUEUES	1
-#define VIRT_CPSW_MAX_RX_FLOWS	1
-
-#define VIRT_CPSW_MIN_PACKET_SIZE	ETH_ZLEN
-#define VIRT_CPSW_MAX_PACKET_SIZE	(VLAN_ETH_FRAME_LEN + ETH_FCS_LEN)
-
-/* Number of TX/RX descriptors */
-#define VIRT_CPSW_MAX_TX_DESC	500
-#define VIRT_CPSW_MAX_RX_DESC	500
-
-#define VIRT_CPSW_NAV_PS_DATA_SIZE 16
-#define VIRT_CPSW_NAV_SW_DATA_SIZE 16
-
-#define VIRT_CPSW_DRV_NAME "j721e-cpsw-virt-mac"
-
-struct virt_cpsw_tx_chn {
-	struct device *dev;
-	struct k3_cppi_desc_pool *desc_pool;
-	struct k3_udma_glue_tx_channel *tx_chn;
-	u32 descs_num;
-	unsigned int irq;
-	u32 id;
-};
-
-struct virt_cpsw_rx_chn {
-	struct device *dev;
-	struct k3_cppi_desc_pool *desc_pool;
-	struct k3_udma_glue_rx_channel *rx_chn;
-	u32 descs_num;
-	unsigned int irq;
-};
-
-struct virt_cpsw_port {
-	struct virt_cpsw_common *common;
-	struct net_device *ndev;
-	const char *name;
-	u8 local_mac_addr[ETH_ALEN];
-};
-
-struct virt_cpsw_common {
-	struct device *dev;
-	struct virt_cpsw_port ports;
-
-	struct virt_cpsw_tx_chn tx_chns;
-	struct napi_struct napi_tx;
-	struct hrtimer tx_hrtimer;
-	unsigned long tx_pace_timeout;
-	struct completion tdown_complete;
-	atomic_t tdown_cnt;
-	struct virt_cpsw_rx_chn rx_chns;
-	struct napi_struct napi_rx;
-	bool rx_irq_disabled;
-	struct hrtimer rx_hrtimer;
-	unsigned long rx_pace_timeout;
-
-	const char *rdev_name;
-	struct rpmsg_remotedev *rdev;
-	struct rpmsg_remotedev_eth_switch_ops *rdev_switch_ops;
-	u32 rdev_features;
-	u32 rdev_mtu;
-	u8 rdev_mac_addr[ETH_ALEN];
-	u32 rdev_tx_psil_dst_id;
-	u32 tx_psil_id_base;
-	u32 rdev_rx_flow_id;
-};
-
-struct virt_cpsw_ndev_stats {
-	u64 tx_packets;
-	u64 tx_bytes;
-	u64 rx_packets;
-	u64 rx_bytes;
-	struct u64_stats_sync syncp;
-};
-
-struct virt_cpsw_ndev_priv {
-	struct virt_cpsw_ndev_stats __percpu *stats;
-	struct virt_cpsw_port	*port;
-};
-
-#define virt_ndev_to_priv(ndev) \
-	((struct virt_cpsw_ndev_priv *)netdev_priv(ndev))
-#define virt_ndev_to_port(ndev) (virt_ndev_to_priv(ndev)->port)
-#define virt_ndev_to_common(ndev) (virt_ndev_to_port(ndev)->common)
-
-static void virt_cpsw_nuss_ndo_host_tx_timeout(struct net_device *ndev,
-					       unsigned int txqueue)
-{
-	struct virt_cpsw_common *common = virt_ndev_to_common(ndev);
-	struct virt_cpsw_tx_chn *tx_chn = &common->tx_chns;
-	struct netdev_queue *netif_txq;
-	unsigned long trans_start;
-
-	/* process every txq*/
-	netif_txq = netdev_get_tx_queue(ndev, txqueue);
-	trans_start = netif_txq->trans_start;
-
-	netdev_err(ndev, "txq:%d DRV_XOFF:%d tmo:%u dql_avail:%d free_desc:%zu\n",
-		   txqueue,
-		   netif_tx_queue_stopped(netif_txq),
-		   jiffies_to_msecs(jiffies - trans_start),
-		   dql_avail(&netif_txq->dql),
-		   k3_cppi_desc_pool_avail(tx_chn->desc_pool));
-
-	if (netif_tx_queue_stopped(netif_txq)) {
-		/* try recover if stopped by us */
-		txq_trans_update(netif_txq);
-		netif_tx_wake_queue(netif_txq);
-	}
-}
-
-static int virt_cpsw_nuss_rx_push(struct virt_cpsw_common *common,
-				  struct sk_buff *skb)
-{
-	struct cppi5_host_desc_t *desc_rx;
-	struct virt_cpsw_rx_chn *rx_chn = &common->rx_chns;
-	struct device *dev = common->dev;
-	dma_addr_t desc_dma;
-	dma_addr_t buf_dma;
-	u32 pkt_len = skb_tailroom(skb);
-	void *swdata;
-
-	desc_rx = k3_cppi_desc_pool_alloc(rx_chn->desc_pool);
-	if (!desc_rx) {
-		dev_err(dev, "Failed to allocate RXFDQ descriptor\n");
-		return -ENOMEM;
-	}
-	desc_dma = k3_cppi_desc_pool_virt2dma(rx_chn->desc_pool, desc_rx);
-
-	buf_dma = dma_map_single(dev, skb->data, pkt_len, DMA_FROM_DEVICE);
-	if (unlikely(dma_mapping_error(dev, buf_dma))) {
-		k3_cppi_desc_pool_free(rx_chn->desc_pool, desc_rx);
-		dev_err(dev, "Failed to map rx skb buffer\n");
-		return -EINVAL;
-	}
-
-	cppi5_hdesc_init(desc_rx, CPPI5_INFO0_HDESC_EPIB_PRESENT,
-			 VIRT_CPSW_NAV_PS_DATA_SIZE);
-	cppi5_hdesc_attach_buf(desc_rx, 0, 0, buf_dma, skb_tailroom(skb));
-	swdata = cppi5_hdesc_get_swdata(desc_rx);
-	*((void **)swdata) = skb;
-
-	return k3_udma_glue_push_rx_chn(rx_chn->rx_chn, 0, desc_rx, desc_dma);
-}
-
-static int virt_cpsw_nuss_common_open(struct virt_cpsw_common *common,
-				      netdev_features_t features)
-{
-	struct sk_buff *skb;
-	int i, ret;
-
-	for (i = 0; i < common->rx_chns.descs_num; i++) {
-		skb = __netdev_alloc_skb_ip_align(NULL,
-						  VIRT_CPSW_MAX_PACKET_SIZE,
-						  GFP_KERNEL);
-		if (!skb) {
-			dev_err(common->dev, "cannot allocate skb\n");
-			return -ENOMEM;
-		}
-
-		ret = virt_cpsw_nuss_rx_push(common, skb);
-		if (ret < 0) {
-			dev_err(common->dev,
-				"cannot submit skb to channel rx, error %d\n",
-				ret);
-			kfree_skb(skb);
-			return ret;
-		}
-		kmemleak_not_leak(skb);
-	}
-	ret = k3_udma_glue_rx_flow_enable(common->rx_chns.rx_chn, 0);
-	if (ret)
-		return ret;
-
-	ret = k3_udma_glue_enable_tx_chn(common->tx_chns.tx_chn);
-	if (ret)
-		return ret;
-
-	napi_enable(&common->napi_tx);
-	napi_enable(&common->napi_rx);
-	if (common->rx_irq_disabled) {
-		common->rx_irq_disabled = false;
-		enable_irq(common->rx_chns.irq);
-	}
-
-	return 0;
-}
-
-static void virt_cpsw_nuss_tx_cleanup(void *data, dma_addr_t desc_dma);
-static void virt_cpsw_nuss_rx_cleanup(void *data, dma_addr_t desc_dma);
-
-static void virt_cpsw_nuss_common_stop(struct virt_cpsw_common *common)
-{
-	int i;
-
-	/* shutdown tx channels */
-	atomic_set(&common->tdown_cnt, VIRT_CPSW_MAX_TX_QUEUES);
-	/* ensure new tdown_cnt value is visible */
-	smp_mb__after_atomic();
-	reinit_completion(&common->tdown_complete);
-
-	k3_udma_glue_tdown_tx_chn(common->tx_chns.tx_chn, false);
-
-	i = wait_for_completion_timeout(&common->tdown_complete,
-					msecs_to_jiffies(1000));
-	if (!i)
-		dev_err(common->dev, "tx teardown timeout\n");
-
-	k3_udma_glue_reset_tx_chn(common->tx_chns.tx_chn,
-				  &common->tx_chns,
-				  virt_cpsw_nuss_tx_cleanup);
-	k3_udma_glue_disable_tx_chn(common->tx_chns.tx_chn);
-	napi_disable(&common->napi_tx);
-	hrtimer_cancel(&common->tx_hrtimer);
-
-	k3_udma_glue_rx_flow_disable(common->rx_chns.rx_chn, 0);
-	/* Need some delay to process RX ring before reset */
-	msleep(100);
-	k3_udma_glue_reset_rx_chn(common->rx_chns.rx_chn, 0,
-				  &common->rx_chns,
-				  virt_cpsw_nuss_rx_cleanup, false);
-	napi_disable(&common->napi_rx);
-	hrtimer_cancel(&common->rx_hrtimer);
-}
-
-static int virt_cpsw_nuss_ndo_stop(struct net_device *ndev)
-{
-	struct virt_cpsw_common *common = virt_ndev_to_common(ndev);
-	struct rpmsg_remotedev_eth_switch_ops *rdev_ops;
-	struct device *dev = common->dev;
-	int ret;
-
-	rdev_ops = common->rdev_switch_ops;
-	netif_tx_stop_all_queues(ndev);
-	netif_carrier_off(ndev);
-
-	ret = rdev_ops->unregister_mac(common->rdev, ndev->dev_addr,
-				       common->rdev_rx_flow_id);
-	if (ret)
-		dev_err(dev, "unregister_mac rpmsg - fail %d\n", ret);
-
-	virt_cpsw_nuss_common_stop(common);
-
-	dev_info(common->dev, "virt_cpsw_nuss mac stopped\n");
-	return 0;
-}
-
-static int virt_cpsw_nuss_ndo_open(struct net_device *ndev)
-{
-	struct virt_cpsw_common *common = virt_ndev_to_common(ndev);
-	struct rpmsg_remotedev_eth_switch_ops *rdev_ops;
-	struct device *dev = common->dev;
-	int ret;
-
-	rdev_ops = common->rdev_switch_ops;
-	netdev_tx_reset_queue(netdev_get_tx_queue(ndev, 0));
-
-	ret = virt_cpsw_nuss_common_open(common, ndev->features);
-	if (ret)
-		return ret;
-
-	ret = rdev_ops->register_mac(common->rdev,
-				     ndev->dev_addr,
-				     common->rdev_rx_flow_id);
-	if (ret) {
-		dev_err(dev, "register_mac rpmsg - fail %d\n", ret);
-		virt_cpsw_nuss_common_stop(common);
-		return ret;
-	}
-
-	netif_tx_wake_all_queues(ndev);
-	netif_carrier_on(ndev);
-
-	dev_info(common->dev, "virt_cpsw_nuss mac started\n");
-	return 0;
-}
-
-static void virt_cpsw_nuss_rx_cleanup(void *data, dma_addr_t desc_dma)
-{
-	struct virt_cpsw_rx_chn *rx_chn = data;
-	struct cppi5_host_desc_t *desc_rx;
-	struct sk_buff *skb;
-	dma_addr_t buf_dma;
-	u32 buf_dma_len;
-	void **swdata;
-
-	desc_rx = k3_cppi_desc_pool_dma2virt(rx_chn->desc_pool, desc_dma);
-	swdata = cppi5_hdesc_get_swdata(desc_rx);
-	skb = *swdata;
-	cppi5_hdesc_get_obuf(desc_rx, &buf_dma, &buf_dma_len);
-
-	dma_unmap_single(rx_chn->dev, buf_dma, buf_dma_len, DMA_FROM_DEVICE);
-	k3_cppi_desc_pool_free(rx_chn->desc_pool, desc_rx);
-
-	dev_kfree_skb_any(skb);
-}
-
-/* RX psdata[2] word format - checksum information */
-#define AM65_CPSW_RX_PSD_CSUM_ADD	GENMASK(15, 0)
-#define AM65_CPSW_RX_PSD_CSUM_ERR	BIT(16)
-#define AM65_CPSW_RX_PSD_IS_FRAGMENT	BIT(17)
-#define AM65_CPSW_RX_PSD_IS_TCP		BIT(18)
-#define AM65_CPSW_RX_PSD_IPV6_VALID	BIT(19)
-#define AM65_CPSW_RX_PSD_IPV4_VALID	BIT(20)
-
-static void virt_cpsw_nuss_rx_csum(struct sk_buff *skb, u32 csum_info)
-{
-	/* HW can verify IPv4/IPv6 TCP/UDP packets checksum
-	 * csum information provides in psdata[2] word:
-	 * AM65_CPSW_RX_PSD_CSUM_ERR bit - indicates csum error
-	 * AM65_CPSW_RX_PSD_IPV6_VALID and AM65_CPSW_RX_PSD_IPV4_VALID
-	 * bits - indicates IPv4/IPv6 packet
-	 * AM65_CPSW_RX_PSD_IS_FRAGMENT bit - indicates fragmented packet
-	 * AM65_CPSW_RX_PSD_CSUM_ADD has value 0xFFFF for non fragmented packets
-	 * or csum value for fragmented packets if !AM65_CPSW_RX_PSD_CSUM_ERR
-	 */
-	skb_checksum_none_assert(skb);
-
-	if (unlikely(!(skb->dev->features & NETIF_F_RXCSUM)))
-		return;
-
-	if ((csum_info & (AM65_CPSW_RX_PSD_IPV6_VALID |
-			  AM65_CPSW_RX_PSD_IPV4_VALID)) &&
-			  !(csum_info & AM65_CPSW_RX_PSD_CSUM_ERR)) {
-		/* csum for fragmented packets is unsupported */
-		if (!(csum_info & AM65_CPSW_RX_PSD_IS_FRAGMENT))
-			skb->ip_summed = CHECKSUM_UNNECESSARY;
-	}
-}
-
-static int virt_cpsw_nuss_rx_packets(struct virt_cpsw_common *common,
-				     u32 flow_idx)
-{
-	struct virt_cpsw_rx_chn *rx_chn = &common->rx_chns;
-	struct device *dev = common->dev;
-	struct virt_cpsw_ndev_priv *ndev_priv;
-	struct virt_cpsw_ndev_stats *stats;
-	struct net_device *ndev;
-	struct cppi5_host_desc_t *desc_rx;
-	struct sk_buff *skb, *new_skb;
-	dma_addr_t desc_dma, buf_dma;
-	u32 buf_dma_len, pkt_len, port_id = 0, csum_info;
-	int ret = 0;
-	void **swdata;
-	u32 *psdata;
-
-	ret = k3_udma_glue_pop_rx_chn(rx_chn->rx_chn, flow_idx, &desc_dma);
-	if (ret) {
-		if (ret != -ENODATA)
-			dev_err(dev, "RX: pop chn fail %d\n", ret);
-		return ret;
-	}
-
-	if (desc_dma & 0x1) {
-		dev_dbg(dev, "%s RX tdown flow: %u\n", __func__, flow_idx);
-		return 0;
-	}
-
-	desc_rx = k3_cppi_desc_pool_dma2virt(rx_chn->desc_pool, desc_dma);
-	dev_dbg(dev, "%s flow_idx: %u desc %pad\n",
-		__func__, flow_idx, &desc_dma);
-
-	swdata = cppi5_hdesc_get_swdata(desc_rx);
-	skb = *swdata;
-	cppi5_hdesc_get_obuf(desc_rx, &buf_dma, &buf_dma_len);
-	pkt_len = cppi5_hdesc_get_pktlen(desc_rx);
-	cppi5_desc_get_tags_ids(&desc_rx->hdr, &port_id, NULL);
-	/* read port for dbg */
-	dev_dbg(dev, "%s rx port_id:%d\n", __func__, port_id);
-	ndev = common->ports.ndev;
-	skb->dev = ndev;
-
-	psdata = cppi5_hdesc_get_psdata(desc_rx);
-	csum_info = psdata[2];
-	dev_dbg(dev, "%s rx csum_info:%#x\n", __func__, csum_info);
-
-	dma_unmap_single(dev, buf_dma, buf_dma_len, DMA_FROM_DEVICE);
-
-	k3_cppi_desc_pool_free(rx_chn->desc_pool, desc_rx);
-
-	if (unlikely(!netif_running(skb->dev))) {
-		dev_kfree_skb_any(skb);
-		return -ENODEV;
-	}
-
-	new_skb = netdev_alloc_skb_ip_align(ndev, VIRT_CPSW_MAX_PACKET_SIZE);
-	if (new_skb) {
-		skb_put(skb, pkt_len);
-		skb->protocol = eth_type_trans(skb, ndev);
-		virt_cpsw_nuss_rx_csum(skb, csum_info);
-		napi_gro_receive(&common->napi_rx, skb);
-
-		ndev_priv = netdev_priv(ndev);
-		stats = this_cpu_ptr(ndev_priv->stats);
-
-		u64_stats_update_begin(&stats->syncp);
-		stats->rx_packets++;
-		stats->rx_bytes += pkt_len;
-		u64_stats_update_end(&stats->syncp);
-		kmemleak_not_leak(new_skb);
-	} else {
-		ndev->stats.rx_dropped++;
-		new_skb = skb;
-	}
-
-	if (netif_dormant(ndev)) {
-		dev_kfree_skb_any(new_skb);
-		ndev->stats.rx_dropped++;
-		return -ENODEV;
-	}
-
-	ret = virt_cpsw_nuss_rx_push(common, new_skb);
-	if (WARN_ON(ret < 0)) {
-		dev_kfree_skb_any(new_skb);
-		ndev->stats.rx_errors++;
-		ndev->stats.rx_dropped++;
-	}
-
-	return ret;
-}
-
-static enum hrtimer_restart virt_cpsw_nuss_rx_timer_callback(struct hrtimer *timer)
-{
-	struct virt_cpsw_common *common =
-			container_of(timer, struct virt_cpsw_common, rx_hrtimer);
-
-	enable_irq(common->rx_chns.irq);
-	return HRTIMER_NORESTART;
-}
-
-static int virt_cpsw_nuss_rx_poll(struct napi_struct *napi_rx, int budget)
-{
-	struct virt_cpsw_common *common =
-			container_of(napi_rx, struct virt_cpsw_common, napi_rx);
-	int num_rx = 0;
-	int cur_budget;
-	int ret;
-
-	/* process every flow */
-	cur_budget = budget;
-
-	while (cur_budget--) {
-		ret = virt_cpsw_nuss_rx_packets(common, 0);
-		if (ret)
-			break;
-		num_rx++;
-	}
-
-	dev_dbg(common->dev, "%s num_rx:%d %d\n", __func__, num_rx, budget);
-
-	if (num_rx < budget && napi_complete_done(napi_rx, num_rx)) {
-		if (common->rx_irq_disabled) {
-			common->rx_irq_disabled = false;
-			if (unlikely(common->rx_pace_timeout)) {
-				hrtimer_start(&common->rx_hrtimer,
-					      ns_to_ktime(common->rx_pace_timeout),
-					      HRTIMER_MODE_REL_PINNED);
-			} else {
-				enable_irq(common->rx_chns.irq);
-			}
-		}
-	}
-
-	return num_rx;
-}
-
-static void virt_cpsw_nuss_xmit_free(struct virt_cpsw_tx_chn *tx_chn,
-				     struct device *dev,
-				     struct cppi5_host_desc_t *desc)
-{
-	struct cppi5_host_desc_t *first_desc, *next_desc;
-	dma_addr_t buf_dma, next_desc_dma;
-	u32 buf_dma_len;
-
-	first_desc = desc;
-	next_desc = first_desc;
-
-	cppi5_hdesc_get_obuf(first_desc, &buf_dma, &buf_dma_len);
-
-	dma_unmap_single(dev, buf_dma, buf_dma_len,
-			 DMA_TO_DEVICE);
-
-	next_desc_dma = cppi5_hdesc_get_next_hbdesc(first_desc);
-	while (next_desc_dma) {
-		next_desc = k3_cppi_desc_pool_dma2virt(tx_chn->desc_pool,
-						       next_desc_dma);
-		cppi5_hdesc_get_obuf(next_desc, &buf_dma, &buf_dma_len);
-
-		dma_unmap_page(dev, buf_dma, buf_dma_len,
-			       DMA_TO_DEVICE);
-
-		next_desc_dma = cppi5_hdesc_get_next_hbdesc(next_desc);
-
-		k3_cppi_desc_pool_free(tx_chn->desc_pool, next_desc);
-	}
-
-	k3_cppi_desc_pool_free(tx_chn->desc_pool, first_desc);
-}
-
-static void virt_cpsw_nuss_tx_cleanup(void *data, dma_addr_t desc_dma)
-{
-	struct virt_cpsw_tx_chn *tx_chn = data;
-	struct cppi5_host_desc_t *desc_tx;
-	struct sk_buff *skb;
-	void **swdata;
-
-	desc_tx = k3_cppi_desc_pool_dma2virt(tx_chn->desc_pool, desc_dma);
-	swdata = cppi5_hdesc_get_swdata(desc_tx);
-	skb = *(swdata);
-	virt_cpsw_nuss_xmit_free(tx_chn, tx_chn->dev, desc_tx);
-
-	dev_kfree_skb_any(skb);
-}
-
-static int virt_cpsw_nuss_tx_compl_packets(struct virt_cpsw_common *common,
-					   int chn, unsigned int budget, bool *tdown)
-{
-	struct cppi5_host_desc_t *desc_tx;
-	struct device *dev = common->dev;
-	struct netdev_queue *netif_txq;
-	struct virt_cpsw_tx_chn *tx_chn;
-	struct net_device *ndev;
-	unsigned int total_bytes = 0;
-	struct sk_buff *skb;
-	dma_addr_t desc_dma;
-	int res, num_tx = 0;
-	void **swdata;
-
-	tx_chn = &common->tx_chns;
-
-	while (budget--) {
-		struct virt_cpsw_ndev_priv *ndev_priv;
-		struct virt_cpsw_ndev_stats *stats;
-
-		res = k3_udma_glue_pop_tx_chn(tx_chn->tx_chn, &desc_dma);
-		if (res == -ENODATA)
-			break;
-
-		if (desc_dma & 0x1) {
-			if (atomic_dec_and_test(&common->tdown_cnt))
-				complete(&common->tdown_complete);
-			*tdown = true;
-			break;
-		}
-
-		desc_tx = k3_cppi_desc_pool_dma2virt(tx_chn->desc_pool,
-						     desc_dma);
-		swdata = cppi5_hdesc_get_swdata(desc_tx);
-		skb = *(swdata);
-		virt_cpsw_nuss_xmit_free(tx_chn, dev, desc_tx);
-
-		ndev = skb->dev;
-
-		ndev_priv = netdev_priv(ndev);
-		stats = this_cpu_ptr(ndev_priv->stats);
-		u64_stats_update_begin(&stats->syncp);
-		stats->tx_packets++;
-		stats->tx_bytes += skb->len;
-		u64_stats_update_end(&stats->syncp);
-
-		total_bytes += skb->len;
-		napi_consume_skb(skb, budget);
-		num_tx++;
-	}
-
-	if (!num_tx)
-		return 0;
-
-	netif_txq = netdev_get_tx_queue(ndev, 0);
-
-	netdev_tx_completed_queue(netif_txq, num_tx, total_bytes);
-	dev_dbg(dev, "compl 0 %d Bytes\n", total_bytes);
-
-	if (netif_tx_queue_stopped(netif_txq)) {
-		/* Check whether the queue is stopped due to stalled tx dma,
-		 * if the queue is stopped then wake the queue as
-		 * we have free desc for tx
-		 */
-		__netif_tx_lock(netif_txq, smp_processor_id());
-		if (netif_running(ndev) &&
-		    (k3_cppi_desc_pool_avail(tx_chn->desc_pool) >=
-		     MAX_SKB_FRAGS))
-			netif_tx_wake_queue(netif_txq);
-
-		__netif_tx_unlock(netif_txq);
-	}
-	dev_dbg(dev, "%s:%u pkt:%d\n", __func__, chn, num_tx);
-
-	return num_tx;
-}
-
-static enum hrtimer_restart virt_cpsw_nuss_tx_timer_callback(struct hrtimer *timer)
-{
-	struct virt_cpsw_common *common =
-			container_of(timer, struct virt_cpsw_common, tx_hrtimer);
-
-	enable_irq(common->tx_chns.irq);
-	return HRTIMER_NORESTART;
-}
-
-static int virt_cpsw_nuss_tx_poll(struct napi_struct *napi_tx, int budget)
-{
-	struct virt_cpsw_common *common =
-			container_of(napi_tx, struct virt_cpsw_common, napi_tx);
-	bool tdown = false;
-	int num_tx;
-
-	/* process every unprocessed channel */
-	num_tx = virt_cpsw_nuss_tx_compl_packets(common, 0, budget, &tdown);
-
-	if (num_tx >= budget)
-		return budget;
-
-	if (napi_complete_done(napi_tx, num_tx)) {
-		if (unlikely(common->tx_pace_timeout && !tdown)) {
-			hrtimer_start(&common->tx_hrtimer,
-				      ns_to_ktime(common->tx_pace_timeout),
-				      HRTIMER_MODE_REL_PINNED);
-		} else {
-			enable_irq(common->tx_chns.irq);
-		}
-	}
-
-	return 0;
-}
-
-static irqreturn_t virt_cpsw_nuss_rx_irq(int irq, void *dev_id)
-{
-	struct virt_cpsw_common *common = dev_id;
-
-	common->rx_irq_disabled = true;
-	disable_irq_nosync(irq);
-	napi_schedule(&common->napi_rx);
-
-	return IRQ_HANDLED;
-}
-
-static irqreturn_t virt_cpsw_nuss_tx_irq(int irq, void *dev_id)
-{
-	struct virt_cpsw_common *common = dev_id;
-
-	disable_irq_nosync(irq);
-	napi_schedule(&common->napi_tx);
-
-	return IRQ_HANDLED;
-}
-
-static netdev_tx_t virt_cpsw_nuss_ndo_xmit(struct sk_buff *skb,
-					   struct net_device *ndev)
-{
-	struct virt_cpsw_common *common = virt_ndev_to_common(ndev);
-	struct device *dev = common->dev;
-	struct cppi5_host_desc_t *first_desc, *next_desc, *cur_desc;
-	struct virt_cpsw_tx_chn *tx_chn;
-	struct netdev_queue *netif_txq;
-	dma_addr_t desc_dma, buf_dma;
-	int ret, i;
-	u32 pkt_len;
-	void **swdata;
-	u32 *psdata;
-
-	/* padding enabled in hw */
-	pkt_len = skb_headlen(skb);
-
-	tx_chn = &common->tx_chns;
-	netif_txq = netdev_get_tx_queue(ndev, 0);
-
-	/* Map the linear buffer */
-	buf_dma = dma_map_single(dev, skb->data, pkt_len,
-				 DMA_TO_DEVICE);
-	if (unlikely(dma_mapping_error(dev, buf_dma))) {
-		dev_err(dev, "Failed to map tx skb buffer\n");
-		ndev->stats.tx_errors++;
-		goto drop_free_skb;
-	}
-
-	first_desc = k3_cppi_desc_pool_alloc(tx_chn->desc_pool);
-	if (!first_desc) {
-		dev_dbg(dev, "Failed to allocate descriptor\n");
-		dma_unmap_single(dev, buf_dma, pkt_len, DMA_TO_DEVICE);
-		goto busy_stop_q;
-	}
-
-	cppi5_hdesc_init(first_desc, CPPI5_INFO0_HDESC_EPIB_PRESENT,
-			 VIRT_CPSW_NAV_PS_DATA_SIZE);
-	cppi5_desc_set_pktids(&first_desc->hdr, 0, 0x3FFF);
-	cppi5_hdesc_set_pkttype(first_desc, 0x7);
-	/* target port has to be 0 */
-	cppi5_desc_set_tags_ids(&first_desc->hdr, 0, 0);
-
-	cppi5_hdesc_attach_buf(first_desc, buf_dma, pkt_len, buf_dma, pkt_len);
-	swdata = cppi5_hdesc_get_swdata(first_desc);
-	*(swdata) = skb;
-	psdata = cppi5_hdesc_get_psdata(first_desc);
-
-	/* HW csum offload if enabled */
-	psdata[2] = 0;
-	if (likely(skb->ip_summed == CHECKSUM_PARTIAL)) {
-		unsigned int cs_start, cs_offset;
-
-		cs_start = skb_transport_offset(skb);
-		cs_offset = cs_start + skb->csum_offset;
-		/* HW numerates bytes starting from 1 */
-		psdata[2] = ((cs_offset + 1) << 24) |
-			    ((cs_start + 1) << 16) | (skb->len - cs_start);
-		dev_dbg(dev, "%s tx psdata:%#x\n", __func__, psdata[2]);
-	}
-
-	if (!skb_is_nonlinear(skb))
-		goto done_tx;
-
-	dev_dbg(dev, "fragmented SKB\n");
-
-	/* Handle the case where skb is fragmented in pages */
-	cur_desc = first_desc;
-	for (i = 0; i < skb_shinfo(skb)->nr_frags; i++) {
-		skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
-		u32 frag_size = skb_frag_size(frag);
-
-		next_desc = k3_cppi_desc_pool_alloc(tx_chn->desc_pool);
-		if (!next_desc) {
-			dev_err(dev, "Failed to allocate descriptor\n");
-			goto busy_free_descs;
-		}
-
-		buf_dma = skb_frag_dma_map(dev, frag, 0, frag_size,
-					   DMA_TO_DEVICE);
-		if (unlikely(dma_mapping_error(dev, buf_dma))) {
-			dev_err(dev, "Failed to map tx skb page\n");
-			k3_cppi_desc_pool_free(tx_chn->desc_pool, next_desc);
-			ndev->stats.tx_errors++;
-			goto drop_free_descs;
-		}
-
-		cppi5_hdesc_reset_hbdesc(next_desc);
-		cppi5_hdesc_attach_buf(next_desc,
-				       buf_dma, frag_size, buf_dma, frag_size);
-
-		desc_dma = k3_cppi_desc_pool_virt2dma(tx_chn->desc_pool,
-						      next_desc);
-		cppi5_hdesc_link_hbdesc(cur_desc, desc_dma);
-
-		pkt_len += frag_size;
-		cur_desc = next_desc;
-	}
-	WARN_ON(pkt_len != skb->len);
-
-done_tx:
-	skb_tx_timestamp(skb);
-
-	/* report bql before sending packet */
-	dev_dbg(dev, "push 0 %d Bytes\n", pkt_len);
-
-	netdev_tx_sent_queue(netif_txq, pkt_len);
-
-	cppi5_hdesc_set_pktlen(first_desc, pkt_len);
-	desc_dma = k3_cppi_desc_pool_virt2dma(tx_chn->desc_pool, first_desc);
-	ret = k3_udma_glue_push_tx_chn(tx_chn->tx_chn, first_desc, desc_dma);
-	if (ret) {
-		dev_err(dev, "can't push desc %d\n", ret);
-		/* inform bql */
-		netdev_tx_completed_queue(netif_txq, 1, pkt_len);
-		ndev->stats.tx_errors++;
-		goto drop_free_descs;
-	}
-
-	if (k3_cppi_desc_pool_avail(tx_chn->desc_pool) < MAX_SKB_FRAGS) {
-		netif_tx_stop_queue(netif_txq);
-		/* Barrier, so that stop_queue visible to other cpus */
-		smp_mb__after_atomic();
-		dev_dbg(dev, "netif_tx_stop_queue %d\n", 0);
-
-		/* re-check for smp */
-		if (k3_cppi_desc_pool_avail(tx_chn->desc_pool) >=
-		    MAX_SKB_FRAGS) {
-			netif_tx_wake_queue(netif_txq);
-			dev_dbg(dev, "netif_tx_wake_queue %d\n", 0);
-		}
-	}
-
-	return NETDEV_TX_OK;
-
-drop_free_descs:
-	virt_cpsw_nuss_xmit_free(tx_chn, dev, first_desc);
-drop_free_skb:
-	ndev->stats.tx_dropped++;
-	dev_kfree_skb_any(skb);
-	return NETDEV_TX_OK;
-
-busy_free_descs:
-	virt_cpsw_nuss_xmit_free(tx_chn, dev, first_desc);
-busy_stop_q:
-	netif_tx_stop_queue(netif_txq);
-	return NETDEV_TX_BUSY;
-}
-
-static void virt_cpsw_nuss_ndo_get_stats(struct net_device *dev,
-					 struct rtnl_link_stats64 *stats)
-{
-	struct virt_cpsw_ndev_priv *ndev_priv = netdev_priv(dev);
-	unsigned int start;
-	int cpu;
-
-	for_each_possible_cpu(cpu) {
-		struct virt_cpsw_ndev_stats *cpu_stats;
-		u64 rx_packets;
-		u64 rx_bytes;
-		u64 tx_packets;
-		u64 tx_bytes;
-
-		cpu_stats = per_cpu_ptr(ndev_priv->stats, cpu);
-		do {
-			start = u64_stats_fetch_begin_irq(&cpu_stats->syncp);
-			rx_packets = cpu_stats->rx_packets;
-			rx_bytes   = cpu_stats->rx_bytes;
-			tx_packets = cpu_stats->tx_packets;
-			tx_bytes   = cpu_stats->tx_bytes;
-		} while (u64_stats_fetch_retry_irq(&cpu_stats->syncp, start));
-
-		stats->rx_packets += rx_packets;
-		stats->rx_bytes   += rx_bytes;
-		stats->tx_packets += tx_packets;
-		stats->tx_bytes   += tx_bytes;
-	}
-
-	stats->rx_errors	= dev->stats.rx_errors;
-	stats->rx_dropped	= dev->stats.rx_dropped;
-	stats->tx_dropped	= dev->stats.tx_dropped;
-}
-
-static const struct net_device_ops virt_cpsw_nuss_netdev_ops = {
-	.ndo_open		= virt_cpsw_nuss_ndo_open,
-	.ndo_stop		= virt_cpsw_nuss_ndo_stop,
-	.ndo_start_xmit		= virt_cpsw_nuss_ndo_xmit,
-	.ndo_get_stats64        = virt_cpsw_nuss_ndo_get_stats,
-	.ndo_validate_addr	= eth_validate_addr,
-	.ndo_set_mac_address	= eth_mac_addr,
-	.ndo_tx_timeout		= virt_cpsw_nuss_ndo_host_tx_timeout,
-};
-
-static void virt_cpsw_nuss_get_drvinfo(struct net_device *ndev,
-				       struct ethtool_drvinfo *info)
-{
-	struct virt_cpsw_common *common = virt_ndev_to_common(ndev);
-	struct rpmsg_remotedev_eth_switch_ops *rdev_ops;
-	char fw_version[ETHTOOL_FWVERS_LEN];
-
-	rdev_ops = common->rdev_switch_ops;
-
-	strlcpy(info->driver, dev_driver_string(common->dev),
-		sizeof(info->driver));
-	strlcpy(info->version, VIRT_CPSW_DRV_VER, sizeof(info->version));
-	strlcpy(info->bus_info, dev_name(common->dev), sizeof(info->bus_info));
-
-	rdev_ops->get_fw_ver(common->rdev, fw_version, ETHTOOL_FWVERS_LEN);
-	strlcpy(info->fw_version, fw_version, ETHTOOL_FWVERS_LEN);
-}
-
-static const char virt_cpsw_nuss_ethtool_priv_flags[][ETH_GSTRING_LEN] = {
-	"RPMSG Ping test",
-	"RPMSG Read reg",
-	"RPMSG Dump stat",
-};
-
-static int
-virt_cpsw_nuss_get_sset_count(struct net_device __always_unused *ndev, int sset)
-{
-	switch (sset) {
-	case ETH_SS_TEST:
-		return ARRAY_SIZE(virt_cpsw_nuss_ethtool_priv_flags);
-	default:
-		return -EOPNOTSUPP;
-	}
-}
-
-static void
-virt_cpsw_nuss_get_strings(struct net_device __always_unused *ndev,
-			   u32 stringset, u8 *data)
-{
-	switch (stringset) {
-	case ETH_SS_TEST:
-		memcpy(data, virt_cpsw_nuss_ethtool_priv_flags,
-		       sizeof(virt_cpsw_nuss_ethtool_priv_flags));
-		break;
-	}
-}
-
-static void virt_cpsw_nuss_self_test(struct net_device *ndev,
-				     struct ethtool_test *eth_test, u64 *data)
-{
-	struct virt_cpsw_common *common = virt_ndev_to_common(ndev);
-	struct device *dev = common->dev;
-	static const char ping_data[] = "0123456789";
-	u32 reg_val;
-	int ret;
-
-	data[0] = 0;
-	ret = common->rdev_switch_ops->ping(common->rdev,
-					    ping_data, strlen(ping_data));
-	if (ret) {
-		dev_err(dev, "rpmsg ping fail %d\n", ret);
-		eth_test->flags |= ETH_TEST_FL_FAILED;
-		data[0] = 1;
-	}
-
-	data[1] = 0;
-	ret = common->rdev_switch_ops->read_reg(common->rdev,
-						0x0C000000, &reg_val);
-	if (ret) {
-		dev_err(dev, "rpmsg read_reg fail %d\n", ret);
-		eth_test->flags |= ETH_TEST_FL_FAILED;
-		data[1] = 1;
-	}
-	dev_dbg(dev, "read_reg rpmsg cpsw_nuss_ver - 0x0C000000:%08X\n",
-		reg_val);
-
-	ret = common->rdev_switch_ops->read_reg(common->rdev,
-						0x0C020000, &reg_val);
-	if (ret) {
-		dev_err(dev, "rpmsg read_reg fail %d\n", ret);
-		eth_test->flags |= ETH_TEST_FL_FAILED;
-		data[1] = 1;
-	}
-	dev_dbg(dev, "read_reg rpmsg cpsw_ver - 0x0C020000:%08X\n",
-		reg_val);
-
-	ret = 0;
-	data[2] = 0;
-	if (common->rdev_features & RPMSG_KDRV_ETHSWITCH_FEATURE_DUMP_STATS)
-		ret = common->rdev_switch_ops->dbg_dump_stats(common->rdev);
-	if (ret) {
-		dev_err(dev, "rpmsg dump_stats fail %d\n", ret);
-		eth_test->flags |= ETH_TEST_FL_FAILED;
-		data[2] = 1;
-	}
-}
-
-static int virt_cpsw_nuss_get_coalesce(struct net_device *ndev, struct ethtool_coalesce *coal)
-{
-	struct virt_cpsw_common *common = virt_ndev_to_common(ndev);
-
-	coal->rx_coalesce_usecs = common->rx_pace_timeout / 1000;
-	coal->tx_coalesce_usecs = common->tx_pace_timeout / 1000;
-	return 0;
-}
-
-static int virt_cpsw_nuss_set_coalesce(struct net_device *ndev, struct ethtool_coalesce *coal)
-{
-	struct virt_cpsw_common *common = virt_ndev_to_common(ndev);
-
-	if (coal->rx_coalesce_usecs && coal->rx_coalesce_usecs < 20)
-		coal->rx_coalesce_usecs = 20;
-
-	if (coal->tx_coalesce_usecs && coal->tx_coalesce_usecs < 20)
-		coal->tx_coalesce_usecs = 20;
-
-	common->tx_pace_timeout = coal->tx_coalesce_usecs * 1000;
-	common->rx_pace_timeout = coal->rx_coalesce_usecs * 1000;
-
-	return 0;
-}
-
-const struct ethtool_ops virt_cpsw_nuss_ethtool_ops = {
-	.get_drvinfo		= virt_cpsw_nuss_get_drvinfo,
-	.get_sset_count		= virt_cpsw_nuss_get_sset_count,
-	.get_strings		= virt_cpsw_nuss_get_strings,
-	.self_test		= virt_cpsw_nuss_self_test,
-	.get_link		= ethtool_op_get_link,
-	.supported_coalesce_params = ETHTOOL_COALESCE_USECS,
-	.get_coalesce           = virt_cpsw_nuss_get_coalesce,
-	.set_coalesce           = virt_cpsw_nuss_set_coalesce,
-};
-
-static void virt_cpsw_nuss_free_tx_chns(void *data)
-{
-	struct virt_cpsw_common *common = data;
-	struct virt_cpsw_tx_chn	*tx_chn = &common->tx_chns;
-
-	if (!IS_ERR_OR_NULL(tx_chn->desc_pool))
-		k3_cppi_desc_pool_destroy(tx_chn->desc_pool);
-
-	if (!IS_ERR_OR_NULL(tx_chn->tx_chn))
-		k3_udma_glue_release_tx_chn(tx_chn->tx_chn);
-
-	memset(tx_chn, 0, sizeof(*tx_chn));
-}
-
-static int virt_cpsw_nuss_init_tx_chns(struct virt_cpsw_common *common)
-{
-	u32 max_desc_num = ALIGN(VIRT_CPSW_MAX_TX_DESC, MAX_SKB_FRAGS);
-	struct virt_cpsw_tx_chn	*tx_chn = &common->tx_chns;
-	struct k3_udma_glue_tx_channel_cfg tx_cfg = { 0 };
-	struct device *dev = common->dev;
-	struct k3_ring_cfg ring_cfg = {
-		.elm_size = K3_RINGACC_RING_ELSIZE_8,
-		.mode = K3_RINGACC_RING_MODE_RING,
-		.flags = 0
-	};
-	char tx_chn_name[IFNAMSIZ];
-	u32 hdesc_size, tx_chn_num;
-	int ret = 0, ret1;
-
-	/* convert to tx chn offset */
-	tx_chn_num = common->rdev_tx_psil_dst_id - common->tx_psil_id_base;
-	snprintf(tx_chn_name, sizeof(tx_chn_name), "tx%d", tx_chn_num);
-
-	init_completion(&common->tdown_complete);
-
-	hdesc_size = cppi5_hdesc_calc_size(true, VIRT_CPSW_NAV_PS_DATA_SIZE,
-					   VIRT_CPSW_NAV_SW_DATA_SIZE);
-
-	tx_cfg.swdata_size = VIRT_CPSW_NAV_SW_DATA_SIZE;
-	tx_cfg.tx_cfg = ring_cfg;
-	tx_cfg.txcq_cfg = ring_cfg;
-	tx_cfg.tx_cfg.size = max_desc_num;
-	tx_cfg.txcq_cfg.size = max_desc_num;
-
-	tx_chn->dev = dev;
-	tx_chn->id = 0;
-	tx_chn->descs_num = max_desc_num;
-	tx_chn->desc_pool = k3_cppi_desc_pool_create_name(dev,
-							  tx_chn->descs_num,
-							  hdesc_size,
-							  tx_chn_name);
-	if (IS_ERR(tx_chn->desc_pool)) {
-		ret = PTR_ERR(tx_chn->desc_pool);
-		dev_err(dev, "Failed to create poll %d\n", ret);
-		goto err;
-	}
-
-	tx_chn->tx_chn = k3_udma_glue_request_tx_chn(dev, tx_chn_name, &tx_cfg);
-	if (IS_ERR(tx_chn->tx_chn)) {
-		ret = PTR_ERR(tx_chn->tx_chn);
-		dev_err(dev, "Failed to request tx dma channel %d\n", ret);
-		goto err;
-	}
-
-	tx_chn->irq = k3_udma_glue_tx_get_irq(tx_chn->tx_chn);
-	if (tx_chn->irq <= 0) {
-		dev_err(dev, "Failed to get tx dma irq %d\n", tx_chn->irq);
-		ret = -ENXIO;
-	}
-
-err:
-	ret1 = devm_add_action(dev, virt_cpsw_nuss_free_tx_chns, common);
-	if (ret1) {
-		dev_err(dev, "failed to add free_tx_chns action %d", ret1);
-		return ret1;
-	}
-
-	return ret;
-}
-
-static void virt_cpsw_nuss_free_rx_chns(void *data)
-{
-	struct virt_cpsw_common *common = data;
-	struct virt_cpsw_rx_chn *rx_chn = &common->rx_chns;
-
-	if (!IS_ERR_OR_NULL(rx_chn->desc_pool))
-		k3_cppi_desc_pool_destroy(rx_chn->desc_pool);
-
-	if (!IS_ERR_OR_NULL(rx_chn->rx_chn))
-		k3_udma_glue_release_rx_chn(rx_chn->rx_chn);
-}
-
-static int virt_cpsw_nuss_init_rx_chns(struct virt_cpsw_common *common)
-{
-	struct virt_cpsw_rx_chn *rx_chn = &common->rx_chns;
-	struct k3_udma_glue_rx_channel_cfg rx_cfg = {0};
-	u32  max_desc_num = VIRT_CPSW_MAX_RX_DESC;
-	struct device *dev = common->dev;
-	u32 hdesc_size;
-	int ret = 0, ret1;
-	struct k3_ring_cfg rxring_cfg = {
-		.elm_size = K3_RINGACC_RING_ELSIZE_8,
-		.mode = K3_RINGACC_RING_MODE_MESSAGE,
-		.flags = 0,
-	};
-	struct k3_ring_cfg fdqring_cfg = {
-		.elm_size = K3_RINGACC_RING_ELSIZE_8,
-		.mode = K3_RINGACC_RING_MODE_MESSAGE,
-		.flags = 0,
-	};
-	struct k3_udma_glue_rx_flow_cfg rx_flow_cfg = {
-		.rx_cfg = rxring_cfg,
-		.rxfdq_cfg = fdqring_cfg,
-		.ring_rxq_id = K3_RINGACC_RING_ID_ANY,
-		.ring_rxfdq0_id = K3_RINGACC_RING_ID_ANY,
-		.src_tag_lo_sel = K3_UDMA_GLUE_SRC_TAG_LO_USE_REMOTE_SRC_TAG,
-	};
-
-	hdesc_size = cppi5_hdesc_calc_size(true, VIRT_CPSW_NAV_PS_DATA_SIZE,
-					   VIRT_CPSW_NAV_SW_DATA_SIZE);
-
-	rx_cfg.swdata_size = VIRT_CPSW_NAV_SW_DATA_SIZE;
-	rx_cfg.flow_id_num = VIRT_CPSW_MAX_RX_FLOWS;
-	rx_cfg.flow_id_base = common->rdev_rx_flow_id;
-	rx_cfg.remote = true;
-
-	/* init all flows */
-	rx_chn->dev = dev;
-	rx_chn->descs_num = max_desc_num;
-	rx_chn->desc_pool = k3_cppi_desc_pool_create_name(dev,
-							  rx_chn->descs_num,
-							  hdesc_size, "rx");
-	if (IS_ERR(rx_chn->desc_pool)) {
-		ret = PTR_ERR(rx_chn->desc_pool);
-		dev_err(dev, "Failed to create rx poll %d\n", ret);
-		goto err;
-	}
-
-	rx_chn->rx_chn = k3_udma_glue_request_rx_chn(dev, "rx", &rx_cfg);
-	if (IS_ERR(rx_chn->rx_chn)) {
-		ret = PTR_ERR(rx_chn->rx_chn);
-		dev_err(dev, "Failed to request rx dma channel %d\n", ret);
-		goto err;
-	}
-
-	common->rdev_rx_flow_id =
-			k3_udma_glue_rx_get_flow_id_base(rx_chn->rx_chn);
-	dev_dbg(dev, "used flow-id-base %u\n", common->rdev_rx_flow_id);
-
-	rx_flow_cfg.rx_cfg.size = max_desc_num;
-	rx_flow_cfg.rxfdq_cfg.size = max_desc_num;
-	ret = k3_udma_glue_rx_flow_init(rx_chn->rx_chn,
-					0, &rx_flow_cfg);
-	if (ret) {
-		dev_err(dev, "Failed to init rx flow%d %d\n", 0, ret);
-		goto err;
-	}
-
-	rx_chn->irq = k3_udma_glue_rx_get_irq(rx_chn->rx_chn, 0);
-	if (rx_chn->irq <= 0) {
-		ret = -ENXIO;
-		dev_err(dev, "Failed to get rx dma irq %d\n", rx_chn->irq);
-	}
-
-err:
-	ret1 = devm_add_action(dev, virt_cpsw_nuss_free_rx_chns, common);
-	if (ret1) {
-		dev_err(dev, "failed to add free_rx_chns action %d", ret1);
-		return ret1;
-	}
-
-	return ret;
-}
-
-static int virt_cpsw_nuss_of(struct virt_cpsw_common *common)
-{
-	struct device *dev = common->dev;
-	struct device_node *port_np;
-	struct virt_cpsw_port *port;
-	const void *mac_addr;
-	int ret;
-
-	ret = of_property_read_u32(dev->of_node, "ti,psil-base",
-				   &common->tx_psil_id_base);
-	if (ret) {
-		dev_err(dev, "ti,psil-base read fail %d\n", ret);
-		return ret;
-	}
-
-	port_np = of_get_child_by_name(dev->of_node, "virt_emac_port");
-	if (!port_np)
-		return -ENOENT;
-
-	port = &common->ports;
-	port->common = common;
-	port->name = of_get_property(port_np, "ti,label", NULL);
-
-	mac_addr = of_get_mac_address(port_np);
-	if (!IS_ERR(mac_addr))
-		ether_addr_copy(port->local_mac_addr, mac_addr);
-
-	of_node_put(port_np);
-	return 0;
-}
-
-static int virt_cpsw_nuss_rdev_init(struct virt_cpsw_common *common)
-{
-	struct rpmsg_rdev_eth_switch_attach_ext_info attach_info = { 0 };
-	struct device *dev = common->dev;
-	int ret;
-
-	ret = common->rdev_switch_ops->attach_ext(common->rdev, &attach_info);
-	if (ret) {
-		dev_err(dev, "rpmsg attach - fail %d\n", ret);
-		return ret;
-	}
-	dev_dbg(dev, "rpmsg attach_ext - rx_mtu:%d features:%08X tx_mtu[0]:%d flow_idx:%d tx_cpsw_psil_dst_id:%d mac_addr:%pM\n",
-		attach_info.rx_mtu, attach_info.features,
-		attach_info.tx_mtu[0],
-		attach_info.flow_idx,
-		attach_info.tx_cpsw_psil_dst_id,
-		attach_info.mac_addr);
-	common->rdev_features = attach_info.features;
-	common->rdev_mtu = VIRT_CPSW_MAX_PACKET_SIZE;
-	common->rdev_tx_psil_dst_id = attach_info.tx_cpsw_psil_dst_id &
-				     (~0x8000);
-	common->rdev_rx_flow_id = attach_info.flow_idx;
-	ether_addr_copy(common->rdev_mac_addr, attach_info.mac_addr);
-
-	return 0;
-}
-
-static int virt_cpsw_nuss_init_ndev(struct virt_cpsw_common *common)
-{
-	struct virt_cpsw_ndev_priv *ndev_priv;
-	struct device *dev = common->dev;
-	struct virt_cpsw_port *port;
-	int ret;
-
-	port = &common->ports;
-
-	/* alloc netdev */
-	port->ndev = devm_alloc_etherdev_mqs(common->dev,
-					     sizeof(struct virt_cpsw_ndev_priv),
-					     1, 1);
-	if (!port->ndev) {
-		dev_err(dev, "error allocating net_device\n");
-		return -ENOMEM;
-	}
-
-	ndev_priv = netdev_priv(port->ndev);
-	ndev_priv->port = port;
-	SET_NETDEV_DEV(port->ndev, dev);
-
-	if (is_valid_ether_addr(port->local_mac_addr))
-		ether_addr_copy(port->ndev->dev_addr, port->local_mac_addr);
-	else if (is_valid_ether_addr(common->rdev_mac_addr))
-		ether_addr_copy(port->ndev->dev_addr, common->rdev_mac_addr);
-
-	port->ndev->min_mtu = VIRT_CPSW_MIN_PACKET_SIZE;
-	port->ndev->max_mtu = VIRT_CPSW_MAX_PACKET_SIZE;
-	port->ndev->hw_features = NETIF_F_SG |
-				  NETIF_F_RXCSUM;
-	port->ndev->features = port->ndev->hw_features;
-	port->ndev->vlan_features |=  NETIF_F_SG;
-	port->ndev->netdev_ops = &virt_cpsw_nuss_netdev_ops;
-	port->ndev->ethtool_ops = &virt_cpsw_nuss_ethtool_ops;
-
-	/* TX checksum offload if supported */
-	if (common->rdev_features & RPMSG_KDRV_ETHSWITCH_FEATURE_TXCSUM)
-		port->ndev->features |= NETIF_F_HW_CSUM;
-
-	ndev_priv->stats = netdev_alloc_pcpu_stats(struct virt_cpsw_ndev_stats);
-	if (!ndev_priv->stats)
-		return -ENOMEM;
-
-	ret = devm_add_action_or_reset(dev, (void(*)(void *))free_percpu,
-				       ndev_priv->stats);
-	if (ret) {
-		dev_err(dev, "failed to add percpu stat free action %d", ret);
-		return ret;
-	}
-
-	netif_tx_napi_add(port->ndev, &common->napi_tx,
-			  virt_cpsw_nuss_tx_poll, NAPI_POLL_WEIGHT);
-	netif_napi_add(port->ndev, &common->napi_rx,
-		       virt_cpsw_nuss_rx_poll, NAPI_POLL_WEIGHT);
-
-	hrtimer_init(&common->tx_hrtimer, CLOCK_MONOTONIC, HRTIMER_MODE_REL_PINNED);
-	common->tx_hrtimer.function = &virt_cpsw_nuss_tx_timer_callback;
-	hrtimer_init(&common->rx_hrtimer, CLOCK_MONOTONIC, HRTIMER_MODE_REL_PINNED);
-	common->rx_hrtimer.function = &virt_cpsw_nuss_rx_timer_callback;
-
-	ret = register_netdev(port->ndev);
-	if (ret)
-		dev_err(dev, "error registering slave net device %d\n", ret);
-
-	/* can't auto unregister ndev using devm_add_action() due to broken
-	 * devres release sequence in DD core
-	 */
-
-	return ret;
-}
-
-static void virt_cpsw_nuss_cleanup_ndev(struct virt_cpsw_common *common)
-{
-	if (common->ports.ndev)
-		unregister_netdev(common->ports.ndev);
-}
-
-static bool virt_cpsw_dev_check(const struct net_device *ndev)
-{
-	return ndev->netdev_ops == &virt_cpsw_nuss_netdev_ops;
-}
-
-static int virt_cpsw_inetaddr_event(struct notifier_block *unused,
-				    unsigned long event, void *ptr)
-{
-	struct in_ifaddr *ifa = (struct in_ifaddr *)ptr;
-	struct rpmsg_remotedev_eth_switch_ops *rdev_ops;
-	struct net_device *ndev = ifa->ifa_dev->dev;
-	struct virt_cpsw_common *common;
-	int ret = 0;
-
-	if (!virt_cpsw_dev_check(ndev))
-		goto out;
-
-	common = virt_ndev_to_common(ndev);
-	rdev_ops = common->rdev_switch_ops;
-	switch (event) {
-	case NETDEV_UP:
-		ret = rdev_ops->register_ipv4(common->rdev,
-					      ndev->dev_addr,
-					      ifa->ifa_address);
-		if (ret)
-			dev_err(common->dev, "register_ipv4 rpmsg - fail %d\n",
-				ret);
-		dev_dbg(common->dev, "NETDEV_UP %pI4 %s\n",
-			&ifa->ifa_address, ifa->ifa_label);
-		break;
-
-	case NETDEV_DOWN:
-		ret = rdev_ops->unregister_ipv4(common->rdev,
-						ifa->ifa_address);
-		if (ret)
-			dev_err(common->dev, "unregister_ipv4 rpmsg - fail %d\n",
-				ret);
-		dev_dbg(common->dev, "NETDEV_DOWN %pI4\n", &ifa->ifa_address);
-		break;
-	}
-
-out:
-	return notifier_from_errno(ret);
-}
-
-static struct notifier_block virt_cpsw_inetaddr_nb __read_mostly = {
-	.notifier_call = virt_cpsw_inetaddr_event,
-};
-
-static const struct of_device_id virt_cpsw_virt_of_mtable[] = {
-	{ .compatible = "ti,j721e-cpsw-virt-mac", },
-	{ /* sentinel */ },
-};
-MODULE_DEVICE_TABLE(of, virt_cpsw_virt_of_mtable);
-
-static int virt_cpsw_nuss_probe(struct platform_device *pdev)
-{
-	struct device *dev = &pdev->dev;
-	struct virt_cpsw_common *common;
-	int ret;
-
-	common = devm_kzalloc(dev, sizeof(struct virt_cpsw_common), GFP_KERNEL);
-	if (!common)
-		return -ENOMEM;
-	common->dev = dev;
-
-	ret = of_property_read_string(dev->of_node, "ti,remote-name",
-				      &common->rdev_name);
-	if (ret < 0) {
-		dev_info(dev, "remote-name is not set %d\n", ret);
-		return ret;
-	}
-
-	common->rdev = rpmsg_remotedev_get_named_device(common->rdev_name);
-	if (!common->rdev)
-		return -EPROBE_DEFER;
-	if (IS_ERR(common->rdev)) {
-		ret = PTR_ERR(common->rdev);
-		return ret;
-	}
-	common->rdev_switch_ops = common->rdev->device.eth_switch.ops;
-	ret = devm_add_action_or_reset(dev,
-				       (void(*)(void *))rpmsg_remotedev_put_device,
-				       common->rdev);
-	if (ret) {
-		dev_err(dev, "add remotedev put device action fail:%d", ret);
-		return ret;
-	}
-
-	ret = virt_cpsw_nuss_of(common);
-	if (ret)
-		return ret;
-
-	ret = virt_cpsw_nuss_rdev_init(common);
-	if (ret)
-		return ret;
-	/* init tx channels */
-	ret = virt_cpsw_nuss_init_tx_chns(common);
-	if (ret)
-		return ret;
-	ret = virt_cpsw_nuss_init_rx_chns(common);
-	if (ret)
-		return ret;
-
-	if (common->tx_chns.irq == 0 || common->rx_chns.irq == 0)
-		return -ENXIO;
-
-	dev_set_drvdata(dev, common);
-
-	ret = virt_cpsw_nuss_init_ndev(common);
-	if (ret)
-		return ret;
-
-	ret = dma_coerce_mask_and_coherent(dev, DMA_BIT_MASK(48));
-	if (ret) {
-		dev_err(dev, "error setting dma mask: %d\n", ret);
-		goto unreg_ndev;
-	}
-
-	ret = devm_request_irq(dev, common->tx_chns.irq,
-			       virt_cpsw_nuss_tx_irq,
-			       IRQF_TRIGGER_HIGH, dev_name(dev), common);
-	if (ret) {
-		dev_err(dev, "failure requesting tx irq %u, %d\n",
-			common->tx_chns.irq, ret);
-		goto unreg_ndev;
-	}
-
-	ret = devm_request_irq(dev, common->rx_chns.irq,
-			       virt_cpsw_nuss_rx_irq,
-			       IRQF_TRIGGER_HIGH, dev_name(dev), common);
-	if (ret) {
-		dev_err(dev, "failure requesting rx irq %u, %d\n",
-			common->rx_chns.irq, ret);
-		goto unreg_ndev;
-	}
-
-	register_inetaddr_notifier(&virt_cpsw_inetaddr_nb);
-
-	dev_info(common->dev, "virt_cpsw_nuss mac loaded\n");
-	dev_info(dev, "rdev_features:%08X rdev_mtu:%d flow_id:%d tx_psil_dst_id:%04X\n",
-		 common->rdev_features,
-		 common->rdev_mtu,
-		 common->rdev_rx_flow_id,
-		 common->rdev_tx_psil_dst_id);
-	dev_info(dev, "local_mac_addr:%pM rdev_mac_addr:%pM\n",
-		 common->ports.local_mac_addr,
-		 common->rdev_mac_addr);
-
-	return 0;
-
-unreg_ndev:
-	virt_cpsw_nuss_cleanup_ndev(common);
-	return ret;
-}
-
-static int virt_cpsw_nuss_remove(struct platform_device *pdev)
-{
-	struct virt_cpsw_common *common = platform_get_drvdata(pdev);
-	struct device *dev = common->dev;
-	int ret;
-
-	unregister_inetaddr_notifier(&virt_cpsw_inetaddr_nb);
-
-	/* must unregister ndevs here because DD release_driver routine calls
-	 * dma_deconfigure(dev) before devres_release_all(dev)
-	 */
-	virt_cpsw_nuss_cleanup_ndev(common);
-
-	ret = common->rdev_switch_ops->detach(common->rdev);
-	if (ret)
-		dev_err(dev, "rpmsg  detach - fail %d\n", ret);
-
-	return 0;
-}
-
-static struct platform_driver virt_cpsw_nuss_driver = {
-	.driver = {
-		.name = VIRT_CPSW_DRV_NAME,
-		.of_match_table = virt_cpsw_virt_of_mtable,
-	},
-	.probe = virt_cpsw_nuss_probe,
-	.remove = virt_cpsw_nuss_remove,
-};
-
-module_platform_driver(virt_cpsw_nuss_driver);
-
-MODULE_LICENSE("GPL v2");
-MODULE_AUTHOR("Grygorii Strashko <grygorii.strashko@ti.com>");
-MODULE_DESCRIPTION("TI J721E VIRT CPSW Ethernet mac driver");
diff --git a/drivers/net/ethernet/ti/netcp_core.c b/drivers/net/ethernet/ti/netcp_core.c
index d7a144b4a09f..dc50e948195d 100644
--- a/drivers/net/ethernet/ti/netcp_core.c
+++ b/drivers/net/ethernet/ti/netcp_core.c
@@ -1350,8 +1350,8 @@ int netcp_txpipe_open(struct netcp_tx_pipe *tx_pipe)
 	tx_pipe->dma_queue = knav_queue_open(name, tx_pipe->dma_queue_id,
 					     KNAV_QUEUE_SHARED);
 	if (IS_ERR(tx_pipe->dma_queue)) {
-		dev_err(dev, "Could not open DMA queue for channel \"%s\": %d\n",
-			name, ret);
+		dev_err(dev, "Could not open DMA queue for channel \"%s\": %pe\n",
+			name, tx_pipe->dma_queue);
 		ret = PTR_ERR(tx_pipe->dma_queue);
 		goto err;
 	}
diff --git a/drivers/net/ethernet/ti/prueth.h b/drivers/net/ethernet/ti/prueth.h
deleted file mode 100644
index efe813728e99..000000000000
--- a/drivers/net/ethernet/ti/prueth.h
+++ /dev/null
@@ -1,487 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-
-/* PRU ICSS Ethernet driver
- *
- * Copyright (C) 2015-2021 Texas Instruments Incorporated - https://www.ti.com
- */
-
-#ifndef __NET_TI_PRUETH_H
-#define __NET_TI_PRUETH_H
-
-#include <linux/types.h>
-#include <linux/phy.h>
-#include <linux/pruss.h>
-#include <linux/types.h>
-#include <net/lredev.h>
-
-#include "icss_switch.h"
-#include "prueth_ptp.h"
-
-#define PRUETH_NUMQUEUES	5
-
-/* PRUSS local memory map */
-#define ICSS_LOCAL_SHARED_RAM   0x00010000
-
-#define EMAC_POLL_WEIGHT	(64) /* Default NAPI poll weight */
-#define EMAC_MAX_PKTLEN		(ETH_HLEN + VLAN_HLEN + ETH_DATA_LEN)
-
-#define PRUETH_NSP_TIMER_MS	(100) /* Refresh NSP counters every 100ms */
-/* default timer for NSP and HSR/PRP */
-#define PRUETH_TIMER_MS	(10)
-
-#define PRUETH_REG_DUMP_VER		1
-
-/* Encoding: 32-16: Reserved, 16-8: Reg dump version, 8-0: Ethertype  */
-#define PRUETH_REG_DUMP_GET_VER(x)	((PRUETH_REG_DUMP_VER << 8) | ((x)->eth_type))
-
-/* PRU Ethernet Type - Ethernet functionality (protocol
- * implemented) provided by the PRU firmware being loaded.
- */
-enum pruss_ethtype {
-	PRUSS_ETHTYPE_EMAC = 0,
-	PRUSS_ETHTYPE_HSR,
-	PRUSS_ETHTYPE_PRP,
-	PRUSS_ETHTYPE_SWITCH,
-	PRUSS_ETHTYPE_MAX,
-};
-
-#define PRUETH_IS_EMAC(p)	((p)->eth_type == PRUSS_ETHTYPE_EMAC)
-#define PRUETH_IS_SWITCH(p)	((p)->eth_type == PRUSS_ETHTYPE_SWITCH)
-#define PRUETH_IS_HSR(p)	((p)->eth_type == PRUSS_ETHTYPE_HSR)
-#define PRUETH_IS_PRP(p)	((p)->eth_type == PRUSS_ETHTYPE_PRP)
-#define PRUETH_IS_LRE(p)	(PRUETH_IS_HSR(p) || PRUETH_IS_PRP(p))
-
-/**
- * struct prueth_queue_desc - Queue descriptor
- * @rd_ptr:	Read pointer, points to a buffer descriptor in Shared PRU RAM.
- * @wr_ptr:	Write pointer, points to a buffer descriptor in Shared PRU RAM.
- * @busy_s:	Slave queue busy flag, set by slave(us) to request access from
- *		master(PRU).
- * @status:	Bit field status register, Bits:
- *			0: Master queue busy flag.
- *			1: Packet has been placed in collision queue.
- *			2: Packet has been discarded due to overflow.
- * @max_fill_level:	Maximum queue usage seen.
- * @overflow_cnt:	Count of queue overflows.
- *
- * Each port has up to 4 queues with variable length. The queue is processed
- * as ring buffer with read and write pointers. Both pointers are address
- * pointers and increment by 4 for each buffer descriptor position. Queue has
- * a length defined in constants and a status.
- */
-struct prueth_queue_desc {
-	u16 rd_ptr;
-	u16 wr_ptr;
-	u8 busy_s;
-	u8 status;
-	u8 max_fill_level;
-	u8 overflow_cnt;
-} __packed;
-
-/**
- * struct prueth_queue - Information about a queue in memory
- * @buffer_offset: buffer offset in OCMC RAM
- * @queue_desc_offset: queue descriptor offset in Shared RAM
- * @buffer_desc_offset: buffer descriptors offset in Shared RAM
- * @buffer_desc_end: end address of buffer descriptors in Shared RAM
- */
-struct prueth_queue_info {
-	u16 buffer_offset;
-	u16 queue_desc_offset;
-	u16 buffer_desc_offset;
-	u16 buffer_desc_end;
-} __packed;
-
-/**
- * struct prueth_packet_info - Info about a packet in buffer
- * @start_offset: start offset of the frame in the buffer for HSR/PRP
- * @shadow: this packet is stored in the collision queue
- * @port: port packet is on
- * @length: length of packet
- * @broadcast: this packet is a broadcast packet
- * @error: this packet has an error
- * @sv_frame: indicate if the frame is a SV frame for HSR/PRP
- * @lookup_success: src mac found in FDB
- * @flood: packet is to be flooded
- * @timstamp: Specifies if timestamp is appended to the packet
- */
-struct prueth_packet_info {
-	bool start_offset;
-	bool shadow;
-	unsigned int port;
-	unsigned int length;
-	bool broadcast;
-	bool error;
-	bool sv_frame;
-	bool lookup_success;
-	bool flood;
-	bool timestamp;
-};
-
-/**
- * struct port_statistics - Statistics structure for capturing statistics
- *			    on PRUs
- * @tx_bcast: Number of broadcast packets sent
- * @tx_mcast:Number of multicast packets sent
- * @tx_ucast:Number of unicast packets sent
- *
- * @tx_octets:Number of undersized frames rcvd
- *
- * @rx_bcast:Number of broadcast packets rcvd
- * @rx_mcast:Number of multicast packets rcvd
- * @rx_ucast:Number of unicast packets rcvd
- *
- * @rx_octets:Number of Rx packets
- *
- * @tx64byte:Number of 64 byte packets sent
- * @tx65_127byte:Number of 65-127 byte packets sent
- * @tx128_255byte:Number of 128-255 byte packets sent
- * @tx256_511byte:Number of 256-511 byte packets sent
- * @tx512_1023byte:Number of 512-1023 byte packets sent
- * @tx1024byte:Number of 1024 and larger size packets sent
- *
- * @rx64byte:Number of 64 byte packets rcvd
- * @rx65_127byte:Number of 65-127 byte packets rcvd
- * @rx128_255byte:Number of 128-255 byte packets rcvd
- * @rx256_511byte:Number of 256-511 byte packets rcvd
- * @rx512_1023byte:Number of 512-1023 byte packets rcvd
- * @rx1024byte:Number of 1024 and larger size packets rcvd
- *
- * @late_coll:Number of late collisions(Half Duplex)
- * @single_coll:Number of single collisions (Half Duplex)
- * @multi_coll:Number of multiple collisions (Half Duplex)
- * @excess_coll:Number of excess collisions(Half Duplex)
- *
- * @rx_misalignment_frames:Number of non multiple of 8 byte frames rcvd
- * @stormprev_counter:Number of packets dropped because of Storm Prevention
- * @mac_rxerror:Number of MAC receive errors
- * @sfd_error:Number of invalid SFD
- * @def_tx:Number of transmissions deferred
- * @mac_txerror:Number of MAC transmit errors
- * @rx_oversized_frames:Number of oversized frames rcvd
- * @rx_undersized_frames:Number of undersized frames rcvd
- * @rx_crc_frames:Number of CRC error frames rcvd
- * @dropped_packets:Number of packets dropped due to link down on opposite port
- *
- * @tx_hwq_overflow:Hardware Tx Queue (on PRU) over flow count
- * @tx_hwq_underflow:Hardware Tx Queue (on PRU) under flow count
- *
- * @u32 cs_error: Number of carrier sense errors
- * @sqe_test_error: Number of MAC receive errors
- *
- * Above fields are aligned so that it's consistent
- * with the memory layout in PRU DRAM, this is to facilitate easy
- * memcpy. Don't change the order of the fields.
- *
- * @vlan_dropped: Number of VLAN tagged packets dropped
- * @multicast_dropped: Number of multicast packets dropped
- */
-struct port_statistics {
-	u32 tx_bcast;
-	u32 tx_mcast;
-	u32 tx_ucast;
-
-	u32 tx_octets;
-
-	u32 rx_bcast;
-	u32 rx_mcast;
-	u32 rx_ucast;
-
-	u32 rx_octets;
-
-	u32 tx64byte;
-	u32 tx65_127byte;
-	u32 tx128_255byte;
-	u32 tx256_511byte;
-	u32 tx512_1023byte;
-	u32 tx1024byte;
-
-	u32 rx64byte;
-	u32 rx65_127byte;
-	u32 rx128_255byte;
-	u32 rx256_511byte;
-	u32 rx512_1023byte;
-	u32 rx1024byte;
-
-	u32 late_coll;
-	u32 single_coll;
-	u32 multi_coll;
-	u32 excess_coll;
-
-	u32 rx_misalignment_frames;
-	u32 stormprev_counter_bc;
-	u32 stormprev_counter_mc;
-	u32 stormprev_counter_uc;
-	u32 mac_rxerror;
-	u32 sfd_error;
-	u32 def_tx;
-	u32 mac_txerror;
-	u32 rx_oversized_frames;
-	u32 rx_undersized_frames;
-	u32 rx_crc_frames;
-	u32 dropped_packets;
-
-	u32 tx_hwq_overflow;
-	u32 tx_hwq_underflow;
-
-	u32 cs_error;
-	u32 sqe_test_error;
-
-	u32 vlan_dropped;
-	u32 multicast_dropped;
-} __packed;
-
-/* In switch mode there are 3 real ports i.e. 3 mac addrs.
- * however Linux sees only the host side port. The other 2 ports
- * are the switch ports.
- * In emac mode there are 2 real ports i.e. 2 mac addrs.
- * Linux sees both the ports.
- */
-enum prueth_port {
-	PRUETH_PORT_HOST = 0,	/* host side port */
-	PRUETH_PORT_MII0,	/* physical port MII 0 */
-	PRUETH_PORT_MII1,	/* physical port MII 1 */
-};
-
-enum prueth_mac {
-	PRUETH_MAC0 = 0,
-	PRUETH_MAC1,
-	PRUETH_NUM_MACS,
-};
-
-/* In both switch & emac modes there are 3 port queues
- * EMAC mode:
- *	RX packets for both MII0 & MII1 ports come on
- *	QUEUE_HOST.
- *	TX packets for MII0 go on QUEUE_MII0, TX packets
- *	for MII1 go on QUEUE_MII1.
- * Switch mode:
- *	Host port RX packets come on QUEUE_HOST
- *	TX packets might have to go on MII0 or MII1 or both.
- *	MII0 TX queue is QUEUE_MII0 and MII1 TX queue is
- *	QUEUE_MII1.
- */
-enum prueth_port_queue_id {
-	PRUETH_PORT_QUEUE_HOST = 0,
-	PRUETH_PORT_QUEUE_MII0,
-	PRUETH_PORT_QUEUE_MII1,
-	PRUETH_PORT_QUEUE_MAX,
-};
-
-/* Each port queue has 4 queues and 1 collision queue */
-enum prueth_queue_id {
-	PRUETH_QUEUE1 = 0,
-	PRUETH_QUEUE2,
-	PRUETH_QUEUE3,
-	PRUETH_QUEUE4,
-	PRUETH_COLQUEUE,	/* collision queue */
-};
-
-/* PRUeth memory range identifiers */
-enum prueth_mem {
-	PRUETH_MEM_DRAM0 = 0,
-	PRUETH_MEM_DRAM1,
-	PRUETH_MEM_SHARED_RAM,
-	PRUETH_MEM_OCMC,
-	PRUETH_MEM_MAX,
-};
-
-/* Firmware offsets/size information */
-struct prueth_fw_offsets {
-	u32 index_array_offset;
-	u32 bin_array_offset;
-	u32 nt_array_offset;
-	u32 index_array_loc;
-	u32 bin_array_loc;
-	u32 nt_array_loc;
-	u32 index_array_max_entries;
-	u32 bin_array_max_entries;
-	u32 nt_array_max_entries;
-	u32 vlan_ctrl_byte;
-	u32 vlan_filter_tbl;
-	u32 mc_ctrl_byte;
-	u32 mc_filter_mask;
-	u32 mc_filter_tbl;
-	/* IEP wrap is used in the rx packet ordering logic and
-	 * is different for ICSSM v1.0 vs 2.1
-	 */
-	u32 iep_wrap;
-	u16 hash_mask;
-};
-
-/**
- * @fw_name: firmware names of firmware to run on PRU
- */
-struct prueth_firmware {
-	const char *fw_name[PRUSS_ETHTYPE_MAX];
-};
-
-/**
- * struct prueth_private_data - PRU Ethernet private data
- * @fw_names: firmware names to be used for PRUSS ethernet usecases
- */
-struct prueth_private_data {
-	const struct prueth_firmware fw_pru[PRUSS_NUM_PRUS];
-	bool support_lre;
-	bool support_switch;
-};
-
-struct nsp_counter {
-	unsigned long cookie;
-	u16 credit;
-};
-
-/* data for each emac port */
-struct prueth_emac {
-	struct prueth *prueth;
-	struct net_device *ndev;
-	u8 mac_addr[6];
-	u32 msg_enable;
-
-	int link;
-	int speed;
-	int duplex;
-
-	const char *phy_id;
-	struct device_node *phy_node;
-	phy_interface_t phy_if;
-	struct phy_device *phydev;
-	struct rproc *pru;
-
-	enum prueth_port port_id;
-	enum prueth_port_queue_id tx_port_queue;
-
-	enum prueth_queue_id rx_queue_start;
-	enum prueth_queue_id rx_queue_end;
-
-	enum prueth_mem dram;
-
-	int rx_irq;
-	int tx_irq;
-
-	struct prueth_queue_desc __iomem *rx_queue_descs;
-	struct prueth_queue_desc __iomem *tx_queue_descs;
-
-	struct port_statistics stats; /* stats holder when i/f is down */
-	unsigned char mc_filter_mask[ETH_ALEN];	/* for multicast filtering */
-
-	spinlock_t lock;	/* serialize access */
-	spinlock_t addr_lock;	/* serialize access to VLAN/MC filter table */
-
-	struct nsp_counter nsp_bc;
-	struct nsp_counter nsp_mc;
-	struct nsp_counter nsp_uc;
-	bool nsp_enabled;
-
-	int offload_fwd_mark;
-
-	struct sk_buff *ptp_skb[PRUETH_PTP_TS_EVENTS];
-	spinlock_t ptp_skb_lock;	/* serialize access */
-	int emac_ptp_tx_irq;
-	bool ptp_tx_enable;
-	bool ptp_rx_enable;
-};
-
-struct prueth_ndev_priority {
-	struct net_device *ndev;
-	int priority;
-};
-
-/**
- * struct prueth - PRUeth structure
- * @dev: device
- * @pruss: pruss handle
- * @pru0: rproc instance to PRU0
- * @pru1: rproc instance to PRU1
- * @mem: PRUSS memory resources we need to access
- * @sram_pool: OCMC ram pool for buffers
- * @mii_rt: regmap to mii_rt block
- * @iep: Pointer to ICSS IEP data
- *
- * @eth_node: node for each emac node
- * @emac: emac data for three ports, one host and two physical
- * @registered_netdevs: net device for each registered emac
- *
- * @hw_bridge_dev: pointer to hw_bridge device
- * @fdb_tbl: pointer to FDB table struct
- *
- * @prueth_ndev_nb: netdev notifier block
- * @prueth_sw_switchdev_notifier: non blocking switchdev notifier block
- * @prueth_sw_switchdev_bl_notifier: blocking switchdev notifier block
- *
- * @emac_configured: bit mask to configured ports
- * @br_members: bit mask indicating ports that are part of the bridge
- * @eth_type: flag indicate firmware mode (Dual emac vs Switch etc)
- * @base_mac: random mac used as physical ID for each port of a switch
- */
-struct prueth {
-	struct device *dev;
-	struct pruss *pruss;
-	struct rproc *pru0, *pru1;
-	struct pruss_mem_region mem[PRUETH_MEM_MAX];
-	struct gen_pool *sram_pool;
-	struct regmap *mii_rt;
-	struct icss_iep *iep;
-	struct hrtimer tbl_check_timer;
-	const struct prueth_private_data *fw_data;
-	struct prueth_fw_offsets *fw_offsets;
-
-	/* HSR-PRP */
-	bool support_lre;
-	struct prueth_ndev_priority *hp, *lp;
-	int rx_lpq_irq;
-	int rx_hpq_irq;
-	unsigned int hsr_mode;
-	unsigned int tbl_check_period;
-	unsigned int node_table_clear;
-	unsigned int node_table_clear_last_cmd;
-	unsigned int tbl_check_mask;
-	enum iec62439_3_tr_modes prp_tr_mode;
-	struct node_tbl	*nt;
-	struct nt_queue_t *mac_queue;
-	struct kthread_worker *nt_kworker;
-	struct kthread_work nt_work;
-	u32 rem_cnt;
-	/* lock between kthread worker and rx packet processing code */
-	spinlock_t nt_lock;
-	struct lre_statistics *lre_stats;
-
-	struct device_node *eth_node[PRUETH_NUM_MACS];
-	struct prueth_emac *emac[PRUETH_NUM_MACS];
-	struct net_device *registered_netdevs[PRUETH_NUM_MACS];
-	struct device_node *prueth_np;
-
-	struct net_device *hw_bridge_dev;
-	struct fdb_tbl *fdb_tbl;
-
-	struct notifier_block prueth_ndev_nb;
-	struct notifier_block prueth_sw_switchdev_notifier;
-	struct notifier_block prueth_sw_switchdev_bl_notifier;
-
-	unsigned int eth_type;
-	/* mutex to enter critical region in ndo_open() and
-	 * ndo_kill() as common resources for switch based firmware is
-	 * to be initialized for the first port in ndo_open() and
-	 * cleaned up on last port in ndo_stop().
-	 */
-	u8 emac_configured;
-	u8 br_members;
-	u8 base_mac[ETH_ALEN];
-};
-
-int emac_ndo_setup_tc(struct net_device *dev, enum tc_setup_type type,
-		      void *type_data);
-void parse_packet_info(struct prueth *prueth, u32 buffer_descriptor,
-		       struct prueth_packet_info *pkt_info);
-int emac_rx_packet(struct prueth_emac *emac, u16 *bd_rd_ptr,
-		   struct prueth_packet_info *pkt_info,
-		   const struct prueth_queue_info *rxqueue);
-int emac_add_del_vid(struct prueth_emac *emac,
-		     bool add, __be16 proto, u16 vid);
-
-extern const struct prueth_queue_desc queue_descs[][NUM_QUEUES];
-
-void emac_mc_filter_bin_allow(struct prueth_emac *emac, u8 hash);
-void emac_mc_filter_bin_disallow(struct prueth_emac *emac, u8 hash);
-u8 emac_get_mc_hash(u8 *mac, u8 *mask);
-#endif /* __NET_TI_PRUETH_H */
diff --git a/drivers/net/ethernet/ti/prueth_core.c b/drivers/net/ethernet/ti/prueth_core.c
deleted file mode 100644
index 14f8538772ff..000000000000
--- a/drivers/net/ethernet/ti/prueth_core.c
+++ /dev/null
@@ -1,3350 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-
-/* PRU ICSS Ethernet Driver
- *
- * Copyright (C) 2015-2021 Texas Instruments Incorporated - https://www.ti.com
- *	Roger Quadros <rogerq@ti.com>
- *	Andrew F. Davis <afd@ti.com>
- */
-
-#include <linux/etherdevice.h>
-#include <linux/genalloc.h>
-#include <linux/if_bridge.h>
-#include <linux/if_hsr.h>
-#include <linux/if_vlan.h>
-#include <linux/interrupt.h>
-#include <linux/kernel.h>
-#include <linux/mfd/syscon.h>
-#include <linux/module.h>
-#include <linux/net_tstamp.h>
-#include <linux/of.h>
-#include <linux/of_irq.h>
-#include <linux/of_mdio.h>
-#include <linux/of_net.h>
-#include <linux/of_platform.h>
-#include <linux/phy.h>
-#include <linux/pruss.h>
-#include <linux/ptp_classify.h>
-#include <linux/regmap.h>
-#include <linux/remoteproc.h>
-#include <net/pkt_cls.h>
-
-#include "prueth.h"
-#include "icss_mii_rt.h"
-#include "icss_vlan_mcast_filter_mmap.h"
-#include "prueth_lre.h"
-#include "prueth_switch.h"
-#include "icss_iep.h"
-
-#define PRUETH_MODULE_VERSION "0.2"
-#define PRUETH_MODULE_DESCRIPTION "PRUSS Ethernet driver"
-
-#define OCMC_RAM_SIZE		(SZ_64K - SZ_8K)
-#define PRUETH_ETH_TYPE_OFFSET		12
-#define PRUETH_ETH_TYPE_UPPER_SHIFT	8
-
-/* TX Minimum Inter packet gap */
-#define TX_MIN_IPG		0xb8
-
-#define TX_START_DELAY		0x40
-#define TX_CLK_DELAY_100M	0x6
-#define TX_CLK_DELAY_10M	0
-
-/* PRUSS_IEP_GLOBAL_CFG register definitions */
-#define PRUSS_IEP_GLOBAL_CFG	0
-
-#define PRUSS_IEP_GLOBAL_CFG_CNT_ENABLE		BIT(0)
-
-/* Netif debug messages possible */
-#define PRUETH_EMAC_DEBUG	(NETIF_MSG_DRV | \
-				 NETIF_MSG_PROBE | \
-				 NETIF_MSG_LINK | \
-				 NETIF_MSG_TIMER | \
-				 NETIF_MSG_IFDOWN | \
-				 NETIF_MSG_IFUP | \
-				 NETIF_MSG_RX_ERR | \
-				 NETIF_MSG_TX_ERR | \
-				 NETIF_MSG_TX_QUEUED | \
-				 NETIF_MSG_INTR | \
-				 NETIF_MSG_TX_DONE | \
-				 NETIF_MSG_RX_STATUS | \
-				 NETIF_MSG_PKTDATA | \
-				 NETIF_MSG_HW | \
-				 NETIF_MSG_WOL)
-
-static int debug_level = -1;
-module_param(debug_level, int, 0444);
-MODULE_PARM_DESC(debug_level, "PRUETH debug level (NETIF_MSG bits)");
-
-/* ensure that order of PRUSS mem regions is same as enum prueth_mem */
-static enum pruss_mem pruss_mem_ids[] = { PRUSS_MEM_DRAM0, PRUSS_MEM_DRAM1,
-					  PRUSS_MEM_SHRD_RAM2 };
-
-static struct prueth_fw_offsets fw_offsets_v2_1 = {
-	.hash_mask = ICSS_LRE_V2_1_HASH_MASK,
-	.index_array_offset = ICSS_LRE_V2_1_INDEX_ARRAY_NT,
-	.bin_array_offset = ICSS_LRE_V2_1_BIN_ARRAY,
-	.nt_array_offset = ICSS_LRE_V2_1_NODE_TABLE_NEW,
-	.index_array_loc = ICSS_LRE_V2_1_INDEX_ARRAY_LOC,
-	.bin_array_loc = ICSS_LRE_V2_1_BIN_ARRAY_LOC,
-	.nt_array_loc = ICSS_LRE_V2_1_NODE_TABLE_LOC,
-	.index_array_max_entries = ICSS_LRE_V2_1_INDEX_TBL_MAX_ENTRIES,
-	.bin_array_max_entries = ICSS_LRE_V2_1_BIN_TBL_MAX_ENTRIES,
-	.nt_array_max_entries = ICSS_LRE_V2_1_NODE_TBL_MAX_ENTRIES,
-	.iep_wrap = 0xffffffff,
-};
-
-static void prueth_set_fw_offsets(struct prueth *prueth)
-{
-	/* Set VLAN/Multicast filter control and table offsets */
-	if (PRUETH_IS_EMAC(prueth) || PRUETH_IS_SWITCH(prueth)) {
-		prueth->fw_offsets->vlan_ctrl_byte  =
-			ICSS_EMAC_FW_VLAN_FILTER_CTRL_BITMAP_OFFSET;
-		prueth->fw_offsets->vlan_filter_tbl =
-			ICSS_EMAC_FW_VLAN_FLTR_TBL_BASE_ADDR;
-
-		prueth->fw_offsets->mc_ctrl_byte  =
-			ICSS_EMAC_FW_MULTICAST_FILTER_CTRL_OFFSET;
-		prueth->fw_offsets->mc_filter_mask =
-			ICSS_EMAC_FW_MULTICAST_FILTER_MASK_OFFSET;
-		prueth->fw_offsets->mc_filter_tbl =
-			ICSS_EMAC_FW_MULTICAST_FILTER_TABLE;
-
-	} else {
-		prueth->fw_offsets->vlan_ctrl_byte  =
-			ICSS_LRE_FW_VLAN_FLTR_CTRL_BYTE;
-		prueth->fw_offsets->vlan_filter_tbl =
-			ICSS_LRE_FW_VLAN_FLTR_TBL_BASE_ADDR;
-
-		prueth->fw_offsets->mc_ctrl_byte  =
-			ICSS_LRE_FW_MULTICAST_TABLE_SEARCH_OP_CONTROL_BIT;
-		prueth->fw_offsets->mc_filter_mask =
-			ICSS_LRE_FW_MULTICAST_FILTER_MASK;
-		prueth->fw_offsets->mc_filter_tbl =
-			ICSS_LRE_FW_MULTICAST_FILTER_TABLE;
-
-	}
-}
-
-static inline u32 prueth_read_reg(struct prueth *prueth,
-				  enum prueth_mem region,
-				  unsigned int reg)
-{
-	return readl_relaxed(prueth->mem[region].va + reg);
-}
-
-static inline void prueth_write_reg(struct prueth *prueth,
-				    enum prueth_mem region,
-				    unsigned int reg, u32 val)
-{
-	writel_relaxed(val, prueth->mem[region].va + reg);
-}
-
-static inline void prueth_ptp_ts_enable(struct prueth_emac *emac)
-{
-	void __iomem *sram = emac->prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-	u8 val = 0;
-
-	if (emac->ptp_tx_enable) {
-		/* Disable fw background task */
-		val &= ~TIMESYNC_CTRL_BG_ENABLE;
-		/* Enable forced 2-step */
-		val |= TIMESYNC_CTRL_FORCED_2STEP;
-	}
-
-	writeb(val, sram + TIMESYNC_CTRL_VAR_OFFSET);
-	/* disable PTP forwarding for switch */
-	if (PRUETH_IS_SWITCH(emac->prueth))
-		writeb(1, sram + DISABLE_PTP_FRAME_FORWARDING_CTRL_OFFSET);
-}
-
-static inline void prueth_ptp_tx_ts_enable(struct prueth_emac *emac, bool enable)
-{
-	emac->ptp_tx_enable = enable;
-	prueth_ptp_ts_enable(emac);
-}
-
-static inline bool prueth_ptp_tx_ts_is_enabled(struct prueth_emac *emac)
-{
-	return !!emac->ptp_tx_enable;
-}
-
-static inline void prueth_ptp_rx_ts_enable(struct prueth_emac *emac, bool enable)
-{
-	emac->ptp_rx_enable = enable;
-	prueth_ptp_ts_enable(emac);
-}
-
-static inline bool prueth_ptp_rx_ts_is_enabled(struct prueth_emac *emac)
-{
-	return !!emac->ptp_rx_enable;
-}
-
-static inline
-void prueth_set_reg(struct prueth *prueth, enum prueth_mem region,
-		    unsigned int reg, u32 mask, u32 set)
-{
-	u32 val;
-
-	val = prueth_read_reg(prueth, region, reg);
-	val &= ~mask;
-	val |= (set & mask);
-	prueth_write_reg(prueth, region, reg, val);
-}
-
-static const struct prueth_queue_info queue_infos[][NUM_QUEUES] = {
-	[PRUETH_PORT_QUEUE_HOST] = {
-		[PRUETH_QUEUE1] = {
-			P0_Q1_BUFFER_OFFSET,
-			HOST_QUEUE_DESC_OFFSET,
-			P0_Q1_BD_OFFSET,
-			P0_Q1_BD_OFFSET + ((HOST_QUEUE_1_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE2] = {
-			P0_Q2_BUFFER_OFFSET,
-			HOST_QUEUE_DESC_OFFSET + 8,
-			P0_Q2_BD_OFFSET,
-			P0_Q2_BD_OFFSET + ((HOST_QUEUE_2_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE3] = {
-			P0_Q3_BUFFER_OFFSET,
-			HOST_QUEUE_DESC_OFFSET + 16,
-			P0_Q3_BD_OFFSET,
-			P0_Q3_BD_OFFSET + ((HOST_QUEUE_3_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE4] = {
-			P0_Q4_BUFFER_OFFSET,
-			HOST_QUEUE_DESC_OFFSET + 24,
-			P0_Q4_BD_OFFSET,
-			P0_Q4_BD_OFFSET + ((HOST_QUEUE_4_SIZE - 1) * BD_SIZE),
-		},
-	},
-	[PRUETH_PORT_QUEUE_MII0] = {
-		[PRUETH_QUEUE1] = {
-			P1_Q1_BUFFER_OFFSET,
-			P1_Q1_BUFFER_OFFSET + ((QUEUE_1_SIZE - 1) * ICSS_BLOCK_SIZE),
-			P1_Q1_BD_OFFSET,
-			P1_Q1_BD_OFFSET + ((QUEUE_1_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE2] = {
-			P1_Q2_BUFFER_OFFSET,
-			P1_Q2_BUFFER_OFFSET + ((QUEUE_2_SIZE - 1) * ICSS_BLOCK_SIZE),
-			P1_Q2_BD_OFFSET,
-			P1_Q2_BD_OFFSET + ((QUEUE_2_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE3] = {
-			P1_Q3_BUFFER_OFFSET,
-			P1_Q3_BUFFER_OFFSET + ((QUEUE_3_SIZE - 1) * ICSS_BLOCK_SIZE),
-			P1_Q3_BD_OFFSET,
-			P1_Q3_BD_OFFSET + ((QUEUE_3_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE4] = {
-			P1_Q4_BUFFER_OFFSET,
-			P1_Q4_BUFFER_OFFSET + ((QUEUE_4_SIZE - 1) * ICSS_BLOCK_SIZE),
-			P1_Q4_BD_OFFSET,
-			P1_Q4_BD_OFFSET + ((QUEUE_4_SIZE - 1) * BD_SIZE),
-		},
-	},
-	[PRUETH_PORT_QUEUE_MII1] = {
-		[PRUETH_QUEUE1] = {
-			P2_Q1_BUFFER_OFFSET,
-			P2_Q1_BUFFER_OFFSET + ((QUEUE_1_SIZE - 1) * ICSS_BLOCK_SIZE),
-			P2_Q1_BD_OFFSET,
-			P2_Q1_BD_OFFSET + ((QUEUE_1_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE2] = {
-			P2_Q2_BUFFER_OFFSET,
-			P2_Q2_BUFFER_OFFSET + ((QUEUE_2_SIZE - 1) * ICSS_BLOCK_SIZE),
-			P2_Q2_BD_OFFSET,
-			P2_Q2_BD_OFFSET + ((QUEUE_2_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE3] = {
-			P2_Q3_BUFFER_OFFSET,
-			P2_Q3_BUFFER_OFFSET + ((QUEUE_3_SIZE - 1) * ICSS_BLOCK_SIZE),
-			P2_Q3_BD_OFFSET,
-			P2_Q3_BD_OFFSET + ((QUEUE_3_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE4] = {
-			P2_Q4_BUFFER_OFFSET,
-			P2_Q4_BUFFER_OFFSET + ((QUEUE_4_SIZE - 1) * ICSS_BLOCK_SIZE),
-			P2_Q4_BD_OFFSET,
-			P2_Q4_BD_OFFSET + ((QUEUE_4_SIZE - 1) * BD_SIZE),
-		},
-	},
-};
-
-const struct prueth_queue_desc queue_descs[][NUM_QUEUES] = {
-	[PRUETH_PORT_QUEUE_HOST] = {
-		{ .rd_ptr = P0_Q1_BD_OFFSET, .wr_ptr = P0_Q1_BD_OFFSET, },
-		{ .rd_ptr = P0_Q2_BD_OFFSET, .wr_ptr = P0_Q2_BD_OFFSET, },
-		{ .rd_ptr = P0_Q3_BD_OFFSET, .wr_ptr = P0_Q3_BD_OFFSET, },
-		{ .rd_ptr = P0_Q4_BD_OFFSET, .wr_ptr = P0_Q4_BD_OFFSET, },
-	},
-	[PRUETH_PORT_QUEUE_MII0] = {
-		{ .rd_ptr = P1_Q1_BD_OFFSET, .wr_ptr = P1_Q1_BD_OFFSET, },
-		{ .rd_ptr = P1_Q2_BD_OFFSET, .wr_ptr = P1_Q2_BD_OFFSET, },
-		{ .rd_ptr = P1_Q3_BD_OFFSET, .wr_ptr = P1_Q3_BD_OFFSET, },
-		{ .rd_ptr = P1_Q4_BD_OFFSET, .wr_ptr = P1_Q4_BD_OFFSET, },
-	},
-	[PRUETH_PORT_QUEUE_MII1] = {
-		{ .rd_ptr = P2_Q1_BD_OFFSET, .wr_ptr = P2_Q1_BD_OFFSET, },
-		{ .rd_ptr = P2_Q2_BD_OFFSET, .wr_ptr = P2_Q2_BD_OFFSET, },
-		{ .rd_ptr = P2_Q3_BD_OFFSET, .wr_ptr = P2_Q3_BD_OFFSET, },
-		{ .rd_ptr = P2_Q4_BD_OFFSET, .wr_ptr = P2_Q4_BD_OFFSET, },
-	}
-};
-
-static void prueth_hostconfig(struct prueth *prueth)
-{
-	void __iomem *sram_base = prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-	void __iomem *sram;
-
-	/* queue size lookup table */
-	sram = sram_base + HOST_QUEUE_SIZE_ADDR;
-	writew(HOST_QUEUE_1_SIZE, sram);
-	writew(HOST_QUEUE_2_SIZE, sram + 2);
-	writew(HOST_QUEUE_3_SIZE, sram + 4);
-	writew(HOST_QUEUE_4_SIZE, sram + 6);
-
-	/* queue information table */
-	sram = sram_base + HOST_Q1_RX_CONTEXT_OFFSET;
-	memcpy_toio(sram, queue_infos[PRUETH_PORT_QUEUE_HOST],
-		    sizeof(queue_infos[PRUETH_PORT_QUEUE_HOST]));
-
-	/* buffer offset table */
-	sram = sram_base + HOST_QUEUE_OFFSET_ADDR;
-	writew(P0_Q1_BUFFER_OFFSET, sram);
-	writew(P0_Q2_BUFFER_OFFSET, sram + 2);
-	writew(P0_Q3_BUFFER_OFFSET, sram + 4);
-	writew(P0_Q4_BUFFER_OFFSET, sram + 6);
-
-	/* buffer descriptor offset table*/
-	sram = sram_base + HOST_QUEUE_DESCRIPTOR_OFFSET_ADDR;
-	writew(P0_Q1_BD_OFFSET, sram);
-	writew(P0_Q2_BD_OFFSET, sram + 2);
-	writew(P0_Q3_BD_OFFSET, sram + 4);
-	writew(P0_Q4_BD_OFFSET, sram + 6);
-
-	/* queue table */
-	sram = sram_base + HOST_QUEUE_DESC_OFFSET;
-	memcpy_toio(sram, queue_descs[PRUETH_PORT_QUEUE_HOST],
-		    sizeof(queue_descs[PRUETH_PORT_QUEUE_HOST]));
-}
-
-#define prueth_mii_set(dir, port, mask, set) \
-	regmap_update_bits(prueth->mii_rt, PRUSS_MII_RT_##dir##CFG##port, \
-			   PRUSS_MII_RT_##dir##CFG_##dir##_##mask, set)
-
-static void prueth_mii_init(struct prueth *prueth)
-{
-	/* Configuration of Port 0 Rx */
-	prueth_mii_set(RX, 0, ENABLE, PRUSS_MII_RT_RXCFG_RX_ENABLE);
-	prueth_mii_set(RX, 0, DATA_RDY_MODE_DIS,
-		       PRUSS_MII_RT_RXCFG_RX_DATA_RDY_MODE_DIS);
-	prueth_mii_set(RX, 0, MUX_SEL, 0x0);
-	prueth_mii_set(RX, 0, L2_EN, PRUSS_MII_RT_RXCFG_RX_L2_EN);
-	prueth_mii_set(RX, 0, CUT_PREAMBLE, PRUSS_MII_RT_RXCFG_RX_CUT_PREAMBLE);
-	prueth_mii_set(RX, 0, L2_EOF_SCLR_DIS,
-		       PRUSS_MII_RT_RXCFG_RX_L2_EOF_SCLR_DIS);
-
-	/* Configuration of Port 0 Tx */
-	prueth_mii_set(TX, 0, ENABLE, PRUSS_MII_RT_TXCFG_TX_ENABLE);
-	prueth_mii_set(TX, 0, AUTO_PREAMBLE,
-		       PRUSS_MII_RT_TXCFG_TX_AUTO_PREAMBLE);
-	prueth_mii_set(TX, 0, 32_MODE_EN, PRUSS_MII_RT_TXCFG_TX_32_MODE_EN);
-	if (!PRUETH_IS_EMAC(prueth))
-		prueth_mii_set(TX, 0, MUX_SEL, PRUSS_MII_RT_TXCFG_TX_MUX_SEL);
-	else
-		prueth_mii_set(TX, 0, MUX_SEL, 0x0);
-	prueth_mii_set(TX, 0, START_DELAY_MASK,
-		       TX_START_DELAY << PRUSS_MII_RT_TXCFG_TX_START_DELAY_SHIFT);
-	prueth_mii_set(TX, 0, CLK_DELAY_MASK,
-		       TX_CLK_DELAY_100M << PRUSS_MII_RT_TXCFG_TX_CLK_DELAY_SHIFT);
-
-	/* Configuration of Port 1 Rx */
-	prueth_mii_set(RX, 1, ENABLE, PRUSS_MII_RT_RXCFG_RX_ENABLE);
-	prueth_mii_set(RX, 1,
-		       DATA_RDY_MODE_DIS, PRUSS_MII_RT_RXCFG_RX_DATA_RDY_MODE_DIS);
-	prueth_mii_set(RX, 1, MUX_SEL, PRUSS_MII_RT_RXCFG_RX_MUX_SEL);
-	prueth_mii_set(RX, 1, L2_EN, PRUSS_MII_RT_RXCFG_RX_L2_EN);
-	prueth_mii_set(RX, 1, CUT_PREAMBLE, PRUSS_MII_RT_RXCFG_RX_CUT_PREAMBLE);
-	prueth_mii_set(RX, 1, L2_EOF_SCLR_DIS,
-		       PRUSS_MII_RT_RXCFG_RX_L2_EOF_SCLR_DIS);
-
-	/* Configuration of Port 1 Tx */
-	prueth_mii_set(TX, 1, ENABLE, PRUSS_MII_RT_TXCFG_TX_ENABLE);
-	prueth_mii_set(TX, 1, AUTO_PREAMBLE,
-		       PRUSS_MII_RT_TXCFG_TX_AUTO_PREAMBLE);
-	prueth_mii_set(TX, 1, 32_MODE_EN, PRUSS_MII_RT_TXCFG_TX_32_MODE_EN);
-	if (!PRUETH_IS_EMAC(prueth))
-		prueth_mii_set(TX, 1, MUX_SEL, 0x0);
-	else
-		prueth_mii_set(TX, 1, MUX_SEL, PRUSS_MII_RT_TXCFG_TX_MUX_SEL);
-	prueth_mii_set(TX, 1, START_DELAY_MASK,
-		       TX_START_DELAY << PRUSS_MII_RT_TXCFG_TX_START_DELAY_SHIFT);
-	prueth_mii_set(TX, 1, CLK_DELAY_MASK,
-		       TX_CLK_DELAY_100M << PRUSS_MII_RT_TXCFG_TX_CLK_DELAY_SHIFT);
-
-	/* Min frame length should be set to 64 to allow receive of standard
-	 * Ethernet frames such as PTP, LLDP that will not have the tag/rct.
-	 * Actual size written to register is size - 1 per TRM. This also
-	 * includes CRC/FCS.
-	 */
-	regmap_update_bits(prueth->mii_rt,
-			   PRUSS_MII_RT_RX_FRMS0,
-			   PRUSS_MII_RT_RX_FRMS_MIN_FRM_MASK,
-			   (PRUSS_MII_RT_RX_FRMS_MIN_FRM - 1) <<
-			   PRUSS_MII_RT_RX_FRMS_MIN_FRM_SHIFT);
-
-	regmap_update_bits(prueth->mii_rt,
-			   PRUSS_MII_RT_RX_FRMS1,
-			   PRUSS_MII_RT_RX_FRMS_MIN_FRM_MASK,
-			   (PRUSS_MII_RT_RX_FRMS_MIN_FRM - 1) <<
-			   PRUSS_MII_RT_RX_FRMS_MIN_FRM_SHIFT);
-
-	/* For EMAC, set Max frame size to 1522 i.e size with VLAN and for
-	 * HSR/PRP set it to 1528 i.e size with tag or rct. Actual size
-	 * written to register is size - 1 as per TRM. Since driver
-	 * support run time change of protocol, driver must overwrite
-	 * the values based on Ethernet type.
-	 */
-	if (PRUETH_IS_LRE(prueth)) {
-		regmap_update_bits(prueth->mii_rt,
-				   PRUSS_MII_RT_RX_FRMS0,
-				   PRUSS_MII_RT_RX_FRMS_MAX_FRM_MASK,
-				   (PRUSS_MII_RT_RX_FRMS_MAX_FRM_LRE - 1) <<
-				   PRUSS_MII_RT_RX_FRMS_MAX_FRM_SHIFT);
-
-		regmap_update_bits(prueth->mii_rt,
-				   PRUSS_MII_RT_RX_FRMS1,
-				   PRUSS_MII_RT_RX_FRMS_MAX_FRM_MASK,
-				   (PRUSS_MII_RT_RX_FRMS_MAX_FRM_LRE - 1) <<
-				   PRUSS_MII_RT_RX_FRMS_MAX_FRM_SHIFT);
-	} else {
-		regmap_update_bits(prueth->mii_rt,
-				   PRUSS_MII_RT_RX_FRMS0,
-				   PRUSS_MII_RT_RX_FRMS_MAX_FRM_MASK,
-				   (PRUSS_MII_RT_RX_FRMS_MAX - 1) <<
-				   PRUSS_MII_RT_RX_FRMS_MAX_FRM_SHIFT);
-
-		regmap_update_bits(prueth->mii_rt,
-				   PRUSS_MII_RT_RX_FRMS1,
-				   PRUSS_MII_RT_RX_FRMS_MAX_FRM_MASK,
-				   (PRUSS_MII_RT_RX_FRMS_MAX - 1) <<
-				   PRUSS_MII_RT_RX_FRMS_MAX_FRM_SHIFT);
-	}
-}
-
-static void prueth_clearmem(struct prueth *prueth, enum prueth_mem region)
-{
-	memset_io(prueth->mem[region].va, 0, prueth->mem[region].size);
-}
-
-static void prueth_hostinit(struct prueth *prueth)
-{
-	/* Clear shared RAM */
-	prueth_clearmem(prueth, PRUETH_MEM_SHARED_RAM);
-
-	/* Clear OCMC RAM */
-	prueth_clearmem(prueth, PRUETH_MEM_OCMC);
-
-	/* Clear data RAMs */
-	if (prueth->eth_node[PRUETH_MAC0])
-		prueth_clearmem(prueth, PRUETH_MEM_DRAM0);
-	if (prueth->eth_node[PRUETH_MAC1])
-		prueth_clearmem(prueth, PRUETH_MEM_DRAM1);
-
-	/* Initialize host queues in shared RAM */
-	if (!PRUETH_IS_EMAC(prueth))
-		prueth_sw_hostconfig(prueth);
-	else
-		prueth_hostconfig(prueth);
-
-	/* Configure MII_RT */
-	prueth_mii_init(prueth);
-}
-
-/* This function initialize the driver in EMAC or HSR or PRP mode
- * based on eth_type
- */
-static void prueth_init_ethernet_mode(struct prueth *prueth)
-{
-	prueth_set_fw_offsets(prueth);
-	prueth_hostinit(prueth);
-	if (PRUETH_IS_LRE(prueth))
-		prueth_lre_config(prueth);
-}
-
-static void prueth_port_enable(struct prueth_emac *emac, bool enable)
-{
-	void __iomem *port_ctrl, *vlan_ctrl;
-	struct prueth *prueth = emac->prueth;
-	u32 vlan_ctrl_offset = prueth->fw_offsets->vlan_ctrl_byte;
-	void __iomem *ram = prueth->mem[emac->dram].va;
-
-	port_ctrl = ram + PORT_CONTROL_ADDR;
-	writeb(!!enable, port_ctrl);
-
-	/* HSR/PRP firmware use a different memory and offset
-	 * for VLAN filter control
-	 */
-	if (PRUETH_IS_LRE(prueth))
-		ram = prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-	vlan_ctrl = ram + vlan_ctrl_offset;
-	writeb(!!enable, vlan_ctrl);
-}
-
-static int prueth_emac_config(struct prueth_emac *emac)
-{
-	struct prueth *prueth = emac->prueth;
-
-	/* PRU needs local shared RAM address for C28 */
-	u32 sharedramaddr = ICSS_LOCAL_SHARED_RAM;
-
-	/* PRU needs real global OCMC address for C30*/
-	u32 ocmcaddr = (u32)prueth->mem[PRUETH_MEM_OCMC].pa;
-	void __iomem *sram = prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-	void __iomem *dram_base;
-	void __iomem *mac_addr;
-	void __iomem *dram;
-
-	/* Clear data RAM */
-	prueth_clearmem(prueth, emac->dram);
-
-	dram_base = prueth->mem[emac->dram].va;
-
-	/* setup mac address */
-	mac_addr = dram_base + PORT_MAC_ADDR;
-	memcpy_toio(mac_addr, emac->mac_addr, 6);
-
-	/* queue information table */
-	dram = dram_base + TX_CONTEXT_Q1_OFFSET_ADDR;
-	memcpy_toio(dram, queue_infos[emac->port_id],
-		    sizeof(queue_infos[emac->port_id]));
-
-	/* queue table */
-	dram = dram_base + PORT_QUEUE_DESC_OFFSET;
-	memcpy_toio(dram, queue_descs[emac->port_id],
-		    sizeof(queue_descs[emac->port_id]));
-
-	emac->rx_queue_descs = sram + HOST_QUEUE_DESC_OFFSET;
-	emac->tx_queue_descs = dram;
-
-	/* Set in constant table C28 of PRU0 to ICSS Shared memory */
-	pru_rproc_set_ctable(emac->pru, PRU_C28, sharedramaddr);
-
-	/* Set in constant table C30 of PRU0 to OCMC memory */
-	pru_rproc_set_ctable(emac->pru, PRU_C30, ocmcaddr);
-
-	return 0;
-}
-
-/* update phy/port status information for firmware */
-static void emac_update_phystatus(struct prueth_emac *emac)
-{
-	struct prueth *prueth = emac->prueth;
-	enum prueth_mem region;
-	u32 phy_speed, port_status = 0;
-	u8 delay;
-
-	region = emac->dram;
-	phy_speed = emac->speed;
-	prueth_write_reg(prueth, region, PHY_SPEED_OFFSET, phy_speed);
-
-	if (phy_speed == SPEED_10)
-		delay = TX_CLK_DELAY_10M;
-	else
-		delay = TX_CLK_DELAY_100M;
-
-	if (emac->port_id) {
-		prueth_mii_set(TX, 1, CLK_DELAY_MASK,
-			       delay << PRUSS_MII_RT_TXCFG_TX_CLK_DELAY_SHIFT);
-	} else {
-		prueth_mii_set(TX, 0, CLK_DELAY_MASK,
-			       delay << PRUSS_MII_RT_TXCFG_TX_CLK_DELAY_SHIFT);
-	}
-
-	if (emac->duplex == DUPLEX_HALF)
-		port_status |= PORT_IS_HD_MASK;
-	if (emac->link)
-		port_status |= PORT_LINK_MASK;
-	writeb(port_status, prueth->mem[region].va + PORT_STATUS_OFFSET);
-}
-
-/* called back by PHY layer if there is change in link state of hw port*/
-static void emac_adjust_link(struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct phy_device *phydev = emac->phydev;
-	unsigned long flags;
-	bool new_state = false;
-
-	spin_lock_irqsave(&emac->lock, flags);
-
-	if (phydev->link) {
-		/* check the mode of operation - full/half duplex */
-		if (phydev->duplex != emac->duplex) {
-			new_state = true;
-			emac->duplex = phydev->duplex;
-		}
-		if (phydev->speed != emac->speed) {
-			new_state = true;
-			emac->speed = phydev->speed;
-		}
-		if (!emac->link) {
-			new_state = true;
-			emac->link = 1;
-		}
-	} else if (emac->link) {
-		new_state = true;
-		emac->link = 0;
-		/* defaults for no link */
-
-		/* f/w only support 10 or 100 */
-		emac->speed = SPEED_100;
-
-		/* half duplex may not be supported by f/w */
-		emac->duplex = DUPLEX_FULL;
-	}
-
-	emac_update_phystatus(emac);
-
-	if (new_state)
-		phy_print_status(phydev);
-
-	if (emac->link) {
-		/* link ON */
-		netif_carrier_on(ndev);
-
-		/* reactivate the transmit queue if it is stopped */
-		if (netif_running(ndev) && netif_queue_stopped(ndev))
-			netif_wake_queue(ndev);
-	} else {
-		/* link OFF */
-		netif_carrier_off(ndev);
-		if (!netif_queue_stopped(ndev))
-			netif_stop_queue(ndev);
-	}
-
-	spin_unlock_irqrestore(&emac->lock, flags);
-}
-
-/**
- * emac_tx_hardirq - EMAC Tx interrupt handler
- * @irq: interrupt number
- * @dev_id: pointer to net_device
- *
- * This is called whenever a packet has finished being transmitted, this clears
- * up hardware buffer space, our only task is to re-enable the transmit queue
- * if it was previously disabled due to hardware queue being full
- *
- * Returns interrupt handled condition
- */
-static irqreturn_t emac_tx_hardirq(int irq, void *dev_id)
-{
-	struct net_device *ndev = (struct net_device *)dev_id;
-
-	if (unlikely(netif_queue_stopped(ndev)))
-		netif_wake_queue(ndev);
-
-	return IRQ_HANDLED;
-}
-
-static u8 prueth_ptp_ts_event_type(struct sk_buff *skb)
-{
-	unsigned int ptp_class = ptp_classify_raw(skb);
-	struct ptp_header *hdr;
-	u8 msgtype, event_type;
-
-	if (ptp_class == PTP_CLASS_NONE)
-		return PRUETH_PTP_TS_EVENTS;
-
-	hdr = ptp_parse_header(skb, ptp_class);
-	if (!hdr)
-		return PRUETH_PTP_TS_EVENTS;
-
-	msgtype = ptp_get_msgtype(hdr, ptp_class);
-	/* Treat E2E Delay Req/Resp messages sane as P2P peer delay req/resp
-	 * in driver here since firmware stores timestamps in the same memory
-	 * location for either (since they cannot operate simultaneously
-	 * anyway)
-	 */
-	switch (msgtype & 0xf) {
-	case PTP_MSGTYPE_SYNC:
-		event_type = PRUETH_PTP_SYNC;
-		break;
-	case PTP_MSGTYPE_DELAY_REQ:
-	case PTP_MSGTYPE_PDELAY_REQ:
-		event_type = PRUETH_PTP_DLY_REQ;
-		break;
-	/* TODO: Check why PTP_MSGTYPE_DELAY_RESP needs timestamp
-	 * and need for it.
-	 */
-	case 0x9:
-	case PTP_MSGTYPE_PDELAY_RESP:
-		event_type = PRUETH_PTP_DLY_RESP;
-		break;
-	default:
-		event_type = PRUETH_PTP_TS_EVENTS;
-	}
-
-	return event_type;
-}
-
-static void prueth_ptp_tx_ts_reset(struct prueth_emac *emac, u8 event)
-{
-	void __iomem *sram = emac->prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-	u32 ts_notify_offs, ts_offs;
-
-	ts_offs = prueth_tx_ts_offs_get(emac->port_id - 1, event);
-	ts_notify_offs = prueth_tx_ts_notify_offs_get(emac->port_id - 1, event);
-
-	writeb(0, sram + ts_notify_offs);
-	memset_io(sram + ts_offs, 0, sizeof(u64));
-}
-
-static int prueth_ptp_tx_ts_enqueue(struct prueth_emac *emac, struct sk_buff *skb)
-{
-	unsigned long flags;
-	u8 event, changed = 0;
-
-	if (skb_vlan_tagged(skb)) {
-		__skb_pull(skb, VLAN_HLEN);
-		changed += VLAN_HLEN;
-	}
-
-	event = prueth_ptp_ts_event_type(skb);
-	__skb_push(skb, changed);
-	if (event == PRUETH_PTP_TS_EVENTS) {
-		netdev_err(emac->ndev, "invalid PTP event\n");
-		return -EINVAL;
-	}
-
-	spin_lock_irqsave(&emac->ptp_skb_lock, flags);
-	if (emac->ptp_skb[event]) {
-		dev_consume_skb_any(emac->ptp_skb[event]);
-		prueth_ptp_tx_ts_reset(emac, event);
-		netdev_warn(emac->ndev, "Dropped event waiting for tx ts.\n");
-	}
-
-	skb_get(skb);
-	emac->ptp_skb[event] = skb;
-	spin_unlock_irqrestore(&emac->ptp_skb_lock, flags);
-
-	return 0;
-}
-
-static irqreturn_t prueth_ptp_tx_irq_handle(int irq, void *dev)
-{
-	struct net_device *ndev = (struct net_device *)dev;
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	if (unlikely(netif_queue_stopped(ndev)))
-		netif_wake_queue(ndev);
-
-	if (prueth_ptp_tx_ts_is_enabled(emac))
-		return IRQ_WAKE_THREAD;
-
-	return IRQ_HANDLED;
-}
-
-static u64 prueth_ptp_ts_get(struct prueth_emac *emac, u32 ts_offs)
-{
-	void __iomem *sram = emac->prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-	u64 cycles;
-
-	memcpy_fromio(&cycles, sram + ts_offs, sizeof(cycles));
-	memset_io(sram + ts_offs, 0, sizeof(cycles));
-
-	return cycles;
-}
-
-static void prueth_ptp_tx_ts_get(struct prueth_emac *emac, u8 event)
-{
-	struct skb_shared_hwtstamps ssh;
-	struct sk_buff *skb;
-	unsigned long flags;
-	u64 ns;
-
-	/* get the msg from list */
-	spin_lock_irqsave(&emac->ptp_skb_lock, flags);
-	skb = emac->ptp_skb[event];
-	emac->ptp_skb[event] = NULL;
-	spin_unlock_irqrestore(&emac->ptp_skb_lock, flags);
-	if (!skb) {
-		netdev_err(emac->ndev, "no tx msg %u found waiting for ts\n",
-			   event);
-		return;
-	}
-
-	/* get timestamp */
-	ns = prueth_ptp_ts_get(emac,
-			       prueth_tx_ts_offs_get(emac->port_id - 1, event));
-	memset(&ssh, 0, sizeof(ssh));
-	ssh.hwtstamp = ns_to_ktime(ns);
-	skb_tstamp_tx(skb, &ssh);
-
-	dev_consume_skb_any(skb);
-}
-
-static irqreturn_t prueth_ptp_tx_irq_work(int irq, void *dev)
-{
-	struct prueth_emac *emac = netdev_priv(dev);
-	u32 ts_notify_offs, ts_notify_mask, i;
-	void __iomem *sram;
-
-	/* get and reset the ts notifications */
-	sram = emac->prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-	for (i = 0; i < PRUETH_PTP_TS_EVENTS; i++) {
-		ts_notify_offs = prueth_tx_ts_notify_offs_get(emac->port_id - 1,
-							      i);
-		memcpy_fromio(&ts_notify_mask, sram + ts_notify_offs,
-			      PRUETH_PTP_TS_NOTIFY_SIZE);
-		memset_io(sram + ts_notify_offs, 0, PRUETH_PTP_TS_NOTIFY_SIZE);
-
-		if (ts_notify_mask & PRUETH_PTP_TS_NOTIFY_MASK)
-			prueth_ptp_tx_ts_get(emac, i);
-	}
-
-	return IRQ_HANDLED;
-}
-
-/**
- * prueth_tx_enqueue - queue a packet to firmware for transmission
- *
- * @emac: EMAC data structure
- * @skb: packet data buffer
- * @queue_id: priority queue id
- */
-static int prueth_tx_enqueue(struct prueth_emac *emac, struct sk_buff *skb,
-			     enum prueth_queue_id queue_id)
-{
-	struct net_device *ndev = emac->ndev;
-	struct prueth *prueth = emac->prueth;
-	int pktlen;
-	struct prueth_queue_desc __iomem *queue_desc;
-	const struct prueth_queue_info *txqueue;
-	u16 bd_rd_ptr, bd_wr_ptr, update_wr_ptr;
-	int write_block, read_block, free_blocks, update_block, pkt_block_size;
-	unsigned int buffer_desc_count;
-	bool buffer_wrapped = false;
-	void *src_addr;
-	void *dst_addr;
-
-	/* OCMC RAM is not cached and write order is not important */
-	void *ocmc_ram = (__force void *)emac->prueth->mem[PRUETH_MEM_OCMC].va;
-	void __iomem *sram = prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-	void __iomem *dram;
-	u32 wr_buf_desc;
-	int ret;
-	int txport = emac->tx_port_queue; /* which port to tx: MII0 or MII1 */
-
-	if (!PRUETH_IS_EMAC(prueth))
-		dram = prueth->mem[PRUETH_MEM_DRAM1].va;
-	else
-		dram = emac->prueth->mem[emac->dram].va;
-
-	if (eth_skb_pad(skb)) {
-		if (netif_msg_tx_err(emac) && net_ratelimit())
-			netdev_err(ndev, "packet pad failed");
-		return ret;
-	}
-	src_addr = skb->data;
-	pktlen = skb->len;
-
-	/* Get the tx queue */
-	queue_desc = emac->tx_queue_descs + queue_id;
-	if (!PRUETH_IS_EMAC(prueth))
-		txqueue = &sw_queue_infos[txport][queue_id];
-	else
-		txqueue = &queue_infos[txport][queue_id];
-	buffer_desc_count = txqueue->buffer_desc_end -
-			    txqueue->buffer_desc_offset;
-	buffer_desc_count /= BD_SIZE;
-	buffer_desc_count++;
-
-	bd_rd_ptr = readw(&queue_desc->rd_ptr);
-	bd_wr_ptr = readw(&queue_desc->wr_ptr);
-
-	/* the PRU firmware deals mostly in pointers already
-	 * offset into ram, we would like to deal in indexes
-	 * within the queue we are working with for code
-	 * simplicity, calculate this here
-	 */
-	write_block = (bd_wr_ptr - txqueue->buffer_desc_offset) / BD_SIZE;
-	read_block = (bd_rd_ptr - txqueue->buffer_desc_offset) / BD_SIZE;
-	if (write_block > read_block) {
-		free_blocks = buffer_desc_count - write_block;
-		free_blocks += read_block;
-	} else if (write_block < read_block) {
-		free_blocks = read_block - write_block;
-	} else { /* they are all free */
-		free_blocks = buffer_desc_count;
-	}
-	pkt_block_size = DIV_ROUND_UP(pktlen, ICSS_BLOCK_SIZE);
-	if (pkt_block_size > free_blocks) /* out of queue space */
-		return -ENOBUFS;
-
-	/* calculate end BD address post write */
-	update_block = write_block + pkt_block_size;
-
-	/* Check for wrap around */
-	if (update_block >= buffer_desc_count) {
-		update_block %= buffer_desc_count;
-		buffer_wrapped = true;
-	}
-
-	dst_addr = ocmc_ram + txqueue->buffer_offset +
-		   (write_block * ICSS_BLOCK_SIZE);
-
-	/* Copy the data from socket buffer(DRAM) to PRU buffers(OCMC) */
-	if (buffer_wrapped) { /* wrapped around buffer */
-		int bytes = (buffer_desc_count - write_block) * ICSS_BLOCK_SIZE;
-		int remaining;
-
-		/* bytes is integral multiple of ICSS_BLOCK_SIZE but
-		 * entire packet may have fit within the last BD
-		 * if pkt_info.length is not integral multiple of
-		 * ICSS_BLOCK_SIZE
-		 */
-		if (pktlen < bytes)
-			bytes = pktlen;
-
-		/* copy non-wrapped part */
-		memcpy(dst_addr, src_addr, bytes);
-
-		/* copy wrapped part */
-		src_addr += bytes;
-		remaining = pktlen - bytes;
-		dst_addr = ocmc_ram + txqueue->buffer_offset;
-		memcpy(dst_addr, src_addr, remaining);
-	} else {
-		memcpy(dst_addr, src_addr, pktlen);
-	}
-
-	if (skb_shinfo(skb)->tx_flags & SKBTX_HW_TSTAMP &&
-	    prueth_ptp_tx_ts_is_enabled(emac)) {
-		skb_shinfo(skb)->tx_flags |= SKBTX_IN_PROGRESS;
-		prueth_ptp_tx_ts_enqueue(emac, skb);
-	}
-
-	/* update first buffer descriptor */
-	wr_buf_desc = (pktlen << PRUETH_BD_LENGTH_SHIFT) & PRUETH_BD_LENGTH_MASK;
-	if (PRUETH_IS_HSR(prueth))
-		wr_buf_desc |= BIT(PRUETH_BD_HSR_FRAME_SHIFT);
-
-	if (!PRUETH_IS_EMAC(prueth))
-		writel(wr_buf_desc, sram + bd_wr_ptr);
-	else
-		writel(wr_buf_desc, dram + bd_wr_ptr);
-
-	/* update the write pointer in this queue descriptor, the firmware
-	 * polls for this change so this will signal the start of transmission
-	 */
-	update_wr_ptr = txqueue->buffer_desc_offset + (update_block * BD_SIZE);
-	writew(update_wr_ptr, &queue_desc->wr_ptr);
-
-	return 0;
-}
-
-void parse_packet_info(struct prueth *prueth, u32 buffer_descriptor,
-		       struct prueth_packet_info *pkt_info)
-{
-	/* For HSR, start_offset indicates Tag is not present and actual
-	 * data starts at an offset of 6 bytes from start of the buffer.
-	 * For example, for Supervisor frame start_offset is set, but for
-	 * data frame it is reset. For PRP, start_offset indicate if RCT
-	 * is present in the data or not. i.e in this case, depending upon
-	 * LRE_TRANSPARENT_RECEPTION state RCT is to be stripped or not
-	 * before passing data to upper layer. Software adjust the skb->len
-	 * accordingly. TODO Support for LRE_TRANSPARENT_RECEPTION set to
-	 * passRCT is TBD.
-	 */
-	if (PRUETH_IS_LRE(prueth))
-		pkt_info->start_offset = !!(buffer_descriptor &
-					    PRUETH_BD_START_FLAG_MASK);
-	else
-		pkt_info->start_offset = false;
-
-	pkt_info->shadow = !!(buffer_descriptor & PRUETH_BD_SHADOW_MASK);
-	pkt_info->port = (buffer_descriptor & PRUETH_BD_PORT_MASK) >>
-			 PRUETH_BD_PORT_SHIFT;
-	pkt_info->length = (buffer_descriptor & PRUETH_BD_LENGTH_MASK) >>
-			   PRUETH_BD_LENGTH_SHIFT;
-	pkt_info->broadcast = !!(buffer_descriptor & PRUETH_BD_BROADCAST_MASK);
-	pkt_info->error = !!(buffer_descriptor & PRUETH_BD_ERROR_MASK);
-	if (PRUETH_IS_LRE(prueth))
-		pkt_info->sv_frame = !!(buffer_descriptor &
-					PRUETH_BD_SUP_HSR_FRAME_MASK);
-	else
-		pkt_info->sv_frame = false;
-	pkt_info->lookup_success = !!(buffer_descriptor &
-				      PRUETH_BD_LOOKUP_SUCCESS_MASK);
-	pkt_info->flood = !!(buffer_descriptor & PRUETH_BD_SW_FLOOD_MASK);
-	pkt_info->timestamp = !!(buffer_descriptor & PRUETH_BD_TIMESTAMP_MASK);
-}
-
-/* get packet from queue
- * negative for error
- */
-int emac_rx_packet(struct prueth_emac *emac, u16 *bd_rd_ptr,
-		   struct prueth_packet_info *pkt_info,
-		   const struct prueth_queue_info *rxqueue)
-{
-	struct net_device *ndev = emac->ndev;
-	struct prueth *prueth = emac->prueth;
-	int read_block, update_block, pkt_block_size;
-	bool buffer_wrapped = false, prp_rct = false;
-	unsigned int buffer_desc_count;
-	struct sk_buff *skb;
-	void *src_addr;
-	void *dst_addr;
-	u64 ts;
-
-	void *nt_dst_addr;
-	u8 macid[6];
-	/* OCMC RAM is not cached and read order is not important */
-	void *ocmc_ram = (__force void *)emac->prueth->mem[PRUETH_MEM_OCMC].va;
-	struct skb_shared_hwtstamps *ssh;
-	unsigned int actual_pkt_len;
-	u16 start_offset = 0, type;
-	u8 offset = 0, *ptr;
-
-	if (PRUETH_IS_HSR(prueth))
-		start_offset = (pkt_info->start_offset ?
-				ICSS_LRE_TAG_RCT_SIZE : 0);
-	else if (PRUETH_IS_PRP(prueth) && pkt_info->start_offset)
-		prp_rct = true;
-
-	/* the PRU firmware deals mostly in pointers already
-	 * offset into ram, we would like to deal in indexes
-	 * within the queue we are working with for code
-	 * simplicity, calculate this here
-	 */
-	buffer_desc_count = rxqueue->buffer_desc_end -
-			    rxqueue->buffer_desc_offset;
-	buffer_desc_count /= BD_SIZE;
-	buffer_desc_count++;
-	read_block = (*bd_rd_ptr - rxqueue->buffer_desc_offset) / BD_SIZE;
-	pkt_block_size = DIV_ROUND_UP(pkt_info->length, ICSS_BLOCK_SIZE);
-	if (pkt_info->timestamp)
-		pkt_block_size++;
-
-	/* calculate end BD address post read */
-	update_block = read_block + pkt_block_size;
-
-	/* Check for wrap around */
-	if (update_block >= buffer_desc_count) {
-		update_block %= buffer_desc_count;
-		if (update_block)
-			buffer_wrapped = true;
-	}
-
-	/* calculate new pointer in ram */
-	*bd_rd_ptr = rxqueue->buffer_desc_offset + (update_block * BD_SIZE);
-
-	/* Pkt len w/ HSR tag removed, If applicable */
-	actual_pkt_len = pkt_info->length - start_offset;
-
-	/* Allocate a socket buffer for this packet */
-	skb = netdev_alloc_skb_ip_align(ndev, actual_pkt_len);
-	if (!skb) {
-		if (netif_msg_rx_err(emac) && net_ratelimit())
-			netdev_err(ndev, "failed rx buffer alloc\n");
-		return -ENOMEM;
-	}
-	dst_addr = skb->data;
-	nt_dst_addr = dst_addr;
-
-	/* Get the start address of the first buffer from
-	 * the read buffer description
-	 */
-	if (pkt_info->shadow) {
-		src_addr = ocmc_ram + P0_COL_BUFFER_OFFSET;
-	} else {
-		src_addr = ocmc_ram + rxqueue->buffer_offset +
-			   (read_block * ICSS_BLOCK_SIZE);
-	}
-	src_addr += start_offset;
-
-	/* Copy the data from PRU buffers(OCMC) to socket buffer(DRAM) */
-	if (buffer_wrapped) { /* wrapped around buffer */
-		int bytes = (buffer_desc_count - read_block) * ICSS_BLOCK_SIZE;
-		int remaining;
-
-		/* bytes is integral multiple of ICSS_BLOCK_SIZE but
-		 * entire packet may have fit within the last BD
-		 * if pkt_info.length is not integral multiple of
-		 * ICSS_BLOCK_SIZE
-		 */
-		if (pkt_info->length < bytes)
-			bytes = pkt_info->length;
-
-		/* If applicable, account for the HSR tag removed */
-		bytes -= start_offset;
-
-		/* copy non-wrapped part */
-		memcpy(dst_addr, src_addr, bytes);
-
-		/* copy wrapped part */
-		dst_addr += bytes;
-		remaining = actual_pkt_len - bytes;
-		if (pkt_info->shadow)
-			src_addr += bytes;
-		else
-			src_addr = ocmc_ram + rxqueue->buffer_offset;
-		memcpy(dst_addr, src_addr, remaining);
-		src_addr += remaining;
-	} else {
-		memcpy(dst_addr, src_addr, actual_pkt_len);
-		src_addr += actual_pkt_len;
-	}
-
-	if (pkt_info->timestamp) {
-		src_addr = (void *)roundup((uintptr_t)src_addr, ICSS_BLOCK_SIZE);
-		dst_addr = &ts;
-		memcpy(dst_addr, src_addr, sizeof(ts));
-	}
-
-	if (PRUETH_IS_SWITCH(emac->prueth)) {
-		skb->offload_fwd_mark = emac->offload_fwd_mark;
-		if (!pkt_info->lookup_success)
-			prueth_sw_learn_fdb(emac, skb->data + ETH_ALEN);
-	}
-
-	if (prueth_ptp_rx_ts_is_enabled(emac) && pkt_info->timestamp) {
-		ssh = skb_hwtstamps(skb);
-		memset(ssh, 0, sizeof(*ssh));
-		ssh->hwtstamp = ns_to_ktime(ts);
-	}
-
-	/* Check if VLAN tag is present since SV payload location will change
-	 * based on that
-	 */
-	if (PRUETH_IS_LRE(prueth)) {
-		ptr = nt_dst_addr + PRUETH_ETH_TYPE_OFFSET;
-		type = (*ptr++) << PRUETH_ETH_TYPE_UPPER_SHIFT;
-		type |= *ptr++;
-		if (type == ETH_P_8021Q)
-			offset = 4;
-	}
-
-	/* TODO. The check for FW_REV_V1_0 is a workaround since
-	 * lookup of MAC address in Node table by this version of firmware
-	 * is not reliable. Once this issue is fixed in firmware, this driver
-	 * check has to be removed.
-	 */
-	if (PRUETH_IS_LRE(prueth) && !pkt_info->lookup_success) {
-		if (PRUETH_IS_PRP(prueth)) {
-			memcpy(macid,
-			       ((pkt_info->sv_frame) ?
-				nt_dst_addr + LRE_SV_FRAME_OFFSET + offset :
-				nt_dst_addr + ICSS_LRE_TAG_RCT_SIZE),
-				ICSS_LRE_TAG_RCT_SIZE);
-
-			prueth_lre_nt_insert(prueth, macid, emac->port_id,
-					     pkt_info->sv_frame,
-					     LRE_PROTO_PRP);
-
-		} else if (pkt_info->sv_frame) {
-			memcpy(macid,
-			       nt_dst_addr + LRE_SV_FRAME_OFFSET + offset,
-			       ICSS_LRE_TAG_RCT_SIZE);
-			prueth_lre_nt_insert(prueth, macid, emac->port_id,
-					     pkt_info->sv_frame,
-					     LRE_PROTO_HSR);
-		}
-	}
-
-	/* For PRP, firmware always send us RCT. So skip Tag if
-	 * prp_tr_mode is IEC62439_3_TR_REMOVE_RCT
-	 */
-	if (prp_rct && prueth->prp_tr_mode == IEC62439_3_TR_REMOVE_RCT)
-		actual_pkt_len -= ICSS_LRE_TAG_RCT_SIZE;
-
-	if (!pkt_info->sv_frame) {
-		skb_put(skb, actual_pkt_len);
-
-		if (PRUETH_IS_SWITCH(emac->prueth)) {
-			skb->offload_fwd_mark = emac->offload_fwd_mark;
-			if (!pkt_info->lookup_success)
-				prueth_sw_learn_fdb(emac, skb->data + ETH_ALEN);
-		}
-
-		/* send packet up the stack */
-		skb->protocol = eth_type_trans(skb, ndev);
-		local_bh_disable();
-		netif_receive_skb(skb);
-		local_bh_enable();
-	} else {
-		dev_kfree_skb_any(skb);
-	}
-
-	/* update stats */
-	ndev->stats.rx_bytes += actual_pkt_len;
-	ndev->stats.rx_packets++;
-
-	return 0;
-}
-
-/**
- * emac_rx_thread - EMAC Rx interrupt thread handler
- * @irq: interrupt number
- * @dev_id: pointer to net_device
- *
- * EMAC Rx Interrupt thread handler - function to process the rx frames in a
- * irq thread function. There is only limited buffer at the ingress to
- * queue the frames. As the frames are to be emptied as quickly as
- * possible to avoid overflow, irq thread is necessary. Current implementation
- * based on NAPI poll results in packet loss due to overflow at
- * the ingress queues. Industrial use case requires loss free packet
- * processing. Tests shows that with threaded irq based processing,
- * no overflow happens when receiving at ~92Mbps for MTU sized frames and thus
- * meet the requirement for industrial use case.
- *
- * Returns interrupt handled condition
- */
-static irqreturn_t emac_rx_thread(int irq, void *dev_id)
-{
-	struct net_device *ndev = (struct net_device *)dev_id;
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	int start_queue, end_queue;
-	struct prueth_queue_desc __iomem *queue_desc;
-	const struct prueth_queue_info *rxqueue;
-	u8 overflow_cnt;
-	u16 bd_rd_ptr, bd_wr_ptr, update_rd_ptr;
-	u32 rd_buf_desc;
-	void __iomem *shared_ram = emac->prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-	struct prueth_packet_info pkt_info;
-	struct net_device_stats *ndevstats = &emac->ndev->stats;
-	int i, ret, used = 0;
-	struct prueth_emac *other_emac;
-
-	other_emac = prueth->emac[other_port_id(emac->port_id) - 1];
-
-	if (PRUETH_IS_SWITCH(prueth)) {
-		start_queue = PRUETH_QUEUE1;
-		end_queue = PRUETH_QUEUE4;
-	} else {
-		start_queue = emac->rx_queue_start;
-		end_queue = emac->rx_queue_end;
-	}
-
-retry:
-	/* search host queues for packets */
-	for (i = start_queue; i <= end_queue; i++) {
-		queue_desc = emac->rx_queue_descs + i;
-		if (PRUETH_IS_SWITCH(emac->prueth))
-			rxqueue = &sw_queue_infos[PRUETH_PORT_HOST][i];
-		else
-			rxqueue = &queue_infos[PRUETH_PORT_HOST][i];
-
-		overflow_cnt = readb(&queue_desc->overflow_cnt);
-		if (overflow_cnt > 0) {
-			emac->ndev->stats.rx_over_errors += overflow_cnt;
-
-			/* reset to zero */
-			writeb(0, &queue_desc->overflow_cnt);
-		}
-
-		bd_rd_ptr = readw(&queue_desc->rd_ptr);
-		bd_wr_ptr = readw(&queue_desc->wr_ptr);
-
-		/* while packets are available in this queue */
-		while (bd_rd_ptr != bd_wr_ptr) {
-			/* get packet info from the read buffer descriptor */
-			rd_buf_desc = readl(shared_ram + bd_rd_ptr);
-			parse_packet_info(prueth, rd_buf_desc, &pkt_info);
-
-			if (pkt_info.length <= 0) {
-				/* a packet length of zero will cause us to
-				 * never move the read pointer ahead, locking
-				 * the driver, so we manually have to move it
-				 * to the write pointer, discarding all
-				 * remaining packets in this queue. This should
-				 * never happen.
-				 */
-				update_rd_ptr = bd_wr_ptr;
-				ndevstats->rx_length_errors++;
-			} else if (pkt_info.length > EMAC_MAX_PKTLEN) {
-				/* if the packet is too large we skip it but we
-				 * still need to move the read pointer ahead
-				 * and assume something is wrong with the read
-				 * pointer as the firmware should be filtering
-				 * these packets
-				 */
-				update_rd_ptr = bd_wr_ptr;
-				ndevstats->rx_length_errors++;
-			} else {
-				update_rd_ptr = bd_rd_ptr;
-				if (PRUETH_IS_SWITCH(emac->prueth)) {
-					if (pkt_info.port ==
-						other_emac->port_id) {
-						emac = other_emac;
-					}
-				}
-
-				ret = emac_rx_packet(emac, &update_rd_ptr,
-						     &pkt_info, rxqueue);
-				if (ret)
-					return IRQ_HANDLED;
-				used++;
-			}
-
-			/* after reading the buffer descriptor we clear it
-			 * to prevent improperly moved read pointer errors
-			 * from simply looking like old packets.
-			 */
-			writel(0, shared_ram + bd_rd_ptr);
-
-			/* update read pointer in queue descriptor */
-			writew(update_rd_ptr, &queue_desc->rd_ptr);
-			bd_rd_ptr = update_rd_ptr;
-		}
-	}
-
-	if (used) {
-		used = 0;
-		goto retry;
-	}
-
-	return IRQ_HANDLED;
-}
-
-/* get statistics maintained by the PRU firmware into @pstats */
-static void emac_get_stats(struct prueth_emac *emac,
-			   struct port_statistics *pstats)
-{
-	void __iomem *dram;
-
-	dram = emac->prueth->mem[emac->dram].va;
-	memcpy_fromio(pstats, dram + STATISTICS_OFFSET, STAT_SIZE);
-
-	pstats->vlan_dropped =
-		readl(dram + ICSS_EMAC_FW_VLAN_FILTER_DROP_CNT_OFFSET);
-	pstats->multicast_dropped =
-		readl(dram + ICSS_EMAC_FW_MULTICAST_FILTER_DROP_CNT_OFFSET);
-}
-
-/* set PRU firmware statistics */
-static void emac_set_stats(struct prueth_emac *emac,
-			   struct port_statistics *pstats)
-{
-	void __iomem *dram;
-
-	dram = emac->prueth->mem[emac->dram].va;
-	memcpy_toio(dram + STATISTICS_OFFSET, pstats, STAT_SIZE);
-
-	writel(pstats->vlan_dropped, dram +
-			ICSS_EMAC_FW_VLAN_FILTER_DROP_CNT_OFFSET);
-	writel(pstats->multicast_dropped, dram +
-			ICSS_EMAC_FW_MULTICAST_FILTER_DROP_CNT_OFFSET);
-}
-
-static int emac_set_boot_pru(struct prueth_emac *emac, struct net_device *ndev)
-{
-	const struct prueth_firmware *pru_firmwares;
-	struct prueth *prueth = emac->prueth;
-	const char *fw_name;
-	int ret = 0;
-
-	pru_firmwares = &prueth->fw_data->fw_pru[emac->port_id - 1];
-	fw_name = pru_firmwares->fw_name[prueth->eth_type];
-	if (!fw_name) {
-		netdev_err(ndev, "eth_type %d not supported\n",
-			   prueth->eth_type);
-		return -ENODEV;
-	}
-
-	ret = rproc_set_firmware(emac->pru, fw_name);
-	if (ret) {
-		netdev_err(ndev, "failed to set PRU0 firmware %s: %d\n",
-			   fw_name, ret);
-		return ret;
-	}
-
-	ret = rproc_boot(emac->pru);
-	if (ret) {
-		netdev_err(ndev, "failed to boot PRU0: %d\n", ret);
-		return ret;
-	}
-
-	return ret;
-}
-
-static int emac_request_irqs(struct prueth_emac *emac)
-{
-	struct net_device *ndev = emac->ndev;
-	int ret = 0;
-
-	ret = request_threaded_irq(emac->rx_irq, NULL, emac_rx_thread,
-				   IRQF_TRIGGER_HIGH | IRQF_ONESHOT,
-				   ndev->name, ndev);
-	if (ret) {
-		netdev_err(ndev, "unable to request RX IRQ\n");
-		return ret;
-	}
-
-	if (PRUETH_IS_EMAC(emac->prueth) && emac->tx_irq > 0) {
-		ret = request_irq(emac->tx_irq, emac_tx_hardirq,
-				  IRQF_TRIGGER_HIGH, ndev->name, ndev);
-		if (ret) {
-			netdev_err(ndev, "unable to request TX IRQ\n");
-			free_irq(emac->rx_irq, ndev);
-			return ret;
-		}
-	}
-
-	if (emac->emac_ptp_tx_irq) {
-		ret = request_threaded_irq(emac->emac_ptp_tx_irq,
-					   prueth_ptp_tx_irq_handle,
-					   prueth_ptp_tx_irq_work,
-					   IRQF_TRIGGER_HIGH | IRQF_ONESHOT,
-					   ndev->name, ndev);
-		if (ret) {
-			netdev_err(ndev, "unable to request PTP TX IRQ\n");
-			free_irq(emac->rx_irq, ndev);
-			free_irq(emac->tx_irq, ndev);
-		}
-	}
-
-	return ret;
-}
-
-static int emac_sanitize_feature_flags(struct prueth_emac *emac)
-{
-	if ((PRUETH_IS_HSR(emac->prueth) || PRUETH_IS_PRP(emac->prueth)) &&
-	    !(emac->ndev->features & NETIF_F_HW_HSR_TAG_RM)) {
-		netdev_err(emac->ndev, "Error: Turn ON HSR offload\n");
-		return -EINVAL;
-	}
-
-	if ((PRUETH_IS_EMAC(emac->prueth) || PRUETH_IS_SWITCH(emac->prueth)) &&
-	    (emac->ndev->features & NETIF_F_HW_HSR_TAG_RM)) {
-		netdev_err(emac->ndev, "Error: Turn OFF HSR offload\n");
-		return -EINVAL;
-	}
-
-	return 0;
-}
-
-/* Function to free memory related to sw/lre */
-static void prueth_free_memory(struct prueth *prueth)
-{
-	if (PRUETH_IS_SWITCH(prueth))
-		prueth_sw_free_fdb_table(prueth);
-	if (PRUETH_IS_LRE(prueth))
-		prueth_lre_free_memory(prueth);
-}
-
-/**
- * emac_ndo_open - EMAC device open
- * @ndev: network adapter device
- *
- * Called when system wants to start the interface.
- *
- * Returns 0 for a successful open, or appropriate error code
- */
-static int emac_ndo_open(struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	int ret;
-
-	/* set h/w MAC as user might have re-configured */
-	ether_addr_copy(emac->mac_addr, ndev->dev_addr);
-
-	netif_carrier_off(ndev);
-
-	if (!prueth->emac_configured)
-		prueth_init_ethernet_mode(prueth);
-
-	ret = emac_sanitize_feature_flags(emac);
-	if (ret)
-		return ret;
-
-	/* reset and start PRU firmware */
-	if (!PRUETH_IS_EMAC(prueth)) {
-		ret = prueth_sw_emac_config(emac);
-		if (ret)
-			return ret;
-
-		if (PRUETH_IS_SWITCH(prueth)) {
-			ret = prueth_sw_init_fdb_table(prueth);
-		} else {
-			/* HSR/PRP */
-			prueth_lre_config_check_flags(prueth);
-			ret = prueth_lre_init_node_table(prueth);
-		}
-	} else {
-		prueth_emac_config(emac);
-	}
-
-	if (ret)
-		return ret;
-
-	/* restore stats */
-	emac_set_stats(emac, &emac->stats);
-	if (PRUETH_IS_LRE(prueth))
-		prueth_lre_set_stats(prueth, prueth->lre_stats);
-
-	if (!prueth->emac_configured) {
-		ret = icss_iep_init(prueth->iep, NULL, NULL, 0);
-		if (ret) {
-			netdev_err(ndev, "Failed to initialize iep: %d\n", ret);
-			goto free_mem;
-		}
-	}
-
-	if (!PRUETH_IS_EMAC(prueth)) {
-		ret = prueth_sw_boot_prus(prueth, ndev);
-		if (ret)
-			goto iep_exit;
-	} else {
-		/* boot the PRU */
-		ret = emac_set_boot_pru(emac, ndev);
-		if (ret) {
-			netdev_err(ndev, "failed to boot PRU: %d\n", ret);
-			goto iep_exit;
-		}
-	}
-
-	if (PRUETH_IS_EMAC(prueth) || PRUETH_IS_SWITCH(prueth))
-		ret = emac_request_irqs(emac);
-	else
-		ret = prueth_lre_request_irqs(emac);
-	if (ret)
-		goto rproc_shutdown;
-
-	/* start PHY */
-	phy_start(emac->phydev);
-
-	/* enable the port and vlan */
-	prueth_port_enable(emac, true);
-
-	prueth->emac_configured |= BIT(emac->port_id);
-	if (PRUETH_IS_SWITCH(prueth))
-		prueth_sw_port_set_stp_state(prueth, emac->port_id,
-					     BR_STATE_LEARNING);
-	if (netif_msg_drv(emac))
-		dev_notice(&ndev->dev, "started\n");
-
-	return 0;
-
-rproc_shutdown:
-	if (!PRUETH_IS_EMAC(prueth))
-		prueth_sw_shutdown_prus(emac, ndev);
-	else
-		rproc_shutdown(emac->pru);
-iep_exit:
-	if (!prueth->emac_configured)
-		icss_iep_exit(prueth->iep);
-free_mem:
-	if (PRUETH_IS_SWITCH(prueth))
-		prueth_sw_free_fdb_table(prueth);
-
-	prueth_free_memory(emac->prueth);
-	return ret;
-}
-
-/**
- * emac_ndo_stop - EMAC device stop
- * @ndev: network adapter device
- *
- * Called when system wants to stop or down the interface.
- */
-static int emac_ndo_stop(struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	int i;
-
-	prueth->emac_configured &= ~BIT(emac->port_id);
-
-	/* disable the mac port */
-	prueth_port_enable(emac, false);
-
-	/* stop PHY */
-	phy_stop(emac->phydev);
-
-	/* inform the upper layers. */
-	netif_stop_queue(ndev);
-
-	netif_carrier_off(ndev);
-
-	/* Cleanup ptp related stuff for all protocols */
-	prueth_ptp_tx_ts_enable(emac, 0);
-	prueth_ptp_rx_ts_enable(emac, 0);
-	for (i = 0; i < PRUETH_PTP_TS_EVENTS; i++) {
-		if (emac->ptp_skb[i]) {
-			prueth_ptp_tx_ts_reset(emac, i);
-			dev_consume_skb_any(emac->ptp_skb[i]);
-			emac->ptp_skb[i] = NULL;
-		}
-	}
-	/* stop the PRU */
-	if (!PRUETH_IS_EMAC(prueth))
-		prueth_sw_shutdown_prus(emac, ndev);
-	else
-		rproc_shutdown(emac->pru);
-
-	/* save and lre stats */
-	emac_get_stats(emac, &emac->stats);
-	if (PRUETH_IS_LRE(prueth) && !prueth->emac_configured)
-		prueth_lre_get_stats(prueth, prueth->lre_stats);
-
-	/* free table memory of the switch */
-	if (PRUETH_IS_SWITCH(emac->prueth))
-		prueth_sw_free_fdb_table(prueth);
-
-	/* free rx and tx interrupts */
-	if (PRUETH_IS_EMAC(emac->prueth) && emac->tx_irq > 0)
-		free_irq(emac->tx_irq, ndev);
-	/* For EMAC and Switch, interrupt is per port.
-	 * So free interrupts same way
-	 */
-	if (PRUETH_IS_EMAC(emac->prueth) || PRUETH_IS_SWITCH(prueth)) {
-		free_irq(emac->rx_irq, ndev);
-		if (emac->emac_ptp_tx_irq)
-			free_irq(emac->emac_ptp_tx_irq, ndev);
-
-	} else {
-		/* Free interrupts on last port */
-		prueth_lre_free_irqs(emac);
-	}
-
-	/* free memory related to sw/lre */
-	prueth_free_memory(emac->prueth);
-
-	if (!prueth->emac_configured)
-		icss_iep_exit(prueth->iep);
-
-	if (netif_msg_drv(emac))
-		dev_notice(&ndev->dev, "stopped\n");
-
-	return 0;
-}
-
-static void prueth_change_to_switch_mode(struct prueth *prueth)
-{
-	bool portstatus[PRUETH_NUM_MACS];
-	struct prueth_emac *emac;
-	struct net_device *ndev;
-	int i, ret;
-
-	for (i = 0; i < PRUETH_NUM_MACS; i++) {
-		emac = prueth->emac[i];
-		ndev = emac->ndev;
-
-		portstatus[i] = netif_running(ndev);
-		if (!portstatus[i])
-			continue;
-
-		ret = ndev->netdev_ops->ndo_stop(ndev);
-		if (ret < 0) {
-			netdev_err(ndev, "failed to stop: %d", ret);
-			return;
-		}
-	}
-
-	prueth->eth_type = PRUSS_ETHTYPE_SWITCH;
-
-	for (i = 0; i < PRUETH_NUM_MACS; i++) {
-		emac = prueth->emac[i];
-		ndev = emac->ndev;
-
-		if (!portstatus[i])
-			continue;
-
-		ret = ndev->netdev_ops->ndo_open(ndev);
-		if (ret < 0) {
-			netdev_err(ndev, "failed to start: %d", ret);
-			return;
-		}
-	}
-
-	dev_info(prueth->dev, "TI PRU ethernet now in Switch mode\n");
-}
-
-static void prueth_change_to_emac_mode(struct prueth *prueth)
-{
-	struct prueth_emac *emac;
-	struct net_device *ndev;
-	bool portstatus[PRUETH_NUM_MACS];
-	int i, ret;
-
-	for (i = 0; i < PRUETH_NUM_MACS; i++) {
-		emac = prueth->emac[i];
-		ndev = emac->ndev;
-
-		portstatus[i] = netif_running(ndev);
-		if (!portstatus[i])
-			continue;
-
-		ret = ndev->netdev_ops->ndo_stop(ndev);
-		if (ret < 0) {
-			netdev_err(ndev, "failed to stop: %d", ret);
-			return;
-		}
-	}
-
-	prueth->eth_type = PRUSS_ETHTYPE_EMAC;
-
-	for (i = 0; i < PRUETH_NUM_MACS; i++) {
-		emac = prueth->emac[i];
-		ndev = emac->ndev;
-
-		if (!portstatus[i])
-			continue;
-
-		ret = ndev->netdev_ops->ndo_open(ndev);
-		if (ret < 0) {
-			netdev_err(ndev, "failed to start: %d", ret);
-			return;
-		}
-	}
-
-	dev_info(prueth->dev, "TI PRU ethernet now in Dual EMAC mode\n");
-}
-
-/* VLAN-tag PCP to priority queue map for EMAC used by driver. Should be
- * in sync with fw_pcp_default_priority_queue_map[]
- * Index is PCP val.
- *   low  - pcp 0..1 maps to Q4
- *              2..3 maps to Q3
- *              4..5 maps to Q2
- *   high - pcp 6..7 maps to Q1.
- *
- * VLAN-tag PCP to priority queue map for Switch/HSR/PRP used by driver
- * Index is PCP val / 2.
- *   low  - pcp 0..3 maps to Q4 for Host
- *   high - pcp 4..7 maps to Q3 for Host
- *   low  - pcp 0..3 maps to Q2 for PRU-x where x = 1 for PRUETH_PORT_MII0
- *          0 for PRUETH_PORT_MII1
- *   high - pcp 4..7 maps to Q1 for PRU-x
- */
-static const unsigned short emac_pcp_tx_priority_queue_map[] = {
-	PRUETH_QUEUE4, PRUETH_QUEUE4,
-	PRUETH_QUEUE3, PRUETH_QUEUE3,
-	PRUETH_QUEUE2, PRUETH_QUEUE2,
-	PRUETH_QUEUE1, PRUETH_QUEUE1,
-};
-
-static u16 prueth_get_tx_queue_id(struct prueth *prueth, struct sk_buff *skb)
-{
-	u16 vlan_tci, pcp;
-	int err;
-
-	err = vlan_get_tag(skb, &vlan_tci);
-	if (likely(err))
-		pcp = 0;
-	else
-		pcp = (vlan_tci & VLAN_PRIO_MASK) >> VLAN_PRIO_SHIFT;
-	/* For HSR/PRP, we use only QUEUE4 and QUEUE3 at the egress. QUEUE2 and
-	 * QUEUE1 are used for port to port traffic. Current version of SWITCH
-	 * firmware uses 4 egress queues.
-	 */
-	if (PRUETH_IS_LRE(prueth))
-		pcp >>= 1;
-
-	return emac_pcp_tx_priority_queue_map[pcp];
-}
-
-/**
- * emac_ndo_start_xmit - EMAC Transmit function
- * @skb: SKB pointer
- * @ndev: EMAC network adapter
- *
- * Called by the system to transmit a packet  - we queue the packet in
- * EMAC hardware transmit queue
- *
- * Returns success(NETDEV_TX_OK) or error code (typically out of desc's)
- */
-static int emac_ndo_start_xmit(struct sk_buff *skb, struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	int ret = 0;
-	u16 qid;
-
-	if (unlikely(!emac->link)) {
-		if (netif_msg_tx_err(emac) && net_ratelimit())
-			netdev_err(ndev, "No link to transmit");
-		goto fail_tx;
-	}
-
-	qid = prueth_get_tx_queue_id(emac->prueth, skb);
-	ret = prueth_tx_enqueue(emac, skb, qid);
-	if (ret) {
-		if (ret != -ENOBUFS && netif_msg_tx_err(emac) &&
-		    net_ratelimit())
-			netdev_err(ndev, "packet queue failed: %d\n", ret);
-		goto fail_tx;
-	}
-
-	ndev->stats.tx_packets++;
-	ndev->stats.tx_bytes += skb->len;
-	dev_kfree_skb_any(skb);
-
-	return NETDEV_TX_OK;
-
-fail_tx:
-	if (ret == -ENOBUFS) {
-		/* no free TX queue */
-		if (emac->tx_irq > 0)
-			netif_stop_queue(ndev);
-		ret = NETDEV_TX_BUSY;
-	} else {
-		/* error */
-		ndev->stats.tx_dropped++;
-		ret = NET_XMIT_DROP;
-	}
-
-	return ret;
-}
-
-/**
- * emac_ndo_tx_timeout - EMAC Transmit timeout function
- * @ndev: The EMAC network adapter
- * @txqueue: TX queue being used
- *
- * Called when system detects that a skb timeout period has expired
- * potentially due to a fault in the adapter in not being able to send
- * it out on the wire.
- */
-static void emac_ndo_tx_timeout(struct net_device *ndev, unsigned int txqueue)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	if (netif_msg_tx_err(emac))
-		netdev_err(ndev, "xmit timeout");
-
-	ndev->stats.tx_errors++;
-
-	/* TODO: can we recover or need to reboot firmware? */
-
-	netif_wake_queue(ndev);
-}
-
-/**
- * emac_ndo_getstats - EMAC get statistics function
- * @ndev: The EMAC network adapter
- *
- * Called when system wants to get statistics from the device.
- *
- * We return the statistics in net_device_stats structure pulled from emac
- */
-static struct net_device_stats *emac_ndo_get_stats(struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct port_statistics pstats;
-	struct net_device_stats *stats = &ndev->stats;
-
-	emac_get_stats(emac, &pstats);
-	stats->collisions = pstats.late_coll + pstats.single_coll +
-			    pstats.multi_coll + pstats.excess_coll;
-	stats->multicast = pstats.rx_mcast;
-
-	return stats;
-}
-
-/* enable/disable MC filter */
-static void emac_mc_filter_ctrl(struct prueth_emac *emac, bool enable)
-{
-	struct prueth *prueth = emac->prueth;
-	void __iomem *ram = prueth->mem[emac->dram].va;
-	u32 mc_ctrl_byte = prueth->fw_offsets->mc_ctrl_byte;
-	void __iomem *mc_filter_ctrl;
-	u32 reg;
-
-	if (PRUETH_IS_LRE(prueth))
-		ram = prueth->mem[PRUETH_MEM_DRAM1].va;
-
-	mc_filter_ctrl = ram + mc_ctrl_byte;
-
-	if (enable)
-		reg = ICSS_EMAC_FW_MULTICAST_FILTER_CTRL_ENABLED;
-	else
-		reg = ICSS_EMAC_FW_MULTICAST_FILTER_CTRL_DISABLED;
-
-	writeb(reg, mc_filter_ctrl);
-}
-
-/* reset MC filter bins */
-static void emac_mc_filter_reset(struct prueth_emac *emac)
-{
-	struct prueth *prueth = emac->prueth;
-	void __iomem *ram = prueth->mem[emac->dram].va;
-	u32 mc_filter_tbl_base = prueth->fw_offsets->mc_filter_tbl;
-	void __iomem *mc_filter_tbl;
-
-	if (PRUETH_IS_LRE(prueth))
-		ram = prueth->mem[PRUETH_MEM_DRAM1].va;
-
-	mc_filter_tbl = ram + mc_filter_tbl_base;
-	memset_io(mc_filter_tbl, 0, ICSS_EMAC_FW_MULTICAST_TABLE_SIZE_BYTES);
-}
-
-/* set MC filter hashmask */
-static void emac_mc_filter_hashmask(struct prueth_emac *emac,
-				    u8 mask[ICSS_EMAC_FW_MULTICAST_FILTER_MASK_SIZE_BYTES])
-{
-	struct prueth *prueth = emac->prueth;
-	void __iomem *ram = prueth->mem[emac->dram].va;
-	u32 mc_filter_mask_base = prueth->fw_offsets->mc_filter_mask;
-	void __iomem *mc_filter_mask;
-
-	if (PRUETH_IS_LRE(prueth))
-		ram = prueth->mem[PRUETH_MEM_DRAM1].va;
-
-	mc_filter_mask = ram + mc_filter_mask_base;
-	memcpy_toio(mc_filter_mask, mask,
-		    ICSS_EMAC_FW_MULTICAST_FILTER_MASK_SIZE_BYTES);
-}
-
-static void emac_mc_filter_bin_update(struct prueth_emac *emac, u8 hash, u8 val)
-{
-	struct prueth *prueth = emac->prueth;
-	u32 mc_filter_tbl_base = prueth->fw_offsets->mc_filter_tbl;
-	void __iomem *mc_filter_tbl;
-	void __iomem *ram = prueth->mem[emac->dram].va;
-
-	if (PRUETH_IS_LRE(prueth))
-		ram = prueth->mem[PRUETH_MEM_DRAM1].va;
-
-	mc_filter_tbl = ram + mc_filter_tbl_base;
-	writeb(val, mc_filter_tbl + hash);
-}
-
-void emac_mc_filter_bin_allow(struct prueth_emac *emac, u8 hash)
-{
-	emac_mc_filter_bin_update(emac, hash, ICSS_EMAC_FW_MULTICAST_FILTER_HOST_RCV_ALLOWED);
-}
-
-void emac_mc_filter_bin_disallow(struct prueth_emac *emac, u8 hash)
-{
-	emac_mc_filter_bin_update(emac, hash, ICSS_EMAC_FW_MULTICAST_FILTER_HOST_RCV_NOT_ALLOWED);
-}
-
-u8 emac_get_mc_hash(u8 *mac, u8 *mask)
-{
-	int j;
-	u8 hash;
-
-	for (j = 0, hash = 0; j < ETH_ALEN; j++)
-		hash ^= (mac[j] & mask[j]);
-
-	return hash;
-}
-
-/**
- * emac_ndo_set_rx_mode - EMAC set receive mode function
- * @ndev: The EMAC network adapter
- *
- * Called when system wants to set the receive mode of the device.
- *
- */
-static void emac_ndo_set_rx_mode(struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	void __iomem *sram = prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-	u32 reg = readl(sram + EMAC_PROMISCUOUS_MODE_OFFSET);
-	bool promisc = ndev->flags & IFF_PROMISC;
-	struct netdev_hw_addr *ha;
-	unsigned long flags;
-	u32 mask;
-	u8 hash;
-
-	if (PRUETH_IS_SWITCH(prueth)) {
-		netdev_dbg(ndev,
-			   "%s: promisc/mc filtering not supported for switch\n",
-			   __func__);
-		return;
-	}
-
-	if (promisc && PRUETH_IS_LRE(prueth)) {
-		netdev_dbg(ndev,
-			   "%s: promisc mode not supported for LRE\n",
-			   __func__);
-		return;
-	}
-
-	/* for LRE, it is a shared table. So lock the access */
-	spin_lock_irqsave(&emac->addr_lock, flags);
-
-	/* Disable and reset multicast filter, allows allmulti */
-	emac_mc_filter_ctrl(emac, false);
-	emac_mc_filter_reset(emac);
-	emac_mc_filter_hashmask(emac, emac->mc_filter_mask);
-
-	if (PRUETH_IS_EMAC(prueth)) {
-		switch (emac->port_id) {
-		case PRUETH_PORT_MII0:
-			mask = EMAC_P1_PROMISCUOUS_BIT;
-			break;
-		case PRUETH_PORT_MII1:
-			mask = EMAC_P2_PROMISCUOUS_BIT;
-			break;
-		default:
-			netdev_err(ndev, "%s: invalid port\n", __func__);
-			return;
-		}
-
-		if (promisc) {
-			/* Enable promiscuous mode */
-			reg |= mask;
-		} else {
-			/* Disable promiscuous mode */
-			reg &= ~mask;
-		}
-
-		writel(reg, sram + EMAC_PROMISCUOUS_MODE_OFFSET);
-
-		if (promisc)
-			goto unlock;
-	}
-
-	if (ndev->flags & IFF_ALLMULTI && !PRUETH_IS_SWITCH(prueth))
-		goto unlock;
-
-	emac_mc_filter_ctrl(emac, true);	/* all multicast blocked */
-
-	if (netdev_mc_empty(ndev))
-		goto unlock;
-
-	netdev_for_each_mc_addr(ha, ndev) {
-		hash = emac_get_mc_hash(ha->addr, emac->mc_filter_mask);
-		emac_mc_filter_bin_allow(emac, hash);
-	}
-
-	/* Add bridge device's MC addresses as well */
-	if (prueth->hw_bridge_dev) {
-		netdev_for_each_mc_addr(ha, prueth->hw_bridge_dev) {
-			hash = emac_get_mc_hash(ha->addr, emac->mc_filter_mask);
-			emac_mc_filter_bin_allow(emac, hash);
-		}
-	}
-
-unlock:
-	spin_unlock_irqrestore(&emac->addr_lock, flags);
-}
-
-static int emac_hwtstamp_config_set(struct net_device *ndev, struct ifreq *ifr)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct hwtstamp_config cfg;
-
-	if (copy_from_user(&cfg, ifr->ifr_data, sizeof(cfg)))
-		return -EFAULT;
-
-	/* reserved for future extensions */
-	if (cfg.flags)
-		return -EINVAL;
-
-	if (cfg.tx_type != HWTSTAMP_TX_OFF && cfg.tx_type != HWTSTAMP_TX_ON)
-		return -ERANGE;
-
-	switch (cfg.rx_filter) {
-	case HWTSTAMP_FILTER_NONE:
-		prueth_ptp_rx_ts_enable(emac, 0);
-		break;
-	case HWTSTAMP_FILTER_PTP_V2_L4_EVENT:
-	case HWTSTAMP_FILTER_PTP_V2_L4_SYNC:
-	case HWTSTAMP_FILTER_PTP_V2_L4_DELAY_REQ:
-	case HWTSTAMP_FILTER_PTP_V2_L2_EVENT:
-	case HWTSTAMP_FILTER_PTP_V2_L2_SYNC:
-	case HWTSTAMP_FILTER_PTP_V2_L2_DELAY_REQ:
-	case HWTSTAMP_FILTER_PTP_V2_EVENT:
-	case HWTSTAMP_FILTER_PTP_V2_SYNC:
-	case HWTSTAMP_FILTER_PTP_V2_DELAY_REQ:
-		prueth_ptp_rx_ts_enable(emac, 1);
-		cfg.rx_filter = HWTSTAMP_FILTER_PTP_V2_EVENT;
-		break;
-	case HWTSTAMP_FILTER_ALL:
-	case HWTSTAMP_FILTER_PTP_V1_L4_EVENT:
-	case HWTSTAMP_FILTER_PTP_V1_L4_SYNC:
-	case HWTSTAMP_FILTER_PTP_V1_L4_DELAY_REQ:
-	default:
-		return -ERANGE;
-	}
-
-	prueth_ptp_tx_ts_enable(emac, cfg.tx_type == HWTSTAMP_TX_ON);
-
-	return copy_to_user(ifr->ifr_data, &cfg, sizeof(cfg)) ? -EFAULT : 0;
-}
-
-static int emac_hwtstamp_config_get(struct net_device *ndev, struct ifreq *ifr)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct hwtstamp_config cfg;
-
-	cfg.flags = 0;
-	cfg.tx_type = prueth_ptp_tx_ts_is_enabled(emac) ?
-		      HWTSTAMP_TX_ON : HWTSTAMP_TX_OFF;
-	cfg.rx_filter = prueth_ptp_rx_ts_is_enabled(emac) ?
-			HWTSTAMP_FILTER_PTP_V2_EVENT : HWTSTAMP_FILTER_NONE;
-
-	return copy_to_user(ifr->ifr_data, &cfg, sizeof(cfg)) ? -EFAULT : 0;
-}
-
-static int emac_ndo_ioctl(struct net_device *ndev, struct ifreq *ifr, int cmd)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	switch (cmd) {
-	case SIOCSHWTSTAMP:
-		return emac_hwtstamp_config_set(ndev, ifr);
-	case SIOCGHWTSTAMP:
-		return emac_hwtstamp_config_get(ndev, ifr);
-	}
-
-	return phy_mii_ioctl(emac->phydev, ifr, cmd);
-}
-
-int emac_add_del_vid(struct prueth_emac *emac,
-		     bool add, __be16 proto, u16 vid)
-{
-	struct prueth *prueth = emac->prueth;
-	u32 vlan_filter_tbl = prueth->fw_offsets->vlan_filter_tbl;
-	void __iomem *ram = prueth->mem[emac->dram].va;
-	unsigned long flags;
-	u8 bit_index, val;
-	u16 byte_index;
-
-	if (proto != htons(ETH_P_8021Q))
-		return -EINVAL;
-
-	if (vid >= ICSS_EMAC_FW_VLAN_FILTER_VID_MAX)
-		return -EINVAL;
-
-	if (PRUETH_IS_LRE(prueth))
-		ram =  prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-
-	/* By default, VLAN ID 0 (priority tagged packets) is routed to
-	 * host, so nothing to be done if vid = 0
-	 */
-	if (!vid)
-		return 0;
-
-	/* for LRE, it is a shared table. So lock the access */
-	spin_lock_irqsave(&emac->addr_lock, flags);
-
-	/* VLAN filter table is 512 bytes (4096 bit) bitmap.
-	 * Each bit controls enabling or disabling corresponding
-	 * VID. Therefore byte index that controls a given VID is
-	 * can calculated as vid / 8 and the bit within that byte
-	 * that controls VID is given by vid % 8. Allow untagged
-	 * frames to host by default.
-	 */
-	byte_index = vid / BITS_PER_BYTE;
-	bit_index = vid % BITS_PER_BYTE;
-	val = readb(ram + vlan_filter_tbl + byte_index);
-	if (add)
-		val |= BIT(bit_index);
-	else
-		val &= ~BIT(bit_index);
-	writeb(val, ram + vlan_filter_tbl + byte_index);
-
-	spin_unlock_irqrestore(&emac->addr_lock, flags);
-
-	netdev_dbg(emac->ndev, "%s VID bit at index %d and bit %d\n",
-		   add ? "Setting" : "Clearing", byte_index, bit_index);
-
-	return 0;
-}
-
-static int emac_ndo_vlan_rx_add_vid(struct net_device *dev,
-				    __be16 proto, u16 vid)
-{
-	struct prueth_emac *emac = netdev_priv(dev);
-
-	return emac_add_del_vid(emac, true, proto, vid);
-}
-
-static int emac_ndo_vlan_rx_kill_vid(struct net_device *dev,
-				     __be16 proto, u16 vid)
-{
-	struct prueth_emac *emac = netdev_priv(dev);
-
-	return emac_add_del_vid(emac, false, proto, vid);
-}
-
-static int emac_get_port_parent_id(struct net_device *dev,
-				   struct netdev_phys_item_id *ppid)
-{
-	struct prueth_emac *emac = netdev_priv(dev);
-	struct prueth *prueth = emac->prueth;
-
-	ppid->id_len = sizeof(prueth->base_mac);
-	memcpy(&ppid->id, &prueth->base_mac, ppid->id_len);
-
-	return 0;
-}
-
-static int emac_ndo_get_phys_port_name(struct net_device *ndev, char *name,
-				       size_t len)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	int err;
-
-	err = snprintf(name, len, "p%d", emac->port_id);
-
-	if (err >= len)
-		return -EINVAL;
-
-	return 0;
-}
-
-/**
- * emac_ndo_set_features - function to set feature flag
- * @ndev: The network adapter device
- *
- * Called when ethtool -K option is invoked by user
- *
- * Change the eth_type in the prueth structure  based on hsr or prp
- * offload options from user through ethtool -K command. If the device
- * is running or if the other paired device is running, then don't accept.
- * Otherwise, set the ethernet type and offload feature flag
- *
- * Returns success if eth_type and feature flags are updated  or error
- * otherwise.
- */
-static int emac_ndo_set_features(struct net_device *ndev,
-				 netdev_features_t features)
-{
-	struct prueth_emac *emac = netdev_priv(ndev), *other_emac;
-	struct prueth *prueth = emac->prueth;
-	enum prueth_port other_port;
-	netdev_features_t wanted = features & NETIF_F_HW_HSR_TAG_RM;
-	netdev_features_t have = ndev->features & NETIF_F_HW_HSR_TAG_RM;
-	bool change_request = ((wanted ^ have) != 0);
-	int ret = -EBUSY;
-
-	if (!prueth->support_lre)
-		return 0;
-
-	if (PRUETH_IS_SWITCH(prueth)) {
-		/* Don't allow switching to HSR/PRP ethtype from Switch.
-		 * User needs to first remove eth ports from a bridge which
-		 * will automatically put the ethtype back to EMAC. So
-		 * disallow this.
-		 */
-		netdev_err(ndev,
-			   "Switch to HSR/PRP/EMAC not allowed\n");
-		return -EINVAL;
-	}
-
-	if (netif_running(ndev) && change_request) {
-		netdev_err(ndev,
-			   "Can't change feature when device runs\n");
-		return ret;
-	}
-
-	other_port = other_port_id(emac->port_id);
-	/* MAC instance index starts from 0. So index by port_id - 1 */
-	other_emac = prueth->emac[other_port - 1];
-	if (other_emac && netif_running(other_emac->ndev) && change_request) {
-		netdev_err(ndev,
-			   "Can't change feature when other device runs\n");
-		return ret;
-	}
-
-	if (features & NETIF_F_HW_HSR_TAG_RM) {
-		ndev->features |= NETIF_F_HW_HSR_TAG_RM;
-	} else if (features & NETIF_F_HW_HSR_FWD) {
-		ndev->features |= NETIF_F_HW_HSR_FWD;
-	} else {
-		prueth->eth_type = PRUSS_ETHTYPE_EMAC;
-		ndev->features &= ~(NETIF_F_HW_HSR_TAG_RM | NETIF_F_HW_HSR_FWD);
-	}
-
-	return 0;
-}
-
-static const struct net_device_ops emac_netdev_ops = {
-	.ndo_open = emac_ndo_open,
-	.ndo_stop = emac_ndo_stop,
-	.ndo_start_xmit = emac_ndo_start_xmit,
-	.ndo_set_mac_address = eth_mac_addr,
-	.ndo_validate_addr = eth_validate_addr,
-	.ndo_tx_timeout = emac_ndo_tx_timeout,
-	.ndo_get_stats = emac_ndo_get_stats,
-	.ndo_set_rx_mode = emac_ndo_set_rx_mode,
-	.ndo_do_ioctl = emac_ndo_ioctl,
-	.ndo_set_features = emac_ndo_set_features,
-	.ndo_vlan_rx_add_vid = emac_ndo_vlan_rx_add_vid,
-	.ndo_vlan_rx_kill_vid = emac_ndo_vlan_rx_kill_vid,
-	.ndo_setup_tc = emac_ndo_setup_tc,
-	.ndo_get_port_parent_id = emac_get_port_parent_id,
-	.ndo_get_phys_port_name = emac_ndo_get_phys_port_name,
-};
-
-/**
- * emac_get_drvinfo - Get EMAC driver information
- * @ndev: The network adapter
- * @info: ethtool info structure containing name and version
- *
- * Returns EMAC driver information (name and version)
- */
-static void emac_get_drvinfo(struct net_device *ndev,
-			     struct ethtool_drvinfo *info)
-{
-	strlcpy(info->driver, PRUETH_MODULE_DESCRIPTION, sizeof(info->driver));
-	strlcpy(info->version, PRUETH_MODULE_VERSION, sizeof(info->version));
-}
-
-/**
- * emac_get_link_ksettings - Get EMAC settings
- * @ndev: The network adapter
- * @ecmd: ethtool command
- *
- * Executes ethool get command
- */
-static int emac_get_link_ksettings(struct net_device *ndev,
-				   struct ethtool_link_ksettings *ecmd)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	if (!emac->phydev)
-		return -EOPNOTSUPP;
-
-	phy_ethtool_ksettings_get(emac->phydev, ecmd);
-	return 0;
-}
-
-/**
- * emac_set_link_ksettings - Set EMAC settings
- * @ndev: The EMAC network adapter
- * @ecmd: ethtool command
- *
- * Executes ethool set command
- */
-static int emac_set_link_ksettings(struct net_device *ndev,
-				   const struct ethtool_link_ksettings *ecmd)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	if (!emac->phydev)
-		return -EOPNOTSUPP;
-
-	return phy_ethtool_ksettings_set(emac->phydev, ecmd);
-}
-
-#define PRUETH_STAT_OFFSET(m) offsetof(struct port_statistics, m)
-
-static const struct {
-	char string[ETH_GSTRING_LEN];
-	u32 offset;
-} prueth_ethtool_stats[] = {
-	{"txBcast", PRUETH_STAT_OFFSET(tx_bcast)},
-	{"txMcast", PRUETH_STAT_OFFSET(tx_mcast)},
-	{"txUcast", PRUETH_STAT_OFFSET(tx_ucast)},
-	{"txOctets", PRUETH_STAT_OFFSET(tx_octets)},
-	{"rxBcast", PRUETH_STAT_OFFSET(rx_bcast)},
-	{"rxMcast", PRUETH_STAT_OFFSET(rx_mcast)},
-	{"rxUcast", PRUETH_STAT_OFFSET(rx_ucast)},
-	{"rxOctets", PRUETH_STAT_OFFSET(rx_octets)},
-
-	{"tx64byte", PRUETH_STAT_OFFSET(tx64byte)},
-	{"tx65_127byte", PRUETH_STAT_OFFSET(tx65_127byte)},
-	{"tx128_255byte", PRUETH_STAT_OFFSET(tx128_255byte)},
-	{"tx256_511byte", PRUETH_STAT_OFFSET(tx256_511byte)},
-	{"tx512_1023byte", PRUETH_STAT_OFFSET(tx512_1023byte)},
-	{"tx1024byte", PRUETH_STAT_OFFSET(tx1024byte)},
-	{"rx64byte", PRUETH_STAT_OFFSET(rx64byte)},
-	{"rx65_127byte", PRUETH_STAT_OFFSET(rx65_127byte)},
-	{"rx128_255byte", PRUETH_STAT_OFFSET(rx128_255byte)},
-	{"rx256_511byte", PRUETH_STAT_OFFSET(rx256_511byte)},
-	{"rx512_1023byte", PRUETH_STAT_OFFSET(rx512_1023byte)},
-	{"rx1024byte", PRUETH_STAT_OFFSET(rx1024byte)},
-
-	{"lateColl", PRUETH_STAT_OFFSET(late_coll)},
-	{"singleColl", PRUETH_STAT_OFFSET(single_coll)},
-	{"multiColl", PRUETH_STAT_OFFSET(multi_coll)},
-	{"excessColl", PRUETH_STAT_OFFSET(excess_coll)},
-
-	{"rxMisAlignmentFrames", PRUETH_STAT_OFFSET(rx_misalignment_frames)},
-	{"stormPrevCounterBC", PRUETH_STAT_OFFSET(stormprev_counter_bc)},
-	{"stormPrevCounterMC", PRUETH_STAT_OFFSET(stormprev_counter_mc)},
-	{"stormPrevCounterUC", PRUETH_STAT_OFFSET(stormprev_counter_uc)},
-	{"macRxError", PRUETH_STAT_OFFSET(mac_rxerror)},
-	{"SFDError", PRUETH_STAT_OFFSET(sfd_error)},
-	{"defTx", PRUETH_STAT_OFFSET(def_tx)},
-	{"macTxError", PRUETH_STAT_OFFSET(mac_txerror)},
-	{"rxOverSizedFrames", PRUETH_STAT_OFFSET(rx_oversized_frames)},
-	{"rxUnderSizedFrames", PRUETH_STAT_OFFSET(rx_undersized_frames)},
-	{"rxCRCFrames", PRUETH_STAT_OFFSET(rx_crc_frames)},
-	{"droppedPackets", PRUETH_STAT_OFFSET(dropped_packets)},
-
-	{"txHWQOverFlow", PRUETH_STAT_OFFSET(tx_hwq_overflow)},
-	{"txHWQUnderFlow", PRUETH_STAT_OFFSET(tx_hwq_underflow)},
-	{"vlanDropped", PRUETH_STAT_OFFSET(vlan_dropped)},
-	{"multicastDropped", PRUETH_STAT_OFFSET(multicast_dropped)},
-};
-
-static int emac_get_sset_count(struct net_device *ndev, int stringset)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	int a_size;
-
-	switch (stringset) {
-	case ETH_SS_STATS:
-		a_size = ARRAY_SIZE(prueth_ethtool_stats);
-		a_size += prueth_lre_get_sset_count(emac->prueth);
-
-		return a_size;
-	default:
-		return -EOPNOTSUPP;
-	}
-}
-
-static void emac_get_strings(struct net_device *ndev, u32 stringset, u8 *data)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	u8 *p = data;
-	int i;
-
-	switch (stringset) {
-	case ETH_SS_STATS:
-		for (i = 0; i < ARRAY_SIZE(prueth_ethtool_stats); i++) {
-			memcpy(p, prueth_ethtool_stats[i].string,
-			       ETH_GSTRING_LEN);
-			p += ETH_GSTRING_LEN;
-		}
-		prueth_lre_get_strings(emac->prueth, p);
-		break;
-	default:
-		break;
-	}
-}
-
-static void emac_get_ethtool_stats(struct net_device *ndev,
-				   struct ethtool_stats *stats, u64 *data)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct port_statistics pstats;
-	u32 val;
-	int i;
-	void *ptr;
-
-	emac_get_stats(emac, &pstats);
-
-	for (i = 0; i < ARRAY_SIZE(prueth_ethtool_stats); i++) {
-		ptr = &pstats;
-		ptr += prueth_ethtool_stats[i].offset;
-		val = *(u32 *)ptr;
-		data[i] = val;
-	}
-	prueth_lre_update_stats(emac->prueth, &data[i]);
-}
-
-static int emac_get_regs_len(struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-
-	/* VLAN Table at the end of the memory map, after MultiCast
-	 * filter region. So VLAN table base +
-	 * size will give the entire size of reg dump in case of
-	 * Dual-EMAC firmware.
-	 */
-	if (PRUETH_IS_EMAC(prueth) || PRUETH_IS_SWITCH(prueth)) {
-		return ICSS_EMAC_FW_VLAN_FLTR_TBL_BASE_ADDR +
-		       ICSS_EMAC_FW_VLAN_FILTER_TABLE_SIZE_BYTES;
-	}
-
-	return 0;
-}
-
-static void emac_get_regs(struct net_device *ndev, struct ethtool_regs *regs,
-			  void *p)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	void __iomem *ram;
-	u8 *reg = p;
-
-	regs->version = PRUETH_REG_DUMP_GET_VER(prueth);
-
-	/* Dump firmware's VLAN and MC tables */
-	if (PRUETH_IS_EMAC(prueth) || PRUETH_IS_SWITCH(prueth)) {
-		ram = prueth->mem[emac->dram].va;
-		memcpy_fromio(reg, ram, emac_get_regs_len(ndev));
-		return;
-	}
-}
-
-static int emac_get_ts_info(struct net_device *ndev,
-			    struct ethtool_ts_info *info)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	if ((PRUETH_IS_EMAC(emac->prueth) && !emac->emac_ptp_tx_irq))
-		return ethtool_op_get_ts_info(ndev, info);
-
-	info->so_timestamping =
-		SOF_TIMESTAMPING_TX_HARDWARE |
-		SOF_TIMESTAMPING_TX_SOFTWARE |
-		SOF_TIMESTAMPING_RX_HARDWARE |
-		SOF_TIMESTAMPING_RX_SOFTWARE |
-		SOF_TIMESTAMPING_SOFTWARE |
-		SOF_TIMESTAMPING_RAW_HARDWARE;
-
-	info->phc_index = icss_iep_get_ptp_clock_idx(emac->prueth->iep);
-	info->tx_types = BIT(HWTSTAMP_TX_OFF) | BIT(HWTSTAMP_TX_ON);
-	info->rx_filters = BIT(HWTSTAMP_FILTER_NONE) | BIT(HWTSTAMP_FILTER_PTP_V2_EVENT);
-
-	return 0;
-}
-
-/* Ethtool support for EMAC adapter */
-static const struct ethtool_ops emac_ethtool_ops = {
-	.get_drvinfo = emac_get_drvinfo,
-	.get_link_ksettings = emac_get_link_ksettings,
-	.set_link_ksettings = emac_set_link_ksettings,
-	.get_link = ethtool_op_get_link,
-	.get_ts_info = emac_get_ts_info,
-	.get_sset_count = emac_get_sset_count,
-	.get_strings = emac_get_strings,
-	.get_ethtool_stats = emac_get_ethtool_stats,
-	.get_regs = emac_get_regs,
-	.get_regs_len = emac_get_regs_len,
-};
-
-/* get emac_port corresponding to eth_node name */
-static int prueth_node_port(struct device_node *eth_node)
-{
-	if (!strcmp(eth_node->name, "ethernet-mii0"))
-		return PRUETH_PORT_MII0;
-	else if (!strcmp(eth_node->name, "ethernet-mii1"))
-		return PRUETH_PORT_MII1;
-	else
-		return -EINVAL;
-}
-
-/* get MAC instance corresponding to eth_node name */
-static int prueth_node_mac(struct device_node *eth_node)
-{
-	if (!strcmp(eth_node->name, "ethernet-mii0"))
-		return PRUETH_MAC0;
-	else if (!strcmp(eth_node->name, "ethernet-mii1"))
-		return PRUETH_MAC1;
-	else
-		return -EINVAL;
-}
-
-static int prueth_netdev_init(struct prueth *prueth,
-			      struct device_node *eth_node)
-{
-	enum prueth_port port;
-	enum prueth_mac mac;
-	struct net_device *ndev;
-	struct prueth_emac *emac;
-	const u8 *mac_addr;
-	int ret;
-
-	port = prueth_node_port(eth_node);
-	if (port < 0)
-		return -EINVAL;
-
-	mac = prueth_node_mac(eth_node);
-	if (mac < 0)
-		return -EINVAL;
-
-	ndev = devm_alloc_etherdev(prueth->dev, sizeof(*emac));
-	if (!ndev)
-		return -ENOMEM;
-
-	SET_NETDEV_DEV(ndev, prueth->dev);
-	emac = netdev_priv(ndev);
-	prueth->emac[mac] = emac;
-	emac->prueth = prueth;
-	emac->ndev = ndev;
-	emac->port_id = port;
-	memset(&emac->mc_filter_mask[0], 0xff, ETH_ALEN); /* default mask */
-
-	/* by default eth_type is EMAC */
-	switch (port) {
-	case PRUETH_PORT_MII0:
-		emac->tx_port_queue = PRUETH_PORT_QUEUE_MII0;
-
-		/* packets from MII0 are on queues 1 through 2 */
-		emac->rx_queue_start = PRUETH_QUEUE1;
-		emac->rx_queue_end = PRUETH_QUEUE2;
-
-		emac->dram = PRUETH_MEM_DRAM0;
-		emac->pru = prueth->pru0;
-		break;
-	case PRUETH_PORT_MII1:
-		emac->tx_port_queue = PRUETH_PORT_QUEUE_MII1;
-
-		/* packets from MII1 are on queues 3 through 4 */
-		emac->rx_queue_start = PRUETH_QUEUE3;
-		emac->rx_queue_end = PRUETH_QUEUE4;
-
-		emac->dram = PRUETH_MEM_DRAM1;
-		emac->pru = prueth->pru1;
-		break;
-	default:
-		return -EINVAL;
-	}
-
-	emac->rx_irq = of_irq_get_byname(eth_node, "rx");
-	if (emac->rx_irq < 0) {
-		ret = emac->rx_irq;
-		if (ret != -EPROBE_DEFER)
-			dev_err(prueth->dev, "could not get rx irq\n");
-		goto free;
-	}
-	emac->tx_irq = of_irq_get_byname(eth_node, "tx");
-	if (emac->tx_irq < 0) {
-		if (emac->tx_irq != -EPROBE_DEFER)
-			dev_dbg(prueth->dev, "tx irq not configured\n");
-	}
-
-	emac->emac_ptp_tx_irq = of_irq_get_byname(eth_node, "emac_ptp_tx");
-	if (emac->emac_ptp_tx_irq < 0) {
-		emac->emac_ptp_tx_irq = 0;
-		dev_err(prueth->dev, "could not get ptp tx irq. Skipping PTP support\n");
-	}
-
-	emac->msg_enable = netif_msg_init(debug_level, PRUETH_EMAC_DEBUG);
-	spin_lock_init(&emac->lock);
-	spin_lock_init(&emac->ptp_skb_lock);
-	spin_lock_init(&emac->addr_lock);
-
-	/* get mac address from DT and set private and netdev addr */
-	mac_addr = of_get_mac_address(eth_node);
-	if (!IS_ERR(mac_addr))
-		ether_addr_copy(ndev->dev_addr, mac_addr);
-	if (!is_valid_ether_addr(ndev->dev_addr)) {
-		eth_hw_addr_random(ndev);
-		dev_warn(prueth->dev, "port %d: using random MAC addr: %pM\n",
-			 port, ndev->dev_addr);
-	}
-	ether_addr_copy(emac->mac_addr, ndev->dev_addr);
-
-	emac->phy_node = of_parse_phandle(eth_node, "phy-handle", 0);
-	if (!emac->phy_node) {
-		dev_err(prueth->dev, "couldn't find phy-handle\n");
-		ret = -ENODEV;
-		goto free;
-	}
-
-	ret = of_get_phy_mode(eth_node, &emac->phy_if);
-	if (ret) {
-		dev_err(prueth->dev, "could not get phy-mode property err %d\n", ret);
-		goto free;
-	}
-
-	/* connect PHY */
-	emac->phydev = of_phy_connect(ndev, emac->phy_node,
-				      &emac_adjust_link, 0, emac->phy_if);
-	if (!emac->phydev) {
-		dev_dbg(prueth->dev, "couldn't connect to phy %s\n",
-			emac->phy_node->full_name);
-		ret = -EPROBE_DEFER;
-		goto free;
-	}
-
-	/* remove unsupported modes */
-	phy_remove_link_mode(emac->phydev, ETHTOOL_LINK_MODE_10baseT_Half_BIT);
-	phy_remove_link_mode(emac->phydev, ETHTOOL_LINK_MODE_10baseT_Full_BIT);
-
-	if (of_property_read_bool(eth_node, "ti,no-half-duplex")) {
-		phy_remove_link_mode(emac->phydev,
-				     ETHTOOL_LINK_MODE_100baseT_Half_BIT);
-	}
-
-	phy_remove_link_mode(emac->phydev, ETHTOOL_LINK_MODE_Pause_BIT);
-	phy_remove_link_mode(emac->phydev, ETHTOOL_LINK_MODE_Asym_Pause_BIT);
-
-	ndev->features |= NETIF_F_HW_VLAN_CTAG_FILTER | NETIF_F_HW_TC;
-
-	if (prueth->support_lre)
-		ndev->hw_features |= (NETIF_F_HW_HSR_FWD | NETIF_F_HW_HSR_TAG_RM);
-
-	ndev->hw_features |= NETIF_F_HW_VLAN_CTAG_FILTER;
-
-	ndev->netdev_ops = &emac_netdev_ops;
-	ndev->ethtool_ops = &emac_ethtool_ops;
-	if (prueth->support_lre)
-		ndev->lredev_ops = &prueth_lredev_ops;
-
-	/* for HSR/PRP */
-	if (prueth->support_lre && emac->port_id == PRUETH_PORT_MII0) {
-		prueth->hp->ndev = ndev;
-		prueth->hp->priority = 0;
-		prueth->lp->ndev = ndev;
-		prueth->lp->priority = 1;
-	}
-
-	return 0;
-
-free:
-	prueth->emac[mac] = NULL;
-
-	return ret;
-}
-
-static void prueth_netdev_exit(struct prueth *prueth,
-			       struct device_node *eth_node)
-{
-	struct prueth_emac *emac;
-	enum prueth_mac mac;
-
-	mac = prueth_node_mac(eth_node);
-	if (mac < 0)
-		return;
-
-	emac = prueth->emac[mac];
-	if (!emac)
-		return;
-
-	phy_disconnect(emac->phydev);
-
-	prueth->emac[mac] = NULL;
-}
-
-bool prueth_sw_port_dev_check(const struct net_device *ndev)
-{
-	if (ndev->netdev_ops != &emac_netdev_ops)
-		return false;
-
-	if (ndev->features & NETIF_F_HW_HSR_TAG_RM)
-		return true;
-
-	return false;
-}
-
-static void prueth_port_offload_fwd_mark_update(struct prueth *prueth)
-{
-	int set_val = 0;
-	int i;
-	u8 all_slaves = BIT(PRUETH_PORT_MII0) | BIT(PRUETH_PORT_MII1);
-
-	if (prueth->br_members == all_slaves)
-		set_val = 1;
-
-	dev_dbg(prueth->dev, "set offload_fwd_mark %d, mbrs=0x%x\n",
-		set_val, prueth->br_members);
-
-	for (i = 0; i < PRUETH_NUM_MACS; i++)
-		prueth->emac[i]->offload_fwd_mark = set_val;
-
-	/* Bridge is created, load switch firmware, if not already in
-	 * that mode
-	 */
-	if (set_val && !PRUETH_IS_SWITCH(prueth))
-		prueth_change_to_switch_mode(prueth);
-
-	/* Bridge is deleted, switch to Dual EMAC mode */
-	if (!prueth->br_members && !PRUETH_IS_EMAC(prueth))
-		prueth_change_to_emac_mode(prueth);
-}
-
-static int prueth_ndev_port_link(struct net_device *ndev,
-				 struct net_device *br_ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-
-	dev_dbg(prueth->dev, "%s: br_mbrs=0x%x %s\n",
-		__func__, prueth->br_members, ndev->name);
-
-	if (!prueth->br_members) {
-		prueth->hw_bridge_dev = br_ndev;
-	} else {
-		/* This is adding the port to a second bridge, this is
-		 * unsupported
-		 */
-		if (prueth->hw_bridge_dev != br_ndev)
-			return -EOPNOTSUPP;
-	}
-
-	prueth->br_members |= BIT(emac->port_id);
-
-	prueth_port_offload_fwd_mark_update(prueth);
-
-	return NOTIFY_DONE;
-}
-
-static void prueth_ndev_port_unlink(struct net_device *ndev)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-
-	dev_dbg(prueth->dev, "emac_sw_ndev_port_unlink\n");
-
-	prueth->br_members &= ~BIT(emac->port_id);
-
-	prueth_port_offload_fwd_mark_update(prueth);
-
-	if (!prueth->br_members)
-		prueth->hw_bridge_dev = NULL;
-}
-
-static int prueth_ndev_event(struct notifier_block *unused,
-			     unsigned long event, void *ptr)
-{
-	struct net_device *ndev = netdev_notifier_info_to_dev(ptr);
-	struct netdev_notifier_changeupper_info *info;
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	int ret = NOTIFY_DONE;
-	enum hsr_version ver;
-
-	if (!prueth_sw_port_dev_check(ndev))
-		return NOTIFY_DONE;
-
-	switch (event) {
-	case NETDEV_CHANGEUPPER:
-		info = ptr;
-
-		if (ndev->features & NETIF_F_HW_HSR_TAG_RM) {
-			if (is_hsr_master(info->upper_dev)) {
-				hsr_get_version(info->upper_dev, &ver);
-				if (ver == HSR_V1)
-					prueth->eth_type = PRUSS_ETHTYPE_HSR;
-				else if (ver == PRP_V1)
-					prueth->eth_type = PRUSS_ETHTYPE_PRP;
-			}
-		}
-
-		if (netif_is_bridge_master(info->upper_dev)) {
-			if (info->linking)
-				ret = prueth_ndev_port_link(ndev,
-							    info->upper_dev);
-			else
-				prueth_ndev_port_unlink(ndev);
-		}
-		break;
-	default:
-		return NOTIFY_DONE;
-	}
-
-	return notifier_from_errno(ret);
-}
-
-static int prueth_register_notifiers(struct prueth *prueth)
-{
-	struct notifier_block *nb;
-	int ret;
-
-	nb = &prueth->prueth_ndev_nb;
-	nb->notifier_call = prueth_ndev_event;
-	ret = register_netdevice_notifier(nb);
-	if (ret) {
-		dev_err(prueth->dev,
-			"register netdevice notifier failed ret: %d\n", ret);
-		return ret;
-	}
-
-	ret = prueth_sw_register_notifiers(prueth);
-	if (ret) {
-		unregister_netdevice_notifier(nb);
-		return ret;
-	}
-
-	return 0;
-}
-static const struct of_device_id prueth_dt_match[];
-
-static int prueth_probe(struct platform_device *pdev)
-{
-	struct prueth *prueth;
-	struct device *dev = &pdev->dev;
-	struct device_node *np = dev->of_node;
-	struct device_node *eth0_node, *eth1_node;
-	const struct of_device_id *match;
-	enum pruss_pru_id pruss_id0, pruss_id1;
-	bool has_lre = false;
-	struct pruss *pruss;
-	int i, ret;
-
-	if (!np)
-		return -ENODEV;	/* we don't support non DT */
-
-	match = of_match_device(prueth_dt_match, dev);
-	if (!match)
-		return -ENODEV;
-
-	prueth = devm_kzalloc(dev, sizeof(*prueth), GFP_KERNEL);
-	if (!prueth)
-		return -ENOMEM;
-
-	platform_set_drvdata(pdev, prueth);
-
-	prueth->dev = dev;
-	prueth->fw_data = match->data;
-	prueth->prueth_np = np;
-
-	eth0_node = of_get_child_by_name(np, "ethernet-mii0");
-	if (!of_device_is_available(eth0_node)) {
-		of_node_put(eth0_node);
-		eth0_node = NULL;
-	}
-
-	eth1_node = of_get_child_by_name(np, "ethernet-mii1");
-	if (!of_device_is_available(eth1_node)) {
-		of_node_put(eth1_node);
-		eth1_node = NULL;
-	}
-
-	/* At least one node must be present and available else we fail */
-	if (!eth0_node && !eth1_node) {
-		dev_err(dev, "neither ethernet-mii0 nor ethernet-mii1 node available\n");
-		ret = -ENODEV;
-		goto put_node;
-	}
-
-	prueth->eth_node[PRUETH_MAC0] = eth0_node;
-	prueth->eth_node[PRUETH_MAC1] = eth1_node;
-
-	prueth->mii_rt = syscon_regmap_lookup_by_phandle(np, "mii-rt");
-	if (IS_ERR(prueth->mii_rt)) {
-		dev_err(dev, "couldn't get mii-rt syscon regmap\n");
-		return -ENODEV;
-	}
-
-	if (eth0_node) {
-		prueth->pru0 = pru_rproc_get(np, 0, &pruss_id0);
-		if (IS_ERR(prueth->pru0)) {
-			ret = PTR_ERR(prueth->pru0);
-			if (ret != -EPROBE_DEFER)
-				dev_err(dev, "unable to get PRU0: %d\n", ret);
-			goto put_node;
-		}
-	}
-
-	if (eth1_node) {
-		prueth->pru1 = pru_rproc_get(np, 1, &pruss_id1);
-		if (IS_ERR(prueth->pru1)) {
-			ret = PTR_ERR(prueth->pru1);
-			if (ret != -EPROBE_DEFER)
-				dev_err(dev, "unable to get PRU1: %d\n", ret);
-			goto put_pru0;
-		}
-	}
-
-	pruss = pruss_get(prueth->pru0 ? prueth->pru0 : prueth->pru1);
-	if (IS_ERR(pruss)) {
-		ret = PTR_ERR(pruss);
-		dev_err(dev, "unable to get pruss handle\n");
-		goto put_pru1;
-	}
-	prueth->pruss = pruss;
-
-	ret = pruss_cfg_ocp_master_ports(prueth->pruss, 1);
-	if (ret) {
-		dev_err(dev, "couldn't enabled ocp master port: %d\n", ret);
-		goto put_pruss;
-	}
-
-	/* Configure PRUSS */
-	if (eth0_node)
-		pruss_cfg_gpimode(pruss, pruss_id0, PRUSS_GPI_MODE_MII);
-	if (eth1_node)
-		pruss_cfg_gpimode(pruss, pruss_id1, PRUSS_GPI_MODE_MII);
-	pruss_cfg_miirt_enable(pruss, true);
-	pruss_cfg_xfr_enable(pruss, true);
-
-	/* Get PRUSS mem resources */
-	/* OCMC is system resource which we get separately */
-	for (i = 0; i < ARRAY_SIZE(pruss_mem_ids); i++) {
-		/* skip appropriate DRAM if not required */
-		if (!eth0_node && i == PRUETH_MEM_DRAM0)
-			continue;
-
-		if (!eth1_node && i == PRUETH_MEM_DRAM1)
-			continue;
-
-		ret = pruss_request_mem_region(pruss, pruss_mem_ids[i],
-					       &prueth->mem[i]);
-		if (ret) {
-			dev_err(dev, "unable to get PRUSS resource %d: %d\n",
-				i, ret);
-			goto put_mem;
-		}
-	}
-
-	prueth->sram_pool = of_gen_pool_get(np, "sram", 0);
-	if (!prueth->sram_pool) {
-		dev_err(dev, "unable to get SRAM pool\n");
-		ret = -ENODEV;
-
-		goto put_mem;
-	}
-	prueth->mem[PRUETH_MEM_OCMC].va =
-			(void __iomem *)gen_pool_alloc(prueth->sram_pool,
-						       OCMC_RAM_SIZE);
-	if (!prueth->mem[PRUETH_MEM_OCMC].va) {
-		dev_err(dev, "unable to allocate OCMC resource\n");
-		ret = -ENOMEM;
-		goto put_mem;
-	}
-	prueth->mem[PRUETH_MEM_OCMC].pa =
-			gen_pool_virt_to_phys(prueth->sram_pool,
-					      (unsigned long)prueth->mem[PRUETH_MEM_OCMC].va);
-	prueth->mem[PRUETH_MEM_OCMC].size = OCMC_RAM_SIZE;
-	dev_dbg(dev, "ocmc: pa %pa va %p size %#zx\n",
-		&prueth->mem[PRUETH_MEM_OCMC].pa,
-		prueth->mem[PRUETH_MEM_OCMC].va,
-		prueth->mem[PRUETH_MEM_OCMC].size);
-
-	if (IS_ENABLED(CONFIG_HSR) && prueth->fw_data->support_lre) {
-		prueth->fw_offsets = &fw_offsets_v2_1;
-		has_lre = true;
-	}
-
-	/* if lre is supported, then both eth nodes to be present in
-	 * DT node. If not, reset the support flag
-	 */
-	if (has_lre && (!eth0_node || !eth1_node))
-		has_lre = false;
-
-	if (has_lre) {
-		/* need to configure interrupts per queue common for
-		 * both ports
-		 */
-		prueth->hp = devm_kzalloc(dev,
-					  sizeof(struct prueth_ndev_priority),
-					  GFP_KERNEL);
-		if (!prueth->hp) {
-			ret = -ENOMEM;
-			goto free_pool;
-		}
-		prueth->lp = devm_kzalloc(dev,
-					  sizeof(struct prueth_ndev_priority),
-					  GFP_KERNEL);
-		if (!prueth->hp) {
-			ret = -ENOMEM;
-			goto free_pool;
-		}
-
-		prueth->lre_stats = devm_kzalloc(dev,
-						 sizeof(*prueth->lre_stats),
-						 GFP_KERNEL);
-		if (!prueth->lre_stats) {
-			ret = -ENOMEM;
-			goto free_pool;
-		}
-
-		prueth->rx_lpq_irq = of_irq_get_byname(np, "rx_lre_lp");
-		prueth->rx_hpq_irq = of_irq_get_byname(np, "rx_lre_hp");
-		if (prueth->rx_lpq_irq < 0 || prueth->rx_hpq_irq < 0)
-			has_lre = false;
-	}
-	prueth->support_lre = has_lre;
-
-	/* setup netdev interfaces */
-	if (eth0_node) {
-		ret = prueth_netdev_init(prueth, eth0_node);
-		if (ret) {
-			if (ret != -EPROBE_DEFER) {
-				dev_err(dev, "netdev init %s failed: %d\n",
-					eth0_node->name, ret);
-			}
-			goto free_pool;
-		}
-	}
-
-	if (eth1_node) {
-		ret = prueth_netdev_init(prueth, eth1_node);
-		if (ret) {
-			if (ret != -EPROBE_DEFER) {
-				dev_err(dev, "netdev init %s failed: %d\n",
-					eth1_node->name, ret);
-			}
-			goto netdev_exit;
-		}
-	}
-
-	prueth->iep = icss_iep_get(np);
-	if (IS_ERR(prueth->iep)) {
-		ret = PTR_ERR(prueth->iep);
-		dev_err(dev, "unable to get IEP\n");
-		goto netdev_exit;
-	}
-
-	prueth_set_fw_offsets(prueth);
-	prueth_hostinit(prueth);
-
-	/* register the network devices */
-	if (eth0_node) {
-		ret = register_netdev(prueth->emac[PRUETH_MAC0]->ndev);
-		if (ret) {
-			dev_err(dev, "can't register netdev for port MII0");
-			goto iep_put;
-		}
-
-		prueth->registered_netdevs[PRUETH_MAC0] = prueth->emac[PRUETH_MAC0]->ndev;
-	}
-
-	if (eth1_node) {
-		ret = register_netdev(prueth->emac[PRUETH_MAC1]->ndev);
-		if (ret) {
-			dev_err(dev, "can't register netdev for port MII1");
-			goto netdev_unregister;
-		}
-
-		prueth->registered_netdevs[PRUETH_MAC1] = prueth->emac[PRUETH_MAC1]->ndev;
-	}
-
-	ret = prueth_register_notifiers(prueth);
-	if (ret) {
-		dev_err(dev, "can't register switchdev notifiers");
-		goto netdev_unregister;
-	}
-
-	eth_random_addr(prueth->base_mac);
-
-	dev_info(dev, "TI PRU ethernet driver initialized: %s EMAC mode\n",
-		 (!eth0_node || !eth1_node) ? "single" : "dual");
-
-	return 0;
-
-netdev_unregister:
-	for (i = 0; i < PRUETH_NUM_MACS; i++) {
-		if (!prueth->registered_netdevs[i])
-			continue;
-		unregister_netdev(prueth->registered_netdevs[i]);
-	}
-
-iep_put:
-	icss_iep_put(prueth->iep);
-netdev_exit:
-	for (i = 0; i < PRUETH_NUM_MACS; i++) {
-		struct device_node *eth_node;
-
-		eth_node = prueth->eth_node[i];
-		if (!eth_node)
-			continue;
-
-		prueth_netdev_exit(prueth, eth_node);
-	}
-
-free_pool:
-	gen_pool_free(prueth->sram_pool,
-		      (unsigned long)prueth->mem[PRUETH_MEM_OCMC].va, OCMC_RAM_SIZE);
-
-put_mem:
-	pruss_cfg_ocp_master_ports(prueth->pruss, 0);
-	for (i = PRUETH_MEM_DRAM0; i < PRUETH_MEM_OCMC; i++) {
-		if (prueth->mem[i].va)
-			pruss_release_mem_region(pruss, &prueth->mem[i]);
-	}
-
-put_pruss:
-	pruss_put(prueth->pruss);
-
-put_pru1:
-	if (eth1_node)
-		pru_rproc_put(prueth->pru1);
-put_pru0:
-	if (eth0_node)
-		pru_rproc_put(prueth->pru0);
-
-put_node:
-	of_node_put(eth1_node);
-	of_node_put(eth0_node);
-
-	return ret;
-}
-
-static int prueth_remove(struct platform_device *pdev)
-{
-	struct device_node *eth_node;
-	struct prueth *prueth = platform_get_drvdata(pdev);
-	int i;
-
-	unregister_netdevice_notifier(&prueth->prueth_ndev_nb);
-	prueth_sw_unregister_notifiers(prueth);
-
-	for (i = 0; i < PRUETH_NUM_MACS; i++) {
-		if (!prueth->registered_netdevs[i])
-			continue;
-		unregister_netdev(prueth->registered_netdevs[i]);
-	}
-
-	for (i = 0; i < PRUETH_NUM_MACS; i++) {
-		eth_node = prueth->eth_node[i];
-		if (!eth_node)
-			continue;
-
-		prueth_netdev_exit(prueth, eth_node);
-		of_node_put(eth_node);
-	}
-
-	gen_pool_free(prueth->sram_pool,
-		      (unsigned long)prueth->mem[PRUETH_MEM_OCMC].va,
-		      OCMC_RAM_SIZE);
-
-	for (i = PRUETH_MEM_DRAM0; i < PRUETH_MEM_OCMC; i++) {
-		if (prueth->mem[i].va)
-			pruss_release_mem_region(prueth->pruss, &prueth->mem[i]);
-	}
-
-	icss_iep_put(prueth->iep);
-
-	pruss_put(prueth->pruss);
-
-	if (prueth->eth_node[PRUETH_MAC0])
-		pru_rproc_put(prueth->pru1);
-	if (prueth->eth_node[PRUETH_MAC1])
-		pru_rproc_put(prueth->pru0);
-
-	return 0;
-}
-
-#ifdef CONFIG_PM_SLEEP
-static int prueth_suspend(struct device *dev)
-{
-	struct prueth *prueth = dev_get_drvdata(dev);
-	struct net_device *ndev;
-	int i, ret;
-
-	for (i = 0; i < PRUETH_NUM_MACS; i++) {
-		ndev = prueth->registered_netdevs[i];
-
-		if (!ndev)
-			continue;
-
-		if (netif_running(ndev)) {
-			netif_device_detach(ndev);
-			ret = emac_ndo_stop(ndev);
-			if (ret < 0) {
-				netdev_err(ndev, "failed to stop: %d", ret);
-				return ret;
-			}
-		}
-	}
-
-	pruss_cfg_ocp_master_ports(prueth->pruss, 0);
-
-	return 0;
-}
-
-static int prueth_resume(struct device *dev)
-{
-	struct prueth *prueth = dev_get_drvdata(dev);
-	struct net_device *ndev;
-	int i, ret;
-
-	pruss_cfg_ocp_master_ports(prueth->pruss, 1);
-
-	for (i = 0; i < PRUETH_NUM_MACS; i++) {
-		ndev = prueth->registered_netdevs[i];
-
-		if (!ndev)
-			continue;
-
-		if (netif_running(ndev)) {
-			ret = emac_ndo_open(ndev);
-			if (ret < 0) {
-				netdev_err(ndev, "failed to start: %d", ret);
-				return ret;
-			}
-			netif_device_attach(ndev);
-		}
-	}
-
-	return 0;
-}
-
-#endif /* CONFIG_PM_SLEEP */
-
-static const struct dev_pm_ops prueth_dev_pm_ops = {
-	SET_SYSTEM_SLEEP_PM_OPS(prueth_suspend, prueth_resume)
-};
-
-/* AM33xx SoC-specific firmware data */
-static struct prueth_private_data am335x_prueth_pdata = {
-	.fw_pru[PRUSS_PRU0] = {
-		.fw_name[PRUSS_ETHTYPE_EMAC] =
-			"ti-pruss/am335x-pru0-prueth-fw.elf",
-	},
-	.fw_pru[PRUSS_PRU1] = {
-		.fw_name[PRUSS_ETHTYPE_EMAC] =
-			"ti-pruss/am335x-pru1-prueth-fw.elf",
-	},
-	.support_lre = false,
-};
-
-/* AM437x SoC-specific firmware data */
-static struct prueth_private_data am437x_prueth_pdata = {
-	.fw_pru[PRUSS_PRU0] = {
-		.fw_name[PRUSS_ETHTYPE_EMAC] =
-			"ti-pruss/am437x-pru0-prueth-fw.elf",
-	},
-	.fw_pru[PRUSS_PRU1] = {
-		.fw_name[PRUSS_ETHTYPE_EMAC] =
-			"ti-pruss/am437x-pru1-prueth-fw.elf",
-	},
-	.support_lre = false,
-};
-
-/* AM57xx SoC-specific firmware data */
-static struct prueth_private_data am57xx_prueth_pdata = {
-	.fw_pru[PRUSS_PRU0] = {
-		.fw_name[PRUSS_ETHTYPE_EMAC] =
-			"ti-pruss/am57xx-pru0-prueth-fw.elf",
-		.fw_name[PRUSS_ETHTYPE_HSR] =
-			"ti-pruss/am57xx-pru0-pruhsr-fw.elf",
-		.fw_name[PRUSS_ETHTYPE_PRP] =
-			"ti-pruss/am57xx-pru0-pruprp-fw.elf",
-		.fw_name[PRUSS_ETHTYPE_SWITCH] =
-			"ti-pruss/am57xx-pru0-prusw-fw.elf",
-	},
-	.fw_pru[PRUSS_PRU1] = {
-		.fw_name[PRUSS_ETHTYPE_EMAC] =
-			"ti-pruss/am57xx-pru1-prueth-fw.elf",
-		.fw_name[PRUSS_ETHTYPE_HSR] =
-			"ti-pruss/am57xx-pru1-pruhsr-fw.elf",
-		.fw_name[PRUSS_ETHTYPE_PRP] =
-			"ti-pruss/am57xx-pru1-pruprp-fw.elf",
-		.fw_name[PRUSS_ETHTYPE_SWITCH] =
-			"ti-pruss/am57xx-pru1-prusw-fw.elf",
-	},
-	.support_lre = true,
-	.support_switch = true,
-};
-
-/* 66AK2G SoC-specific firmware data */
-static struct prueth_private_data k2g_prueth_pdata = {
-	.fw_pru[PRUSS_PRU0] = {
-		.fw_name[PRUSS_ETHTYPE_EMAC] =
-			"ti-pruss/k2g-pru0-prueth-fw.elf",
-	},
-	.fw_pru[PRUSS_PRU1] = {
-		.fw_name[PRUSS_ETHTYPE_EMAC] =
-			"ti-pruss/k2g-pru1-prueth-fw.elf",
-	},
-	.support_lre = false,
-};
-
-static const struct of_device_id prueth_dt_match[] = {
-	{ .compatible = "ti,am57-prueth", .data = &am57xx_prueth_pdata, },
-	{ .compatible = "ti,am4376-prueth", .data = &am437x_prueth_pdata, },
-	{ .compatible = "ti,am3359-prueth", .data = &am335x_prueth_pdata, },
-	{ .compatible = "ti,k2g-prueth", .data = &k2g_prueth_pdata, },
-	{ /* sentinel */ }
-};
-MODULE_DEVICE_TABLE(of, prueth_dt_match);
-
-static struct platform_driver prueth_driver = {
-	.probe = prueth_probe,
-	.remove = prueth_remove,
-	.driver = {
-		.name = "prueth",
-		.of_match_table = prueth_dt_match,
-		.pm = &prueth_dev_pm_ops,
-	},
-};
-module_platform_driver(prueth_driver);
-
-MODULE_AUTHOR("Roger Quadros <rogerq@ti.com>");
-MODULE_AUTHOR("Andrew F. Davis <afd@ti.com>");
-MODULE_DESCRIPTION("PRU Ethernet Driver");
-MODULE_LICENSE("GPL v2");
diff --git a/drivers/net/ethernet/ti/prueth_fdb_tbl.h b/drivers/net/ethernet/ti/prueth_fdb_tbl.h
deleted file mode 100644
index 1c004185a11a..000000000000
--- a/drivers/net/ethernet/ti/prueth_fdb_tbl.h
+++ /dev/null
@@ -1,67 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2019-2021 Texas Instruments Incorporated - https://www.ti.com */
-#ifndef __NET_TI_PRUSS_FDB_TBL_H
-#define __NET_TI_PRUSS_FDB_TBL_H
-
-#include <linux/kernel.h>
-#include <linux/debugfs.h>
-#include "prueth.h"
-
-#define ETHER_ADDR_LEN 6
-
-/* 4 bytes */
-struct fdb_index_tbl_entry_t {
-	u16 bucket_idx;     /* Bucket Table index of first Bucket
-			     * with this MAC address
-			     */
-	u16 bucket_entries; /* Number of entries in this bucket */
-} __packed;
-
-/* 4 * 256 = 1024 = 0x200 bytes */
-struct fdb_index_array_t {
-	struct fdb_index_tbl_entry_t index_tbl_entry[FDB_INDEX_TBL_MAX_ENTRIES];
-} __packed;
-
-/* 10 bytes */
-struct fdb_mac_tbl_entry_t {
-	u8  mac[ETHER_ADDR_LEN];
-	u16 age;
-	u8  port; /* 0 based: 0=port1, 1=port2 */
-	u8  is_static:1;
-	u8  active:1;
-} __packed;
-
-/* 10 * 256 = 2560 = 0xa00 bytes */
-struct fdb_mac_tbl_array_t {
-	struct fdb_mac_tbl_entry_t mac_tbl_entry[FDB_MAC_TBL_MAX_ENTRIES];
-} __packed;
-
-/* 1 byte */
-struct fdb_stp_config {
-	u8  state; /* per-port STP state (defined in FW header) */
-} __packed;
-
-/* 1 byte */
-struct fdb_flood_config {
-	u8 host_flood_enable:1;
-	u8 port1_flood_enable:1;
-	u8 port2_flood_enable:1;
-} __packed;
-
-/* 2 byte */
-struct fdb_arbitration {
-	u8  host_lock;
-	u8  pru_locks;
-} __packed;
-
-struct fdb_tbl {
-	struct fdb_index_array_t *index_a; /* fdb index table */
-	struct fdb_mac_tbl_array_t *mac_tbl_a; /* fdb mac table */
-	struct fdb_stp_config *port1_stp_cfg; /* port 1 strp config */
-	struct fdb_stp_config *port2_stp_cfg; /* port 2 strp config */
-	struct fdb_flood_config *flood_enable_flags; /* per-port flood enable */
-	struct fdb_arbitration *locks; /* fdb locking mechanism */
-	u16 total_entries; /* total num entries in hash table */
-};
-
-#endif
diff --git a/drivers/net/ethernet/ti/prueth_lre.c b/drivers/net/ethernet/ti/prueth_lre.c
deleted file mode 100644
index 224fa0b9d8dc..000000000000
--- a/drivers/net/ethernet/ti/prueth_lre.c
+++ /dev/null
@@ -1,1299 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/* Texas Instruments PRUETH hsr/prp Link Redunancy Entity (LRE) Driver.
- *
- * Copyright (C) 2020 Texas Instruments Incorporated - http://www.ti.com
- */
-
-#include <linux/kernel.h>
-#include <linux/regmap.h>
-#include <linux/string.h>
-#include <linux/spinlock_types.h>
-
-#include "icss_lre_firmware.h"
-#include "prueth.h"
-#include "prueth_lre.h"
-#include "prueth_switch.h"
-
-void prueth_lre_config_check_flags(struct prueth *prueth)
-{
-	void __iomem *dram1 = prueth->mem[PRUETH_MEM_DRAM1].va;
-
-	/* HSR/PRP: initialize check table when first port is up */
-	if (prueth->emac_configured)
-		return;
-
-	prueth->tbl_check_mask = (ICSS_LRE_HOST_TIMER_NODE_TABLE_CHECK_BIT |
-				  ICSS_LRE_HOST_TIMER_HOST_TABLE_CHECK_BIT);
-	if (PRUETH_IS_HSR(prueth))
-		prueth->tbl_check_mask |=
-			ICSS_LRE_HOST_TIMER_PORT_TABLE_CHECK_BITS;
-	writel(prueth->tbl_check_mask, dram1 + ICSS_LRE_HOST_TIMER_CHECK_FLAGS);
-}
-
-/* A group of PCPs are mapped to a Queue. This is the size of firmware
- * array in shared memory
- */
-#define PCP_GROUP_TO_QUEUE_MAP_SIZE	4
-
-/* PRU firmware default PCP to priority Queue map for ingress & egress
- *
- * At ingress to Host
- * ==================
- * byte 0 => PRU 1, PCP 0-3 => Q3
- * byte 1 => PRU 1, PCP 4-7 => Q2
- * byte 2 => PRU 0, PCP 0-3 => Q1
- * byte 3 => PRU 0, PCP 4-7 => Q0
- *
- * At egress to wire/network on PRU-0 and PRU-1
- * ============================================
- * byte 0 => Host, PCP 0-3 => Q3
- * byte 1 => Host, PCP 4-7 => Q2
- *
- * PRU-0
- * -----
- * byte 2 => PRU-1, PCP 0-3 => Q1
- * byte 3 => PRU-1, PCP 4-7 => Q0
- *
- * PRU-1
- * -----
- * byte 2 => PRU-0, PCP 0-3 => Q1
- * byte 3 => PRU-0, PCP 4-7 => Q0
- *
- * queue names below are named 1 based. i.e PRUETH_QUEUE1 is Q0,
- * PRUETH_QUEUE2 is Q1 and so forth. Firmware convention is that
- * a lower queue number has higher priority than a higher queue
- * number.
- */
-static u8 fw_pcp_default_priority_queue_map[PCP_GROUP_TO_QUEUE_MAP_SIZE] = {
-	/* port 2 or PRU 1 */
-	PRUETH_QUEUE4, PRUETH_QUEUE3,
-	/* port 1 or PRU 0 */
-	PRUETH_QUEUE2, PRUETH_QUEUE1,
-};
-
-static void prueth_lre_pcp_queue_map_config(struct prueth *prueth)
-{
-	void __iomem *sram  = prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-
-	memcpy_toio(sram + ICSS_LRE_QUEUE_2_PCP_MAP_OFFSET,
-		    &fw_pcp_default_priority_queue_map[0],
-		    PCP_GROUP_TO_QUEUE_MAP_SIZE);
-}
-
-static void prueth_lre_host_table_init(struct prueth *prueth)
-{
-	void __iomem *dram0 = prueth->mem[PRUETH_MEM_DRAM0].va;
-	void __iomem *dram1 = prueth->mem[PRUETH_MEM_DRAM1].va;
-
-	memset_io(dram0 + ICSS_LRE_DUPLICATE_HOST_TABLE, 0,
-		  ICSS_LRE_DUPLICATE_HOST_TABLE_DMEM_SIZE);
-
-	writel(ICSS_LRE_DUPLICATE_HOST_TABLE_SIZE_INIT,
-	       dram1 + ICSS_LRE_DUPLICATE_HOST_TABLE_SIZE);
-
-	writel(ICSS_LRE_TABLE_CHECK_RESOLUTION_10_MS,
-	       dram1 + ICSS_LRE_DUPLI_HOST_CHECK_RESO);
-
-	writel(ICSS_LRE_MASTER_SLAVE_BUSY_BITS_CLEAR,
-	       dram1 + ICSS_LRE_HOST_DUPLICATE_ARBITRATION);
-}
-
-static void pru2host_mac(u8 *mac)
-{
-	swap(mac[0], mac[3]);
-	swap(mac[1], mac[2]);
-	swap(mac[4], mac[5]);
-}
-
-static u16 get_hash(u8 *mac, u16 hash_mask)
-{
-	int j;
-	u16 hash;
-
-	for (j = 0, hash = 0; j < ETH_ALEN; j++)
-		hash ^= mac[j];
-	hash = hash & hash_mask;
-
-	return hash;
-}
-
-void pru_spin_lock(struct node_tbl *nt)
-{
-	while (1) {
-		nt->nt_info->arm_lock = 1;
-		if (!nt->nt_info->fw_lock)
-			break;
-		nt->nt_info->arm_lock = 0;
-	}
-}
-
-static inline void pru_spin_unlock(struct node_tbl *nt)
-{
-	nt->nt_info->arm_lock = 0;
-}
-
-int prueth_lre_nt_insert(struct prueth *prueth,
-			 u8 *mac, int port, int sv_frame, int proto)
-{
-	struct nt_queue_t *q = prueth->mac_queue;
-	unsigned long flags;
-	int ret = LRE_OK;
-
-	/* Will encounter a null mac_queue if we are in the middle of
-	 * ndo_close. So check and return. Otherwise a kernel crash is
-	 * seen when doing ifdown continuously.
-	 */
-	if (!q)
-		return ret;
-
-	spin_lock_irqsave(&prueth->nt_lock, flags);
-	if (q->full) {
-		ret = LRE_ERR;
-	} else {
-		memcpy(q->nt_queue[q->wr_ind].mac, mac, ETH_ALEN);
-		q->nt_queue[q->wr_ind].sv_frame = sv_frame;
-		q->nt_queue[q->wr_ind].port_id = port;
-		q->nt_queue[q->wr_ind].proto = proto;
-
-		q->wr_ind++;
-		q->wr_ind &= (PRUETH_MAC_QUEUE_MAX - 1);
-		if (q->wr_ind == q->rd_ind)
-			q->full = true;
-	}
-	spin_unlock_irqrestore(&prueth->nt_lock, flags);
-
-	return ret;
-}
-
-static inline bool node_expired(struct node_tbl *nt, u16 node, u16 forget_time)
-{
-	struct node_tbl_t nt_node = nt->nt_array->node_tbl[node];
-
-	return ((nt_node.time_last_seen_s > forget_time ||
-		 nt_node.status & ICSS_LRE_NT_REM_NODE_TYPE_SANAB) &&
-		 nt_node.time_last_seen_a > forget_time &&
-		 nt_node.time_last_seen_b > forget_time);
-}
-
-#define IND_BIN_NO(x)		nt->index_array->index_tbl[x].bin_no_entries
-#define IND_BINOFS(x)		nt->index_array->index_tbl[x].bin_offset
-#define BIN_NODEOFS(x)		nt->bin_array->bin_tbl[x].node_tbl_offset
-
-static void _prueth_lre_init_node_table(struct prueth *prueth)
-{
-	struct nt_queue_t *q = prueth->mac_queue;
-	struct node_tbl *nt = prueth->nt;
-	int j;
-
-	const struct prueth_fw_offsets *fw_offsets = prueth->fw_offsets;
-
-	nt->nt_array = prueth->mem[fw_offsets->nt_array_loc].va +
-		       fw_offsets->nt_array_offset;
-	memset_io(nt->nt_array, 0, sizeof(struct node_tbl_t) *
-		  fw_offsets->nt_array_max_entries);
-
-	nt->bin_array = prueth->mem[fw_offsets->bin_array_loc].va +
-			fw_offsets->bin_array_offset;
-	memset_io(nt->bin_array, 0, sizeof(struct bin_tbl_t) *
-		  fw_offsets->bin_array_max_entries);
-
-	nt->index_array = prueth->mem[fw_offsets->index_array_loc].va +
-			  fw_offsets->index_array_offset;
-	memset_io(nt->index_array, 0, sizeof(struct node_index_tbl_t) *
-		  fw_offsets->index_array_max_entries);
-
-	nt->nt_info = prueth->mem[fw_offsets->nt_array_loc].va +
-		      fw_offsets->nt_array_offset +
-		      (sizeof(struct node_tbl_t) *
-		       fw_offsets->nt_array_max_entries);
-	memset_io(nt->nt_info, 0, sizeof(struct node_tbl_info_t));
-
-	nt->nt_lre_cnt =
-		prueth->mem[PRUETH_MEM_SHARED_RAM].va + ICSS_LRE_CNT_NODES;
-	memset_io(nt->nt_lre_cnt, 0, sizeof(struct node_tbl_lre_cnt_t));
-
-	nt->nt_array_max_entries = fw_offsets->nt_array_max_entries;
-	nt->bin_array_max_entries = fw_offsets->bin_array_max_entries;
-	nt->index_array_max_entries = fw_offsets->index_array_max_entries;
-	nt->hash_mask = fw_offsets->hash_mask;
-
-	for (j = 0; j < fw_offsets->index_array_max_entries; j++)
-		IND_BINOFS(j) = fw_offsets->bin_array_max_entries;
-	for (j = 0; j < fw_offsets->bin_array_max_entries; j++)
-		BIN_NODEOFS(j) = fw_offsets->nt_array_max_entries;
-	for (j = 0; j < fw_offsets->nt_array_max_entries; j++)
-		nt->nt_array->node_tbl[j].entry_state = ICSS_LRE_NODE_FREE;
-
-	q->rd_ind = 0;
-	q->wr_ind = 0;
-	q->full = false;
-}
-
-static u16 find_free_bin(struct node_tbl *nt)
-{
-	u16 j;
-
-	for (j = 0; j < nt->bin_array_max_entries; j++)
-		if (BIN_NODEOFS(j) == nt->nt_array_max_entries)
-			break;
-
-	return j;
-}
-
-/* find first free node table slot and write it to the next_free_slot */
-static u16 next_free_slot_update(struct node_tbl *nt)
-{
-	int j;
-
-	nt->nt_info->next_free_slot = nt->nt_array_max_entries;
-	for (j = 0; j < nt->nt_array_max_entries; j++) {
-		if (nt->nt_array->node_tbl[j].entry_state ==
-				ICSS_LRE_NODE_FREE) {
-			nt->nt_info->next_free_slot = j;
-			break;
-		}
-	}
-
-	return nt->nt_info->next_free_slot;
-}
-
-static void inc_time(u16 *t)
-{
-	*t += 1;
-	if (*t > ICSS_LRE_MAX_FORGET_TIME)
-		*t = ICSS_LRE_MAX_FORGET_TIME;
-}
-
-void node_table_update_time(struct node_tbl *nt)
-{
-	int j;
-	u16 ofs;
-	struct nt_array_t *nt_arr = nt->nt_array;
-	struct node_tbl_t *node;
-
-	for (j = 0; j < nt->bin_array_max_entries; j++) {
-		ofs = nt->bin_array->bin_tbl[j].node_tbl_offset;
-		if (ofs < nt->nt_array_max_entries) {
-			node = &nt_arr->node_tbl[ofs];
-			inc_time(&node->time_last_seen_a);
-			inc_time(&node->time_last_seen_b);
-			/* increment time_last_seen_s if nod is not SAN */
-			if ((node->status &
-			     ICSS_LRE_NT_REM_NODE_TYPE_SANAB) == 0)
-				inc_time(&node->time_last_seen_s);
-		}
-	}
-}
-
-static void write2node_slot(struct node_tbl *nt, u16 node, int port,
-			    int sv_frame, int proto)
-{
-	memset(&nt->nt_array->node_tbl[node], 0, sizeof(struct node_tbl_t));
-	nt->nt_array->node_tbl[node].entry_state = ICSS_LRE_NODE_TAKEN;
-
-	if (port == 0x01) {
-		nt->nt_array->node_tbl[node].status =
-			ICSS_LRE_NT_REM_NODE_TYPE_SANA;
-		nt->nt_array->node_tbl[node].cnt_ra = 1;
-		if (sv_frame)
-			nt->nt_array->node_tbl[node].cnt_rx_sup_a = 1;
-	} else {
-		nt->nt_array->node_tbl[node].status =
-			ICSS_LRE_NT_REM_NODE_TYPE_SANB;
-		nt->nt_array->node_tbl[node].cnt_rb = 1;
-		if (sv_frame)
-			nt->nt_array->node_tbl[node].cnt_rx_sup_b = 1;
-	}
-
-	if (sv_frame) {
-		nt->nt_array->node_tbl[node].status = (proto == LRE_PROTO_PRP) ?
-			ICSS_LRE_NT_REM_NODE_TYPE_DAN :
-			ICSS_LRE_NT_REM_NODE_TYPE_DAN |
-			ICSS_LRE_NT_REM_NODE_HSR_BIT;
-	}
-}
-
-/* We assume that the _start_ cannot point to middle of a bin */
-static void update_indexes(u16 start, u16 end, struct node_tbl *nt)
-{
-	u16 hash, hash_prev;
-
-	hash_prev = 0xffff; /* invalid hash */
-	for (; start <= end; start++) {
-		hash = get_hash(nt->bin_array->bin_tbl[start].src_mac_id,
-				nt->hash_mask);
-		if (hash != hash_prev)
-			IND_BINOFS(hash) = start;
-		hash_prev = hash;
-	}
-}
-
-/* start > end */
-static void move_up(u16 start, u16 end, struct node_tbl *nt,
-		    bool update)
-{
-	u16 j = end;
-
-	pru_spin_lock(nt);
-
-	for (; j < start; j++)
-		memcpy(&nt->bin_array->bin_tbl[j],
-		       &nt->bin_array->bin_tbl[j + 1],
-		       sizeof(struct bin_tbl_t));
-
-	BIN_NODEOFS(start) = nt->nt_array_max_entries;
-
-	if (update)
-		update_indexes(end, start + 1, nt);
-
-	pru_spin_unlock(nt);
-}
-
-/* start < end */
-static void move_down(u16 start, u16 end, struct node_tbl *nt,
-		      bool update)
-{
-	u16 j = end;
-
-	pru_spin_lock(nt);
-
-	for (; j > start; j--)
-		memcpy(&nt->bin_array->bin_tbl[j],
-		       &nt->bin_array->bin_tbl[j - 1],
-		       sizeof(struct bin_tbl_t));
-
-	nt->bin_array->bin_tbl[start].node_tbl_offset =
-					nt->nt_array_max_entries;
-
-	if (update)
-		update_indexes(start + 1, end, nt);
-
-	pru_spin_unlock(nt);
-}
-
-static int node_table_insert_from_queue(struct node_tbl *nt,
-					struct nt_queue_entry *entry)
-{
-	u8 macid[ETH_ALEN];
-	u16 hash;
-	u16 index;
-	u16 free_node;
-	bool not_found;
-	u16 empty_slot;
-
-	if (!nt)
-		return LRE_ERR;
-
-	memcpy(macid, entry->mac, ETH_ALEN);
-	pru2host_mac(macid);
-
-	hash = get_hash(macid, nt->hash_mask);
-
-	not_found = 1;
-	if (IND_BIN_NO(hash) == 0) {
-		/* there is no bin for this hash, create one */
-		index = find_free_bin(nt);
-		if (index == nt->bin_array_max_entries)
-			return LRE_ERR;
-
-		IND_BINOFS(hash) = index;
-	} else {
-		for (index = IND_BINOFS(hash);
-		     index < IND_BINOFS(hash) + IND_BIN_NO(hash); index++) {
-			if ((memcmp(nt->bin_array->bin_tbl[index].src_mac_id,
-				    macid, ETH_ALEN) == 0)) {
-				not_found = 0;
-				break;
-			}
-		}
-	}
-
-	if (not_found) {
-		free_node = next_free_slot_update(nt);
-
-		/* at this point we might create a new bin and set
-		 * bin_offset at the index table. It was only possible
-		 * if we found a free slot in the bin table.
-		 * So, it also must be a free slot in the node table
-		 * and we will not exit here in this case.
-		 * So, be don't have to take care about fixing IND_BINOFS()
-		 * on return LRE_ERR
-		 */
-		if (free_node >= nt->nt_array_max_entries)
-			return LRE_ERR;
-
-		/* if we are here, we have at least one empty slot in the bin
-		 * table and one slot at the node table
-		 */
-
-		IND_BIN_NO(hash)++;
-
-		/* look for an empty slot downwards */
-		for (empty_slot = index;
-		     (BIN_NODEOFS(empty_slot) != nt->nt_array_max_entries) &&
-		     (empty_slot < nt->nt_array_max_entries);
-		     empty_slot++)
-			;
-
-		/* if emptySlot != maxNodes => empty slot is found,
-		 * else no space available downwards, look upwards
-		 */
-		if (empty_slot != nt->nt_array_max_entries) {
-			move_down(index, empty_slot, nt, true);
-		} else {
-			for (empty_slot = index - 1;
-			     (BIN_NODEOFS(empty_slot) !=
-			     nt->nt_array_max_entries) &&
-			     (empty_slot > 0);
-			     empty_slot--)
-				;
-			/* we're sure to get a space here as nodetable
-			 * has a empty slot, so no need to check for
-			 * value of emptySlot
-			 */
-			move_up(index, empty_slot, nt, true);
-		}
-
-		/* space created, now populate the values*/
-		BIN_NODEOFS(index) = free_node;
-		memcpy(nt->bin_array->bin_tbl[index].src_mac_id, macid,
-		       ETH_ALEN);
-		write2node_slot(nt, free_node, entry->port_id, entry->sv_frame,
-				entry->proto);
-
-		nt->nt_lre_cnt->lre_cnt++;
-	}
-
-	return LRE_OK;
-}
-
-void node_table_check_and_remove(struct node_tbl *nt, u16 forget_time)
-{
-	int j, end_bin;
-	u16 node;
-	u16 hash;
-
-	/*loop to remove a node reaching NODE_FORGET_TIME*/
-	for (j = 0; j < nt->bin_array_max_entries; j++) {
-		node = BIN_NODEOFS(j);
-		if (node >= nt->nt_array_max_entries)
-			continue;
-
-		if (node_expired(nt, node, forget_time)) {
-			hash = get_hash(nt->bin_array->bin_tbl[j].src_mac_id,
-					nt->hash_mask);
-
-			/* remove entry from bin array */
-			end_bin = IND_BINOFS(hash) + IND_BIN_NO(hash) - 1;
-
-			move_up(end_bin, j, nt, false);
-			(IND_BIN_NO(hash))--;
-
-			if (!IND_BIN_NO(hash))
-				IND_BINOFS(hash) = nt->bin_array_max_entries;
-
-			nt->nt_array->node_tbl[node].entry_state =
-							ICSS_LRE_NODE_FREE;
-			BIN_NODEOFS(end_bin) = nt->nt_array_max_entries;
-
-			nt->nt_lre_cnt->lre_cnt--;
-		}
-	}
-}
-
-static int pop_queue(struct prueth *prueth, spinlock_t *lock)
-{
-	unsigned long flags;
-	struct node_tbl *nt = prueth->nt;
-	struct nt_queue_t *q = prueth->mac_queue;
-	struct nt_queue_entry one_mac;
-	int ret = 0;
-
-	spin_lock_irqsave(lock, flags);
-	if (!q->full && q->wr_ind == q->rd_ind) { /* queue empty */
-		ret = 1;
-	} else {
-		memcpy(&one_mac, &q->nt_queue[q->rd_ind],
-		       sizeof(struct nt_queue_entry));
-		spin_unlock_irqrestore(lock, flags);
-		node_table_insert_from_queue(nt, &one_mac);
-		spin_lock_irqsave(lock, flags);
-		q->rd_ind++;
-		q->rd_ind &= (PRUETH_MAC_QUEUE_MAX - 1);
-		q->full = false;
-	}
-	spin_unlock_irqrestore(lock, flags);
-
-	return ret;
-}
-
-void pop_queue_process(struct prueth *prueth, spinlock_t *lock)
-{
-	while (pop_queue(prueth, lock) == 0)
-		;
-}
-
-static void prueth_lre_port_table_init(struct prueth *prueth)
-{
-	void __iomem *dram1 = prueth->mem[PRUETH_MEM_DRAM1].va;
-
-	if (PRUETH_IS_HSR(prueth)) {
-		memset_io(dram1 + ICSS_LRE_DUPLICATE_PORT_TABLE_PRU0, 0,
-			  ICSS_LRE_DUPLICATE_PORT_TABLE_DMEM_SIZE);
-		memset_io(dram1 + ICSS_LRE_DUPLICATE_PORT_TABLE_PRU1, 0,
-			  ICSS_LRE_DUPLICATE_PORT_TABLE_DMEM_SIZE);
-
-		writel(ICSS_LRE_DUPLICATE_PORT_TABLE_SIZE_INIT,
-		       dram1 + ICSS_LRE_DUPLICATE_PORT_TABLE_SIZE);
-	} else {
-		writel(0, dram1 + ICSS_LRE_DUPLICATE_PORT_TABLE_SIZE);
-	}
-
-	writel(ICSS_LRE_TABLE_CHECK_RESOLUTION_10_MS,
-	       dram1 + ICSS_LRE_DUPLI_PORT_CHECK_RESO);
-}
-
-static void prueth_lre_init(struct prueth *prueth)
-{
-	void __iomem *sram = prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-
-	memset_io(sram + ICSS_LRE_START, 0, ICSS_LRE_STATS_DMEM_SIZE);
-
-	writel(ICSS_LRE_IEC62439_CONST_DUPLICATE_DISCARD,
-	       sram + ICSS_LRE_DUPLICATE_DISCARD);
-	writel(ICSS_LRE_IEC62439_CONST_TRANSP_RECEPTION_REMOVE_RCT,
-	       sram + ICSS_LRE_TRANSPARENT_RECEPTION);
-	prueth->prp_tr_mode = IEC62439_3_TR_REMOVE_RCT;
-}
-
-static void prueth_lre_dbg_init(struct prueth *prueth)
-{
-	void __iomem *dram0 = prueth->mem[PRUETH_MEM_DRAM0].va;
-
-	memset_io(dram0 + ICSS_LRE_DBG_START, 0,
-		  ICSS_LRE_DEBUG_COUNTER_DMEM_SIZE);
-}
-
-static void prueth_lre_protocol_init(struct prueth *prueth)
-{
-	void __iomem *dram0 = prueth->mem[PRUETH_MEM_DRAM0].va;
-	void __iomem *dram1 = prueth->mem[PRUETH_MEM_DRAM1].va;
-
-	if (PRUETH_IS_HSR(prueth))
-		writew(prueth->hsr_mode, dram0 + ICSS_LRE_HSR_MODE);
-
-	writel(ICSS_LRE_DUPLICATE_FORGET_TIME_400_MS,
-	       dram1 + ICSS_LRE_DUPLI_FORGET_TIME);
-	writel(ICSS_LRE_SUP_ADDRESS_INIT_OCTETS_HIGH,
-	       dram1 + ICSS_LRE_SUP_ADDR);
-	writel(ICSS_LRE_SUP_ADDRESS_INIT_OCTETS_LOW,
-	       dram1 + ICSS_LRE_SUP_ADDR_LOW);
-}
-
-static void prueth_lre_config_packet_timestamping(struct prueth *prueth)
-{
-	void __iomem *sram = prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-
-	writeb(1, sram + ICSS_LRE_PRIORITY_INTRS_STATUS_OFFSET);
-	writeb(1, sram + ICSS_LRE_TIMESTAMP_PKTS_STATUS_OFFSET);
-}
-
-static void prueth_lre_process_check_flags_event(struct prueth *prueth)
-{
-	void __iomem *dram =  prueth->mem[PRUETH_MEM_DRAM1].va;
-	unsigned long flags;
-
-	if (prueth->node_table_clear) {
-		pru_spin_lock(prueth->nt);
-		spin_lock_irqsave(&prueth->nt_lock, flags);
-		_prueth_lre_init_node_table(prueth);
-		spin_unlock_irqrestore(&prueth->nt_lock, flags);
-		/* we don't have to release the prueth lock
-		 * the note_table_init() cleares it anyway
-		 */
-		prueth->node_table_clear = 0;
-	} else {
-		prueth->tbl_check_mask &=
-			~ICSS_LRE_HOST_TIMER_NODE_TABLE_CLEAR_BIT;
-	}
-
-	/* schedule work here */
-	kthread_queue_work(prueth->nt_kworker, &prueth->nt_work);
-
-	writel(prueth->tbl_check_mask, dram + ICSS_LRE_HOST_TIMER_CHECK_FLAGS);
-}
-
-static enum hrtimer_restart prueth_lre_timer(struct hrtimer *timer)
-{
-	struct prueth *prueth = container_of(timer, struct prueth,
-					     tbl_check_timer);
-	unsigned int timeout = PRUETH_TIMER_MS;
-
-	hrtimer_forward_now(timer, ms_to_ktime(timeout));
-	if (prueth->emac_configured !=
-	    (BIT(PRUETH_PORT_MII0) | BIT(PRUETH_PORT_MII1)))
-		return HRTIMER_RESTART;
-
-	prueth_lre_process_check_flags_event(prueth);
-
-	return HRTIMER_RESTART;
-}
-
-static void prueth_lre_init_timer(struct prueth *prueth)
-{
-	hrtimer_init(&prueth->tbl_check_timer, CLOCK_MONOTONIC,
-		     HRTIMER_MODE_REL);
-	prueth->tbl_check_timer.function = prueth_lre_timer;
-}
-
-static void prueth_lre_start_timer(struct prueth *prueth)
-{
-	unsigned int timeout = PRUETH_TIMER_MS;
-
-	if (hrtimer_active(&prueth->tbl_check_timer))
-		return;
-
-	hrtimer_start(&prueth->tbl_check_timer, ms_to_ktime(timeout),
-		      HRTIMER_MODE_REL);
-}
-
-void prueth_lre_config(struct prueth *prueth)
-{
-	if (PRUETH_IS_HSR(prueth))
-		prueth->hsr_mode = ICSS_LRE_MODEH;
-
-	prueth_lre_init_timer(prueth);
-	prueth_lre_start_timer(prueth);
-	prueth_lre_pcp_queue_map_config(prueth);
-	prueth_lre_host_table_init(prueth);
-	prueth_lre_port_table_init(prueth);
-	prueth_lre_init(prueth);
-	prueth_lre_dbg_init(prueth);
-	prueth_lre_protocol_init(prueth);
-	/* for HSR/PRP LRE driver order the frames based on
-	 * packet timestamp.
-	 */
-	prueth_lre_config_packet_timestamping(prueth);
-}
-
-static void nt_updater(struct kthread_work *work)
-{
-	struct prueth *prueth = container_of(work, struct prueth, nt_work);
-
-	pop_queue_process(prueth, &prueth->nt_lock);
-
-	node_table_update_time(prueth->nt);
-	if (++prueth->rem_cnt >= 100) {
-		node_table_check_and_remove(prueth->nt,
-					    ICSS_LRE_NODE_FORGET_TIME_60000_MS);
-		prueth->rem_cnt = 0;
-	}
-}
-
-static int prueth_lre_emac_rx_packets(struct prueth_emac *emac,
-				      u8 qid1, u8 qid2)
-{
-	struct prueth *prueth = emac->prueth;
-	void *ocmc_ram = (__force void *)prueth->mem[PRUETH_MEM_OCMC].va;
-	u16 bd_rd_ptr, bd_wr_ptr, update_rd_ptr, bd_rd_ptr_o, bd_wr_ptr_o;
-	void __iomem *shared_ram = prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-	struct prueth_queue_desc __iomem *queue_desc, *queue_desc_o;
-	struct net_device_stats *ndevstats = &emac->ndev->stats;
-	int ret, used = 0, port, port0_q_empty, port1_q_empty;
-	unsigned int emac_max_pktlen = PRUETH_MAX_PKTLEN_LRE;
-	const struct prueth_queue_info *rxqueue, *rxqueue_o;
-	u8 overflow_cnt, overflow_cnt_o, status, status_o;
-	struct prueth_queue_desc __iomem *queue_desc_p;
-	struct prueth_packet_info pkt_info, pkt_info_o;
-	const struct prueth_queue_info *rxqueue_p;
-	struct prueth_packet_info *pkt_info_p;
-	struct net_device_stats *ndevstats_o;
-	struct net_device_stats *ndevstats_p;
-	u32 rd_buf_desc, rd_buf_desc_o;
-	struct prueth_emac *other_emac;
-	u16 *bd_rd_ptr_p, *bd_wr_ptr_p;
-	struct prueth_emac *emac_p;
-	u32 pkt_ts, pkt_ts_o;
-	u32 iep_wrap;
-
-	other_emac = prueth->emac[(emac->port_id ^ 0x3) - 1];
-	ndevstats_o = &other_emac->ndev->stats;
-
-	/* use the correct wrap value based on ICSSM version */
-	iep_wrap = prueth->fw_offsets->iep_wrap;
-	/* search host queues for packets */
-	queue_desc = emac->rx_queue_descs + qid1;
-	queue_desc_o = other_emac->rx_queue_descs + qid2;
-
-	rxqueue = &sw_queue_infos[PRUETH_PORT_HOST][qid1];
-	rxqueue_o = &sw_queue_infos[PRUETH_PORT_HOST][qid2];
-
-	status = readb(&queue_desc->status);
-	status_o = readb(&queue_desc_o->status);
-
-retry:
-	overflow_cnt = readb(&queue_desc->overflow_cnt);
-	overflow_cnt_o = readb(&queue_desc_o->overflow_cnt);
-
-	if (overflow_cnt > 0) {
-		emac->ndev->stats.rx_over_errors += overflow_cnt;
-		/* reset to zero */
-		writeb(0, &queue_desc->overflow_cnt);
-	}
-	if (overflow_cnt_o > 0) {
-		other_emac->ndev->stats.rx_over_errors += overflow_cnt_o;
-
-		/* reset to zero */
-		writeb(0, &queue_desc_o->overflow_cnt);
-	}
-
-	bd_rd_ptr = readw(&queue_desc->rd_ptr);
-	bd_wr_ptr = readw(&queue_desc->wr_ptr);
-
-	bd_rd_ptr_o = readw(&queue_desc_o->rd_ptr);
-	bd_wr_ptr_o = readw(&queue_desc_o->wr_ptr);
-
-	port0_q_empty = (bd_rd_ptr == bd_wr_ptr) ? 1 : 0;
-	port1_q_empty = (bd_rd_ptr_o == bd_wr_ptr_o) ? 1 : 0;
-
-	/* while packets are available in this queue */
-	while (!port0_q_empty || !port1_q_empty) {
-		/* get packet info from the read buffer descriptor */
-		rd_buf_desc = readl(shared_ram + bd_rd_ptr);
-		rd_buf_desc_o = readl(shared_ram + bd_rd_ptr_o);
-
-		parse_packet_info(prueth, rd_buf_desc, &pkt_info);
-		parse_packet_info(prueth, rd_buf_desc_o, &pkt_info_o);
-
-		pkt_ts = readl(ocmc_ram + ICSS_LRE_TIMESTAMP_ARRAY_OFFSET +
-			       bd_rd_ptr - SRAM_START_OFFSET);
-		pkt_ts_o = readl(ocmc_ram + ICSS_LRE_TIMESTAMP_ARRAY_OFFSET +
-				 bd_rd_ptr_o - SRAM_START_OFFSET);
-
-		if (!port0_q_empty && !port1_q_empty) {
-			/* Packets in both port queues */
-			/* Calculate diff b/n timestamps and account for
-			 * wraparound
-			 */
-			if (pkt_ts > pkt_ts_o)
-				port = (pkt_ts - pkt_ts_o) > (iep_wrap / 2) ?
-					0 : 1;
-			else
-				port = (pkt_ts_o - pkt_ts) > (iep_wrap / 2) ?
-					1 : 0;
-
-		} else if (!port0_q_empty) {
-			/* Packet(s) in port0 queue only */
-			port = 0;
-		} else {
-			/* Packet(s) in port1 queue only */
-			port = 1;
-		}
-
-		/* Select correct data structures for queue/packet selected */
-		if (port == 0) {
-			pkt_info_p = &pkt_info;
-			bd_wr_ptr_p = &bd_wr_ptr;
-			bd_rd_ptr_p = &bd_rd_ptr;
-			emac_p = emac;
-			ndevstats_p = ndevstats;
-			rxqueue_p = rxqueue;
-			queue_desc_p = queue_desc;
-		} else {
-			pkt_info_p = &pkt_info_o;
-			bd_wr_ptr_p = &bd_wr_ptr_o;
-			bd_rd_ptr_p = &bd_rd_ptr_o;
-			emac_p = other_emac;
-			ndevstats_p = ndevstats_o;
-			rxqueue_p = rxqueue_o;
-			queue_desc_p = queue_desc_o;
-		}
-
-		if ((*pkt_info_p).length <= 0) {
-			/* a packet length of zero will cause us to
-			 * never move the read pointer ahead, locking
-			 * the driver, so we manually have to move it
-			 * to the write pointer, discarding all
-			 * remaining packets in this queue. This should
-			 * never happen.
-			 */
-			update_rd_ptr = *bd_wr_ptr_p;
-			ndevstats_p->rx_length_errors++;
-		} else if ((*pkt_info_p).length > emac_max_pktlen) {
-			/* if the packet is too large we skip it but we
-			 * still need to move the read pointer ahead
-			 * and assume something is wrong with the read
-			 * pointer as the firmware should be filtering
-			 * these packets
-			 */
-			update_rd_ptr = *bd_wr_ptr_p;
-			ndevstats_p->rx_length_errors++;
-		} else {
-			update_rd_ptr = *bd_rd_ptr_p;
-			ret = emac_rx_packet(emac_p, &update_rd_ptr,
-					     pkt_info_p, rxqueue_p);
-			if (ret)
-				return IRQ_HANDLED;
-
-			used++;
-		}
-
-		/* after reading the buffer descriptor we clear it
-		 * to prevent improperly moved read pointer errors
-		 * from simply looking like old packets.
-		 */
-
-		/* update read pointer in queue descriptor */
-		if (port == 0) {
-			writel(0, shared_ram + bd_rd_ptr);
-			writew(update_rd_ptr, &queue_desc->rd_ptr);
-			bd_rd_ptr = update_rd_ptr;
-		} else {
-			writel(0, shared_ram + bd_rd_ptr_o);
-			writew(update_rd_ptr, &queue_desc_o->rd_ptr);
-			bd_rd_ptr_o = update_rd_ptr;
-		}
-
-		port0_q_empty = (bd_rd_ptr == bd_wr_ptr) ? 1 : 0;
-		port1_q_empty = (bd_rd_ptr_o == bd_wr_ptr_o) ? 1 : 0;
-	}
-
-	if (used) {
-		used = 0;
-		goto retry;
-	}
-
-	return IRQ_HANDLED;
-}
-
-static irqreturn_t prueth_lre_emac_rx_hardirq_lp(int irq, void *dev_id)
-{
-	struct prueth_ndev_priority *ndev_prio =
-		(struct prueth_ndev_priority *)dev_id;
-	struct net_device *ndev = ndev_prio->ndev;
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	return prueth_lre_emac_rx_packets(emac, PRUETH_QUEUE2, PRUETH_QUEUE4);
-}
-
-static irqreturn_t prueth_lre_emac_rx_hardirq_hp(int irq, void *dev_id)
-{
-	struct prueth_ndev_priority *ndev_prio =
-		(struct prueth_ndev_priority *)dev_id;
-	struct net_device *ndev = ndev_prio->ndev;
-	struct prueth_emac *emac = netdev_priv(ndev);
-
-	return prueth_lre_emac_rx_packets(emac, PRUETH_QUEUE1, PRUETH_QUEUE3);
-}
-
-int prueth_lre_request_irqs(struct prueth_emac *emac)
-{
-	struct prueth *prueth = emac->prueth;
-	int ret;
-
-	/* HSR/PRP. Request irq when first port is initialized */
-	if (prueth->emac_configured)
-		return 0;
-
-	ret = request_threaded_irq(prueth->rx_hpq_irq, NULL, prueth_lre_emac_rx_hardirq_hp,
-				   IRQF_TRIGGER_HIGH | IRQF_ONESHOT, "eth_hp_int", prueth->hp);
-	if (ret) {
-		netdev_err(emac->ndev, "unable to request RX HPQ IRQ\n");
-		return ret;
-	}
-
-	ret = request_threaded_irq(prueth->rx_lpq_irq, NULL, prueth_lre_emac_rx_hardirq_lp,
-				   IRQF_TRIGGER_HIGH | IRQF_ONESHOT, "eth_lp_int", prueth->lp);
-	if (ret) {
-		netdev_err(emac->ndev, "unable to request RX LPQ IRQ\n");
-		free_irq(prueth->rx_hpq_irq, prueth->hp);
-		return ret;
-	}
-
-	return ret;
-}
-
-void prueth_lre_free_irqs(struct prueth_emac *emac)
-{
-	struct prueth *prueth = emac->prueth;
-
-	/* HSR/PRP: free irqs when last port is down */
-	if (prueth->emac_configured)
-		return;
-
-	free_irq(prueth->rx_lpq_irq, prueth->lp);
-	free_irq(prueth->rx_hpq_irq, prueth->hp);
-}
-
-void prueth_lre_free_memory(struct prueth *prueth)
-{
-	/* HSR/PRP: initialize node table when first port is up */
-	if (prueth->emac_configured)
-		return;
-
-	kfree(prueth->nt);
-	kfree(prueth->mac_queue);
-	prueth->mac_queue = NULL;
-	prueth->nt = NULL;
-}
-
-#define PRUETH_LRE_STAT_OFS(m) offsetof(struct lre_statistics, m)
-static const struct {
-	char string[ETH_GSTRING_LEN];
-	u32 offset;
-} prueth_ethtool_lre_stats[] = {
-	{"lreTxA", PRUETH_LRE_STAT_OFS(cnt_tx_a)},
-	{"lreTxB", PRUETH_LRE_STAT_OFS(cnt_tx_b)},
-	{"lreTxC", PRUETH_LRE_STAT_OFS(cnt_tx_c)},
-
-	{"lreErrWrongLanA", PRUETH_LRE_STAT_OFS(cnt_errwronglan_a)},
-	{"lreErrWrongLanB", PRUETH_LRE_STAT_OFS(cnt_errwronglan_b)},
-	{"lreErrWrongLanC", PRUETH_LRE_STAT_OFS(cnt_errwronglan_c)},
-
-	{"lreRxA", PRUETH_LRE_STAT_OFS(cnt_rx_a)},
-	{"lreRxB", PRUETH_LRE_STAT_OFS(cnt_rx_b)},
-	{"lreRxC", PRUETH_LRE_STAT_OFS(cnt_rx_c)},
-
-	{"lreErrorsA", PRUETH_LRE_STAT_OFS(cnt_errors_a)},
-	{"lreErrorsB", PRUETH_LRE_STAT_OFS(cnt_errors_b)},
-	{"lreErrorsC", PRUETH_LRE_STAT_OFS(cnt_errors_c)},
-
-	{"lreNodes", PRUETH_LRE_STAT_OFS(cnt_nodes)},
-	{"lreProxyNodes", PRUETH_LRE_STAT_OFS(cnt_proxy_nodes)},
-
-	{"lreUniqueRxA", PRUETH_LRE_STAT_OFS(cnt_unique_rx_a)},
-	{"lreUniqueRxB", PRUETH_LRE_STAT_OFS(cnt_unique_rx_b)},
-	{"lreUniqueRxC", PRUETH_LRE_STAT_OFS(cnt_unique_rx_c)},
-
-	{"lreDuplicateRxA", PRUETH_LRE_STAT_OFS(cnt_duplicate_rx_a)},
-	{"lreDuplicateRxB", PRUETH_LRE_STAT_OFS(cnt_duplicate_rx_b)},
-	{"lreDuplicateRxC", PRUETH_LRE_STAT_OFS(cnt_duplicate_rx_c)},
-
-	{"lreMultiRxA", PRUETH_LRE_STAT_OFS(cnt_multiple_rx_a)},
-	{"lreMultiRxB", PRUETH_LRE_STAT_OFS(cnt_multiple_rx_b)},
-	{"lreMultiRxC", PRUETH_LRE_STAT_OFS(cnt_multiple_rx_c)},
-
-	{"lreOwnRxA", PRUETH_LRE_STAT_OFS(cnt_own_rx_a)},
-	{"lreOwnRxB", PRUETH_LRE_STAT_OFS(cnt_own_rx_b)},
-
-	{"lreDuplicateDiscard", PRUETH_LRE_STAT_OFS(duplicate_discard)},
-	{"lreTransRecept", PRUETH_LRE_STAT_OFS(transparent_reception)},
-
-	{"lreNtLookupErrA", PRUETH_LRE_STAT_OFS(node_table_lookup_error_a)},
-	{"lreNtLookupErrB", PRUETH_LRE_STAT_OFS(node_table_lookup_error_b)},
-	{"lreNodeTableFull", PRUETH_LRE_STAT_OFS(node_table_full)},
-	{"lreMulticastDropped", PRUETH_LRE_STAT_OFS(lre_multicast_dropped)},
-	{"lreVlanDropped", PRUETH_LRE_STAT_OFS(lre_vlan_dropped)},
-	{"lrePaceTimerExpired", PRUETH_LRE_STAT_OFS(lre_intr_tmr_exp)},
-	{"lreTotalRxA", PRUETH_LRE_STAT_OFS(lre_total_rx_a)},
-	{"lreTotalRxB", PRUETH_LRE_STAT_OFS(lre_total_rx_b)},
-	{"lreOverflowPru0", PRUETH_LRE_STAT_OFS(lre_overflow_pru0)},
-	{"lreOverflowPru1", PRUETH_LRE_STAT_OFS(lre_overflow_pru1)},
-	{"lreDDCountPru0", PRUETH_LRE_STAT_OFS(lre_cnt_dd_pru0)},
-	{"lreDDCountPru1", PRUETH_LRE_STAT_OFS(lre_cnt_dd_pru1)},
-	{"lreCntSupPru0", PRUETH_LRE_STAT_OFS(lre_cnt_sup_pru0)},
-	{"lreCntSupPru1", PRUETH_LRE_STAT_OFS(lre_cnt_sup_pru1)},
-};
-
-void prueth_lre_set_stats(struct prueth *prueth,
-			  struct lre_statistics *pstats)
-{
-	void __iomem *sram = prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-
-	if (prueth->emac_configured)
-		return;
-
-	/* These two are actually not statistics, so keep original */
-	pstats->duplicate_discard = readl(sram + ICSS_LRE_DUPLICATE_DISCARD);
-	pstats->transparent_reception =
-		readl(sram + ICSS_LRE_TRANSPARENT_RECEPTION);
-	memcpy_fromio(sram + ICSS_LRE_START + 4, pstats, sizeof(*pstats));
-}
-
-void prueth_lre_get_stats(struct prueth *prueth,
-			  struct lre_statistics *pstats)
-{
-	void __iomem *sram = prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-
-	memcpy_fromio(pstats, sram + ICSS_LRE_CNT_TX_A, sizeof(*pstats));
-}
-
-int prueth_lre_get_sset_count(struct prueth *prueth)
-{
-	if (!PRUETH_IS_LRE(prueth))
-		return 0;
-
-	return ARRAY_SIZE(prueth_ethtool_lre_stats);
-}
-
-void prueth_lre_get_strings(struct prueth *prueth, u8 *data)
-{
-	int i;
-
-	if (!PRUETH_IS_LRE(prueth))
-		return;
-
-	for (i = 0; i < ARRAY_SIZE(prueth_ethtool_lre_stats); i++) {
-		memcpy(data, prueth_ethtool_lre_stats[i].string,
-		       ETH_GSTRING_LEN);
-		data += ETH_GSTRING_LEN;
-	}
-}
-
-void prueth_lre_update_stats(struct prueth *prueth, u64 *data)
-{
-	struct lre_statistics lre_stats;
-	void *ptr;
-	u32 val;
-	int i;
-
-	if (!PRUETH_IS_LRE(prueth))
-		return;
-
-	prueth_lre_get_stats(prueth, &lre_stats);
-	for (i = 0; i < ARRAY_SIZE(prueth_ethtool_lre_stats); i++) {
-		ptr = &lre_stats;
-		ptr += prueth_ethtool_lre_stats[i].offset;
-		val = *(u32 *)ptr;
-		data[i] = val;
-	}
-}
-
-static int prueth_lre_attr_get(struct net_device *ndev,
-			       struct lredev_attr *attr)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	void __iomem *sram = prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-	void __iomem *dram0 = prueth->mem[PRUETH_MEM_DRAM0].va;
-	void __iomem *dram1 = prueth->mem[PRUETH_MEM_DRAM1].va;
-	int ret = 0;
-
-	netdev_dbg(ndev, "%d:%s, id %d\n", __LINE__, __func__, attr->id);
-
-	switch (attr->id) {
-	case LREDEV_ATTR_ID_HSR_MODE:
-		if (!PRUETH_IS_HSR(prueth))
-			return -EPERM;
-		attr->mode = readl(dram0 + ICSS_LRE_HSR_MODE);
-		break;
-	case LREDEV_ATTR_ID_DD_MODE:
-		attr->dd_mode = readl(sram + ICSS_LRE_DUPLICATE_DISCARD);
-		break;
-	case LREDEV_ATTR_ID_PRP_TR:
-		if (!PRUETH_IS_PRP(prueth))
-			return -EINVAL;
-		attr->tr_mode = prueth->prp_tr_mode;
-		break;
-	case LREDEV_ATTR_ID_DLRMT:
-		attr->dl_reside_max_time =
-			readl(dram1 + ICSS_LRE_DUPLI_FORGET_TIME) * 10;
-		break;
-	case LREDEV_ATTR_ID_CLEAR_NT:
-		attr->clear_nt_cmd = prueth->node_table_clear_last_cmd;
-		break;
-	default:
-		ret = -EINVAL;
-		break;
-	}
-
-	return ret;
-}
-
-static int prueth_lre_attr_set(struct net_device *ndev,
-			       struct lredev_attr *attr)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	void __iomem *sram = prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-	void __iomem *dram0 = prueth->mem[PRUETH_MEM_DRAM0].va;
-	void __iomem *dram1 = prueth->mem[PRUETH_MEM_DRAM1].va;
-	int ret = 0;
-
-	netdev_dbg(ndev, "%d:%s, id = %d\n", __LINE__, __func__, attr->id);
-
-	switch (attr->id) {
-	case LREDEV_ATTR_ID_HSR_MODE:
-		if (!PRUETH_IS_HSR(prueth))
-			return -EPERM;
-		prueth->hsr_mode = attr->mode;
-		writel(prueth->hsr_mode, dram0 + ICSS_LRE_HSR_MODE);
-		break;
-	case LREDEV_ATTR_ID_DD_MODE:
-		writel(attr->dd_mode, sram + ICSS_LRE_DUPLICATE_DISCARD);
-		break;
-	case LREDEV_ATTR_ID_PRP_TR:
-		if (!PRUETH_IS_PRP(prueth))
-			return -EINVAL;
-		prueth->prp_tr_mode = attr->tr_mode;
-		break;
-	case LREDEV_ATTR_ID_DLRMT:
-		/* input is in milli seconds. Firmware expects in unit
-		 * of 10 msec
-		 */
-		writel((attr->dl_reside_max_time / 10),
-		       dram1 + ICSS_LRE_DUPLI_FORGET_TIME);
-		break;
-	case LREDEV_ATTR_ID_CLEAR_NT:
-		/* need to return last cmd received for corresponding
-		 * get command. So save it
-		 */
-		prueth->node_table_clear_last_cmd = attr->clear_nt_cmd;
-		if (attr->clear_nt_cmd == IEC62439_3_CLEAR_NT)
-			prueth->node_table_clear = 1;
-		else
-			prueth->node_table_clear = 0;
-		break;
-	default:
-		ret = -EINVAL;
-		break;
-	}
-
-	return ret;
-}
-
-static int emac_lredev_update_node_entry(struct node_tbl_t *node,
-					 struct lre_node_table_entry table[],
-					 int j)
-{
-	u8 val, is_hsr, updated = 1;
-
-	table[j].time_last_seen_a = node->time_last_seen_a;
-	table[j].time_last_seen_b = node->time_last_seen_b;
-
-	is_hsr = node->status & ICSS_LRE_NT_REM_NODE_HSR_BIT;
-	val = (node->status & ICSS_LRE_NT_REM_NODE_TYPE_MASK) >>
-					ICSS_LRE_NT_REM_NODE_TYPE_SHIFT;
-	switch (val) {
-	case ICSS_LRE_NT_REM_NODE_TYPE_DAN:
-		if (is_hsr)
-			table[j].node_type = IEC62439_3_DANH;
-		else
-			table[j].node_type = IEC62439_3_DANP;
-		break;
-
-	case ICSS_LRE_NT_REM_NODE_TYPE_REDBOX:
-		if (is_hsr)
-			table[j].node_type = IEC62439_3_REDBOXH;
-		else
-			table[j].node_type = IEC62439_3_REDBOXP;
-		break;
-
-	case ICSS_LRE_NT_REM_NODE_TYPE_VDAN:
-		if (is_hsr)
-			table[j].node_type = IEC62439_3_VDANH;
-		else
-			table[j].node_type = IEC62439_3_VDANP;
-		break;
-	default:
-		updated = 0;
-		break;
-	}
-
-	return updated;
-}
-
-static int prueth_lre_get_node_table(struct net_device *ndev,
-				     struct lre_node_table_entry table[],
-				     int size)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	struct node_tbl *nt = prueth->nt;
-	struct bin_tbl_t *bin;
-	struct node_tbl_t *node;
-	int i, j = 0, updated;
-	unsigned long flags;
-
-	netdev_dbg(ndev, "%d:%s\n", __LINE__, __func__);
-
-	if (size < nt->nt_lre_cnt->lre_cnt)
-		netdev_warn(ndev,
-			    "actual table size %d is < required size %d\n",
-			    size,  nt->nt_lre_cnt->lre_cnt);
-
-	spin_lock_irqsave(&prueth->nt_lock, flags);
-	for (i = 0; i < nt->bin_array_max_entries; i++) {
-		if (nt->bin_array->bin_tbl[i].node_tbl_offset <
-		    nt->nt_array_max_entries) {
-			bin =  &nt->bin_array->bin_tbl[i];
-			if (WARN_ON(bin->node_tbl_offset >=
-					nt->nt_array_max_entries))
-				continue;
-			node =  &nt->nt_array->node_tbl[bin->node_tbl_offset];
-
-			if (!(node->entry_state & 0x1))
-				continue;
-
-			updated = emac_lredev_update_node_entry(node, table, j);
-			if (updated) {
-				table[j].mac_address[0] = bin->src_mac_id[3];
-				table[j].mac_address[1] = bin->src_mac_id[2];
-				table[j].mac_address[2] = bin->src_mac_id[1];
-				table[j].mac_address[3] = bin->src_mac_id[0];
-				table[j].mac_address[4] = bin->src_mac_id[5];
-				table[j].mac_address[5] = bin->src_mac_id[4];
-				j++;
-			}
-		}
-	}
-	spin_unlock_irqrestore(&prueth->nt_lock, flags);
-
-	return j;
-}
-
-static int prueth_lre_get_lre_stats(struct net_device *ndev,
-				    struct lre_stats *stats)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	void __iomem *sram = prueth->mem[PRUETH_MEM_SHARED_RAM].va;
-
-	memcpy_fromio(stats, sram + ICSS_LRE_CNT_TX_A, sizeof(*stats));
-
-	return 0;
-}
-
-static int prueth_lre_set_sv_vlan_id(struct net_device *ndev, u16 vid)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-
-	if (!PRUETH_IS_LRE(prueth))
-		return 0;
-
-	return emac_add_del_vid(emac, true, htons(ETH_P_8021Q), vid);
-}
-
-const struct lredev_ops prueth_lredev_ops = {
-	.lredev_attr_get = prueth_lre_attr_get,
-	.lredev_attr_set = prueth_lre_attr_set,
-	.lredev_get_node_table = prueth_lre_get_node_table,
-	.lredev_get_stats = prueth_lre_get_lre_stats,
-	.lredev_set_sv_vlan_id = prueth_lre_set_sv_vlan_id,
-};
-
-int prueth_lre_init_node_table(struct prueth *prueth)
-{
-	/* HSR/PRP: initialize node table when first port is up */
-	if (prueth->emac_configured)
-		return 0;
-
-	/* initialize for node table handling in driver for HSR/PRP */
-	prueth->mac_queue = kmalloc(sizeof(*prueth->mac_queue), GFP_KERNEL);
-	prueth->nt = kmalloc(sizeof(*prueth->nt), GFP_KERNEL);
-	if (!prueth->mac_queue || !prueth->nt) {
-		kfree(prueth->mac_queue);
-		kfree(prueth->nt);
-		prueth->mac_queue = NULL;
-		prueth->nt = NULL;
-		return -ENOMEM;
-	}
-
-	_prueth_lre_init_node_table(prueth);
-	spin_lock_init(&prueth->nt_lock);
-	kthread_init_work(&prueth->nt_work, nt_updater);
-	prueth->nt_kworker = kthread_create_worker(0, "prueth_nt");
-
-	return 0;
-}
diff --git a/drivers/net/ethernet/ti/prueth_lre.h b/drivers/net/ethernet/ti/prueth_lre.h
deleted file mode 100644
index 1e1e71d62ce3..000000000000
--- a/drivers/net/ethernet/ti/prueth_lre.h
+++ /dev/null
@@ -1,200 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2020 Texas Instruments Incorporated - http://www.ti.com
- */
-
-#ifndef __NET_TI_PRUETH_LRE_H
-#define __NET_TI_PRUETH_LRE_H
-
-#include <linux/etherdevice.h>
-#include <linux/interrupt.h>
-#include <linux/if_vlan.h>
-
-#include "prueth.h"
-#include "icss_lre_firmware.h"
-
-#define PRUETH_MAX_PKTLEN_LRE		(VLAN_ETH_FRAME_LEN +  ETH_FCS_LEN + \
-					 ICSS_LRE_TAG_RCT_SIZE)
-#define PRUETH_MAC_QUEUE_MAX_SHIFT			6
-#define PRUETH_MAC_QUEUE_MAX		BIT(PRUETH_MAC_QUEUE_MAX_SHIFT)
-#define PRUETH_LRE_INDEX_TBL_MAX_ENTRIES	256
-#define PRUETH_LRE_BIN_TBL_MAX_ENTRIES		256
-#define PRUETH_LRE_NODE_TBL_MAX_ENTRIES		256
-#define LRE_PROTO_HSR			0
-#define LRE_PROTO_PRP			1
-#define LRE_OK				0
-#define LRE_ERR				-1
-#define LRE_SV_FRAME_OFFSET		20
-
-/* Link Redundancy Entity stats counters */
-struct lre_statistics {
-	u32 cnt_tx_a;
-	u32 cnt_tx_b;
-	u32 cnt_tx_c;
-
-	u32 cnt_errwronglan_a;
-	u32 cnt_errwronglan_b;
-	u32 cnt_errwronglan_c;
-
-	u32 cnt_rx_a;
-	u32 cnt_rx_b;
-	u32 cnt_rx_c;
-
-	u32 cnt_errors_a;
-	u32 cnt_errors_b;
-	u32 cnt_errors_c;
-
-	u32 cnt_nodes;
-	u32 cnt_proxy_nodes;
-
-	u32 cnt_unique_rx_a;
-	u32 cnt_unique_rx_b;
-	u32 cnt_unique_rx_c;
-
-	u32 cnt_duplicate_rx_a;
-	u32 cnt_duplicate_rx_b;
-	u32 cnt_duplicate_rx_c;
-
-	u32 cnt_multiple_rx_a;
-	u32 cnt_multiple_rx_b;
-	u32 cnt_multiple_rx_c;
-
-	u32 cnt_own_rx_a;
-	u32 cnt_own_rx_b;
-
-	u32 duplicate_discard;
-	u32 transparent_reception;
-
-	u32 node_table_lookup_error_a;
-	u32 node_table_lookup_error_b;
-	u32 node_table_full;
-	u32 lre_multicast_dropped;
-	u32 lre_vlan_dropped;
-	u32 lre_intr_tmr_exp;
-
-	/* additional debug counters */
-	u32 lre_total_rx_a; /* count of all frames received at port-A */
-	u32 lre_total_rx_b; /* count of all frames received at port-B */
-	u32 lre_overflow_pru0; /* count of overflow frames to host on PRU 0 */
-	u32 lre_overflow_pru1; /* count of overflow frames to host on PRU 1 */
-	u32 lre_cnt_dd_pru0; /* count of DD frames to host on PRU 0 */
-	u32 lre_cnt_dd_pru1; /* count of DD frames to host on PRU 1 */
-	u32 lre_cnt_sup_pru0; /* count of supervisor frames to host on PRU 0 */
-	u32 lre_cnt_sup_pru1; /* count of supervisor frames to host on PRU 1 */
-} __packed;
-
-/* node table info */
-struct prueth_lre_node {
-	u8 mac[6];
-	u8 state;
-	u8 status;
-
-	u32 cnt_rx_a;
-	u32 cnt_rx_b;
-
-	u32 prp_lid_err_a;
-	u32 prp_lid_err_b;
-
-	u8 cnt_rx_sup_a;
-	u8 cnt_rx_sup_b;
-	u16 time_last_seen_sup;
-
-	u16 time_last_seen_a;
-	u16 time_last_seen_b;
-} __packed;
-
-/* NT queue definitions */
-struct nt_queue_entry {
-	u8 mac[ETH_ALEN];
-	unsigned int sv_frame:1;
-	unsigned int proto:1;
-	int port_id:6;
-};
-
-struct nt_queue_t {
-	struct nt_queue_entry nt_queue[PRUETH_MAC_QUEUE_MAX];
-	int rd_ind;
-	int wr_ind;
-	bool full;
-};
-
-struct node_index_tbl_t {
-	u16 bin_offset;
-	u16 bin_no_entries;
-	u8  lin_bin;	/* 0 - linear; 1 - binary; */
-	u8  res1;
-} __packed;
-
-struct bin_tbl_t {
-	u8 src_mac_id[ETH_ALEN];
-	u16 node_tbl_offset;
-} __packed;
-
-struct node_tbl_t {
-	u8 mac[ETH_ALEN];
-	u8  entry_state;
-	u8  status;
-	u32 cnt_ra;
-	u32 cnt_rb;
-	u32 err_wla;
-	u32 err_wlb;
-	u8  cnt_rx_sup_a;
-	u8  cnt_rx_sup_b;
-	u16 time_last_seen_s;
-	u16 time_last_seen_a;
-	u16 time_last_seen_b;
-} __packed;
-
-struct node_tbl_lre_cnt_t {
-	u16 lre_cnt;
-} __packed;
-
-struct node_tbl_info_t {
-	u32 next_free_slot;
-	u8  arm_lock;
-	u8  res;
-	u16 fw_lock; /* firmware use this field as 2 independent bytes
-		      * first byte for PRU0, second for PRU1
-		      */
-} __packed;
-
-struct nt_array_t {
-	struct node_tbl_t	node_tbl[PRUETH_LRE_NODE_TBL_MAX_ENTRIES];
-} __packed;
-struct index_array_t {
-	struct node_index_tbl_t index_tbl[PRUETH_LRE_INDEX_TBL_MAX_ENTRIES];
-} __packed;
-struct bin_array_t {
-	struct bin_tbl_t	bin_tbl[PRUETH_LRE_BIN_TBL_MAX_ENTRIES];
-} __packed;
-
-struct node_tbl {
-	struct bin_array_t *bin_array;
-	struct index_array_t *index_array;
-	struct nt_array_t *nt_array;
-	struct node_tbl_info_t *nt_info;
-	struct node_tbl_lre_cnt_t *nt_lre_cnt;
-	u32 index_array_max_entries;
-	u32 bin_array_max_entries;
-	u32 nt_array_max_entries;
-	u16 hash_mask;
-};
-
-void prueth_lre_config(struct prueth *prueth);
-int prueth_lre_init_node_table(struct prueth *prueth);
-int prueth_lre_request_irqs(struct prueth_emac *emac);
-void prueth_lre_free_irqs(struct prueth_emac *emac);
-int prueth_lre_get_sset_count(struct prueth *prueth);
-void prueth_lre_get_strings(struct prueth *prueth, u8 *data);
-void prueth_lre_update_stats(struct prueth *prueth, u64 *data);
-void prueth_lre_set_stats(struct prueth *prueth,
-			  struct lre_statistics *pstats);
-void prueth_lre_get_stats(struct prueth *prueth,
-			  struct lre_statistics *pstats);
-void prueth_lre_config_check_flags(struct prueth *prueth);
-void prueth_lre_free_memory(struct prueth *prueth);
-int prueth_lre_nt_insert(struct prueth *prueth,
-			 u8 *mac, int port, int sv_frame, int proto);
-
-extern const struct lredev_ops prueth_lredev_ops;
-
-#endif /* __NET_TI_PRUETH_LRE_H */
diff --git a/drivers/net/ethernet/ti/prueth_ptp.h b/drivers/net/ethernet/ti/prueth_ptp.h
deleted file mode 100644
index 00ec122e004d..000000000000
--- a/drivers/net/ethernet/ti/prueth_ptp.h
+++ /dev/null
@@ -1,85 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/*
- * Copyright (C) 2020-2021 Texas Instruments Incorporated - https://www.ti.com
- */
-#ifndef PRUETH_PTP_H
-#define PRUETH_PTP_H
-
-#define RX_SYNC_TIMESTAMP_OFFSET_P1             0x8    /* 8 bytes */
-#define RX_PDELAY_REQ_TIMESTAMP_OFFSET_P1       0x14   /* 12 bytes */
-
-#define DISABLE_PTP_FRAME_FORWARDING_CTRL_OFFSET 0x14	/* 1 byte */
-
-#define RX_PDELAY_RESP_TIMESTAMP_OFFSET_P1      0x20   /* 12 bytes */
-#define RX_SYNC_TIMESTAMP_OFFSET_P2             0x2c   /* 12 bytes */
-#define RX_PDELAY_REQ_TIMESTAMP_OFFSET_P2       0x38   /* 12 bytes */
-#define RX_PDELAY_RESP_TIMESTAMP_OFFSET_P2      0x44   /* 12 bytes */
-#define TIMESYNC_DOMAIN_NUMBER_LIST             0x50   /* 2 bytes */
-#define P1_SMA_LINE_DELAY_OFFSET                0x52   /* 4 bytes */
-#define P2_SMA_LINE_DELAY_OFFSET                0x56   /* 4 bytes */
-#define TIMESYNC_SECONDS_COUNT_OFFSET           0x5a   /* 6 bytes */
-#define TIMESYNC_TC_RCF_OFFSET                  0x60   /* 4 bytes */
-#define DUT_IS_MASTER_OFFSET                    0x64   /* 1 byte */
-#define MASTER_PORT_NUM_OFFSET                  0x65   /* 1 byte */
-#define SYNC_MASTER_MAC_OFFSET                  0x66   /* 6 bytes */
-#define TX_TS_NOTIFICATION_OFFSET_SYNC_P1       0x6c   /* 1 byte */
-#define TX_TS_NOTIFICATION_OFFSET_PDEL_REQ_P1   0x6d   /* 1 byte */
-#define TX_TS_NOTIFICATION_OFFSET_PDEL_RES_P1   0x6e   /* 1 byte */
-#define TX_TS_NOTIFICATION_OFFSET_SYNC_P2       0x6f   /* 1 byte */
-#define TX_TS_NOTIFICATION_OFFSET_PDEL_REQ_P2   0x70   /* 1 byte */
-#define TX_TS_NOTIFICATION_OFFSET_PDEL_RES_P2   0x71   /* 1 byte */
-#define TX_SYNC_TIMESTAMP_OFFSET_P1             0x72   /* 12 bytes */
-#define TX_PDELAY_REQ_TIMESTAMP_OFFSET_P1       0x7e   /* 12 bytes */
-#define TX_PDELAY_RESP_TIMESTAMP_OFFSET_P1      0x8a   /* 12 bytes */
-#define TX_SYNC_TIMESTAMP_OFFSET_P2             0x96   /* 12 bytes */
-#define TX_PDELAY_REQ_TIMESTAMP_OFFSET_P2       0xa2   /* 12 bytes */
-#define TX_PDELAY_RESP_TIMESTAMP_OFFSET_P2      0xae   /* 12 bytes */
-#define TIMESYNC_CTRL_VAR_OFFSET                0xba   /* 1 byte */
-#define DISABLE_SWITCH_SYNC_RELAY_OFFSET        0xbb   /* 1 byte */
-#define MII_RX_CORRECTION_OFFSET                0xbc   /* 2 bytes */
-#define MII_TX_CORRECTION_OFFSET                0xbe   /* 2 bytes */
-#define TIMESYNC_CMP1_CMP_OFFSET                0xc1   /* 8 bytes */
-#define TIMESYNC_SYNC0_CMP_OFFSET               0xc9   /* 8 bytes */
-#define TIMESYNC_CMP1_PERIOD_OFFSET             0xd1   /* 4 bytes */
-#define TIMESYNC_SYNC0_WIDTH_OFFSET             0xd5   /* 4 bytes */
-#define SINGLE_STEP_IEP_OFFSET_P1               0xd9   /* 8 bytes */
-#define SINGLE_STEP_SECONDS_OFFSET_P1           0xe1   /* 8 bytes */
-#define SINGLE_STEP_IEP_OFFSET_P2               0xe9   /* 8 bytes */
-#define SINGLE_STEP_SECONDS_OFFSET_P2           0xf1   /* 8 bytes */
-#define LINK_LOCAL_FRAME_HAS_HSR_TAG            0xf9   /* 1 bytes */
-#define PTP_PREV_TX_TIMESTAMP_P1                0x101  /* 8 bytes */
-#define PTP_PREV_TX_TIMESTAMP_P2                0x109  /* 8 bytes */
-#define PTP_CLK_IDENTITY_OFFSET                 0x111  /* 8 bytes */
-#define PTP_SCRATCH_MEM                         0x119  /* 16 byte */
-#define PTP_IPV4_UDP_E2E_ENABLE                 0x129  /* 1 byte */
-
-enum {
-	PRUETH_PTP_SYNC,
-	PRUETH_PTP_DLY_REQ,
-	PRUETH_PTP_DLY_RESP,
-	PRUETH_PTP_TS_EVENTS,
-};
-
-#define PRUETH_PTP_TS_SIZE		12
-#define PRUETH_PTP_TS_NOTIFY_SIZE	1
-#define PRUETH_PTP_TS_NOTIFY_MASK	0xff
-
-/* Bit definitions for TIMESYNC_CTRL */
-#define TIMESYNC_CTRL_BG_ENABLE    BIT(0)
-#define TIMESYNC_CTRL_FORCED_2STEP BIT(1)
-
-static inline u32 prueth_tx_ts_offs_get(u8 port, u8 event)
-{
-	return TX_SYNC_TIMESTAMP_OFFSET_P1 + port *
-		PRUETH_PTP_TS_EVENTS * PRUETH_PTP_TS_SIZE +
-		event * PRUETH_PTP_TS_SIZE;
-}
-
-static inline u32 prueth_tx_ts_notify_offs_get(u8 port, u8 event)
-{
-	return TX_TS_NOTIFICATION_OFFSET_SYNC_P1 +
-		PRUETH_PTP_TS_EVENTS * PRUETH_PTP_TS_NOTIFY_SIZE * port +
-		event * PRUETH_PTP_TS_NOTIFY_SIZE;
-}
-
-#endif /* PRUETH_PTP_H */
diff --git a/drivers/net/ethernet/ti/prueth_qos.c b/drivers/net/ethernet/ti/prueth_qos.c
deleted file mode 100644
index 008a7cbdf005..000000000000
--- a/drivers/net/ethernet/ti/prueth_qos.c
+++ /dev/null
@@ -1,214 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/* Copyright (C) 2020-2021 Texas Instruments Incorporated - https://www.ti.com
- */
-
-#include <linux/kernel.h>
-#include <linux/pruss.h>
-#include <linux/regmap.h>
-#include <linux/remoteproc.h>
-#include <net/pkt_cls.h>
-
-#include "icss_mii_rt.h"
-#include "icss_vlan_mcast_filter_mmap.h"
-#include "prueth.h"
-
-static void emac_nsp_enable(void __iomem *counter, u16 credit)
-{
-	writel((credit << PRUETH_NSP_CREDIT_SHIFT) | PRUETH_NSP_ENABLE,
-	       counter);
-}
-
-static void prueth_enable_nsp(struct prueth_emac *emac)
-{
-	struct prueth *prueth = emac->prueth;
-	void __iomem *dram = prueth->mem[emac->dram].va;
-
-	if (emac->nsp_bc.cookie)
-		emac_nsp_enable(dram + STORM_PREVENTION_OFFSET_BC,
-				emac->nsp_bc.credit);
-	if (emac->nsp_mc.cookie)
-		emac_nsp_enable(dram + STORM_PREVENTION_OFFSET_MC,
-				emac->nsp_mc.credit);
-	if (emac->nsp_uc.cookie)
-		emac_nsp_enable(dram + STORM_PREVENTION_OFFSET_UC,
-				emac->nsp_uc.credit);
-}
-
-static int emac_flower_parse_policer(struct prueth_emac *emac,
-				     struct netlink_ext_ack *extack,
-				     struct flow_cls_offload *cls,
-				     u64 rate_bytes_per_sec)
-{
-	struct flow_rule *rule = flow_cls_offload_flow_rule(cls);
-	struct flow_dissector *dissector = rule->match.dissector;
-	u8 null_mac[] = {0x00, 0x00, 0x00, 0x00, 0x00, 0x00};
-	u8 bc_mac[] = {0xff, 0xff, 0xff, 0xff, 0xff, 0xff};
-	u8 mc_mac[] = {0x01, 0x00, 0x00, 0x00, 0x00, 0x00};
-	struct flow_match_eth_addrs match;
-	struct nsp_counter *nsp = NULL;
-	char *str;
-	u32 pps;
-
-	if (dissector->used_keys &
-	    ~(BIT(FLOW_DISSECTOR_KEY_BASIC) |
-	      BIT(FLOW_DISSECTOR_KEY_CONTROL) |
-	      BIT(FLOW_DISSECTOR_KEY_ETH_ADDRS))) {
-		NL_SET_ERR_MSG_MOD(extack,
-				   "Unsupported keys used");
-		return -EOPNOTSUPP;
-	}
-
-	if (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_ETH_ADDRS)) {
-		NL_SET_ERR_MSG_MOD(extack, "Not matching on eth address");
-		return -EOPNOTSUPP;
-	}
-
-	flow_rule_match_eth_addrs(rule, &match);
-
-	if (!ether_addr_equal_masked(match.key->src, null_mac,
-				     match.mask->src)) {
-		NL_SET_ERR_MSG_MOD(extack,
-				   "Matching on source MAC not supported");
-		return -EOPNOTSUPP;
-	}
-
-	if (ether_addr_equal(match.key->dst, bc_mac)) {
-		if (!emac->nsp_bc.cookie ||
-		    emac->nsp_bc.cookie == cls->cookie)
-			nsp = &emac->nsp_bc;
-		else
-			NL_SET_ERR_MSG_MOD(extack, "BC Filter already set");
-		str = "Broad";
-	} else if (ether_addr_equal_masked(match.key->dst, mc_mac, mc_mac)) {
-		if (!emac->nsp_mc.cookie ||
-		    emac->nsp_mc.cookie == cls->cookie)
-			nsp = &emac->nsp_mc;
-		else
-			NL_SET_ERR_MSG_MOD(extack, "MC Filter already set");
-		str = "Multi";
-	} else {
-		if (!emac->nsp_uc.cookie ||
-		    emac->nsp_uc.cookie == cls->cookie)
-			nsp = &emac->nsp_uc;
-		else
-			NL_SET_ERR_MSG_MOD(extack, "UC Filter already set");
-		str = "Uni";
-	}
-
-	if (!nsp)
-		return -EOPNOTSUPP;
-
-	/* Calculate number of packets per second for given bps
-	 * assuming min ethernet packet size
-	 */
-	pps = div_u64(rate_bytes_per_sec, ETH_ZLEN);
-	/* Convert that to packets per 100ms */
-	pps /= MSEC_PER_SEC / PRUETH_NSP_TIMER_MS;
-
-	nsp->cookie = cls->cookie;
-	nsp->credit = pps;
-	emac->nsp_enabled = emac->nsp_bc.cookie | emac->nsp_mc.cookie |
-			    emac->nsp_uc.cookie;
-
-	prueth_enable_nsp(emac);
-
-	netdev_dbg(emac->ndev,
-		   "%scast filter set to %d packets per %dms\n", str,
-		   nsp->credit, PRUETH_NSP_TIMER_MS);
-
-	return 0;
-}
-
-static int emac_configure_clsflower(struct prueth_emac *emac,
-				    struct flow_cls_offload *cls)
-{
-	struct flow_rule *rule = flow_cls_offload_flow_rule(cls);
-	struct netlink_ext_ack *extack = cls->common.extack;
-	const struct flow_action_entry *act;
-	int i;
-
-	flow_action_for_each(i, act, &rule->action) {
-		switch (act->id) {
-		case FLOW_ACTION_POLICE:
-			return emac_flower_parse_policer(emac, extack, cls,
-							 act->police.rate_bytes_ps);
-		default:
-			NL_SET_ERR_MSG_MOD(extack,
-					   "Action not supported");
-			return -EOPNOTSUPP;
-		}
-	}
-	return -EOPNOTSUPP;
-}
-
-static int emac_delete_clsflower(struct prueth_emac *emac,
-				 struct flow_cls_offload *cls)
-{
-	struct prueth *prueth = emac->prueth;
-	void __iomem *dram = prueth->mem[emac->dram].va;
-
-	if (cls->cookie == emac->nsp_bc.cookie) {
-		emac->nsp_bc.cookie = 0;
-		emac->nsp_bc.credit = 0;
-		writel(0, dram + STORM_PREVENTION_OFFSET_BC);
-	} else if (cls->cookie == emac->nsp_mc.cookie) {
-		emac->nsp_mc.cookie = 0;
-		emac->nsp_mc.credit = 0;
-		writel(0, dram + STORM_PREVENTION_OFFSET_MC);
-	} else if (cls->cookie == emac->nsp_uc.cookie) {
-		emac->nsp_uc.cookie = 0;
-		emac->nsp_uc.credit = 0;
-		writel(0, dram + STORM_PREVENTION_OFFSET_UC);
-	}
-
-	emac->nsp_enabled = emac->nsp_bc.cookie | emac->nsp_mc.cookie |
-			    emac->nsp_uc.cookie;
-
-	return 0;
-}
-
-static int emac_setup_tc_cls_flower(struct prueth_emac *emac,
-				    struct flow_cls_offload *cls_flower)
-{
-	switch (cls_flower->command) {
-	case FLOW_CLS_REPLACE:
-		return emac_configure_clsflower(emac, cls_flower);
-	case FLOW_CLS_DESTROY:
-		return emac_delete_clsflower(emac, cls_flower);
-	default:
-		return -EOPNOTSUPP;
-	}
-}
-
-static int emac_setup_tc_block_cb(enum tc_setup_type type, void *type_data,
-				  void *cb_priv)
-{
-	struct prueth_emac *emac = cb_priv;
-
-	if (!tc_cls_can_offload_and_chain0(emac->ndev, type_data))
-		return -EOPNOTSUPP;
-
-	switch (type) {
-	case TC_SETUP_CLSFLOWER:
-		return emac_setup_tc_cls_flower(emac, type_data);
-	default:
-		return -EOPNOTSUPP;
-	}
-}
-
-static LIST_HEAD(emac_block_cb_list);
-
-int emac_ndo_setup_tc(struct net_device *dev, enum tc_setup_type type,
-		      void *type_data)
-{
-	struct prueth_emac *emac = netdev_priv(dev);
-
-	if (type == TC_SETUP_BLOCK) {
-		return flow_block_cb_setup_simple(type_data,
-						  &emac_block_cb_list,
-						  emac_setup_tc_block_cb,
-						  emac, emac, true);
-	}
-
-	return -EOPNOTSUPP;
-}
diff --git a/drivers/net/ethernet/ti/prueth_switch.c b/drivers/net/ethernet/ti/prueth_switch.c
deleted file mode 100644
index b8436cc23f4e..000000000000
--- a/drivers/net/ethernet/ti/prueth_switch.c
+++ /dev/null
@@ -1,1341 +0,0 @@
-// SPDX-License-Identifier: GPL-2.0
-/* Texas Instruments PRUETH Switch Driver
- *
- * Copyright (C) 2020-2021 Texas Instruments Incorporated - https://www.ti.com
- */
-
-#include <linux/kernel.h>
-#include <linux/remoteproc.h>
-#include <net/switchdev.h>
-#include "prueth.h"
-#include "prueth_switch.h"
-#include "prueth_fdb_tbl.h"
-
-#define FDB_IDX_TBL() \
-	(&prueth->fdb_tbl->index_a->index_tbl_entry[0])
-
-#define FDB_IDX_TBL_ENTRY(n) \
-	(&prueth->fdb_tbl->index_a->index_tbl_entry[n])
-
-#define FDB_MAC_TBL() \
-	(&prueth->fdb_tbl->mac_tbl_a->mac_tbl_entry[0])
-
-#define FDB_MAC_TBL_ENTRY(n) \
-	(&prueth->fdb_tbl->mac_tbl_a->mac_tbl_entry[n])
-
-#define FDB_LEARN  1
-#define FDB_DELETE 2
-#define FDB_PURGE  3
-
-struct prueth_sw_fdb_work {
-	struct work_struct work;
-	struct prueth_emac *emac;
-	u8 addr[ETH_ALEN];
-	int event;
-};
-
-static inline
-u8 prueth_sw_port_get_stp_state(struct prueth *prueth, enum prueth_port port)
-{
-	struct fdb_tbl *t = prueth->fdb_tbl;
-	u8 state;
-
-	state = readb(port - 1 ?
-		      &t->port2_stp_cfg->state : &t->port1_stp_cfg->state);
-	return state;
-}
-
-const struct prueth_queue_info sw_queue_infos[][NUM_QUEUES] = {
-	[PRUETH_PORT_QUEUE_HOST] = {
-		[PRUETH_QUEUE1] = {
-			P0_Q1_BUFFER_OFFSET,
-			P0_QUEUE_DESC_OFFSET,
-			P0_Q1_BD_OFFSET,
-			P0_Q1_BD_OFFSET + ((HOST_QUEUE_1_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE2] = {
-			P0_Q2_BUFFER_OFFSET,
-			P0_QUEUE_DESC_OFFSET + 8,
-			P0_Q2_BD_OFFSET,
-			P0_Q2_BD_OFFSET + ((HOST_QUEUE_2_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE3] = {
-			P0_Q3_BUFFER_OFFSET,
-			P0_QUEUE_DESC_OFFSET + 16,
-			P0_Q3_BD_OFFSET,
-			P0_Q3_BD_OFFSET + ((HOST_QUEUE_3_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE4] = {
-			P0_Q4_BUFFER_OFFSET,
-			P0_QUEUE_DESC_OFFSET + 24,
-			P0_Q4_BD_OFFSET,
-			P0_Q4_BD_OFFSET + ((HOST_QUEUE_4_SIZE - 1) * BD_SIZE),
-		},
-	},
-	[PRUETH_PORT_QUEUE_MII0] = {
-		[PRUETH_QUEUE1] = {
-			P1_Q1_BUFFER_OFFSET,
-			P1_Q1_BUFFER_OFFSET +
-				((QUEUE_1_SIZE - 1) * ICSS_BLOCK_SIZE),
-			P1_Q1_BD_OFFSET,
-			P1_Q1_BD_OFFSET + ((QUEUE_1_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE2] = {
-			P1_Q2_BUFFER_OFFSET,
-			P1_Q2_BUFFER_OFFSET +
-				((QUEUE_2_SIZE - 1) * ICSS_BLOCK_SIZE),
-			P1_Q2_BD_OFFSET,
-			P1_Q2_BD_OFFSET + ((QUEUE_2_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE3] = {
-			P1_Q3_BUFFER_OFFSET,
-			P1_Q3_BUFFER_OFFSET +
-				((QUEUE_3_SIZE - 1) * ICSS_BLOCK_SIZE),
-			P1_Q3_BD_OFFSET,
-			P1_Q3_BD_OFFSET + ((QUEUE_3_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE4] = {
-			P1_Q4_BUFFER_OFFSET,
-			P1_Q4_BUFFER_OFFSET +
-				((QUEUE_4_SIZE - 1) * ICSS_BLOCK_SIZE),
-			P1_Q4_BD_OFFSET,
-			P1_Q4_BD_OFFSET + ((QUEUE_4_SIZE - 1) * BD_SIZE),
-		},
-	},
-	[PRUETH_PORT_QUEUE_MII1] = {
-		[PRUETH_QUEUE1] = {
-			P2_Q1_BUFFER_OFFSET,
-			P2_Q1_BUFFER_OFFSET +
-				((QUEUE_1_SIZE - 1) * ICSS_BLOCK_SIZE),
-			P2_Q1_BD_OFFSET,
-			P2_Q1_BD_OFFSET + ((QUEUE_1_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE2] = {
-			P2_Q2_BUFFER_OFFSET,
-			P2_Q2_BUFFER_OFFSET +
-				((QUEUE_2_SIZE - 1) * ICSS_BLOCK_SIZE),
-			P2_Q2_BD_OFFSET,
-			P2_Q2_BD_OFFSET + ((QUEUE_2_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE3] = {
-			P2_Q3_BUFFER_OFFSET,
-			P2_Q3_BUFFER_OFFSET +
-				((QUEUE_3_SIZE - 1) * ICSS_BLOCK_SIZE),
-			P2_Q3_BD_OFFSET,
-			P2_Q3_BD_OFFSET + ((QUEUE_3_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE4] = {
-			P2_Q4_BUFFER_OFFSET,
-			P2_Q4_BUFFER_OFFSET +
-				((QUEUE_4_SIZE - 1) * ICSS_BLOCK_SIZE),
-			P2_Q4_BD_OFFSET,
-			P2_Q4_BD_OFFSET + ((QUEUE_4_SIZE - 1) * BD_SIZE),
-		},
-	},
-};
-
-static const struct prueth_queue_info rx_queue_infos[][NUM_QUEUES] = {
-	[PRUETH_PORT_QUEUE_HOST] = {
-		[PRUETH_QUEUE1] = {
-			P0_Q1_BUFFER_OFFSET,
-			HOST_QUEUE_DESC_OFFSET,
-			P0_Q1_BD_OFFSET,
-			P0_Q1_BD_OFFSET + ((HOST_QUEUE_1_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE2] = {
-			P0_Q2_BUFFER_OFFSET,
-			HOST_QUEUE_DESC_OFFSET + 8,
-			P0_Q2_BD_OFFSET,
-			P0_Q2_BD_OFFSET + ((HOST_QUEUE_2_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE3] = {
-			P0_Q3_BUFFER_OFFSET,
-			HOST_QUEUE_DESC_OFFSET + 16,
-			P0_Q3_BD_OFFSET,
-			P0_Q3_BD_OFFSET + ((HOST_QUEUE_3_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE4] = {
-			P0_Q4_BUFFER_OFFSET,
-			HOST_QUEUE_DESC_OFFSET + 24,
-			P0_Q4_BD_OFFSET,
-			P0_Q4_BD_OFFSET + ((HOST_QUEUE_4_SIZE - 1) * BD_SIZE),
-		},
-	},
-	[PRUETH_PORT_QUEUE_MII0] = {
-		[PRUETH_QUEUE1] = {
-			P1_Q1_BUFFER_OFFSET,
-			P1_QUEUE_DESC_OFFSET,
-			P1_Q1_BD_OFFSET,
-			P1_Q1_BD_OFFSET + ((QUEUE_1_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE2] = {
-			P1_Q2_BUFFER_OFFSET,
-			P1_QUEUE_DESC_OFFSET + 8,
-			P1_Q2_BD_OFFSET,
-			P1_Q2_BD_OFFSET + ((QUEUE_2_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE3] = {
-			P1_Q3_BUFFER_OFFSET,
-			P1_QUEUE_DESC_OFFSET + 16,
-			P1_Q3_BD_OFFSET,
-			P1_Q3_BD_OFFSET + ((QUEUE_3_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE4] = {
-			P1_Q4_BUFFER_OFFSET,
-			P1_QUEUE_DESC_OFFSET + 24,
-			P1_Q4_BD_OFFSET,
-			P1_Q4_BD_OFFSET + ((QUEUE_4_SIZE - 1) * BD_SIZE),
-		},
-	},
-	[PRUETH_PORT_QUEUE_MII1] = {
-		[PRUETH_QUEUE1] = {
-			P2_Q1_BUFFER_OFFSET,
-			P2_QUEUE_DESC_OFFSET,
-			P2_Q1_BD_OFFSET,
-			P2_Q1_BD_OFFSET + ((QUEUE_1_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE2] = {
-			P2_Q2_BUFFER_OFFSET,
-			P2_QUEUE_DESC_OFFSET + 8,
-			P2_Q2_BD_OFFSET,
-			P2_Q2_BD_OFFSET + ((QUEUE_2_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE3] = {
-			P2_Q3_BUFFER_OFFSET,
-			P2_QUEUE_DESC_OFFSET + 16,
-			P2_Q3_BD_OFFSET,
-			P2_Q3_BD_OFFSET + ((QUEUE_3_SIZE - 1) * BD_SIZE),
-		},
-		[PRUETH_QUEUE4] = {
-			P2_Q4_BUFFER_OFFSET,
-			P2_QUEUE_DESC_OFFSET + 24,
-			P2_Q4_BD_OFFSET,
-			P2_Q4_BD_OFFSET + ((QUEUE_4_SIZE - 1) * BD_SIZE),
-		},
-	},
-};
-
-static const struct prueth_col_rx_context_info col_rx_context_infos[] = {
-	[PRUETH_PORT_QUEUE_HOST] = {
-		P0_COL_BUFFER_OFFSET,
-		P0_COL_BUFFER_OFFSET,
-		P0_COL_QUEUE_DESC_OFFSET,
-		END_OF_BD_POOL,
-		END_OF_BD_POOL + ((COL_QUEUE_SIZE - 1) * BD_SIZE)
-	},
-	[PRUETH_PORT_QUEUE_MII0] = {
-		P0_COL_BUFFER_OFFSET + (COL_QUEUE_SIZE * ICSS_BLOCK_SIZE),
-		P0_COL_BUFFER_OFFSET + (COL_QUEUE_SIZE * ICSS_BLOCK_SIZE),
-		P0_COL_QUEUE_DESC_OFFSET + 8,
-		END_OF_BD_POOL,
-		END_OF_BD_POOL + ((COL_QUEUE_SIZE - 1) * BD_SIZE)
-	},
-
-	[PRUETH_PORT_QUEUE_MII1] = {
-		P0_COL_BUFFER_OFFSET + (COL_QUEUE_SIZE * ICSS_BLOCK_SIZE),
-		P0_COL_BUFFER_OFFSET + (COL_QUEUE_SIZE * ICSS_BLOCK_SIZE),
-		P0_COL_QUEUE_DESC_OFFSET + 16,
-		END_OF_BD_POOL,
-		END_OF_BD_POOL + ((COL_QUEUE_SIZE - 1) * BD_SIZE)
-	},
-};
-
-static const struct prueth_col_tx_context_info col_tx_context_infos[] = {
-	[PRUETH_PORT_QUEUE_HOST] = {
-		P0_COL_BUFFER_OFFSET,
-		P0_COL_BUFFER_OFFSET,
-		P0_COL_BUFFER_OFFSET + ((COL_QUEUE_SIZE - 1) * ICSS_BLOCK_SIZE),
-	},
-	[PRUETH_PORT_QUEUE_MII0] = {
-		P0_COL_BUFFER_OFFSET + (COL_QUEUE_SIZE * ICSS_BLOCK_SIZE),
-		P0_COL_BUFFER_OFFSET + (COL_QUEUE_SIZE * ICSS_BLOCK_SIZE),
-		P0_COL_BUFFER_OFFSET + ((COL_QUEUE_SIZE - 1) * ICSS_BLOCK_SIZE),
-	},
-	[PRUETH_PORT_QUEUE_MII1] = {
-		P0_COL_BUFFER_OFFSET + (COL_QUEUE_SIZE * ICSS_BLOCK_SIZE),
-		P0_COL_BUFFER_OFFSET + (COL_QUEUE_SIZE * ICSS_BLOCK_SIZE),
-		P0_COL_BUFFER_OFFSET + ((COL_QUEUE_SIZE - 1) * ICSS_BLOCK_SIZE),
-	}
-};
-
-static const struct prueth_queue_desc col_queue_descs[3] = {
-	[PRUETH_PORT_QUEUE_MII0] = {
-		.rd_ptr = END_OF_BD_POOL, .wr_ptr = END_OF_BD_POOL, },
-	[PRUETH_PORT_QUEUE_MII1] = {
-		.rd_ptr = END_OF_BD_POOL, .wr_ptr = END_OF_BD_POOL, }
-};
-
-void prueth_sw_free_fdb_table(struct prueth *prueth)
-{
-	if (prueth->emac_configured)
-		return;
-
-	kfree(prueth->fdb_tbl);
-	prueth->fdb_tbl = NULL;
-}
-
-void prueth_sw_hostconfig(struct prueth *prueth)
-{
-	void __iomem *dram1_base = prueth->mem[PRUETH_MEM_DRAM1].va;
-	void __iomem *dram;
-
-	/* queue information table */
-	dram = dram1_base + P0_Q1_RX_CONTEXT_OFFSET;
-	memcpy_toio(dram, sw_queue_infos[PRUETH_PORT_QUEUE_HOST],
-		    sizeof(sw_queue_infos[PRUETH_PORT_QUEUE_HOST]));
-
-	dram = dram1_base + COL_RX_CONTEXT_P0_OFFSET_ADDR;
-	memcpy_toio(dram, &col_rx_context_infos[PRUETH_PORT_QUEUE_HOST],
-		    sizeof(col_rx_context_infos[PRUETH_PORT_QUEUE_HOST]));
-
-	/* buffer descriptor offset table*/
-	dram = dram1_base + QUEUE_DESCRIPTOR_OFFSET_ADDR;
-	writew(P0_Q1_BD_OFFSET, dram);
-	writew(P0_Q2_BD_OFFSET, dram + 2);
-	writew(P0_Q3_BD_OFFSET, dram + 4);
-	writew(P0_Q4_BD_OFFSET, dram + 6);
-
-	/* buffer offset table */
-	dram = dram1_base + QUEUE_OFFSET_ADDR;
-	writew(P0_Q1_BUFFER_OFFSET, dram);
-	writew(P0_Q2_BUFFER_OFFSET, dram + 2);
-	writew(P0_Q3_BUFFER_OFFSET, dram + 4);
-	writew(P0_Q4_BUFFER_OFFSET, dram + 6);
-
-	/* queue size lookup table */
-	dram = dram1_base + QUEUE_SIZE_ADDR;
-	writew(HOST_QUEUE_1_SIZE, dram);
-	writew(HOST_QUEUE_1_SIZE, dram + 2);
-	writew(HOST_QUEUE_1_SIZE, dram + 4);
-	writew(HOST_QUEUE_1_SIZE, dram + 6);
-
-	/* queue table */
-	dram = dram1_base + P0_QUEUE_DESC_OFFSET;
-	memcpy_toio(dram, queue_descs[PRUETH_PORT_QUEUE_HOST],
-		    sizeof(queue_descs[PRUETH_PORT_QUEUE_HOST]));
-}
-
-static int prueth_sw_port_config(struct prueth *prueth,
-				 enum prueth_port port_id)
-{
-	unsigned int tx_context_ofs_addr, col_tx_context_ofs_addr,
-		     rx_context_ofs, col_rx_context_ofs_addr,
-		     queue_desc_ofs, col_queue_desc_ofs;
-	void __iomem *dram, *dram_base, *dram_mac;
-	struct prueth_emac *emac;
-	void __iomem *dram1_base = prueth->mem[PRUETH_MEM_DRAM1].va;
-
-	emac = prueth->emac[port_id - 1];
-	switch (port_id) {
-	case PRUETH_PORT_MII0:
-		tx_context_ofs_addr     = TX_CONTEXT_P1_Q1_OFFSET_ADDR;
-		col_tx_context_ofs_addr = COL_TX_CONTEXT_P1_Q1_OFFSET_ADDR;
-		rx_context_ofs          = P1_Q1_RX_CONTEXT_OFFSET;
-		col_rx_context_ofs_addr = COL_RX_CONTEXT_P1_OFFSET_ADDR;
-		queue_desc_ofs          = P1_QUEUE_DESC_OFFSET;
-		col_queue_desc_ofs      = P1_COL_QUEUE_DESC_OFFSET;
-
-		/* for switch PORT MII0 mac addr is in DRAM0. */
-		dram_mac = prueth->mem[PRUETH_MEM_DRAM0].va;
-		break;
-	case PRUETH_PORT_MII1:
-		tx_context_ofs_addr     = TX_CONTEXT_P2_Q1_OFFSET_ADDR;
-		col_tx_context_ofs_addr = COL_TX_CONTEXT_P2_Q1_OFFSET_ADDR;
-		rx_context_ofs          = P2_Q1_RX_CONTEXT_OFFSET;
-		col_rx_context_ofs_addr = COL_RX_CONTEXT_P2_OFFSET_ADDR;
-		queue_desc_ofs          = P2_QUEUE_DESC_OFFSET;
-		col_queue_desc_ofs      = P2_COL_QUEUE_DESC_OFFSET;
-
-		/* for switch PORT MII1 mac addr is in DRAM1. */
-		dram_mac = prueth->mem[PRUETH_MEM_DRAM1].va;
-		break;
-	default:
-		netdev_err(emac->ndev, "invalid port\n");
-		return -EINVAL;
-	}
-
-	/* setup mac address */
-	memcpy_toio(dram_mac + PORT_MAC_ADDR, emac->mac_addr, 6);
-
-	/* Remaining switch port configs are in DRAM1 */
-	dram_base = prueth->mem[PRUETH_MEM_DRAM1].va;
-
-	/* queue information table */
-	memcpy_toio(dram_base + tx_context_ofs_addr,
-		    sw_queue_infos[port_id],
-		    sizeof(sw_queue_infos[port_id]));
-
-	memcpy_toio(dram_base + col_tx_context_ofs_addr,
-		    &col_tx_context_infos[port_id],
-		    sizeof(col_tx_context_infos[port_id]));
-
-	memcpy_toio(dram_base + rx_context_ofs,
-		    rx_queue_infos[port_id],
-		    sizeof(rx_queue_infos[port_id]));
-
-	memcpy_toio(dram_base + col_rx_context_ofs_addr,
-		    &col_rx_context_infos[port_id],
-		    sizeof(col_rx_context_infos[port_id]));
-
-	/* buffer descriptor offset table*/
-	dram = dram_base + QUEUE_DESCRIPTOR_OFFSET_ADDR +
-	       (port_id * NUM_QUEUES * sizeof(u16));
-	writew(sw_queue_infos[port_id][PRUETH_QUEUE1].buffer_desc_offset, dram);
-	writew(sw_queue_infos[port_id][PRUETH_QUEUE2].buffer_desc_offset,
-	       dram + 2);
-	writew(sw_queue_infos[port_id][PRUETH_QUEUE3].buffer_desc_offset,
-	       dram + 4);
-	writew(sw_queue_infos[port_id][PRUETH_QUEUE4].buffer_desc_offset,
-	       dram + 6);
-
-	/* buffer offset table */
-	dram = dram_base + QUEUE_OFFSET_ADDR +
-	       port_id * NUM_QUEUES * sizeof(u16);
-	writew(sw_queue_infos[port_id][PRUETH_QUEUE1].buffer_offset, dram);
-	writew(sw_queue_infos[port_id][PRUETH_QUEUE2].buffer_offset,
-	       dram + 2);
-	writew(sw_queue_infos[port_id][PRUETH_QUEUE3].buffer_offset,
-	       dram + 4);
-	writew(sw_queue_infos[port_id][PRUETH_QUEUE4].buffer_offset,
-	       dram + 6);
-
-	/* queue size lookup table */
-	dram = dram_base + QUEUE_SIZE_ADDR +
-	       port_id * NUM_QUEUES * sizeof(u16);
-	writew(QUEUE_1_SIZE, dram);
-	writew(QUEUE_2_SIZE, dram + 2);
-	writew(QUEUE_3_SIZE, dram + 4);
-	writew(QUEUE_4_SIZE, dram + 6);
-
-	/* collision queue table */
-	memcpy_toio(dram_base + col_queue_desc_ofs,
-		    &col_queue_descs[port_id],
-		    sizeof(col_queue_descs[port_id]));
-
-	/* queue table */
-	memcpy_toio(dram_base + queue_desc_ofs,
-		    &queue_descs[port_id][0],
-		    4 * sizeof(queue_descs[port_id][0]));
-
-	emac->rx_queue_descs = dram1_base + P0_QUEUE_DESC_OFFSET;
-	emac->tx_queue_descs = dram1_base +
-		rx_queue_infos[port_id][PRUETH_QUEUE1].queue_desc_offset;
-
-	return 0;
-}
-
-int prueth_sw_emac_config(struct prueth_emac *emac)
-{
-	struct prueth *prueth = emac->prueth;
-
-	/* PRU needs local shared RAM address for C28 */
-	u32 sharedramaddr = ICSS_LOCAL_SHARED_RAM;
-	/* PRU needs real global OCMC address for C30*/
-	u32 ocmcaddr = (u32)prueth->mem[PRUETH_MEM_OCMC].pa;
-	int ret;
-
-	if (prueth->emac_configured & BIT(emac->port_id))
-		return 0;
-
-	ret = prueth_sw_port_config(prueth, emac->port_id);
-	if (ret)
-		return ret;
-
-	if (!prueth->emac_configured) {
-		/* Set in constant table C28 of PRUn to ICSS Shared memory */
-		pru_rproc_set_ctable(prueth->pru0, PRU_C28, sharedramaddr);
-		pru_rproc_set_ctable(prueth->pru1, PRU_C28, sharedramaddr);
-
-		/* Set in constant table C30 of PRUn to OCMC memory */
-		pru_rproc_set_ctable(prueth->pru0, PRU_C30, ocmcaddr);
-		pru_rproc_set_ctable(prueth->pru1, PRU_C30, ocmcaddr);
-	}
-	return 0;
-}
-
-void prueth_sw_fdb_tbl_init(struct prueth *prueth)
-{
-	struct fdb_tbl *t = prueth->fdb_tbl;
-
-	t->index_a = prueth->mem[V2_1_FDB_TBL_LOC].va +
-			V2_1_FDB_TBL_OFFSET;
-
-	t->mac_tbl_a          = (void __iomem *)t->index_a +
-				FDB_INDEX_TBL_MAX_ENTRIES *
-				sizeof(struct fdb_index_tbl_entry_t);
-
-	t->port1_stp_cfg      = (void __iomem *)t->mac_tbl_a +
-				FDB_MAC_TBL_MAX_ENTRIES *
-				sizeof(struct fdb_mac_tbl_entry_t);
-
-	t->port2_stp_cfg      = (void __iomem *)t->port1_stp_cfg +
-				sizeof(struct fdb_stp_config);
-
-	t->flood_enable_flags = (void __iomem *)t->port2_stp_cfg +
-				sizeof(struct fdb_stp_config);
-
-	t->locks              = (void __iomem *)t->flood_enable_flags +
-				sizeof(struct fdb_flood_config);
-
-	t->flood_enable_flags->host_flood_enable  = 1;
-	t->flood_enable_flags->port1_flood_enable = 1;
-	t->flood_enable_flags->port2_flood_enable = 1;
-	t->locks->host_lock                       = 0;
-	t->total_entries                          = 0;
-}
-
-static void prueth_sw_fdb_spin_lock(struct fdb_tbl *fdb_tbl)
-{
-	/* Take the host lock */
-	writeb(1, &fdb_tbl->locks->host_lock);
-
-	/* Wait for the PRUs to release their locks */
-	while (readb(&fdb_tbl->locks->pru_locks))
-		;
-}
-
-static inline void prueth_sw_fdb_spin_unlock(struct fdb_tbl *fdb_tbl)
-{
-	writeb(0, &fdb_tbl->locks->host_lock);
-}
-
-static void mac_copy(u8 *dst, const u8 *src)
-{
-	u8 i;
-
-	for (i = 0; i < 6; i++) {
-		*(dst) = *(src);
-		dst++;
-		src++;
-	}
-}
-
-/* -1  mac_a <  mac_b
- *  0  mac_a == mac_b
- *  1  mac_a >  mac_b
- */
-static s8 mac_cmp(const u8 *mac_a, const u8 *mac_b)
-{
-	s8  ret = 0, i;
-
-	for (i = 0; i < 6; i++) {
-		if (mac_a[i] == mac_b[i])
-			continue;
-
-		ret = mac_a[i] < mac_b[i] ? -1 : 1;
-		break;
-	}
-
-	return ret;
-}
-
-static inline u8 prueth_sw_fdb_hash(const u8 *mac)
-{
-	return mac[0] ^ mac[1] ^ mac[2] ^ mac[3] ^ mac[4] ^ mac[5];
-}
-
-static s16
-prueth_sw_fdb_search(struct fdb_mac_tbl_array_t *mac_tbl,
-		     struct fdb_index_tbl_entry_t *bucket_info,
-		     const u8 *mac)
-{
-	int i;
-	u8 mac_tbl_idx = bucket_info->bucket_idx;
-
-	for (i = 0; i < bucket_info->bucket_entries; i++, mac_tbl_idx++) {
-		if (!mac_cmp(mac, mac_tbl->mac_tbl_entry[mac_tbl_idx].mac))
-			return mac_tbl_idx;
-	}
-
-	return -ENODATA;
-}
-
-static u16 prueth_sw_fdb_find_open_slot(struct fdb_tbl *fdb_tbl)
-{
-	u16 i;
-
-	for (i = 0; i < FDB_MAC_TBL_MAX_ENTRIES; i++) {
-		if (!fdb_tbl->mac_tbl_a->mac_tbl_entry[i].active)
-			break;
-	}
-
-	return i;
-}
-
-/* port: 0 based: 0=port1, 1=port2 */
-static s16
-prueth_sw_fdb_find_bucket_insert_point(struct fdb_tbl *fdb,
-				       struct fdb_index_tbl_entry_t *bkt_info,
-				       const u8 *mac, const u8 port)
-{
-	struct fdb_mac_tbl_array_t *mac_tbl = fdb->mac_tbl_a;
-	struct fdb_mac_tbl_entry_t *e;
-	int i;
-	u8 mac_tbl_idx;
-	s8 cmp;
-
-	mac_tbl_idx = bkt_info->bucket_idx;
-
-	for (i = 0; i < bkt_info->bucket_entries; i++, mac_tbl_idx++) {
-		e = &mac_tbl->mac_tbl_entry[mac_tbl_idx];
-		cmp = mac_cmp(mac, e->mac);
-		if (cmp < 0) {
-			return mac_tbl_idx;
-		} else if (cmp == 0) {
-			if (e->port != port) {
-				/* mac is already in FDB, only port is
-				 * different. So just update the port.
-				 * Note: total_entries and bucket_entries
-				 * remain the same.
-				 */
-				prueth_sw_fdb_spin_lock(fdb);
-				e->port = port;
-				prueth_sw_fdb_spin_unlock(fdb);
-			}
-
-			/* mac and port are the same, touch the fdb */
-			e->age = 0;
-			return -1;
-		}
-	}
-
-	return mac_tbl_idx;
-}
-
-static s16
-prueth_sw_fdb_check_empty_slot_left(struct fdb_mac_tbl_array_t *mac_tbl,
-				    u8 mac_tbl_idx)
-{
-	s16 i;
-
-	for (i = mac_tbl_idx - 1; i > -1; i--) {
-		if (!mac_tbl->mac_tbl_entry[i].active)
-			break;
-	}
-
-	return i;
-}
-
-static s16
-prueth_sw_fdb_check_empty_slot_right(struct fdb_mac_tbl_array_t *mac_tbl,
-				     u8 mac_tbl_idx)
-{
-	s16 i;
-
-	for (i = mac_tbl_idx; i < FDB_MAC_TBL_MAX_ENTRIES; i++) {
-		if (!mac_tbl->mac_tbl_entry[i].active)
-			return i;
-	}
-
-	return -1;
-}
-
-static void prueth_sw_fdb_move_range_left(struct prueth *prueth,
-					  u16 left, u16 right)
-{
-	u16 i;
-	u8 *src, *dst;
-	u32 sz = 0;
-
-	for (i = left; i < right; i++) {
-		dst = (u8 *)FDB_MAC_TBL_ENTRY(i);
-		src = (u8 *)FDB_MAC_TBL_ENTRY(i + 1);
-		sz = sizeof(struct fdb_mac_tbl_entry_t);
-		memcpy_toio(dst, src, sz);
-	}
-}
-
-static void prueth_sw_fdb_move_range_right(struct prueth *prueth,
-					   u16 left, u16 right)
-{
-	u16 i;
-	u8 *src, *dst;
-	u32 sz = 0;
-
-	for (i = right; i > left; i--) {
-		dst = (u8 *)FDB_MAC_TBL_ENTRY(i);
-		src = (u8 *)FDB_MAC_TBL_ENTRY(i - 1);
-		sz = sizeof(struct fdb_mac_tbl_entry_t);
-		memcpy_toio(dst, src, sz);
-	}
-}
-
-static void prueth_sw_fdb_update_index_tbl(struct prueth *prueth,
-					   u16 left, u16 right)
-{
-	u16 i;
-	u8 hash, hash_prev;
-
-	/* To ensure we don't improperly update the
-	 * bucket index, initialize with an invalid
-	 * hash in case we are in leftmost slot
-	 */
-	hash_prev = 0xff;
-
-	if (left > 0) {
-		hash_prev =
-			prueth_sw_fdb_hash(FDB_MAC_TBL_ENTRY(left - 1)->mac);
-	}
-
-	/* For each moved element, update the bucket index */
-	for (i = left; i <= right; i++) {
-		hash = prueth_sw_fdb_hash(FDB_MAC_TBL_ENTRY(i)->mac);
-
-		/* Only need to update buckets once */
-		if (hash != hash_prev)
-			FDB_IDX_TBL_ENTRY(hash)->bucket_idx = i;
-
-		hash_prev = hash;
-	}
-}
-
-static struct fdb_mac_tbl_entry_t *
-prueth_sw_get_empty_mac_tbl_entry(struct prueth *prueth,
-				  struct fdb_index_tbl_entry_t *bucket_info,
-				  u8 suggested_mac_tbl_idx,
-				  bool *update_indexes)
-{
-	struct fdb_tbl *fdb = prueth->fdb_tbl;
-	struct fdb_mac_tbl_array_t *mt = fdb->mac_tbl_a;
-	s16 empty_slot_idx = 0, left = 0, right = 0;
-	u8 mti = suggested_mac_tbl_idx;
-
-	if (!FDB_MAC_TBL_ENTRY(mti)->active) {
-		/* Claim the entry */
-		FDB_MAC_TBL_ENTRY(mti)->active = 1;
-
-		return FDB_MAC_TBL_ENTRY(mti);
-	}
-
-	if (fdb->total_entries == FDB_MAC_TBL_MAX_ENTRIES)
-		return NULL;
-
-	empty_slot_idx = prueth_sw_fdb_check_empty_slot_left(mt, mti);
-	if (empty_slot_idx == -1) {
-		/* Nothing available on the left. But table isn't full
-		 * so there must be space to the right,
-		 */
-		empty_slot_idx = prueth_sw_fdb_check_empty_slot_right(mt, mti);
-
-		/* Shift right */
-		left = mti;
-		right = empty_slot_idx;
-		prueth_sw_fdb_move_range_right(prueth, left, right);
-
-		/* Claim the entry */
-		FDB_MAC_TBL_ENTRY(mti)->active = 1;
-
-		/* There is a chance we moved something in a
-		 * different bucket, update index table
-		 */
-		prueth_sw_fdb_update_index_tbl(prueth, left, right);
-
-		return FDB_MAC_TBL_ENTRY(mti);
-	}
-
-	if (empty_slot_idx == mti - 1) {
-		/* There is space immediately left of the open slot,
-		 * which means the inserted MAC address.
-		 * Must be the lowest-valued MAC address in bucket.
-		 * Update bucket pointer accordingly.
-		 */
-		bucket_info->bucket_idx = empty_slot_idx;
-
-		/* Claim the entry */
-		FDB_MAC_TBL_ENTRY(empty_slot_idx)->active = 1;
-
-		return FDB_MAC_TBL_ENTRY(empty_slot_idx);
-	}
-
-	/* There is empty space to the left, shift MAC table entries left */
-	left = empty_slot_idx;
-	right = mti - 1;
-	prueth_sw_fdb_move_range_left(prueth, left, right);
-
-	/* Claim the entry */
-	FDB_MAC_TBL_ENTRY(mti - 1)->active = 1;
-
-	/* There is a chance we moved something in a
-	 * different bucket, update index table
-	 */
-	prueth_sw_fdb_update_index_tbl(prueth, left, right);
-
-	return FDB_MAC_TBL_ENTRY(mti - 1);
-}
-
-static int prueth_sw_insert_fdb_entry(struct prueth_emac *emac,
-				      const u8 *mac, u8 is_static)
-{
-	struct prueth *prueth = emac->prueth;
-	struct prueth_emac *other_emac;
-	struct fdb_tbl *fdb = prueth->fdb_tbl;
-	struct fdb_index_tbl_entry_t *bucket_info;
-	struct fdb_mac_tbl_entry_t *mac_info;
-	u8 hash_val, mac_tbl_idx;
-	s16 ret;
-
-	other_emac = prueth->emac[other_port_id(emac->port_id) - 1];
-
-	if (fdb->total_entries == FDB_MAC_TBL_MAX_ENTRIES)
-		return -ENOMEM;
-
-	if (mac_cmp(mac, emac->mac_addr) == 0 ||
-	    mac_cmp(mac, other_emac->mac_addr) == 0) {
-		/* Don't insert fdb of own mac addr */
-		return -EINVAL;
-	}
-
-	/* Empty mac table entries are available */
-
-	/* Get the bucket that the mac belongs to */
-	hash_val = prueth_sw_fdb_hash(mac);
-	bucket_info = FDB_IDX_TBL_ENTRY(hash_val);
-
-	if (!bucket_info->bucket_entries) {
-		mac_tbl_idx = prueth_sw_fdb_find_open_slot(fdb);
-		bucket_info->bucket_idx = mac_tbl_idx;
-	}
-
-	ret = prueth_sw_fdb_find_bucket_insert_point(fdb, bucket_info, mac,
-						     emac->port_id - 1);
-
-	if (ret < 0)
-		/* mac is already in fdb table */
-		return 0;
-
-	mac_tbl_idx = ret;
-
-	prueth_sw_fdb_spin_lock(fdb);
-
-	mac_info = prueth_sw_get_empty_mac_tbl_entry(prueth, bucket_info,
-						     mac_tbl_idx, NULL);
-	if (!mac_info) {
-		/* Should not happen */
-		dev_warn(prueth->dev, "OUT of MEM\n");
-		return -ENOMEM;
-	}
-
-	mac_copy(mac_info->mac, mac);
-	mac_info->active = 1;
-	mac_info->age = 0;
-	mac_info->port = emac->port_id - 1;
-	mac_info->is_static = is_static;
-
-	bucket_info->bucket_entries++;
-	fdb->total_entries++;
-
-	prueth_sw_fdb_spin_unlock(fdb);
-
-	dev_dbg(prueth->dev, "added fdb: %pM port=%d total_entries=%u\n",
-		mac, emac->port_id, fdb->total_entries);
-
-	return 0;
-}
-
-static int prueth_sw_delete_fdb_entry(struct prueth_emac *emac,
-				      const u8 *mac, u8 is_static)
-{
-	struct prueth *prueth = emac->prueth;
-	struct fdb_tbl *fdb = prueth->fdb_tbl;
-	struct fdb_mac_tbl_array_t *mt = fdb->mac_tbl_a;
-	struct fdb_index_tbl_entry_t *bucket_info;
-	struct fdb_mac_tbl_entry_t *mac_info;
-	u8 hash_val, mac_tbl_idx;
-	s16 ret, left, right;
-
-	if (fdb->total_entries == 0)
-		return 0;
-
-	/* Get the bucket that the mac belongs to */
-	hash_val = prueth_sw_fdb_hash(mac);
-	bucket_info = FDB_IDX_TBL_ENTRY(hash_val);
-
-	ret = prueth_sw_fdb_search(mt, bucket_info, mac);
-	if (ret < 0)
-		return ret;
-
-	mac_tbl_idx = ret;
-	mac_info = FDB_MAC_TBL_ENTRY(mac_tbl_idx);
-
-	prueth_sw_fdb_spin_lock(fdb);
-
-	/* Shift all elements in bucket to the left. No need to
-	 * update index table since only shifting within bucket.
-	 */
-	left = mac_tbl_idx;
-	right = bucket_info->bucket_idx + bucket_info->bucket_entries - 1;
-	prueth_sw_fdb_move_range_left(prueth, left, right);
-
-	/* Remove end of bucket from table */
-	mac_info = FDB_MAC_TBL_ENTRY(right);
-	mac_info->active = 0;
-	bucket_info->bucket_entries--;
-	fdb->total_entries--;
-
-	prueth_sw_fdb_spin_unlock(fdb);
-
-	dev_dbg(prueth->dev, "del fdb: %pM total_entries=%u\n",
-		mac, fdb->total_entries);
-
-	return 0;
-}
-
-static int prueth_sw_do_purge_fdb(struct prueth_emac *emac)
-{
-	struct prueth *prueth = emac->prueth;
-	struct fdb_tbl *fdb = prueth->fdb_tbl;
-	s16 i;
-
-	if (fdb->total_entries == 0)
-		return 0;
-
-	prueth_sw_fdb_spin_lock(fdb);
-
-	for (i = 0; i < FDB_INDEX_TBL_MAX_ENTRIES; i++)
-		fdb->index_a->index_tbl_entry[i].bucket_entries = 0;
-
-	for (i = 0; i < FDB_MAC_TBL_MAX_ENTRIES; i++)
-		fdb->mac_tbl_a->mac_tbl_entry[i].active = 0;
-
-	fdb->total_entries = 0;
-
-	prueth_sw_fdb_spin_unlock(fdb);
-	return 0;
-}
-
-static void prueth_sw_fdb_work(struct work_struct *work)
-{
-	struct prueth_sw_fdb_work *fdb_work =
-		container_of(work, struct prueth_sw_fdb_work, work);
-	struct prueth_emac *emac = fdb_work->emac;
-
-	rtnl_lock();
-
-	/* Interface is not up */
-	if (!emac->prueth->fdb_tbl) {
-		rtnl_unlock();
-		return;
-	}
-
-	switch (fdb_work->event) {
-	case FDB_LEARN:
-		prueth_sw_insert_fdb_entry(emac, fdb_work->addr, 0);
-		break;
-	case FDB_PURGE:
-		prueth_sw_do_purge_fdb(emac);
-		break;
-	default:
-		break;
-	}
-	rtnl_unlock();
-
-	kfree(fdb_work);
-	dev_put(emac->ndev);
-}
-
-int prueth_sw_learn_fdb(struct prueth_emac *emac, u8 *src_mac)
-{
-	struct prueth_sw_fdb_work *fdb_work;
-
-	fdb_work = kzalloc(sizeof(*fdb_work), GFP_ATOMIC);
-	if (WARN_ON(!fdb_work))
-		return -ENOMEM;
-
-	INIT_WORK(&fdb_work->work, prueth_sw_fdb_work);
-
-	fdb_work->event = FDB_LEARN;
-	fdb_work->emac  = emac;
-	ether_addr_copy(fdb_work->addr, src_mac);
-
-	dev_hold(emac->ndev);
-	queue_work(system_long_wq, &fdb_work->work);
-	return 0;
-}
-
-static int prueth_sw_purge_fdb(struct prueth_emac *emac)
-{
-	struct prueth_sw_fdb_work *fdb_work;
-
-	fdb_work = kzalloc(sizeof(*fdb_work), GFP_ATOMIC);
-	if (WARN_ON(!fdb_work))
-		return -ENOMEM;
-
-	INIT_WORK(&fdb_work->work, prueth_sw_fdb_work);
-
-	fdb_work->event = FDB_PURGE;
-	fdb_work->emac  = emac;
-
-	dev_hold(emac->ndev);
-	queue_work(system_long_wq, &fdb_work->work);
-	return 0;
-}
-
-int prueth_sw_init_fdb_table(struct prueth *prueth)
-{
-	if (prueth->emac_configured)
-		return 0;
-
-	prueth->fdb_tbl = kmalloc(sizeof(*prueth->fdb_tbl), GFP_KERNEL);
-	if (!prueth->fdb_tbl)
-		return -ENOMEM;
-
-	prueth_sw_fdb_tbl_init(prueth);
-
-	return 0;
-}
-
-int prueth_sw_boot_prus(struct prueth *prueth, struct net_device *ndev)
-{
-	const struct prueth_firmware *pru_firmwares;
-	const char *fw_name, *fw_name1;
-	int ret;
-
-	if (prueth->emac_configured)
-		return 0;
-
-	pru_firmwares = &prueth->fw_data->fw_pru[PRUSS_PRU0];
-	fw_name = pru_firmwares->fw_name[prueth->eth_type];
-	pru_firmwares = &prueth->fw_data->fw_pru[PRUSS_PRU1];
-	fw_name1 = pru_firmwares->fw_name[prueth->eth_type];
-
-	ret = rproc_set_firmware(prueth->pru0, fw_name);
-	if (ret) {
-		netdev_err(ndev, "failed to set PRU0 firmware %s: %d\n",
-			   fw_name, ret);
-		return ret;
-	}
-	ret = rproc_boot(prueth->pru0);
-	if (ret) {
-		netdev_err(ndev, "failed to boot PRU: %d\n", ret);
-		return ret;
-	}
-
-	ret = rproc_set_firmware(prueth->pru1, fw_name1);
-	if (ret) {
-		netdev_err(ndev, "failed to set PRU1 firmware %s: %d\n",
-			   fw_name, ret);
-		goto rproc0_shutdown;
-	}
-	ret = rproc_boot(prueth->pru1);
-	if (ret) {
-		netdev_err(ndev, "failed to boot PRU: %d\n", ret);
-		goto rproc0_shutdown;
-	}
-
-	return 0;
-
-rproc0_shutdown:
-	rproc_shutdown(prueth->pru0);
-	return ret;
-}
-
-int prueth_sw_shutdown_prus(struct prueth_emac *emac, struct net_device *ndev)
-{
-	struct prueth *prueth = emac->prueth;
-
-	if (prueth->emac_configured)
-		return 0;
-
-	rproc_shutdown(prueth->pru0);
-	rproc_shutdown(prueth->pru1);
-
-	return 0;
-}
-
-static int prueth_switchdev_attr_set(struct net_device *ndev,
-				     const struct switchdev_attr *attr,
-				     struct switchdev_trans *trans)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	int err = 0;
-	u8 o_state;
-
-	/* Interface is not up */
-	if (!prueth->fdb_tbl)
-		return 0;
-
-	switch (attr->id) {
-	case SWITCHDEV_ATTR_ID_PORT_STP_STATE:
-		o_state = prueth_sw_port_get_stp_state(prueth, emac->port_id);
-		prueth_sw_port_set_stp_state(prueth, emac->port_id,
-					     attr->u.stp_state);
-
-		if (o_state != attr->u.stp_state)
-			prueth_sw_purge_fdb(emac);
-
-		dev_dbg(prueth->dev, "attr set: stp state:%u port:%u\n",
-			attr->u.stp_state, emac->port_id);
-		break;
-	default:
-		err = -EOPNOTSUPP;
-		break;
-	}
-
-	return err;
-}
-
-static int prueth_switchdev_obj_add(struct net_device *ndev,
-				    const struct switchdev_obj *obj,
-				    struct switchdev_trans *trans,
-				    struct netlink_ext_ack *extack)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	struct switchdev_obj_port_mdb *mdb;
-	int ret = 0;
-	u8 hash;
-
-	if (switchdev_trans_ph_prepare(trans))
-		return 0;
-
-	switch (obj->id) {
-	case SWITCHDEV_OBJ_ID_HOST_MDB:
-		mdb = SWITCHDEV_OBJ_PORT_MDB(obj);
-		dev_dbg(prueth->dev, "MDB add: %s: vid %u:%pM  port: %x\n",
-			ndev->name, mdb->vid, mdb->addr, emac->port_id);
-		hash = emac_get_mc_hash(mdb->addr, emac->mc_filter_mask);
-		emac_mc_filter_bin_allow(emac, hash);
-		break;
-	default:
-		ret = -EOPNOTSUPP;
-		break;
-	}
-
-	return ret;
-}
-
-static int prueth_switchdev_obj_del(struct net_device *ndev,
-				    const struct switchdev_obj *obj)
-{
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	struct switchdev_obj_port_mdb *mdb;
-	struct netdev_hw_addr *ha;
-	u8 hash, tmp_hash;
-	int ret = 0;
-
-	switch (obj->id) {
-	case SWITCHDEV_OBJ_ID_HOST_MDB:
-		mdb = SWITCHDEV_OBJ_PORT_MDB(obj);
-		dev_dbg(prueth->dev, "MDB del: %s: vid %u:%pM  port: %x\n",
-			ndev->name, mdb->vid, mdb->addr, emac->port_id);
-		hash = emac_get_mc_hash(mdb->addr, emac->mc_filter_mask);
-		netdev_for_each_mc_addr(ha, prueth->hw_bridge_dev) {
-			tmp_hash = emac_get_mc_hash(ha->addr, emac->mc_filter_mask);
-			/* Another MC address is in the bin. Don't disable. */
-			if (tmp_hash == hash)
-				return 0;
-		}
-		emac_mc_filter_bin_disallow(emac, hash);
-		break;
-	default:
-		ret = -EOPNOTSUPP;
-		break;
-	}
-
-	return ret;
-}
-
-/* switchdev notifiers */
-static int prueth_sw_switchdev_blocking_event(struct notifier_block *unused,
-					      unsigned long event, void *ptr)
-{
-	struct net_device *ndev = switchdev_notifier_info_to_dev(ptr);
-	struct prueth_emac *emac = netdev_priv(ndev);
-	struct prueth *prueth = emac->prueth;
-	int err;
-
-	if (!PRUETH_IS_SWITCH(prueth))
-		return NOTIFY_DONE;
-
-	switch (event) {
-	case SWITCHDEV_PORT_ATTR_SET:
-		err = switchdev_handle_port_attr_set(ndev, ptr,
-						     prueth_sw_port_dev_check,
-						     prueth_switchdev_attr_set);
-		return notifier_from_errno(err);
-
-	case SWITCHDEV_PORT_OBJ_ADD:
-		err = switchdev_handle_port_obj_add(ndev, ptr,
-						    prueth_sw_port_dev_check,
-						    prueth_switchdev_obj_add);
-		return notifier_from_errno(err);
-
-	case SWITCHDEV_PORT_OBJ_DEL:
-		err = switchdev_handle_port_obj_del(ndev, ptr,
-						    prueth_sw_port_dev_check,
-						    prueth_switchdev_obj_del);
-		return notifier_from_errno(err);
-	default:
-		break;
-	}
-
-	return NOTIFY_DONE;
-}
-
-/* switchev event work */
-struct prueth_sw_switchdev_event_work {
-	struct work_struct work;
-	struct switchdev_notifier_fdb_info fdb_info;
-	struct prueth_emac *emac;
-	unsigned long event;
-};
-
-static void
-prueth_sw_fdb_offload_notify(struct net_device *ndev,
-			     struct switchdev_notifier_fdb_info *rcv)
-{
-	struct switchdev_notifier_fdb_info info;
-
-	info.addr = rcv->addr;
-	info.vid = rcv->vid;
-	call_switchdev_notifiers(SWITCHDEV_FDB_OFFLOADED, ndev, &info.info,
-				 NULL);
-}
-
-static void prueth_sw_fdb_add(struct prueth_emac *emac,
-			      struct switchdev_notifier_fdb_info *fdb)
-{
-	prueth_sw_insert_fdb_entry(emac, fdb->addr, 1);
-}
-
-static void prueth_sw_fdb_del(struct prueth_emac *emac,
-			      struct switchdev_notifier_fdb_info *fdb)
-{
-	prueth_sw_delete_fdb_entry(emac, fdb->addr, 1);
-}
-
-static void prueth_sw_switchdev_event_work(struct work_struct *work)
-{
-	struct prueth_sw_switchdev_event_work *switchdev_work =
-		container_of(work, struct prueth_sw_switchdev_event_work, work);
-	struct prueth_emac *emac = switchdev_work->emac;
-	struct switchdev_notifier_fdb_info *fdb;
-	struct prueth *prueth = emac->prueth;
-	int port = emac->port_id;
-
-	rtnl_lock();
-	switch (switchdev_work->event) {
-	case SWITCHDEV_FDB_ADD_TO_DEVICE:
-		fdb = &switchdev_work->fdb_info;
-		dev_dbg(prueth->dev,
-			"prueth fdb add: MACID = %pM vid = %u flags = %u -- port %d\n",
-			fdb->addr, fdb->vid, fdb->added_by_user, port);
-
-		if (!fdb->added_by_user)
-			break;
-
-		prueth_sw_fdb_add(emac, fdb);
-		prueth_sw_fdb_offload_notify(emac->ndev, fdb);
-		break;
-	case SWITCHDEV_FDB_DEL_TO_DEVICE:
-		fdb = &switchdev_work->fdb_info;
-		dev_dbg(prueth->dev,
-			"prueth fdb del: MACID = %pM vid = %u flags = %u -- port %d\n",
-			fdb->addr, fdb->vid, fdb->added_by_user, port);
-
-		if (!fdb->added_by_user)
-			break;
-
-		prueth_sw_fdb_del(emac, fdb);
-		break;
-	default:
-		break;
-	}
-	rtnl_unlock();
-
-	kfree(switchdev_work->fdb_info.addr);
-	kfree(switchdev_work);
-	dev_put(emac->ndev);
-}
-
-/* called under rcu_read_lock() */
-static int prueth_sw_switchdev_event(struct notifier_block *unused,
-				     unsigned long event, void *ptr)
-{
-	struct net_device *ndev = switchdev_notifier_info_to_dev(ptr);
-	struct switchdev_notifier_fdb_info *fdb_info = ptr;
-	struct prueth_sw_switchdev_event_work *switchdev_work;
-	struct prueth_emac *emac = netdev_priv(ndev);
-	int err;
-
-	netdev_dbg(ndev, "switchdev_event: event=%lu", event);
-
-	if (event == SWITCHDEV_PORT_ATTR_SET) {
-		err = switchdev_handle_port_attr_set(ndev, ptr,
-						     prueth_sw_port_dev_check,
-						     prueth_switchdev_attr_set);
-		return notifier_from_errno(err);
-	}
-
-	if (!prueth_sw_port_dev_check(ndev))
-		return NOTIFY_DONE;
-
-	switchdev_work = kzalloc(sizeof(*switchdev_work), GFP_ATOMIC);
-	if (WARN_ON(!switchdev_work))
-		return NOTIFY_BAD;
-
-	INIT_WORK(&switchdev_work->work, prueth_sw_switchdev_event_work);
-	switchdev_work->emac = emac;
-	switchdev_work->event = event;
-
-	switch (event) {
-	case SWITCHDEV_FDB_ADD_TO_DEVICE:
-	case SWITCHDEV_FDB_DEL_TO_DEVICE:
-		memcpy(&switchdev_work->fdb_info, ptr,
-		       sizeof(switchdev_work->fdb_info));
-		switchdev_work->fdb_info.addr = kzalloc(ETH_ALEN, GFP_ATOMIC);
-		if (!switchdev_work->fdb_info.addr)
-			goto err_addr_alloc;
-		ether_addr_copy((u8 *)switchdev_work->fdb_info.addr,
-				fdb_info->addr);
-		dev_hold(ndev);
-		break;
-	default:
-		kfree(switchdev_work);
-		return NOTIFY_DONE;
-	}
-
-	queue_work(system_long_wq, &switchdev_work->work);
-
-	return NOTIFY_DONE;
-
-err_addr_alloc:
-	kfree(switchdev_work);
-	return NOTIFY_BAD;
-}
-
-int prueth_sw_register_notifiers(struct prueth *prueth)
-{
-	struct notifier_block *nb;
-	int ret;
-
-	nb = &prueth->prueth_sw_switchdev_notifier;
-	nb->notifier_call = prueth_sw_switchdev_event;
-	ret = register_switchdev_notifier(nb);
-	if (ret) {
-		dev_err(prueth->dev,
-			"register switchdev notifier failed ret:%d\n", ret);
-		return ret;
-	}
-
-	nb = &prueth->prueth_sw_switchdev_bl_notifier;
-	nb->notifier_call = prueth_sw_switchdev_blocking_event;
-	ret = register_switchdev_blocking_notifier(nb);
-	if (ret) {
-		dev_err(prueth->dev, "register switchdev blocking notifier failed ret:%d\n",
-			ret);
-		nb = &prueth->prueth_sw_switchdev_notifier;
-		unregister_switchdev_notifier(nb);
-		return ret;
-	}
-
-	return 0;
-}
-
-void prueth_sw_unregister_notifiers(struct prueth *prueth)
-{
-	unregister_switchdev_blocking_notifier(&prueth->prueth_sw_switchdev_bl_notifier);
-	unregister_switchdev_notifier(&prueth->prueth_sw_switchdev_notifier);
-}
diff --git a/drivers/net/ethernet/ti/prueth_switch.h b/drivers/net/ethernet/ti/prueth_switch.h
deleted file mode 100644
index 8e1d7d3c114b..000000000000
--- a/drivers/net/ethernet/ti/prueth_switch.h
+++ /dev/null
@@ -1,58 +0,0 @@
-/* SPDX-License-Identifier: GPL-2.0 */
-/* Copyright (C) 2020-2021 Texas Instruments Incorporated - https://www.ti.com
- */
-
-#ifndef __NET_TI_PRUETH_SWITCH_H
-#define __NET_TI_PRUETH_SWITCH_H
-
-#include "prueth.h"
-#include "prueth_fdb_tbl.h"
-
-struct prueth_col_rx_context_info {
-	u16 buffer_offset;
-	u16 buffer_offset2;
-	u16 queue_desc_offset;
-	u16 buffer_desc_offset;
-	u16 buffer_desc_end;
-} __packed;
-
-struct prueth_col_tx_context_info {
-	u16 buffer_offset;
-	u16 buffer_offset2;
-	u16 buffer_offset_end;
-} __packed;
-
-static inline enum prueth_port other_port_id(enum prueth_port port_id)
-{
-	enum prueth_port other_port_id =
-		(port_id == PRUETH_PORT_MII0) ? PRUETH_PORT_MII1 :
-						PRUETH_PORT_MII0;
-	return other_port_id;
-}
-
-static inline
-void prueth_sw_port_set_stp_state(struct prueth *prueth,
-				  enum prueth_port port, u8 state)
-{
-	struct fdb_tbl *t = prueth->fdb_tbl;
-
-	writeb(state, port - 1 ?
-		&t->port2_stp_cfg->state : &t->port1_stp_cfg->state);
-}
-
-void prueth_sw_hostconfig(struct prueth *prueth);
-int prueth_sw_emac_config(struct prueth_emac *emac);
-void prueth_sw_fdb_tbl_init(struct prueth *prueth);
-int prueth_sw_learn_fdb(struct prueth_emac *emac, u8 *src_mac);
-int prueth_sw_boot_prus(struct prueth *prueth, struct net_device *ndev);
-int prueth_sw_shutdown_prus(struct prueth_emac *emac, struct net_device *ndev);
-int prueth_sw_register_notifiers(struct prueth *prueth);
-void prueth_sw_unregister_notifiers(struct prueth *prueth);
-bool prueth_sw_port_dev_check(const struct net_device *ndev);
-int prueth_sw_init_fdb_table(struct prueth *prueth);
-void prueth_sw_free_fdb_table(struct prueth *prueth);
-
-
-extern const struct prueth_queue_info sw_queue_infos[][4];
-
-#endif /* __NET_TI_PRUETH_SWITCH_H */
diff --git a/drivers/net/ethernet/ti/tlan.c b/drivers/net/ethernet/ti/tlan.c
index 267c080ee084..0072ffa6e19e 100644
--- a/drivers/net/ethernet/ti/tlan.c
+++ b/drivers/net/ethernet/ti/tlan.c
@@ -313,9 +313,8 @@ static void tlan_remove_one(struct pci_dev *pdev)
 	pci_release_regions(pdev);
 #endif
 
-	free_netdev(dev);
-
 	cancel_work_sync(&priv->tlan_tqueue);
+	free_netdev(dev);
 }
 
 static void tlan_start(struct net_device *dev)
-- 
2.30.2

